<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[springboot异步方法调用]]></title>
    <url>%2F2019%2F10%2F22%2Fspringboot%E5%BC%82%E6%AD%A5%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[通常情况下，假定需要调用3个Service：Service A，Service B，Service C。假定A、B、C之间没有关联关系，如果每个方法需要耗时3秒，那么总共需要耗费9秒。这显然不是我们希望的。 我们希望Service A，B，C同时调用，然后等待A、B、C全部结束，最后汇总执行结果。在SpringBoot中，实现这一点是很简单的。 在@SpringBootApplication注解下的应用程序类上使用@EnableAsync注解； 启用后，可以在返回CompletableFuture&lt;&gt;的服务中使用@Async注解。 因为你有@EnableAsync，@Async方法将在后台线程池中运行； 等待所有调用执行完毕； 汇总结果。 下面我们用一个小例子来说明。 我们将构建一个查找服务，用于查询GitHub用户信息，并通过GitHub的API检索数据。我们可以通过Spring Initializr来快速创建一个spring boot应用。这里不具体赘述。 1.maven依赖这里只需要即可。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 2.创建一个User用于接收数据123456789101112131415161718192021222324252627282930import com.fasterxml.jackson.annotation.JsonIgnoreProperties;@JsonIgnoreProperties(ignoreUnknown=true)public class User &#123; private String name; private String blog; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getBlog() &#123; return blog; &#125; public void setBlog(String blog) &#123; this.blog = blog; &#125; @Override public String toString() &#123; return "User [name=" + name + ", blog=" + blog + "]"; &#125;&#125; 3.创建一个GitHubService来提供查找服务12345678910111213141516171819202122@Servicepublic class GitHubLookupService &#123; private static final Logger logger = LoggerFactory.getLogger(GitHubLookupService.class); private final RestTemplate restTemplate; public GitHubLookupService(RestTemplateBuilder restTemplateBuilder) &#123; this.restTemplate = restTemplateBuilder.build(); &#125; @Async public CompletableFuture&lt;User&gt; findUser(String user) throws InterruptedException &#123; logger.info("Looking up " + user); String url = String.format("https://api.github.com/users/%s", user); User results = restTemplate.getForObject(url, User.class); // Artificial delay of 1s for demonstration purposes Thread.sleep(1000L); return CompletableFuture.completedFuture(results); &#125;&#125; 4.springboot启动类123456789101112131415161718192021222324252627282930import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import java.util.concurrent.Executor;@SpringBootApplication@EnableAsyncpublic class AsyncMethodApplication &#123; public static void main(String[] args) &#123; // close the application context to shut down the custom ExecutorService SpringApplication.run(AsyncMethodApplication.class, args).close(); &#125; @Bean public Executor taskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(2); executor.setMaxPoolSize(2); executor.setQueueCapacity(500); executor.setThreadNamePrefix("GithubLookup-"); executor.initialize(); return executor; &#125;&#125; 此类还通过定义一个新bean来自定义执行程序。 在这里，该方法被命名为taskExecutor，因为这是Spring搜索的特定方法名称。 在我们的例子中，我们希望将并发线程的数量限制为两个，并将队列的大小限制为500。 还有更多的事情，你可以调整。 如果你不定义一个Executor bean，Spring会创建一个Simplieasynctaskexecutor并使用它。 最后，我们定义了一个测试的Controller： @Slf4j @RestController @RequestMapping("/asyncMethod") public class AsyncMethodTestController { @Autowired private GitHubLookupService gitHubLookupService; @GetMapping("/test") public Object test() throws ExecutionException, InterruptedException { // Start the clock long start = System.currentTimeMillis(); // Kick of multiple, asynchronous lookups CompletableFuture&lt;User&gt; page1 = gitHubLookupService.findUser("PivotalSoftware"); CompletableFuture&lt;User&gt; page2 = gitHubLookupService.findUser("CloudFoundry"); CompletableFuture&lt;User&gt; page3 = gitHubLookupService.findUser("Spring-Projects"); // Wait until they are all done CompletableFuture.allOf(page1,page2,page3).join(); // Print results, including elapsed time log.info("Elapsed time: " + (System.currentTimeMillis() - start)); List&lt;User&gt; result = new ArrayList&lt;&gt;(3); result.add(page1.get()); result.add(page2.get()); result.add(page3.get()); return result; } } 启动应用，访问/asyncMethod/test，我们可以得到下面的结果 控制台打印如下： 我们在查找方法中故意休眠1秒，调用3次。总耗时不到3s，这还不包括本身访问github api的耗时。 如果能够很好的利用异步执行，可以使你的服务快速响应。 参考：https://spring.io/guides/gs/async-method/、https://spring.io/guides/gs/async-method/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gson日期类型字段序列化与反序列化]]></title>
    <url>%2F2019%2F09%2F30%2Fgson%E6%97%A5%E6%9C%9F%E7%B1%BB%E5%9E%8B%E5%AD%97%E6%AE%B5%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[为了避免日期格式转换的问题，在序列化日期类型字段时为Long类型，反序列化为Date类型。 代码如下： 123456789101112131415161718192021222324252627282930313233@Slf4jpublic class GsonDateTest &#123; private static GsonBuilder builder = new GsonBuilder(); private static Gson gson; static &#123; // 将日期序列化为Long类型 builder.registerTypeAdapter(java.util.Date.class, (JsonSerializer&lt;Date&gt;) (date, type, jsonSerializationContext) -&gt; new JsonPrimitive(date.getTime())) // 将Long类型转换为Date .registerTypeAdapter(Date.class, (JsonDeserializer&lt;Date&gt;) (json, typeOfT, context) -&gt; new Date(json.getAsJsonPrimitive().getAsLong())); gson = builder.create(); &#125; public String toJson(Match match) &#123; return gson.toJson(match); &#125; public static void main(String[] args) &#123; GsonDateTest test = new GsonDateTest(); Match match = Match.builder().id(1).name("name 2").build(); Date date = new Date(); match.setMatchTime(date); match.setMatchTimeMs(date.getTime()); String jsonStr = test.toJson(match); log.info("jsonStr:&#123;&#125;",jsonStr); match = gson.fromJson(jsonStr,new TypeToken&lt;Match&gt;()&#123;&#125;.getType()); log.info("match:&#123;&#125;",match); jsonStr = "&#123;\"msgType\":\"season\",\"data\":[&#123;\"sportId\":1,\"pstatus\":0,\"year\":\"2019-2020\",\"tournamentId\":99,\"start\":1563580800000,\"end\":1590883140000,\"ptype\":0,\"id\":11132,\"source\":\"tyson\"&#125;]&#125;"; Type type = new TypeToken&lt;BaseData&lt;SSeason&gt;&gt;()&#123;&#125;.getType(); BaseData&lt;SSeason&gt; sSeason = gson.fromJson(jsonStr,type); log.info("season:&#123;&#125;",sSeason); &#125;&#125; 结果：]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>gson</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle8.2循环]]></title>
    <url>%2F2019%2F09%2F29%2FKettle8.2%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[需求现有多个订单子表，希望将数据抽取到历史表。 表结构如下： 这里有2个子表（t_order_0和t_order_1），数据分别如下 t_order_0数据： t_order_1数据： 备份表为t_order_history。 实现实现步骤如下：获取所有订单子表–&gt;循环每个子表–&gt;查询订单数据–&gt;导入备份表。 作业结构如图： 获取表数量 这里使用模拟匹配查询所有订单子表，因为备份表也会查出来，所以使用“过滤纪录”进行过滤。 执行表数量判断并设置变量 下一步通过“检验字段值”和箭头指向来实现循环 循环控制器 通过“检验字段的值”+箭头指向实现循环。 抽取数据 计数器 PRINT_TABLES这个转换可以不要，这里是打印表名。 PRINT_TABLES 执行一下作业，发现数据已经抽取到备份表了。 参考：https://blog.csdn.net/qq_41704358/article/details/79519133]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自定义线程池拆分任务列表]]></title>
    <url>%2F2019%2F08%2F19%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%8B%86%E5%88%86%E4%BB%BB%E5%8A%A1%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[需求为了减少网络开销，会将数据打包（一个大的List）发送到接收方处理。如果直接使用ThreadPoolExecutor则只会有一个线程处理整个任务List，会导致耗时很久。所以需要将任务进行分割，然后分配给多个线程处理。 实现这里通过继承ThreadPoolExecutor，来实现任务的拆分，并且一个线程池提供了1个任务分发线程和一个线程池空闲检测线程。任务分发线程会从阻塞队列获取任务，然后进行拆分，分配给线程池执行，在线程池忙时会阻塞。空闲线程池检测线程会在线程池有空闲线程时通知任务分发线程分发任务。 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111@Slf4jpublic class DataProcessThreadPoolManager extends ThreadPoolExecutor &#123; private BlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(1000); private final Lock lock = new ReentrantLock(); private final Condition notFull = lock.newCondition(); private int splitSize = 100; // list多少个元素拆分为一组 private int workQueueCapacity = 0; // 线程池工作队列的容量 public DataProcessThreadPoolManager(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, BlockingQueue&lt;Runnable&gt; queue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); workQueueCapacity = workQueue.remainingCapacity(); init(); &#125; public DataProcessThreadPoolManager(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, BlockingQueue&lt;Runnable&gt; queue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); workQueueCapacity = workQueue.remainingCapacity(); init(); &#125; public DataProcessThreadPoolManager(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler,int splitSize) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); workQueueCapacity = workQueue.remainingCapacity(); this.splitSize = splitSize; init(); &#125; public DataProcessThreadPoolManager(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); workQueueCapacity = workQueue.remainingCapacity(); init(); &#125; private void init() &#123; // 任务分发线程 new Thread(() -&gt; &#123; while (true) &#123; try &#123; allocateTask(); &#125; catch (Exception e) &#123; log.error("任务分发线程异常",e); &#125; &#125; &#125;).start(); // 线程池空闲线程检测 new Thread(()-&gt; &#123; while (true) &#123; try &#123; lock.lockInterruptibly(); if (getQueue().size() &lt; workQueueCapacity) notFull.signal(); &#125; catch (InterruptedException e) &#123; log.error("线程池空闲线程检测线程异常",e); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;).start(); &#125; public &lt;T&gt; void addTask(List&lt;T&gt; list, Consumer&lt;List&lt;T&gt;&gt; consumer) &#123; try &#123; if (CollectionUtil.isNotEmpty(list) &amp;&amp; list.size() &gt; splitSize) &#123; // 拆分List splitData(list,consumer); &#125; else &#123; Runnable task = () -&gt; consumer.accept(list); // 将list包装成Runnable，后续给线程池执行 queue.put(task); &#125; &#125; catch (InterruptedException e) &#123; log.error("添加任务到线程池异常",e); &#125; &#125; public void allocateTask() throws InterruptedException &#123; lock.lockInterruptibly(); try &#123; if (getQueue().size() == workQueueCapacity) // 线程池工作队列已满 暂停加入任务到队列 notFull.await(); Runnable task = queue.take(); if (null != task) execute(task); &#125; finally &#123; lock.unlock(); &#125; &#125; /** * 任务分解 将一个大的List拆分为多个小List * @param list * @param consumer */ private void splitData(List list, Consumer consumer) &#123; int size = list.size(); int start = 0; int totalPages = size / splitSize; if (totalPages * splitSize &lt; size) totalPages += 1; for (int i=1;i&lt;=totalPages;i++) &#123; int end = i*splitSize; if (end &gt; size) end = size; addTask(list.subList(start,end),consumer); start = end; &#125; &#125;&#125; 使用方法： 12345// 实例化自定义线程池private final static DataProcessThreadPoolManager BASE_DATA_THREAD_POOL = new DataProcessThreadPoolManager(100, 100, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(100), new ThreadPoolExecutor.DiscardPolicy(),100);// 通过addTask方法添加待执行的任务List（这里不是Runnable，是你实际要处理的数据类型）BASE_DATA_THREAD_POOL.addTask(tournamentBaseData.getData(),list -&gt; tournamentService.handle(list)); 上面的自定义线程池实现了下面几个功能： 1.任务列表拆分，将一个大的List拆分为多个小的List，每个线程执行拆分后的小的List。 2.在线程池忙时会进行阻塞，不会导致线程池执行拒绝策略，导致任务不执行。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Typora图片设置]]></title>
    <url>%2F2019%2F07%2F25%2FTypora%E5%9B%BE%E7%89%87%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[用Typora写markdown很方便，所见即所得。而且图片也可以直接粘贴即可，但默认是觉得路径，导致发布到hexo无法显示。 这里可以通过2个设置解决这个问题，保证在Typora中可以显示图片，同时发布到hexo后也可以正常显示。 1.文件-&gt;偏好设置-&gt;图片插入，复制到指定路径（这里的路径就是hexo的source下新建一个文件夹存储图片），这里是img。这样当你粘贴图片到Typora的时候会自动复制到你指定的目录，而且Typora中显示的路径也是这里指定的路径，注意勾选“优先使用相对路径”，这样显示的就是相对路径了，即/img/xxx.png类似这种。 2.编辑-&gt;图片工具-&gt;设置图片跟目录（这里设置到hexo的source这一层）]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Typrora</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot使用logback记录日志到kafka]]></title>
    <url>%2F2019%2F07%2F25%2Fspringboot%E4%BD%BF%E7%94%A8Logback%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%E5%88%B0kafka%2F</url>
    <content type="text"><![CDATA[引言本文是ELK整合的一部分。流程为：应用程序日志–&gt;kafka–&gt;logstash–&gt;es–&gt;kibana。 这里使用springboot+logback将日志写入到kafka。 使用logback记录日志到kafka由于springboot自带有logback的依赖，所以我们准备一个logback-spring.xml的配置文件即可，application.yml也无需任何配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;contextName&gt;springboot-demo&lt;/contextName&gt; &lt;!-- 定义日志文件的存储地址,勿在 LogBack 的配置中使用相对路径 --&gt; &lt;property name="LOG_PATH" value="d:/logs/" /&gt; &lt;!--输出到控制台--&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 滚动日志 --&gt; &lt;appender name="ROLLING_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名 --&gt; &lt;FileNamePattern&gt;$&#123;LOG_PATH&#125;/springboot-demo.%d.%i.log &lt;/FileNamePattern&gt; &lt;MaxHistory&gt;100&lt;/MaxHistory&gt; &lt;TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;MaxFileSize&gt;50MB&lt;/MaxFileSize&gt; &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125;-%msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- This is the kafkaAppender --&gt; &lt;appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;topic&gt;app-log&lt;/topic&gt; &lt;!-- we don't care how the log messages will be partitioned --&gt; &lt;keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" /&gt; &lt;!-- use async delivery. the application threads are not blocked by logging --&gt; &lt;deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" /&gt; &lt;!-- each &lt;producerConfig&gt; translates to regular kafka-client config (format: key=value) --&gt; &lt;!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs --&gt; &lt;!-- bootstrap.servers is the only mandatory producerConfig --&gt; &lt;producerConfig&gt;bootstrap.servers=192.168.193.100:9092&lt;/producerConfig&gt; &lt;!-- don't wait for a broker to ack the reception of a batch. --&gt; &lt;producerConfig&gt;acks=0&lt;/producerConfig&gt; &lt;!-- wait up to 1000ms and collect log messages before sending them as a batch --&gt; &lt;producerConfig&gt;linger.ms=1000&lt;/producerConfig&gt; &lt;!-- even if the producer buffer runs full, do not block the application but start to drop messages --&gt; &lt;producerConfig&gt;max.block.ms=0&lt;/producerConfig&gt; &lt;!-- define a client-id that you use to identify yourself against the kafka broker --&gt; &lt;producerConfig&gt;client.id=$&#123;HOSTNAME&#125;-$&#123;CONTEXT_NAME&#125;-logback-relaxed&lt;/producerConfig&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 ERROR,WARN,INFO,DEBUG --&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="ROLLING_FILE" /&gt; &lt;appender-ref ref="kafkaAppender" /&gt; &lt;/root&gt;&lt;/configuration&gt; 这里主要关注kafkaAppender这一部分，这里使用了logback-kafka-appender这个依赖。 maven依赖： 1234567891011&lt;!-- https://mvnrepository.com/artifact/org.springframework.kafka/spring-kafka --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--logback-kafka-appender依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.danielwegener&lt;/groupId&gt; &lt;artifactId&gt;logback-kafka-appender&lt;/artifactId&gt; &lt;version&gt;0.2.0-RC2&lt;/version&gt;&lt;/dependency&gt; kafka的配置（application.properties)： 1234567891011121314151617181920212223242526#============== kafka ===================# 指定kafka 代理地址，可以多个spring.kafka.bootstrap-servers=192.168.193.100:9092#=============== provider =======================spring.kafka.producer.retries=0# 每次批量发送消息的数量spring.kafka.producer.batch-size=16384spring.kafka.producer.buffer-memory=33554432# 指定消息key和消息体的编解码方式spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer#=============== consumer =======================# 指定默认消费者group idspring.kafka.consumer.group-id=test-consumer-groupspring.kafka.consumer.auto-offset-reset=earliestspring.kafka.consumer.enable-auto-commit=truespring.kafka.consumer.auto-commit-interval=100# 指定消息key和消息体的编解码方式spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer 记录10条日志，看是否发送到了kafka 123456789101112131415161718192021/** * 通过logback appender来讲日志发送到kafka */private static void sendKafkaLogByLogbackAppender() &#123; Gson gson = new GsonBuilder().create(); IntStream.rangeClosed(1,10).forEach(i-&gt;&#123; Message message = new Message(); message.setId(System.currentTimeMillis()); String name = Math.random() &lt; 0.5 ? "zhangsan "+i:"李四 "+i; User user = User.builder().id(i).name(name).birthday(new Date()).build(); message.setMsg(user); message.setSendTime(new Date()); String msg = gson.toJson(message); log.info(msg); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;);&#125; 由于我们使用了kibana，所以直接在kibana查看即可（注意在logstash配置从kafka接受数据）。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7系统搭建ELK环境]]></title>
    <url>%2F2019%2F07%2F24%2FCentos7%E7%B3%BB%E7%BB%9FES%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[部署架构应用程序日志–&gt;kafka–&gt;logstash–&gt;es–&gt;kibana。 安装Elasticsearch 需要的 Java 最低版本为 Java 8。所以第一步需要确保安装了正确版本的jdk。 我们假定elk的目录为/data/soft/elk。通过下面的命令下载es 1curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.4.0.tar.gz 然后解压缩 1tar -xvf elasticsearch-5.4.0.tar.gz 然后使用下面的命令启动es。 1./bin/elasticsearch.sh 启动正常的话，可以看到下面的日志。 然后我们通过&lt;192.168.193.100:9200&gt;可以看到下面的数据 如果想后台运行ES，加上-d参数即可。./bin/elasticsearch -d。 安装Head插件安装head插件，需要先安装nodejs。 使用node -v确认已安装nodejs。如果没有安装执行yum install nodejs来安装。 可能遇到的问题：没有可用软件包 nodejs。 解决：执行yum install epel-release;然后再安装nodejs。 使用淘宝的npm镜像cnpm 使用npm安装依赖有时会比较慢，我们可以使用淘宝的cnpm镜像。 执行下面的命令来安装： 1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装后，原来使用npm，现在使用cnpm即可。 安装grunt 1cnpm install -g grunt-cli 确认一下版本,grunt --version。 修改HEAD监听的地址 默认HEAD监听 localhost，修改Gruntfile.js，添加hostname 12345678910connect: &#123; server: &#123; options: &#123; hostname: &apos;*&apos;, port: 9100, base: &apos;.&apos;, keepalive: true &#125; &#125;&#125; 既然是跨源访问ES，那么就要在HEAD里面指定ES服务器了，修改_site/app.js 123456789init: function(parent) &#123; this._super(); this.prefs = services.Preferences.instance(); this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://192.168.193.100:9200&quot;; if( this.base_uri.charAt( this.base_uri.length - 1 ) !== &quot;/&quot; ) &#123; // XHR request fails if the URL is not ending with a &quot;/&quot; this.base_uri += &quot;/&quot;; &#125;... 进入HEAD目录，安装HEAD依赖包，执行cnpm install。 启动head插件 使用grunt server来启动head插件，看到下面的内容就说明启动成功了。 head插件使用的端口是9100，记得在防火墙中添加进去。 然后我们浏览器访问http://192.168.193.100:9100/ ps:也可以通过npm run start 来启动，npm run start &amp;后台启动。 停止head插件 查看 9100 （head 端口）端口：lsof -i:9100 杀死进程：kill -9 pid es集群状态的说明 green：每个索引的primary shard和replica shard都是active状态的。 yellow：每个索引的primary shard都是active状态的，但是部分replica shard不是active状态，处于不可用的状态。 red：不是所有索引的primary shard都是active状态的，部分索引有数据丢失了。 安装kafka这里使用的目前最新的版本，从http://kafka.apache.org/downloads下载。 解压缩，得到目录kafka_2.11-2.3.0。 修改配置文件/config/server.properties 1listeners=PLAINTEXT://192.168.193.100:9092 启动kafka： 1./kafka-server-start.sh ../config/server.properties 后台启动kafka: 1./kafka-server-start.sh ../config/server.properties 1&gt;/dev/null 2&gt;&amp;1 &amp; 安装logstash这里的logstash版本是5.4.0与es一致，从https://www.elastic.co/downloads/logstash下载相应的版本。 然后解压缩，进入config目录。 新建一个配置文件，名字随意，这里命名为test.conf。 123456789101112131415161718input &#123; kafka &#123; bootstrap_servers =&gt; &quot;192.168.193.100:9092&quot; topics =&gt; [&quot;app-log&quot;] group_id =&gt; &quot;test-consumer-group&quot; codec =&gt; &quot;json&quot; consumer_threads =&gt; 1 decorate_events =&gt; true &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;127.0.0.1:9200&quot;] index =&gt; &quot;test&quot; workers =&gt; 1 &#125;&#125; 启动logstash 1./bin/logstash -f config/test.conf 使用程序写入100条测试数据到Kafka注意topic要与logstash中配置的一致。 这里使用logback的appender来将日志写入kafka，logstash从kafka接受，然后发送给es。 使用的github上的一个logback-kafka-appender依赖。 安装Kibana从https://www.elastic.co/downloads/kibana下载kibana，kibana要与es的版本一致，所以这里也下载5.4.0版本。 然后解压缩 最后使用./bin/kibana启动。kibana使用的端口号为5601，记得加入防火墙。 浏览器访问http://192.168.193.100:5601 在上面的logstash配置中，我们指定了es中的索引为test。所以在Kibana的Index name or pattern中输入test。然后点下面的Create。 然后再左侧可以看到刚刚配置的索引 点左侧的Discover菜单，然后就将右侧的时间选择为Today，可以看到日志了 kibana常用搜索全文搜索 在搜索栏输入测试，返回所有字段中包含”测试”的文档（document）。 根据字段搜索 根据kibana左侧显示的field搜索。field:value 精确搜索：field:”value” 参考：https://blog.csdn.net/zhengchaooo/article/details/79500130 问题可能会遇到下面的问题： 1.max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] 解决：修改切换到root用户修改配置limits.conf 添加下面两行 命令:vi /etc/security/limits.conf 12* hard nofile 65536* soft nofile 65536 2.max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决：切换到root用户修改配置sysctl.conf vi /etc/sysctl.conf 添加下面配置： 1vm.max_map_count=655360 并执行命令： 1sysctl -p 3.es启动成功，虚拟机中可以访问9200，但windows中无法访问。 首先确保防火墙关闭或添加了9200端口。 1firewall-cmd --zone=public --permanent --add-port=9200/tcp 另外， 修改es配置文件elasticsearch.yml，修改network.host和http.port 12network.host: 0.0.0.0http.port: 9200 然后重启es。 4.安装head插件遇到的问题 4.1 RunScriptError: post install error, please remove node_modules before retry! 重新执行安装命令，遇到npm WARN elasticsearch-head@0.0.0 license should be a valid SPDX license expression问题。 解决：参考https://www.cnblogs.com/shengulong/p/6224908.html，将package.json中的license值修改为Apache-2.0即可。 4.2 _Loading &quot;Gruntfile.js&quot; tasks...ERROR错误 解决：参考https://blog.csdn.net/wang_zhenwei/article/details/78389253 4.3 head插件启动成功后访问9100，没有列出ES的节点，F12打开Console，发现有跨域问题 解决：修改/ES_HOME/config/elasticsearch.yml，增加下面的配置 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 然后重启ES和head即可。 参考：https://blog.csdn.net/u012832088/article/details/80662241 5.kafka Connection to node -1 could not be established. Broker may not be available. 解决：参考https://blog.csdn.net/qq_40633152/article/details/81090306 参考kibana中文文档：https://www.elastic.co/guide/cn/kibana/current/index.html elasticsearch指南：https://www.elastic.co/guide/en/elasticsearch/reference/index.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vmware安装centos7系统]]></title>
    <url>%2F2019%2F07%2F24%2Fwindows%E4%BD%BF%E7%94%A8wmware%E5%AE%89%E8%A3%85centos7%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[下载我是从阿里云镜像下载的。地址：http://mirrors.aliyun.com/centos/7.6.1810/isos/x86_64/ 选择Minimal.iso下载最小化的安装包（900多M），完整版的有4个多G，自己学习研究使用就没必要了。 ## 安装略，新建虚拟机，选择centos7安装包即可。 网络配置使用NAT模式，在VMware-》编辑-》虚拟网络编辑器中，选择VMnet8，可以看到子网IP和子网掩码。取消勾选“使用本地DHCP服务将IP地址分配给虚拟机”。点“NAT设置”可以看到网关IP。 网卡信息修改vi /etc/sysconfig/network-scripts/ifcfg-ens33（有的叫ifcfg-eth0） 12345678910111213141516171819TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=f9c77ab3-bc8c-4cc5-ba91-04835e191aebDEVICE=ens33ONBOOT=yesIPADDR=192.168.193.100NETMASK=255.255.255.0GATEWAY=192.168.193.2ZONE=public 这里的IPADDR随意设置跟网关一个网段即可。ONBOOT：开机启动。NM_CONTROLLED：网络管理组件是否启用，精简版的是没有这个组件的。所以就不需要开启。BOOTPROTO：网络分配方式，静态。IPPADDR：手动指定ip地址。NETMASK：子网掩码。GATEWAY：网关ip。编辑好以后保存退出。 DNS配置vi /etc/resolv.conf 1nameserver 192.168.193.2 这里填网关IP即可。 windows中虚拟机网络适配器配置 网关需要与上面网络编辑器中的网关一致，IP随意。 然后重启网卡 service network restart 用主机ping一下虚拟机然后用虚拟机ping一下www.baidu.com看主机–》虚拟机，虚拟机–》主机，虚拟机–》外网是否通。 如果通，用sxhell连接虚拟机即可（端口22）。 开放端口centos7里面除了默认的firewall还有一个会对开放端口有影响，这个就是selinux，我把他关闭，然后firewall开放我想要的端口就行了，关闭selinux可以参考https://www.linuxidc.com/Linux/2016-11/137723.htm。 firewall开放端口firewall-cmd --zone=public --permanent --add-port=111/tcp添加需要的端口，然后再重新加载下firewall-cmd --reload，最后查看下端口是否真的打开firewall-cmd --list-port。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring事件发布与监听]]></title>
    <url>%2F2019%2F07%2F22%2FSpring%E4%BA%8B%E4%BB%B6%E5%8F%91%E5%B8%83%E4%B8%8E%E7%9B%91%E5%90%AC%2F</url>
    <content type="text"><![CDATA[Spring提供了事件发布、监听的功能，在ApplicationContext中提供了一个publishEvent(ApplicationEvent event)来实现事件的发布，通过实现ApplicationListener来定义监听者的逻辑。 下面我们通过一个例子来说明。 1.定义一个事件 12345public class LogEvent extends ApplicationEvent &#123; public LogEvent(Object source) &#123; super(source); &#125;&#125; 2.定义事件监听者 12345678@Componentpublic class LogEventListener implements ApplicationListener&lt;LogEvent&gt; &#123; @Override public void onApplicationEvent(LogEvent logEvent) &#123; LogEventModel model = (LogEventModel) logEvent.getSource(); System.out.println("--LogEventListener:[device="+model.getDevice() +",phone="+model.getUserPhone()+",nickname="+model.getNickname()+"]."); &#125;&#125; 这里的LogEventModel定义如下： 1234567@Data@Builderpublic class LogEventModel &#123; private String device; private String userPhone; private String nickname;&#125; 3.写一个Spring的工具类，实现ApplicationContextAware，以便使用它来发布事件。 12345678910111213@Componentpublic class SpringUtil implements ApplicationContextAware &#123; private static ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; SpringUtil.applicationContext = applicationContext; &#125; public static void publishEvent(ApplicationEvent event) &#123; applicationContext.publishEvent(event); &#125;&#125; 4.测试 123456789101112@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = &#123;Application.class&#125;)public class SpringEventTest &#123; @org.junit.Test public void test() &#123; LogEventModel model = LogEventModel.builder().device("ios").nickname("jack").userPhone("13888888888").build(); System.out.println("开始发布Spring Event"); SpringUtil.publishEvent(new LogEvent(model)); System.out.println("Spring Event发布完成。"); &#125;&#125; 控制台日志： 123开始发布Spring Event--LogEventListener:[device=ios,phone=13888888888,nickname=jack].Spring Event发布完成。 通过控制台日志，我们注意到事件监听处理逻辑跟主程序是同步执行的，如果想异步执行，可以在LogEventListener的onApplicationContext方法上加入@Async注解，另外在配置类中加入@EnableAsync来启用异步（如果使用Spring Boot，在启动类上加入即可）。 另外事件监听器也可以通过注解的方式来指定 12345678910@Componentpublic class LogEventListener2 &#123; @Async @EventListener(&#123;LogEvent.class&#125;) public void handle(LogEvent logEvent) &#123; LogEventModel model = (LogEventModel) logEvent.getSource(); System.out.println("--LogEventListener2:[device="+model.getDevice() +",phone="+model.getUserPhone()+",nickname="+model.getNickname()+"]."); &#125;&#125; 通常，一些不重要的功能，比如日志记录、邮件发送、数据上报等情形可以考虑使用Spring提供的事件发布监听来优化。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装RabbitMQ]]></title>
    <url>%2F2019%2F07%2F20%2Fcentos7%E5%AE%89%E8%A3%85rabbitmq%2F</url>
    <content type="text"><![CDATA[安装参考：https://www.cnblogs.com/liaojie970/p/6138278.html RabbitMQ 默认端口号 4369 (epmd), 25672 (Erlang distribution) 5672, 5671 (AMQP 0-9-1 without and with TLS) 15672 (if management plugin is enabled) 61613, 61614 (if STOMP is enabled) 1883, 8883 (if MQTT is enabled)c 通过控制台访问http://ip:15672，如果无法访问，执行`rabbitmq-plugins enable rabbitmq_management`. 默认控制台的用户名密码为guest/guest，但是只能本地访问。如果是其他Ip访问，会提示Not management user，可以添加一个用户，然后设置权限。 rabbitmqctl set_user_tags admin administrator ，将admin用户设置为管理员。 参考：https://blog.csdn.net/qq_24095055/article/details/97001679 客户端程序报access to vhost ‘/‘ refused for user xxx增加/目录的访问权限。rabbitmqctl set_permissions -p / admin &#39;.*&#39; &#39;.*&#39; &#39;.*&#39; 开机自启chkconfig rabbitmq-server on]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis批量操作汇总]]></title>
    <url>%2F2019%2F07%2F15%2Fmybatis%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[1.批量insert或update在mapper中使用foreach来实现 2.同时批量insert和updatea.mysql在mapper中使用foreach结合on duplicate update来实现。 b.Oracle在mapper中使用foreach结合merge into来实现。 c.如果使用了mybatisplus它提供了批量save或update，根据id。 d.在代码中使用mybatis的BATCH模式12345678910111213141516171819202122232425262728293031323334353637public int batchSaveOrUpdate(List&lt;FPlayerSuspend&gt; list) &#123; if (null == list || list.isEmpty()) return 0; SqlSession session = sqlSessionTemplate.getSqlSessionFactory().openSession(ExecutorType.BATCH, false); FPlayerSuspendMapper mapper = session.getMapper(FPlayerSuspendMapper.class); try &#123; int size = list.size(); UpdateWrapper&lt;FPlayerSuspend&gt; wrapper = new UpdateWrapper&lt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; FPlayerSuspend item = list.get(i); // 如果缓存或数据库存在，则判断是否变化 变化则更新 缓存或数据库不存在则插入 FPlayerSuspend cache = getFromDbIfCacheNotExist(item.getMatchId(),item.getPlayerId()); if (null == cache) mapper.insert(item); else &#123; // 数据变化则更新 if (isDataChange(item,cache)) &#123; wrapper.eq("schedule_id", item.getMatchId()) .eq("player_id", item.getPlayerId()); mapper.update(item, wrapper); &#125; &#125; if (i % 1000 == 999 || i == size - 1) &#123; session.commit(); session.clearCache(); &#125; &#125; &#125; catch (Exception e) &#123; log.error("批量插入或更新球探球员伤停数据出错", e); session.rollback(); &#125; finally &#123; session.close(); &#125; return 0;&#125; 上面的代码执行的是如果数据库有则更新，没有则插入的逻辑。实际上是有list.size()次数的数据库查询。可以将上面逻辑改为saveOrUpdate(在mapper中实现)。这样就避免了数据库查询，而是在提交到数据库之后才会去查询数据然后做相应处理。 如果使用java8，那么可以调整为下面的形式：首先定义一个函数式接口12345678910/** * @author Donny * @createTime 2019-07-10 15:05 * @description 批量操作数据库的函数式接口定义 */@FunctionalInterfacepublic interface BatchDbOperationInterface&lt;A,B&gt; &#123; // A为要操作的javabean类型，B为相应的Mybatis Mapper void apply(A type,B mapper);&#125; 下面封装JDBC的批量操作12345678910111213141516171819202122232425262728293031@Component@Slf4jpublic class BatchDBOperationImpl &#123; @Autowired private SqlSessionTemplate sqlSessionTemplate; public &lt;A,B&gt; int batchStatment(List&lt;A&gt; list, Class&lt;B&gt; mapperClass, BatchDbOperationInterface&lt;A,B&gt; function) &#123; if (null == list || list.isEmpty()) return 0; SqlSession session = sqlSessionTemplate.getSqlSessionFactory().openSession(ExecutorType.BATCH, false); B mapper = session.getMapper(mapperClass); try &#123; int size = list.size(); for (int i = 0; i &lt; size; i++) &#123; A item = list.get(i); function.apply(item,mapper); if (i % 1000 == 999 || i == size - 1) &#123; session.commit(); session.clearCache(); &#125; &#125; return size; &#125; catch (Exception e) &#123; log.error("批量插入或更新数据出错", e); session.rollback(); &#125; finally &#123; session.close(); &#125; return 0; &#125;&#125; 使用方：123456@Autowiredprivate BatchDBOperationImpl batchDBOperation;public int batchSaveIfNotExist(List&lt;BEuropeOddsDetail&gt; details) &#123; return batchDBOperation.batchStatment(details, BEuropeOddsDetailMapper.class,(item,mapper)-&gt;mapper.insertIfNotExist(item));&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F03%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Kettle分表]]></title>
    <url>%2F2019%2F07%2F02%2F%E4%BD%BF%E7%94%A8Kettle%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[当表数据量比较大的时候（1000w），要考虑分表。这里记录使用Kettle（一个ETL工具）进行分表的操作。 1.预估数据量假定某个表的的数据量是2500万，那就需要分3个表存储。 2.创建表这里假定表名为b_company，需要分3个表。123create table if not exists b_company_0 like b_company;create table if not exists b_company_1 like b_company;create table if not exists b_company_2 like b_company; 执行上面的脚本。 打开Kettle，根据一定的规则（这里以ID划分，根据实际业务），将hash(id)=0的insert到b_company_0，其他的以此类推。a.新建转换–&gt;DB连接–&gt;新建（新建数据库）；b.切换到“核心对象”Tab，选择输入、转换和输出的控件；如图： 表输入用来制定数据来源，内容如下： 这里用了java脚本来实现根据ID生成一列table_name 表输出这里使用了动态表名（根据一行数据的table_name字段） 然后在数据库字段这里，点击“获取字段”，然后去掉table_name，因为我们是用它来确定某行数据应该存储到哪个表的。 kttle 新建作业执行多个转换job按并行和顺序执行参考：https://blog.csdn.net/saga_gallon/article/details/78410902 特别注意如果表数据量大，用的windows10系统，默认情况下锁屏后网络会中断，会导致Kettle执行不成功。到网络和共享中心–&gt;以太网–&gt;Microsoft网络客户端（选中）–&gt;配置–&gt;电源管理–&gt;运行计算机关闭此设备以节省电源（不要勾选）。 或者，直接到控制面板建电源管理中不然计算机进入休眠。位置：控制面板\硬件和声音\电源选项\编辑计划设置。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ配置访问密码]]></title>
    <url>%2F2019%2F05%2F22%2FActiveMQ%E9%85%8D%E7%BD%AE%E8%AE%BF%E9%97%AE%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[控制台密码配置控制台的访问密码可以在jetty-realm.properties中进行配置，默认的配置如下：1234# Defines users that can access the web (console, demo, etc.)# username: password [,rolename ...]admin: admin, adminuser: user, user 依次为用户名: 密码, 角色。 JMS客户端访问密码配置默认ActiveMQ并没有指定密码，JMS客户端不指定密码就可以连接。这样就比较不安全了。可以通过下面的方式添加账号和密码1234567&lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username="admin" password="123" groups="users,admins"/&gt; &lt;/users&gt; &lt;/simpleAuthenticationPlugin&gt;&lt;/plugins&gt; 注意：如果使用了networkConnectors，也需要指定用户名密码。123&lt;networkConnectors&gt; &lt;networkConnector name="bridge" uri="static:(tcp://localhost:61616)" duplex="true" conduitSubscriptions="false" userName="admin" password="123"/&gt;&lt;/networkConnectors&gt; 配置了上面的用户名和密码后，JMS客户端就需要相应的配置了。1ConnectionFactory factory = new ActiveMQConnectionFactory("admin","123","tcp://localhost:61626"); 上面只是一个基础的配置，如果需要更复杂的配置，可以参考：http://activemq.apache.org/security]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ Channel was inactive for too (>30000) long]]></title>
    <url>%2F2019%2F05%2F18%2FActiveMQ-Channel-was-inactive-for-too-long%2F</url>
    <content type="text"><![CDATA[发现MQ周期性的报Channel was inactive for too (&gt;30000) long问题。ActiveMQ有一个InactiveMonitor线程，用来检查连接是否活跃，如果不活跃则会关闭它。默认的检查周期是30s。 具体可以参考ActiveMQ的官方文档：http://activemq.apache.org/activemq-inactivitymonitor.html 解决办法：1.在transport上配置wireFormat.maxInactivityDuration=0；2.设置transport.useInactivityMonitor=false。 这里用的是第二种，第一种没用，不知道什么原因。1234&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name="openwire" uri="tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;amp;transport.useInactivityMonitor=false"/&gt;&lt;/transportConnectors&gt;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ静态网络连接]]></title>
    <url>%2F2019%2F05%2F17%2FActiveMQ%E9%9D%99%E6%80%81%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[前言使用静态网络连接（static networkConnector）可以将多个broker连接起来，作为一个集群对外提供服务。我们假定有amq1和amq2配置了静态网络连接，那么当一个消费者连接到amq2，当生产者发送消息到amq1时，amq2将会作为amq1的一个消费者，将消息转移到amq2，然后投递给连接到amq2的消费者；反之亦然。对于queue，由于一条消息只能被一个消费者消费，所以在上面的情形下，消息将被转移到amq2，然后投递给连接到amq2的消费者；对于topic，amq2从amq1复制消息，然后投递给消费者。 配置这里准备2台activemq，这里分别以activemq1和activemq2称之。 activemq1修改1.修改brokerName为amq1;2.修改openwire端口为61616，其他的transportConnector删除；3.在destinationPolicy增加下面的配置12345&lt;policyEntry queue="&gt;" enableAudit="false"&gt; &lt;networkBridgeFilterFactory&gt; &lt;conditionalNetworkBridgeFilterFactory replayWhenNoConsumers="true"/&gt; &lt;/networkBridgeFilterFactory&gt;&lt;/policyEntry&gt; 这是针对queue的配置。该配置是为了解决消息回流的问题。replayWhenNoConsumers=true表示没有消费者时将消息回流到原始的broker。enableAudit=false为了防止消息回流后被当做重复消息而不被分发。 activemq2修改1.修改brokerName为amq2，2个不要冲突。2.修改openwire端口为61617，其他的transportConnector删除；3.修改netty端口为8162；4.增加下面的配置123&lt;networkConnectors&gt; &lt;networkConnector name="bridge" uri="static:(tcp://localhost:61616)" duplex="true" conduitSubscriptions="false"/&gt;&lt;/networkConnectors&gt; duplex默认为false，单向连接。如果配置为false，那么发送到amq2的消息可以从amq1消费，反之则不行。conduitSubscriptions默认true，是否把同一个broker的多个consumer当做一个来处理。如果配置为true，假定有1个消费者连接amq1，3个消费者连接amq2，那么amq1的那个消费者将接收到50%的消息，amq2的3个消费者一共接收到50%的消息。所以这里设置为false，这样假定发送100条消息，那么每个消费者消费25条消息。 5.在destinationPolicy增加下面的配置12345&lt;policyEntry queue="&gt;" enableAudit="false"&gt; &lt;networkBridgeFilterFactory&gt; &lt;conditionalNetworkBridgeFilterFactory replayWhenNoConsumers="true"/&gt; &lt;/networkBridgeFilterFactory&gt;&lt;/policyEntry&gt; 代码客户端使用failover协议来连接mq。1failover:(tcp://127.0.0.1:61616,tcp://127.0.0.1:61626)?randomize=false 指定randomize为false，这样会先连接127.0.0.1:61616，连接不上才会连接后面的地址。 测试配置duplex=false，测试结果。a.连接amq1发送消息；b.消费者连接amq2接收消息可以发现发送到amq1的消息amq2没法消费。 将duplex改为true，amq2就可以消费amq1的消息了。 其他的就不一一测试了。 注意事项这里使用2个broker，实际可以根据需要配置多个。多个地址用逗号分隔即可。比如uri=”static:(tcp://localhost:61616,tcp://localhost:61636)”。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之虚拟主题]]></title>
    <url>%2F2019%2F04%2F03%2FActiveMQ%E4%B9%8B%E8%99%9A%E6%8B%9F%E4%B8%BB%E9%A2%98%2F</url>
    <content type="text"><![CDATA[虚拟目的地运允许我们创建一个映射到一个或多个实际物理目的地的逻辑目的地，客户端可以使用逻辑目的地来发送和消费消息。 ActiveMQ支持的虚拟Destinations分为有两种，分别是 虚拟主题（Virtual Topics） 组合 Destinations（CompositeDestinations） 虚拟主题发布订阅背后的想法非常棒。允许生产者与消费者分离，这样他们甚至不知道有多少消费者对他们发布的消息感兴趣。JMS规范定义了对持久主题的支持，但是正如我们将描述的，它们有一些限制…… JMS持久主题的限制 一个topic虽然可以有多个订阅者，但每个订阅者都是获取全量的消息，没法实现负载均衡。queue可以实现消费者端消息的负载均衡，但是broker不能讲消息发送给多个应用。所以没法实现发布订阅+消费者分组的功能。 由于只能使用单个的持久订阅在，如果该订阅者出错，应用就无法处理消息了，系统的健壮性不高。 为了解决上面的2个问题，ActiveMQ实现了虚拟topic的功能。虚拟topic以VirtualTopic.开头，比如VirtualTopic.ORDER。 虚拟主题背后的想法是生产者以通常的JMS方式发送给主题。消费者可以继续使用JMS规范中的主题语义。但是，如果主题是虚拟的，则使用者可以从物理队列中使用逻辑主题订阅，从而允许许多使用者在许多计算机和线程上运行以对负载进行负载平衡。 为了解决这两个问题，ActiveMQ中实现了虚拟Topic的功能。使用起来非常简单。对于消息发布者来说，就是一个正常的Topic，名称以VirtualTopic.开头。例如VirtualTopic.TEST。对于消息接收端来说，是个队列，不同应用里使用不同的前缀作为队列的名称，即可表明自己的身份即可实现消费端应用分组。例如Consumer.A.VirtualTopic.TEST，说明它是名称为A的消费端，同理Consumer.B.VirtualTopic.TEST说明是一个名称为B的客户端。可以在同一个应用里使用多个consumer消费此queue，则可以实现上面两个功能。又因为不同应用使用的queue名称不同（前缀不同），所以不同的应用中都可以接收到全部的消息。每个客户端相当于一个持久订阅者，而且这个客户端可以使用多个消费者共同来承担消费任务。 示例生产者123456789101112131415public class Producer &#123; public static void main(String[] args) &#123; String topicName = "VirtualTopic.TEST"; List&lt;String&gt; msgList = Lists.newArrayList(); int msgSize = 10; IntStream.rangeClosed(1,msgSize).forEach(i-&gt; &#123; msgList.add("hello " + i); &#125;); String[] msgs = new String[msgSize]; msgs = msgList.toArray(msgs); MqUtil.sendTopicMsg(topicName,msgs ,false,true,60000); &#125;&#125; 消费者123456789101112131415161718192021222324252627282930313233343536public class Consumer &#123; public static void main(String[] args) &#123; String queueNameA = "Consumer.A.VirtualTopic.TEST"; String queueNameB = "Consumer.B.VirtualTopic.TEST"; MqUtil.addMessageListener(queueNameA,false,msg-&gt;&#123; try &#123; System.out.println("Consumer A1 received:" + ((TextMessage)msg).getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;,false); MqUtil.addMessageListener(queueNameA,false,msg-&gt;&#123; try &#123; System.out.println("Consumer A2 received:" + ((TextMessage)msg).getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;,false); MqUtil.addMessageListener(queueNameB,false,msg-&gt;&#123; try &#123; System.out.println("Consumer B1 received:" + ((TextMessage)msg).getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;,false); MqUtil.addMessageListener(queueNameB,false,msg-&gt;&#123; try &#123; System.out.println("Consumer B2 received:" + ((TextMessage)msg).getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;,false); &#125;&#125; MQ工具类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public final class MqUtil &#123; private final static PooledConnectionFactory FACTORY; static &#123; FACTORY = new org.apache.activemq.jms.pool.PooledConnectionFactory(); ConnectionFactory _factory = new ActiveMQConnectionFactory(Constant.MQ_USERNAME, Constant.MQ_PASSWORD, Constant .uris); FACTORY.setConnectionFactory(_factory); FACTORY.setMaxConnections(100); FACTORY.start(); Runtime.getRuntime().addShutdownHook(new Thread(FACTORY::stop)); &#125; public static void sendMsg(String DestinationName, String[] msgs, boolean isTopic, boolean isTransaction, boolean isPersistent, long expiration) &#123; Connection connection = null; Session session = null; try &#123; connection = isTopic ? FACTORY.createTopicConnection() : FACTORY.createQueueConnection(); connection.start(); session = connection.createSession(isTransaction, Session.AUTO_ACKNOWLEDGE); Destination destination = isTopic ? session.createTopic(DestinationName) : session.createQueue(DestinationName); MessageProducer producer = session.createProducer(destination); for (String msg : msgs) &#123; Message message = session.createTextMessage(msg); if (expiration &gt; 0) &#123; message.setJMSExpiration(expiration); &#125; message.setJMSDeliveryMode(isPersistent ? DeliveryMode.PERSISTENT : DeliveryMode.NON_PERSISTENT); producer.send(message); System.out.println("消息" + msg + "]发送成功."); &#125; if (isTransaction) &#123; session.commit(); &#125; &#125; catch (JMSException e) &#123; e.printStackTrace(); if (isTransaction &amp;&amp; session != null) &#123; try &#123; session.rollback(); &#125; catch (JMSException e1) &#123; e1.printStackTrace(); &#125; &#125; &#125; finally &#123; closeResource(connection, session); &#125; &#125; private static void closeResource(Connection connection, Session session) &#123; if (null != connection) &#123; try &#123; connection.close(); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; if (null != session) &#123; try &#123; session.close(); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void sendQueueMsg(String queueName, String msg, boolean isTransction, boolean isPersistent, long expiration) &#123; sendMsg(queueName, new String[]&#123;msg&#125;, false, isTransction, isPersistent, expiration); &#125; public static void sendTopicMsg(String topicName, String msg, boolean isTransction, boolean isPersistent, long expiration) &#123; sendMsg(topicName, new String[]&#123;msg&#125;, true, isTransction, isPersistent, expiration); &#125; public static void sendTopicMsg(String topicName, String[] msgs, boolean isTransction, boolean isPersistent, long expiration) &#123; sendMsg(topicName, msgs, true, isTransction, isPersistent, expiration); &#125; public static void addMessageListener(String DestinationName, boolean isTopic, MessageListener listener, boolean isTransaction) &#123; Connection connection; Session session; try &#123; connection = isTopic ? FACTORY.createTopicConnection() : FACTORY.createQueueConnection(); connection.start(); session = connection.createSession(isTransaction, Session.AUTO_ACKNOWLEDGE); Destination destination = isTopic ? session.createTopic(DestinationName) : session.createQueue(DestinationName); MessageConsumer consumer = session.createConsumer(destination); consumer.setMessageListener(listener); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者控制台输出：1234567891011121314151617181920Consumer A1 received:hello 1Consumer B1 received:hello 1Consumer A2 received:hello 2Consumer B2 received:hello 2Consumer A1 received:hello 3Consumer B1 received:hello 3Consumer A2 received:hello 4Consumer B2 received:hello 4Consumer A1 received:hello 5Consumer B1 received:hello 5Consumer A2 received:hello 6Consumer B2 received:hello 6Consumer A1 received:hello 7Consumer B1 received:hello 7Consumer A2 received:hello 8Consumer B2 received:hello 8Consumer A1 received:hello 9Consumer B1 received:hello 9Consumer A2 received:hello 10Consumer B2 received:hello 10 可以看到，A1和A2是一组，共同消费VirtualTopic.TEST的数据，B1和B2是一组，同时A1和A2，B1和B2依次消费。即达到了topic的功能又达到了负载均衡和failover的能力，在一组消费者中任何一个挂掉也不会影响消费。 需要注意的是：即使Queue消费了消息，VirtualTopic中的消息仍然不会删除，只有真正的topic订阅者消费消息后，VirtualTopic中的消息才会删除。当然，VirtualTopic中的消息删除，不会影响Queue中的消息，因为Queue中的消息是Copy过去的。 虚拟主题的默认配置默认情况下，虚拟主题名称必须是VirtualTopic.&gt;，消费者队列名称必须为Consumer.*.VirtualTopic.&gt;，当日这个你是可以修改的。下面的示例显示如何使所有主题都成为虚拟主题。下面的示例使用名称&gt;表示“匹配所有主题”。您可以使用此通配符在不同层级应用不同的虚拟主题策略。1234567&lt;destinationInterceptors&gt; &lt;virtualDestinationInterceptor&gt; &lt;virtualDestinations&gt; &lt;virtualTopic name="&gt;" prefix="VirtualTopicConsumers.*." selectorAware="false"/&gt; &lt;/virtualDestinations&gt; &lt;/virtualDestinationInterceptor&gt; &lt;/destinationInterceptors&gt; 配置选项 选项 默认值 描述 selectorAware false 如果consumer端有selector，则只有匹配selector的消息才会分派到对应的queue中去。使用此选项可防止在独占使用者使用选择器时构建不匹配的消息 local false when true, don’t fan out messages that were received over a network concurrentSend false 如果为true，则消息将并行发送，同时允许日志批量写入以减少磁盘IO。 transactedSend false when true, use a transaction for fanout sends such that there is a single disk sync. A local broker transaction will be created if there is no client transaction (5.13) dropOnResourceLimit false 如果为true，将忽略发送期间跑出的ResourceAllocationException setOriginalDestination true 如果为true，则转发消息上的目标设置为使用者队列，而originalDestination消息属性将跟踪虚拟主题（5.16） VirtualSelectorCacheBrokerPlugin当selectorAware=true时，只有活动的消费者才被限定为选择器匹配的条件。如果消费者断开并重新连接，他们将错过消息。selectorAware=true的目的是不构建消息。virtualSelectorCacheBrokerPlugin提供了一个缓存，它可以跟踪与某个消费者的目的地相关联的选择器，这样它们就可以应用于该消费者。这样，所选的消息就会累积起来。现有的选择器集可以被持久化，以便在重启时可以恢复。插件以正常的方式应用于plugins部分。123&lt;plugins&gt; &lt;virtualSelectorCacheBrokerPlugin persistFile="&lt;some path&gt;/selectorcache.data" /&gt;&lt;/plugins&gt; 组合目的地组合目的地允许在各个目的地上建立一对多的关系; 主要用于组合队列。 例如，当消息发送到队列A时，您可能还希望将其转发到队列B和C以及主题D.然后，组合目的地是从虚拟目的地到其他物理目的地集合的映射。 在这种情况下，映射是在broker端，客户端不知道目的地之间的映射。 这与客户端组合目的地不同，客户端使用URL表示法指定必须将消息发送到的实际物理目标。 以下示例显示如何在XML配置中设置元素，以便在将消息发送到MY.QUEUE时，它实际上会转发到物理队列FOO和主题BAR。123456789101112&lt;destinationInterceptors&gt; &lt;virtualDestinationInterceptor&gt; &lt;virtualDestinations&gt; &lt;compositeQueue name="MY.QUEUE"&gt; &lt;forwardTo&gt; &lt;queue physicalName="FOO" /&gt; &lt;topic physicalName="BAR" /&gt; &lt;/forwardTo&gt; &lt;/compositeQueue&gt; &lt;/virtualDestinations&gt; &lt;/virtualDestinationInterceptor&gt;&lt;/destinationInterceptors&gt; 默认情况下，订阅者不能直接从组合队列或主题消费消息 - 它只是一个逻辑构造。 比如上述配置，订阅者只能消费来自FOO和BAR的消息; 而不是MY.QUEUE。12345&lt;compositeQueue name="IncomingOrders" forwardOnly="false"&gt; &lt;forwardTo&gt; &lt;topic physicalName="Notifications" /&gt; &lt;/forwardTo&gt; &lt;/compositeQueue&gt; 发送到IncomingOrders的消息将全部复制并转发到Notifications，然后再放入物理IncomingOrders队列供订阅者使用。 如果未定义forwardOnly属性或将其设置为true，则compositeQueue和compositeTopic之间没有逻辑差异 - 它们可以互换使用。 只有当通过使用forwardOnly使组合目的地成为物理目的地时，compositeTopic / compositeQueue的选择才会对行为产生影响。 使用过滤的目的地从Apache ActiveMQ 4.2开始，您现在可以使用选择器来定义虚拟目的地。 您可能希望创建一个虚拟目的地，该目的地将消息转发到多个目的地，但首先使用选择器来确定消息是否确实必须转到特定目的地。 以下示例显示如果消息匹配指定的选择器，发送到虚拟目的地MY.QUEUE的消息将转发到FOO和BAR。12345678&lt;destinationInterceptors&gt; &lt;virtualDestinationInterceptor&gt; &lt;virtualDestinations&gt; &lt;compositeQueue name="MY.QUEUE"&gt; &lt;forwardTo&gt; &lt;filteredDestination selector="odd = 'yes'" queue="FOO"/&gt; &lt;filteredDestination selector="i = 5" topic="BAR"/&gt; &lt;/forwardTo&gt; &lt;/compositeQueue&gt;&lt;/virtualDestinations&gt; &lt;/virtualDestinationInterceptor&gt; &lt;/destinationInterceptors&gt; 避免broker网络中的重复消息当真正的subscriber和Queue都同时存在VirtualTopic中的时候，而且你的broker架构采用了“forward-brige”结构，那么你需要增加如下配置来避免消息的重复转发问题。在forward-brige架构中，任何通道中的消息都会forward到其他network node中(其他broker上)，当然这个虚拟的Queue的消息也不例外。12345&lt;networkConnectors&gt; &lt;networkConnector uri="static://(tcp://localhost:61617)"&gt; &lt;excludedDestinations&gt; &lt;queue physicalName="Consumer.*.VirtualTopic.&gt;"/&gt; &lt;/excludedDestinations&gt; &lt;/networkConnector&gt; &lt;/networkConnectors&gt; 参考：http://activemq.apache.org/virtual-destinations.html参考：https://shift-alt-ctrl.iteye.com/blog/2065436参考：https://blog.csdn.net/zhu_tianwei/article/details/46303419]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ目的地特性之组合目的地]]></title>
    <url>%2F2019%2F03%2F27%2FActiveMQ%E7%9B%AE%E7%9A%84%E5%9C%B0%E7%89%B9%E6%80%A7%E4%B9%8B%E7%BB%84%E5%90%88%E7%9B%AE%E7%9A%84%E5%9C%B0%2F</url>
    <content type="text"><![CDATA[从ActiveMQ1.1开始，支持一种被称为组合目标的技术。这允许使用单个虚拟的JMS目的地来表示一个JMS目的地的集合。 例如，你可以使用组合目的地在一个操作中将消息发送到12个物理队列。或再一次操作中将消息发送到一个主题和一个队列。 可以在创建目的地或将目的地注册到JNDI时，使用逗号分隔将多个目的地组合起来。比如：1FOO.A,FOO.B,FOO.C 表示3个不同的目的地。这可以与队列或主题一起使用，以表示一组3个目的地。如。123// send to 3 queues as one logical operationQueue queue = new ActiveMQQueue("FOO.A,FOO.B,FOO.C");producer.send(queue, someMessage); 如果希望混合和匹配目的地的类型，可以使用queue://或topic://前缀来区分目的地的类型。例如，在队列中发布消息，同时也可以对某个主题发出通知123// send to queues and topic one logical operationQueue queue = new ActiveMQQueue("FOO.A,topic://NOTIFY.FOO.A");producer.send(queue, someMessage); 还可以在broker配置组合目的地，这样客户端发送到单个目的地的消息将透明地复制到多个物理目的地。 参考：http://activemq.apache.org/composite-destinations.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ目的地之目的地选项]]></title>
    <url>%2F2019%2F03%2F27%2FActiveMQ%E7%9B%AE%E7%9A%84%E5%9C%B0%E4%B9%8B%E7%9B%AE%E7%9A%84%E5%9C%B0%E9%80%89%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[简介目的地选项（Destination Options）是一种向JMS使用者提供扩展配置选项的方法，而无需扩展JMS API。 使用创建使用者的目标名称中的URL查询语法对选项进行编码。 Consumer Options 选项名 默认值 描述 consumer.dispatchAsync true broker是否应该异步的向Consumer发送消息 consumer.exclusive false 是否是一个独占消费者 consumer.maximumPendingMessageLimit 0 配置如果存在缓慢消费者，则用于控制是否删除费持久topic的消息 consumer.noLocal false 与Topic使用者中的noLocal标志相同。 暴露在这里，以便它可以与队列一起使用。 consumer.prefetchSize N/A 消费者预取的消息数，参考prefetch consumer.priority 0 配置消费者优先级，参考Consumer Priority consumer.retroactive false 是否为回溯消费者，参考Retroactive Consumer consumer.selector null 配置JMS选择器 示例12queue = new ActiveMQQueue("TEST.QUEUE?consumer.dispatchAsync=false&amp;consumer.prefetchSize=10");consumer = session.createConsumer(queue);]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之消息持久化]]></title>
    <url>%2F2019%2F03%2F27%2FActiveMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[持久化方式目前ActiveMQ包含以下几种存储方式： AMQ消息存储基于文件的存储方式，是以前的默认消息存储 JDBC消息存储使用数据库作为消息存储 KahaDB消息存储提供了容量的提升和恢复能力，是现在的默认存储方式 LevelDB消息存储基于Google的LevelDB库 Replicated LevelDB消息存储复制的LevelDB存储，需要ZK来选择master节点。 如果你不想使用activeMQ的持久存储，可以在activemq.xml中设置persistent=false来禁用它。1&lt;broker persistent="false"&gt; &lt;/broker&gt; 这样broker会使用&lt;memoryPersistenceAdapter&gt; 各种存储方式介绍AMQ消息存储AMQ介绍 官方文档说ActiveMQ5.0及以上版本，AMQ消息存储是默认的存储方式，这个是不对的。在早期版本的ActiveMQ中默认使用的是AMQ，在5.0以后使用的是KahaDB。 AMQ消息存储是一种可嵌入的事务性消息存储解决方案，非常快速和可靠。消息以日志的形式存储在data log中，以实现持久化。同时被reference store进行索引以提高存取速度。消息索引存储在内存（cache）中，ActiveMQ会定期将索引持久化到Reference store以提高性能。data log文件是有容量限制的，默认为32MB，可以自行配置。当该data log文件中所有消息都被消费完毕的时候，data log文件会被标记为可删除或存档，在下一次消息清理时可以被删除或归档。 配置 AMQ消息存储配置示例： 12345678&lt;broker brokerName="broker" persistent="true" useShutdownHook="false"&gt; &lt;persistenceAdapter&gt; &lt;amqPersistenceAdapter directory="$&#123;activemq.base&#125;/activemq-data" maxFileLength="32mb"/&gt; &lt;/persistenceAdapter&gt; &lt;transportConnectors&gt; &lt;transportConnector uri="tcp://localhost:61616"/&gt; &lt;/transportConnectors&gt;&lt;/broker&gt; AMQ存储配置选项 属性名 默认值 说明 directory activemq-data 存储消息文件和日志的目录 useNIO true 使用 NIO 特性 syncOnWrite false 同步写文件到磁盘 maxFileLength 32mb Message Data日志文件的最大 Size persistentIndex false 持久化日志索引，如果设为 false ，则在内存中保存 maxCheckpointMessageAddSize 4kb 在自动提交前在事务中能保持的最大消息数 cleanupInterval 30000 每隔多少时间清理不再使用的消息日志（毫秒） indexBinSize 1024 这个值是用来提升索引的性能的，值越大，索引相对性能越好 indexKeySize 96 index key的size，index key基于message id indexPageSize 16kb 索引页的size directoryArchive archive 消费完的Data Log存放的目录 archiveDataLogs false 设置为true的话，消费完的Data Log就放到Archive目录，而不是删除。 AMQ存储数据结构在AMQ消息存储中有如下目录结构： broker namebroker name用来区分消息数据的目录。默认目录是localhost。下面是它的子目录： archive丢弃的Data Log就放到这里，当archiveDataLogs 属性配置为true时才会存在 journal用来保存消息数据日志 kr-storereference store目录。 data引用索引所在目录 state存储的状态。如果broker没有正确关闭，那么将清理reference store indexes，并回放消息数据文件（包括消息/ack和事物边界），以重建消息存储状态。如果使用Kaha reference store（缺省值），通过删除/krstore/state目录可以强制恢复。 tmp-storage用于保存可能存储在磁盘上的临时消息的数据文件，以减少内存消耗——例如，非持久性主题消息等待交付给活动但速度较慢的订阅者。 KahaDB消息存储介绍KahaDB是一个基于文件的持久性数据库，并对快速持久化做了优化。它是ActiveMQ5.4及后续版本的默认存储机制。KahaDB使用较少的文件描述符，并提供了比它的前身AMQ更快的恢复能力。 配置要使用KahaDB作为broker的持久性适配器，你可以按如下方式配置：12345&lt;broker brokerName="broker"&gt; &lt;persistenceAdapter&gt; &lt;kahaDB directory="activemq-data" journalMaxFileLength="32mb"/&gt; &lt;/persistenceAdapter&gt;&lt;/broker&gt; 配置选项 属性 默认值 描述 archiveCorruptedIndex false 是否归档错误的索引 archiveDataLogs false 当为true时，归档的消息文件被移到directoryArchive,而不是直接删除 checkForCorruptJournalFiles false 检查消息文件是否损坏，true，检查发现损坏会尝试修复 checkpointInterval 5000 索引写入到消息文件的周期，单位ms checksumJournalFiles false 产生一个checksum，以便能够检测journal文件是否损坏。 cleanupInterval 30000 清除操作周期，单位ms compactAcksAfterNoGC 10 从ActiveMQ5.14.0开始：当确认压缩特性启用时，此值控制必须完成多少存储GC周期，并且在触发压缩逻辑之前不清理任何其他文件，从而可能将跨越日志文件的旧确认压缩到新的日志文件中。值设置得越低，压缩可能发生得越快，如果压缩经常运行，则会影响性能。 compactAcksIgnoresStoreGrowth false 从ActiveMQ 5.14.0开始:当确认压缩特性启用时，该值控制是否在存储仍在增长时运行压缩，或者是否应该只在存储停止增长时运行压缩(由于空闲或达到存储限制)。如果启用了压缩，则无论存储是否仍然有空间或是否处于活动状态都可以运行压缩，这可能会降低总体性能，但会更快地回收空间。 concurrentStoreAndDispatchQueues true 当写入消息的时候，是否转发队列消息 concurrentStoreAndDispatchTopics false 当写入消息的时候，是否转发主题消息（不推荐启用该属性） directory activemq-data 消息文件和日志的存储目录 directoryArchive null 存储被归档的消息文件目录 enableAckCompaction true From ActiveMQ 5.14.0:此设置控制存储是否将定期压缩只包含消息确认的旧日志文件。通过将这些较早的确认压缩到新的日志文件中，可以删除较早的文件，从而释放空间，并允许消息存储在不触及存储大小限制的情况下继续运行。 enableIndexWriteAsync false true表示异步更新索引 enableJournalDiskSyncs true 从ActiveMQ5.14.0已废弃，请参考journalDiskSyncStrategy ignoreMissingJournalfiles false 忽略丢失的消息文件，false，当丢失了消息文件，启动异常 indexCacheSize 10000 内存中，索引的页大小 indexDirectory 从ActiveMQ 5.10.0开始：如果设置，则配置将存储KahaDB索引文件（db.data和db.redo）的位置。 如果未设置，索引文件将存储在directory属性指定的目录中。 indexWriteBatchSize 1000 批量写入的索引数量 journalDiskSyncInterval 1000 同步磁盘时间间隔（单位毫秒） journalDiskSyncStrategy always 从ActiveMQ 5.14.0:该设置配置磁盘同步策略。可用的同步策略列表如下(按安全性递减，性能递增的顺序）：always 始终确保每次写日志之后都有磁盘同步(JMS持久性要求)。这是最安全的选择，但也是最慢的选择，因为它需要在每个消息写入之后进行同步。这相当于废弃的enableJournalDiskSyncs=true属性。periodic磁盘将以设定的时间间隔（如果发生写入）而不是在每次日志写入之后同步，这将减少磁盘上的负载并且应该提高吞吐量。滚动到新的日志文件时，磁盘也将同步。默认间隔为1秒。默认间隔提供非常好的性能，同时比从不磁盘同步更安全，因为数据丢失限制为最多1秒的值。请参阅journalDiskSyncInterval以更改磁盘同步的频率。nevel 永远不会被显式调用，它将由操作系统刷新到磁盘。这相当于设置废弃的属性enableJournalDiskSyncs=false。这是最快的选择，但也是最不安全的，因为无法保证何时将数据刷新到磁盘。因此，broker失败时可能发生消息丢失。 journalMaxFileLength 32mb 一个消息文件的大小 maxAsyncJobs 10000 排队等待存储的异步消息的最大数量(应该与MessageProducer的数量一样） preallocationScope entire_journal 从ActiveMQ 5.14.0:该设置配置如何预先分配日志数据文件。默认策略在第一次使用appender线程时预先分配日志文件。entire_journal：将在首次使用时使用appender线程预分配日志文件。entire_journal_async：将在单独的线程中提前使用预分配。none：禁用预分配。在SSD上，使用entire_journal_async可以避免在首次使用时延迟写入等待预分配。注意：在HDD上，磁盘的额外线程争用会产生负面影响。 因此使用默认值。 preallocationStrategy sparse_file 从ActiveMQ 5.12.0：此设置配置broker在需要新日志文件时尝试预分配日志文件的方式。sparse_file:设置文件长度，os_kernel_copy:委托给操作系统，zeros:不设置文件长度 purgeRecoveredXATransactionStrategy never 从ActiveMQ 5.15.5开始：此设置将在恢复期间提交或回滚所有准备好的XA事务。never：在恢复期间对准备好的XA事务不做任何操作；commit：在恢复期间提交准备好的XA事务；rollback：在恢复期间回滚准备好的XA事务。此功能将对所有准备好的XA事务执行提交或回滚，请考虑使用RecoverXATransaction MBean手动检查特定事务的提交或回滚。 storeOpenWireVersion 11 确定KahaDB日志的OpenWire命令的版本。在ActiveMQ 5.12.0之前：默认值为6。broker的某些功能取决于较新协议修订版中存储在OpenWire命令中的信息，如果将存储版本设置为较低值，这些功能可能无法正常工作。 在许多情况下，broker版本大于5.9.0的KahaDB存储仍然可以被broker读取，但会导致broker继续使用较旧的存储版本，这意味着较新的功能可能无法按预期工作。对于在ActiveMQ 5.9.0之前的版本中创建的KahaDB存储，需要手动设置storeOpenWireVersion =“6”以便启动broker而不会出现错误。 cleanupOnStop true 是否在broker关闭时执行gc/cleanup操作。 慢速文件系统访问诊断日志记录您可以为数据库更新配置一个以毫秒为单位的非零阈值。如果数据库操作比该阈值慢(例如，如果将其设置为500)，您可能会看到如下消息:1Slow KahaDB access: cleanup took 1277 | org.apache.activemq.store.kahadb.MessageDatabase | ActiveMQ Journal Checkpoint Worker 您可以使用系统属性配置用于记录这些消息的阈值，并将其调整为磁盘速度，以便您可以轻松获取运行时异常。1-Dorg.apache.activemq.store.kahadb.LOG_SLOW_ACCESS_TIME=1500 jdbc消息存储ActiveMQ支持一系列的SQL数据库作为消息存储。比如： Apache Derby Axion DB2 HSQL Informix MaxDB MySQL Oracle Postgresql SQLServer Sybase以及一些通用JDBC provider。 自动发现JDBC providerActiveMQ会尝试通过这些配置文件和JDBC驱动程序的返回字符串从JDBC驱动程序自动检测要使用的JDBCAdapter。 你可以在activemq.xml中使用其xbean标识符显式指定JDBC适配器…1&lt;jdbcPersistenceAdapter adapter="postgresql-jdbc-adapter"/&gt; 自定义 SQL DDL您可以使用statements元素配置各种SQL数据类型 - 例如列大小等1234567891011&lt;broker useJmx="false"&gt; &lt;persistenceAdapter&gt; &lt;journaledJDBC useJournal="false"&gt; &lt;statements&gt; &lt;statements stringIdDataType ="VARCHAR(128)"/&gt; &lt;/statements&gt; &lt;/journaledJDBC&gt; &lt;/persistenceAdapter&gt; &lt;/broker&gt; 有关可以在statements元素上设置哪些属性的更多信息，请参阅Statements类。 所有可设置的bean属性都可以用作元素的属性。 使用MySQL如果您使用的是MySQL，则应将relaxAutoCommit标志设置为true。 例如12345678910111213141516171819&lt;beans ...&gt; ... &lt;bean id="mysql-ds" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost/activemq?relaxAutoCommit=true"/&gt; &lt;property name="username" value="amq"/&gt; &lt;property name="password" value="amqPass"/&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;/bean&gt; &lt;broker ...&gt; ... &lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource="#mysql-ds"/&gt; &lt;/persistenceAdapter&gt; ... &lt;/broker&gt;&lt;/beans&gt; 使用Oracle12345678910111213141516171819202122232425&lt;beans ... &gt; &lt;broker xmlns="http://activemq.apache.org/schema/core" brokerName="localhost"&gt; ... &lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataDirectory="$&#123;activemq.base&#125;/data" dataSource="#oracle-ds"/&gt; &lt;/persistenceAdapter&gt; ... &lt;/broker&gt; &lt;!-- Oracle DataSource Sample Setup --&gt; &lt;bean id="oracle-ds" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="oracle.jdbc.driver.OracleDriver"/&gt; &lt;property name="url" value="jdbc:oracle:thin:@localhost:1521:AMQDB"/&gt; &lt;property name="username" value="scott"/&gt; &lt;property name="password" value="tiger"/&gt; &lt;property name="maxActive" value="200"/&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;/bean&gt;&lt;/beans&gt; 使用Spring bean元素配置JDBC驱动程序。 id属性指定配置JDBC持久性适配器时引用驱动程序的名称。 class属性指定实现用于与JDBC驱动程序接口的数据源的类。 destroy-method属性指定JDBC驱动程序关闭时要调用的方法的名称。 LevelDB消息存储 注意：LevelDB存储已被废弃，并不再推荐使用。推荐的存储是：KahaDB。 LevelDB持久性适配器使用LevelDB作为高性能的消息存储。它是一个基于文件的存储库，它使用了Google的LevelDB，将索引保存到包含消息的日志文件中。它经过优化，提供了比KahaDB更快的持久性。它类似于KahahDB，但是它没有使用自定义的b树实现来索引写前日志，而是使用基于LevelDB的索引，由于“append only”文件访问模式，这些索引具有一些很好的属性： 快速更新(不需要进行随机磁盘更新) 并发读取 使用硬链接的快速索引快照 KahaDB和LevelDB存储都必须进行周期性的垃圾收集，以确定可以删除哪些日志文件。在KahaDB的情况下，这可能非常昂贵，因为您增加了存储的数据量，并且在收集发生时可能导致读/写停止。LevelDB存储使用一种便宜得多的算法来确定何时可以收集日志文件并避免这些停顿。 LevelDB的主要优势有： 更高的持久吞吐量 broker重启时恢复时间更快 支持并发的读访问 在垃圾回收周期中不会暂停 使用较少的读取IO操作来加载存储的消息 支持XA事务 检查重复的消息 通过JMX暴露公开状态以进行监控 支持复制 基础配置通过在broker中的persistenceAdapter中加入levelDB元素来配置LevelDB存储。1234567&lt;broker brokerName="broker" persistent="true" ... &gt; ... &lt;persistenceAdapter&gt; &lt;levelDB directory="activemq-data" /&gt; &lt;/persistenceAdapter&gt; ...&lt;/broker&gt; 配置属性 属性名 默认值 描述 directory activemq-data 数据文件的存储目录 readThreads 10 指定允许的并发IO读取数 sync true 是否进行磁盘的同步写操作 logSize 104857600（100mb） log日志文件的最大值（以字节为单位） verifyChecksums false 是否对从文件系统读取的数据进行强制校验 paranoidChecks false 指定LevelDB在检测到内部错误时是否尽快出错。 indexFactory org.fusesource.leveldbjni.JniDBFactory, org.iq80.leveldb.impl.Iq80DBFactory 指定broker尝试加载的LevelDB API工厂实现类的列表（用逗号分隔）。broker将使用第一个成功加载的工厂类。org.fusesource.leveldbjni.JniDBFactory：启用JNI的基本实现。org.iq80.leveldb.impl.Iq80DBFactory：启用纯Java的实现。 indexMaxOpenFiles 1000 指定索引可以使用的打开文件数。LevelDB内部使用多线程进行文件读写操作 indexBlockRestartInterval 16 Specifies the number of keys between restart points for delta encoding of keys. indexWriteBufferSize 4194304 指定在转换为已排序的磁盘文件之前要在内存中构建的索引数据的数量(以字节为单位)。 indexBlockSize 4096 指定每个块的索引数据的大小(以字节为单位)。 indexCacheSize 268435456（256MB） 指定用于缓存索引块的内存的最大量（以字节为单位） indexCompression snappy 指定要应用于索引块的压缩类型。snappy或none。 logCompression snappy 指定要应用于日志记录的压缩类型。snappy或none。 Replicated LevelDB消息存储摘要Replicated LevelDB使用Apache Zookeeper从一组配置为Replicated LevelDB存储的broker节点选择一个作为master。然后，通过复制master的所有更新来同步所有的slave的LevelDB存储，从而使slave保持最新。 Replicated LevelDB存储使用预LevelDB存储相同的数据文件，因此broker可以随时在Replicated LevelDB和LevelDB之间随时切换。 工作原理 它使用Apache Zookeeper来协调集群中的哪个节点作为master节点。选定的master节点启动并接受客户端连接。其他节点成为slave节点，并连接master，与master保持同步。从节点不接受客户端连接。所有持久化操作都将复制到slave节点。如果master挂掉，则具有最新更新的slave节点被提升为master。然后，故障节点可以重新连接，并作为slave节点。 所有的需要同步到磁盘的消息操作都将等待法定数量的slave节点复制数据完成。因此，如果你配置了replicas=3，那么法定的节点数量为3/2+1=2个。master会在本地存储更新，并等待另外一个slave节点存储更新后才会报告成功。换一种说法，Replicated LevelDB存储将会同步复制到法定数量的slave节点，并将异步复制到任何其他节点。 当选择新的master节点时，你还需要至少一个在线的法定数量的节点才能找到具有最新更新的节点。具有最新更新的节点将成为master节点。因此，建议至少使用3个节点，以便在服务不中断的情况下关闭其中一个节点。 部署建议客户端应该使用failover连接集群中的节点，比如：1failover:(tcp://broker1:61616,tcp://broker2:61616,tcp://broker3:61616) 同时为了Zookeeper的高可用，你需要至少运行3个Zookeeperjieidan。不要过渡时会用Zookeeper，过度的Zookeeper可能会认为复制的节点由于处理心跳消息的延迟而离线了。 为了获得最佳结果，确保将hostname属性配置为了集群中其他节点的主机名或ip地址。其他集群成员无法始终访问自动确定的主机名，从而导致slave节点无法与master建立复制会话。 配置您可以配置ActiveMQ使用LevelDB作为它的持久性适配器，如下：123456789101112131415&lt;broker brokerName="broker" ... &gt; ... &lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory="activemq-data" replicas="3" bind="tcp://0.0.0.0:0" zkAddress="zoo1.example.org:2181,zoo2.example.org:2181,zoo3.example.org:2181" zkPassword="password" zkPath="/activemq/leveldb-stores" hostname="broker1.example.org" /&gt; &lt;/persistenceAdapter&gt; ...&lt;/broker&gt; Replicated LevelDB存储属性相同复制集中的的broker节点应该有相同的broker name，相同的复制集中的下面的属性也应该相同。 属性名 默认值 描述 replicas 3 集群节点的数量，至少(replicas/2)+1个，以避免服务中断。 securityToken 一个安全令牌，必须在所有复制节点上匹配，才能接受彼此的复制请求。 zkAddress 127.0.0.1:2181 逗号分隔的ZooKeeper服务器列表。 zkPassword 连接到Zookeeper时使用的密码 zkPath /default Zookeeper主从选举使用的Zookeeper的目录路径 zkSessionTimeout 2s Zookeeper多久检测一个节点失败。（5.11以前，有一个错字zkSessionTmeout） sync quorum_mem 用于控制同步的区域，以“，”分割多个区域。可选项有：local_mem, local_disk, remote_mem, remote_disk, quorum_mem, quorum_disk.如果你配置多个区域，将更强的保证机制将被触发。例如：local_mem, local_disk 与 local_disk 等同quorum_mem 与local_mem, remote_mem 等同quorum_disk 与local_disk, remote_disk等同 不同的复制集可以共享相同的zkPath只要他们有不同的brokerName. 下面的配置属性每个节点特殊的配置： 属性名 默认值 描述 bind tcp://0.0.0.0:61619 当该节点成为主节点时，绑定的地址和端口，用于服务复制协议还支持使用动态端口，只需配置tcp:/ / 0.0.0.0:0 hostname 用于在此节点成为主节点时通告复制服务的主机名。 如果未设置，将自动确定。 weight 1 具有最高权重的最新更新的复制节点将成为主节点。 用于优先选择某些节点成为主节点。 该存储还支持与标准LevelDB存储相同的配置属性，但它不支持可插拔的存储锁。 参考资料参考：http://activemq.apache.org/persistence.htmlAMQ消息存储参考：http://activemq.apache.org/amq-message-store.htmlKahaDB消息存储参考：http://activemq.apache.org/kahadb.htmlJDBC消息存储参考：http://activemq.apache.org/jdbc-support.html、USING JDBC TO CONNECT TO A DATABASE STORELevelDB消息存储参考：http://activemq.apache.org/leveldb-store.html、https://access.redhat.com/documentation/en-us/red_hat_jboss_a-mq/6.2/html/configuring_broker_persistence/leveldbconfigurationReplicated LevelDB消息存储参考：http://activemq.apache.org/replicated-leveldb-store.html、USING THE REPLICATED LEVELDB PERSISTENCE ADAPTER多KahaDB存储：https://access.redhat.com/documentation/en-us/red_hat_jboss_a-mq/6.2/html/configuring_broker_persistence/fusembmultikahadb]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之配置多KahaDB持久性适配器]]></title>
    <url>%2F2019%2F03%2F26%2FActiveMQ%E4%B9%8B%E9%85%8D%E7%BD%AE%E5%A4%9AKahaDB%E6%8C%81%E4%B9%85%E6%80%A7%E9%80%82%E9%85%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[简介从ActiveMQ5.6开始，可以跨多个kahdb持久性适配器分发目标存储。当您的目的地具有不同的性能概要文件或不同的持久性需求时，您可以将它们分布在多个KahaDB消息存储中。 当broker管理的所有Destination有相似的性能和可靠性时，默认的KahaDB持久性存储适配器工作良好。当一个Destination有完全不同的性能配置文件时，例如，与其他Destination上的消费者相比，该Destination上的消费者异常缓慢，存储消息的磁盘使用量将会快速增长。当一个或多个Destination不需要 磁盘同步，而其他的Destination需要磁盘同步时，所有的Destination都将受到性能影响。 多KahaDB持久性适配器允许您跨多个KahaDB消息存储分发broker的Destination。使用多个消息存储允许您使用它更精确地定制消息存储以满足Destination的需要。 使用采用标准通配符语法的过滤器匹配Destination和存储。 配置多KahaDB持久性适配器配置包含多个KahaDB消息存储配置。使用mKahaDB元素指定多KahaDB持久性适配器配置。 mKahaDB元素具有单个属性directory，用于指定适配器写入其数据存储的位置。 此设置是内嵌的KahaDB消息存储库实例的目录属性的默认值。 各个消息存储库可以覆盖此默认设置。 mKahaDB元素有一个子元素filteredPersistenceAdapters。filteredPersistenceAdapters元素包含多个filteredKahaDB元素，用于配置持久性适配器使用的KahaDB消息存储。 每个filteredKahaDB元素配置一个KahaDB消息存储（除了perDestination属性设置为true的情况）。 使用filteredKahaDB元素上的属性指定与消息存储库匹配的Destination： queue——指定queue的名称 topic——指定topic的名称 可以使用显式目标名称或使用通配符指定目标。如果未指定目标，则消息存储将匹配其他筛选器未匹配的任何Destination。 在filteredKahaDB元素中配置的KahaDB消息存储使用标准的KahaDB持久性适配器配置进行配置。它由一个包含在persistenceAdapter元素中的kahaDB元素组成。 通配符语法您可以使用通配符指定一组Destination名称。 这对于在联合层次结构中设置目标的情况很有用。 .分离路径名称 * 匹配路径中的任意名称 &gt; 匹配任意以该名称开头的Destination 配置示例从ActiveMQ 5.15开始，filteredKahaDB支持名为usage的StoreUsage属性。 这允许对匹配的队列施加单独的磁盘限制。1234567891011121314151617181920212223242526&lt;broker brokerName="broker"&gt; &lt;persistenceAdapter&gt; &lt;mKahaDB directory="$&#123;activemq.base&#125;/data/kahadb"&gt; &lt;filteredPersistenceAdapters&gt; &lt;!-- match all queues --&gt; &lt;filteredKahaDB queue="&gt;"&gt; &lt;usage&gt; &lt;storeUsage limit="1g" /&gt; &lt;/usage&gt; &lt;persistenceAdapter&gt; &lt;kahaDB journalMaxFileLength="32mb"/&gt; &lt;/persistenceAdapter&gt; &lt;/filteredKahaDB&gt; &lt;!-- match all destinations --&gt; &lt;filteredKahaDB&gt; &lt;persistenceAdapter&gt; &lt;kahaDB enableJournalDiskSyncs="false"/&gt; &lt;/persistenceAdapter&gt; &lt;/filteredKahaDB&gt; &lt;/filteredPersistenceAdapters&gt; &lt;/mKahaDB&gt; &lt;/persistenceAdapter&gt; &lt;/broker&gt; 上面的配置表示：所有的queue使用第一个消息存储适配器，其他的目的地（这里就是所有的topic）使用第二个消息存储适配器。 为每个Destination指定一个持久性适配器如果filteredKahaDB元素的perDestination设置为true，且没有指定任何的queue和topic，那么每个Destination将有自己的KahaDB实例。 比如：123456789101112131415&lt;broker brokerName="broker" ... &gt; &lt;persistenceAdapter&gt; &lt;mKahaDB directory="$&#123;activemq.base&#125;/data/kahadb"&gt; &lt;filteredPersistenceAdapters&gt; &lt;!-- kahaDB per destinations --&gt; &lt;filteredKahaDB perDestination="true" &gt; &lt;persistenceAdapter&gt; &lt;kahaDB journalMaxFileLength="32mb" /&gt; &lt;/persistenceAdapter&gt; &lt;/filteredKahaDB&gt; &lt;/filteredPersistenceAdapters&gt; &lt;/mKahaDB&gt; &lt;/persistenceAdapter&gt; ...&lt;/broker&gt; 注意：perDestination属性和queue或topic属性组合尚未经过验证，可能会抛出下面的异常：Reason: java.io.IOException: File ‘/opt/java/apache-activemq-5.9.0/data/mKahaDB/lock’ could not be locked as lock is already held for this jvm 事物如果Destination是分布式的，事务可以跨越多个日志。这意味着需要完成两个阶段。这确实会导致记录提交结果的额外磁盘同步的性能损失。 如果事务中只涉及一个日志，则不使用额外的磁盘同步。 在这种情况下不会产生性能损失。 参考：USING A MULTI KAHADB PERSISTENCE ADAPTER参考：http://activemq.apache.org/kahadb.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之消息延迟与定时投递]]></title>
    <url>%2F2019%2F03%2F23%2FActiveMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E5%BB%B6%E8%BF%9F%E4%B8%8E%E5%AE%9A%E6%97%B6%E6%8A%95%E9%80%92%2F</url>
    <content type="text"><![CDATA[简介从ActiveMQ5.4开始，内置了一个可选的持久性调度程序。在activemq.xml中设置broker的schedulerSupport=true来启用。1&lt;broker xmlns="http://activemq.apache.org/schema/core" brokerName="amq1" dataDirectory="$&#123;activemq.data&#125;" schedulerSupport="true"&gt; JMS客户端可以使用下面的属性之一来实现消息的延迟投递： 属性名 类型 描述 AMQ_SCHEDULED_DELAY long broker在投递消息前等待的时间（单位毫秒） AMQ_SCHEDULED_PERIOD long 消息重复投递的间隔（单位毫秒） AMQ_SCHEDULED_REPEAT int 重复投递消息的次数 AMQ_SCHEDULED_CRON String 使用Cron表达式 ActiveMQ也提供了一个封装的消息类型：org.apache.activemq.ScheduledMessage，可以使用这个类来辅助设置。 例如，要让消息在60后投递，你需要设置AMQ_SCHEDULED_DELAY属性：12345MessageProducer producer = session.createProducer(destination);TextMessage message = session.createTextMessage("test msg");long time = 60 * 1000;message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_DELAY, time);producer.send(message); 你还可以设置消息在一定延迟后，重复投递10次，每次重新投递等待10秒：123456789MessageProducer producer = session.createProducer(destination);TextMessage message = session.createTextMessage("test msg");long delay = 30 * 1000;long period = 10 * 1000;int repeat = 9;message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_DELAY, delay);message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_PERIOD, period);message.setIntProperty(ScheduledMessage.AMQ_SCHEDULED_REPEAT, repeat);producer.send(message); 如上，在30秒后开始投递消息，总共投递10次，两次消息投递间隔为10秒。 你还可以使用CRON表达式。比如，如果你希望每小时投递1条消息，可以将CRON设置为0 * * * *。1234MessageProducer producer = session.createProducer(destination);TextMessage message = session.createTextMessage("test msg");message.setStringProperty(ScheduledMessage.AMQ_SCHEDULED_CRON, "0 * * * *");producer.send(message); CRON表达式的优先级高于另外的几个参数，如果在设置了CRON的同时，也有repeat和period参数，则会在每次CRON执行时，重复投递repeat次，每次的间隔为period。 比如每小时投递10次消息，延迟1秒后开始，每次间隔1秒：1234567MessageProducer producer = session.createProducer(destination);TextMessage message = session.createTextMessage("test msg");message.setStringProperty(ScheduledMessage.AMQ_SCHEDULED_CRON, "0 * * * *");message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_DELAY, 1000);message.setLongProperty(ScheduledMessage.AMQ_SCHEDULED_PERIOD, 1000);message.setIntProperty(ScheduledMessage.AMQ_SCHEDULED_REPEAT, 9);producer.send(message); 参考：http://activemq.apache.org/delay-and-schedule-message-delivery.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之消息分发策略]]></title>
    <url>%2F2019%2F03%2F21%2FActiveMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E5%88%86%E5%8F%91%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[分发策略queue的分发策略可插拔的分发策略只适用于topic。queue的分发策略比较固定：轮询（默认）或按照严格顺序。同时我们也应该了解prefect的意义。 ActiveMQ的prefetch缺省参数是针对处理大量消息时的高性能和高吞吐量而设置的，因此默认的prefect值很大，默认的分发策略会尽快尝试将预取缓冲区填满（prefetch buffers）。 然而在有些情况下，例如只有少量的消息而且单个消息的处理时间比较长，那么在缺省的prefetch和dispatch policies下，这些少量的消息总是倾向于被分发到个别的consumer上。这样就会因为负载的不均衡分配而导致处理时间的增加。 对于队列，你可以选择使用轮询或按严格顺序（strictOrderDispatch）。strictOrderDispatch表示在直到当前消费者的prefetch缓冲区满了之后才选择下一个消费者进行消息的分发。 通过下面的方式来启用按严格顺序分发的策略：1&lt;policyEntry queue="&gt;" strictOrderDispatch="false" /&gt; 如果你有几个优先级不同的消费者，消息会先发送给优先级最高的消费者，直到它的prefect缓冲区满，然后再下一个，等等。 从5.14.0版开始——strictOrderDispatch=true选项将确保只有一个消费者时重新发送消息的顺序是严格的。 topic的分发策略所有实现了org.apache.activemq.broker.region.policy.DispatchPolicy的都可以。默认实现是org.apache.activemq.broker.region.policy.SimpleDispatchPolicy，它将消息传递给所有的订阅者。一个更高级的实现示例是org.apache.activemq.broker.region.policy.PriorityNetworkDispatchPolicy，它只会分发给拥有最高优先级的网络消费者。这在循环网络拓扑结构中非常有用，因为在这种拓扑结构中，到消费者的路由不止一条。 下面是一个Destination策略配置示例。1234567891011121314151617181920212223242526272829303132333435&lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry topic="FOO.&gt;"&gt; &lt;dispatchPolicy&gt; &lt;roundRobinDispatchPolicy/&gt; &lt;/dispatchPolicy&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;lastImageSubscriptionRecoveryPolicy/&gt; &lt;/subscriptionRecoveryPolicy&gt; &lt;/policyEntry&gt; &lt;policyEntry topic="ORDERS.&gt;"&gt; &lt;dispatchPolicy&gt; &lt;strictOrderDispatchPolicy/&gt; &lt;/dispatchPolicy&gt; &lt;!-- 1 minutes worth --&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;timedSubscriptionRecoveryPolicy recoverDuration="60000"/&gt; &lt;/subscriptionRecoveryPolicy&gt; &lt;/policyEntry&gt; &lt;policyEntry topic="PRICES.&gt;"&gt; &lt;!-- lets force old messages to be discarded for slow consumers --&gt; &lt;pendingMessageLimitStrategy&gt; &lt;constantPendingMessageLimitStrategy limit="10"/&gt; &lt;/pendingMessageLimitStrategy&gt; &lt;!-- 10 seconds worth --&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;timedSubscriptionRecoveryPolicy recoverDuration="10000"/&gt; &lt;/subscriptionRecoveryPolicy&gt; &lt;/policyEntry&gt; &lt;policyEntry tempTopic="true" advisoryForConsumed="true"/&gt; &lt;policyEntry tempQueue="true" advisoryForConsumed="true"/&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; 参考：http://activemq.apache.org/dispatch-policies.html参考：https://blog.51cto.com/1754966750/1923299]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之订阅恢复策略]]></title>
    <url>%2F2019%2F03%2F21%2FActiveMQ%E4%B9%8B%E8%AE%A2%E9%98%85%E6%81%A2%E5%A4%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[简介生产者在某个topic发送了多条消息后，这个时候非持久订阅者才订阅，那么它是不能获取之前生产者发送的信息的。或者，由于网络问题，非持久类型的消费者处于非活跃状态，无法接收到生产者发送的消息。使用消息恢复策略，可以解决上面的问题。ActiveMQ目前支持一个定时或固定大小的恢复缓冲区，在你连接到broker后，在一段时间内的消息会重新发送给订阅者。 ActiveMQ提供的恢复策略 FixedSizedSubscriptionRecoveryPolicy保留固定字节的消息。 示例：12345&lt;policyEntry topic="&gt;"&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;fixedSizedSubscriptionRecoveryPolicy maximumSize="1024"/&gt; &lt;/subscriptionRecoveryPolicy&gt;&lt;/policyEntry&gt; FixedCountSubscriptionRecoveryPolicy保留固定数量的消息 示例：12345&lt;policyEntry topic="&gt;"&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;fixedCountSubscriptionRecoveryPolicy maximumSize="100"/&gt; &lt;/subscriptionRecoveryPolicy&gt;&lt;/policyEntry&gt; LastImageSubscriptionRecoveryPolicy保留最后一条记录 示例：12345&lt;policyEntry topic="&gt;"&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;lastImageSubscriptionRecoveryPolicy/&gt; &lt;/subscriptionRecoveryPolicy&gt;&lt;/policyEntry&gt; NoSubscriptionRecoveryPolicy禁用回溯，这是默认配置。 示例：12345&lt;policyEntry topic="&gt;"&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;noSubscriptionRecoveryPolicy/&gt; &lt;/subscriptionRecoveryPolicy&gt;&lt;/policyEntry&gt; QueryBasedSubscriptionRecoveryPolicy根据查询机制使用回溯 示例：12345&lt;policyEntry topic="&gt;"&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;queryBasedSubscriptionRecoveryPolicy query="Color='red' AND Name='tom'"/&gt; &lt;/subscriptionRecoveryPolicy&gt;&lt;/policyEntry&gt; TimedSubscriptionRecoveryPolicy保留指定时间内的消息 示例：12345&lt;policyEntry topic="&gt;"&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;timedSubscriptionRecoveryPolicy recoverDuration="60000"/&gt; &lt;/subscriptionRecoveryPolicy&gt;&lt;/policyEntry&gt; RetainedMessageSubscriptionRecoveryPolicy保留ActiveMQ.Retain属性值为true的最后1条消息 示例：12345&lt;policyEntry topic="&gt;"&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;retainedMessageSubscriptionRecoveryPolicy/&gt; &lt;/subscriptionRecoveryPolicy&gt;&lt;/policyEntry&gt; 注意：需要设置retroactive属性为true。即：12Topic topic = session.createTopic("TEST.TOPIC?consumer.retroactive=true");MessageConsumer consumer = session.createConsumer(topic); 参考：http://activemq.apache.org/subscription-recovery-policy.html也可以参考：https://www.cnblogs.com/hapjin/p/5649696.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之Prefect机制]]></title>
    <url>%2F2019%2F03%2F21%2FActiveMQ%E4%B9%8BPrefect%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[简介ActiveMQ的设计目标是成为一个高性能的消息总线。这意味着使用SEDA架构可以异步执行尽可能多的工作。 为了有效利用网络资源，Broker利用“推送”模型向消费者发送消息。 这可确保消费者始终拥有准备处理的消息的本地缓冲区。 替代方案是让消费者明确地从Broker那里提取消息。 单独提取消息不是非常有效，并且会增加每个消息的延迟。 但是，在不限制推送给消费者的消息数量的情况下，客户端的资源可能会被耗尽。因为消息消费通常比消息发送慢的多。为了避免这种情况，ActiveMQ使用预取限制（Prefetch Limit）来限制可以一次发送给单个消费者的最大消息数。消费者依次使用预取限制来调整其预取消息缓冲区的大小。 一旦broker向消费者发送了预取数量的消息，它将不会再向该消费者发送任何消息，直到消费者至少确认了50%的预取消息，比如prefetch size / 2。当broker收到确认后，它将向消费者发送prefect size一半的消息，以填充消费者的本地缓冲区。注意，可以为每个消费者指定预取消息数量。 在数据量较大的情况下，建议使用较大的预取值。但是，对于数据量较小的情况，每个消息需要很长时间处理，预取值应该设置为1.这可以保证消费者一次只处理一条消息。但是，将预取值设置为0将导致消费者每次轮询一条消息，而不是将消息推送给消费者。 何为慢速消费者？ 一个消费者当前待处理的消息数量达到配置的prefetch size的2倍以上，那么该消费者就是慢速消费者。 指定Prefect策略你可以在ActiveMQConnectionFactory或ActiveMQConnection上指定ActiveMQPrefectPolicy。这允许你配置单独的预取值。比如： 如果是在AciveMQConnectionFactory上配置PrefetchPolicy，那么就是所有的Connection都使用此策略；如果是在某个ActiveMQConnection上配置，则是对此Connection起作用。 持久化的queue（默认值：1000） 非持久化的queue（默认值：1000） 持久化的topic（默认值：100） 非持久化的topic（默认值：Short.MAX_VALUE-1） 还可以在用来和broker建立连接的URI上配置prefect限制。1tcp://localhost:61616?jms.prefetchPolicy.all=50 上面的配置表示所有的Destination的预取值限制为50. 1tcp://localhost:61616?jms.prefetchPolicy.queuePrefetch=1 上面的配置表示所有的queue的预取值为1，即每次只推送1条消息给queue的消费者。 也可以针对某个consumer配置，比如：12queue = new ActiveMQQueue("TEST.QUEUE?consumer.prefetchSize=10");consumer = session.createConsumer(queue); 消费者池与预取使用消费者池消费消息时，预取将会是一个问题。未被消费的预取消息只有在消费者关闭时才会释放，但是为了池中的消费者可以被重用，关闭会被延迟到消费者池关闭。这将导致预取的消息直到消费者被重用时才会被消费。从性能角度来看，这个特性是可以被接受的。但是，当池中有多个消费者存在时，这将导致消息投递顺序错乱。 因此，org.apache.activemq.pool.PooledConnectionFactory不会对消费者进行池化。 Springs CachingConnectionFactory支持池化消费者（默认情况下关闭）。如果您在Spring的 DefaultMessageListenerContainer（DMLC）中配置了一个包含多个Consumer线程一起使用的CachingConnectionFactory，那么您要么关闭CachingConnectionFactory中的消费者池（默认情况下是关闭的），要么在使用消费者池时将预取值设置为0.这与每次调用receive(timeout)方法，消费者将使用pool的方式来获取消息。通常建议关闭Spring的CachingConnectionFactory以及任何其他允许池化JMS消费者框架中的缓存。 需要注意的是，Spring的DefaultMessageListenerContainer（DMLC）及其CACHE_CONSUMER缓存级别不受此问题的影响！Spring的DMLC在某种意义上并不池化消费者（pool consumers），即其内部并不使用由多个消费者实例组成的消费者池。相反，它会缓存消费者，也就是说，在DMLC实例的整个生命周期中，都会重用同一个JMS 消费者对象来接收所有消息。其表现很像单纯的手写JMS代码-创建JMS连接，会话，消费者，然后用这个消费者实例接收所有消息。 因此在Spring的DMLC中使用CACHE_CONSUMER是没问题的，即使是使用多个消费者线程，除非你在使用XA事务。CACHE_CONSUMER对XA事务并不生效。然而本地JMS事务和非事务性消费者在Spring的DMLC中使用CACHE_CONSUMER是没问题的。 另请注意，Camel的JMS或ActiveMQ组件在内部使用Springs DMLC。 所以关于Springs DMLC和CACHE_CONSUMER的所有内容都适用于这两个Camel组件。 内存与性能的权衡设置相对较高的预取值可以提高性能。因此，默认值通常大于1000，并且对于对于topic会更高。预取值的大小决定了客户端RAM中保存的消息个数。因此如果RAM有限，你可能需要设置一个较低的值，比如1或10等。 参考：http://activemq.apache.org/what-is-the-prefetch-limit-for.html参考：https://blog.csdn.net/a19881029/article/details/85730150]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之慢消费者处理]]></title>
    <url>%2F2019%2F03%2F21%2FActiveMQ%E4%B9%8B%E6%85%A2%E6%B6%88%E8%B4%B9%E8%80%85%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[简介慢消费者在非持久性主题上会出现问题，因为它们会强制broker为它们在内存保留旧消息。一旦填满，就会导致broker放慢生产者的速度，导致快的消费者也会变慢。 目前，有一个策略可以让你配置broker除了prefect bufer之外还将为消费者保留的最大匹配的消息数。在达到此最大值后，当新消息进入时，旧消息将被丢弃。这将允许你在内存中保留当前消息并继续向慢消费者发送消息，但会丢弃旧消息。 Pending Message Limit Strategy你可以在Destination map配置PendingMessageLimitStrategy的实现类，以便不同topic有不用的策略来处理慢速消费者。例如，你可能希望将此策略引用于价格非常高的，但对于交易和订单而言，你可能不希望丢弃旧的消息。 该策略计算消费者在内存中保留的最大待处理消息数（高于prefetch size）。值为0意味着除了prefect size外不保留任何消息。大于0的值将保留该数量的消息，在新消息进入时丢弃旧的消息。值为-1表示禁止丢弃消息。 目前有两种不同的策略实现： ConstantPendingMessageLimitStrategy PrefetchRatePendingMessageLimitStrategy ConstantPendingMessageLimitStrategy此策略对所有使用者使用常量限制（高于其预取大小）。 示例：1&lt;constantPendingMessageLimitStrategy limit="50"/&gt; PrefetchRatePendingMessageLimitStrategy此种策略是将prefect size 乘以一个你配置的数来计算待处理消息的最大数量。比如，你可以为每个消费者保留大约2.5倍的prefect size的消息。 示例：1&lt;prefetchRatePendingMessageLimitStrategy multiplier="2.5"/&gt; 使用Prefect策略来配置限制在JMS客户端，您可以为持久性的和非持久性的queue和topic配置prefect策略。prefect策略还允许为每个连接/消费者指定最大的预处理消息的数量。 prefect 策略参考：http://activemq.apache.org/what-is-the-prefetch-limit-for.html 配置驱逐策略ActiveMQ有一个MessageEvictionStrategy，用于决定哪个消息应该在慢速消费者身上被驱逐。 默认实现是：1&lt;oldestMessageEvictionStrategy/&gt; 这表示丢弃最旧的消息。 你还可以根据JMS消息属性来丢弃给定属性的消息。 示例：1&lt;uniquePropertyMessageEvictionStrategy propertyName="STOCK"/&gt; propertyName是为特定的价格指定的JMS消息属性。上面的示例表示移除有STOCK属性且最旧的消息。 另外，还可以删除最低优先级且最旧的消息。1&lt;oldestMessageWithLowestPriorityEvictionStrategy/&gt; 示例下面的例子展示了ActiveMQ borker的配置文件。对于PRICES.&gt;通配符范围的topic，pendingMessageLimitStrategy属性设置为仅为每个消费者保留除Prefetch size外，再保留10条消息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://activemq.apache.org/schema/core http://activemq.apache.org/schema/core/activemq-core.xsd"&gt; &lt;bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"/&gt; &lt;broker xmlns="http://activemq.apache.org/schema/core" persistent="false" brokerName="$&#123;brokername&#125;"&gt; &lt;!-- lets define the dispatch policy --&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry topic="FOO.&gt;"&gt; &lt;!--消息分发策略：使用轮询策略--&gt; &lt;dispatchPolicy&gt; &lt;roundRobinDispatchPolicy/&gt; &lt;/dispatchPolicy&gt; &lt;!--恢复策略：只恢复最后1个消息--&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;lastImageSubscriptionRecoveryPolicy/&gt; &lt;/subscriptionRecoveryPolicy&gt; &lt;/policyEntry&gt; &lt;!--对于ORDERS.开头的topic，消息分发策略为：按顺序分发--&gt; &lt;policyEntry topic="ORDERS.&gt;"&gt; &lt;dispatchPolicy&gt; &lt;strictOrderDispatchPolicy/&gt; &lt;/dispatchPolicy&gt; &lt;!-- 恢复最近1分钟内的消息 --&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;timedSubscriptionRecoveryPolicy recoverDuration="60000"/&gt; &lt;/subscriptionRecoveryPolicy&gt; &lt;/policyEntry&gt; &lt;policyEntry topic="PRICES.&gt;"&gt; &lt;!-- lets force old messages to be discarded for slow consumers --&gt; &lt;pendingMessageLimitStrategy&gt; &lt;constantPendingMessageLimitStrategy limit="10"/&gt; &lt;/pendingMessageLimitStrategy&gt; &lt;!-- 10 seconds worth --&gt; &lt;subscriptionRecoveryPolicy&gt; &lt;timedSubscriptionRecoveryPolicy recoverDuration="10000"/&gt; &lt;/subscriptionRecoveryPolicy&gt; &lt;/policyEntry&gt; &lt;policyEntry tempTopic="true" advisoryForConsumed="true"/&gt; &lt;policyEntry tempQueue="true" advisoryForConsumed="true"/&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; &lt;/beans&gt; 使用技巧如果你知道某个特定的消费者会变慢，那么设置它的prefect size小于快速消费者的大小。 例如，如果您知道特定服务器速度很慢并且您的消息速率非常高并且您有一些非常快的消费者，那么您可能希望启用此功能并将慢速服务器上的预取设置为略低于 快速服务器。 监测慢消费者的状况您还可以使用JMX控制台查看活动订阅的统计信息。 这允许您在TopicSubscriptionViewMBean上查看以下统计信息： 统计信息 说明 discarded 在成为慢速消费者后，在订阅的生命周期中丢弃了多少条消息 matched 当前匹配的消息数量，只要预取缓冲区中有一些容量可用，就会立即发送到订阅。因此，非零值意味着此订阅的预取缓冲区已满 参考：http://activemq.apache.org/slow-consumer-handling.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之定期清理离线的持久订阅者]]></title>
    <url>%2F2019%2F03%2F20%2FActiveMQ%E4%B9%8B%E5%AE%9A%E6%9C%9F%E6%B8%85%E7%90%86%E7%A6%BB%E7%BA%BF%E7%9A%84%E6%8C%81%E4%B9%85%E8%AE%A2%E9%98%85%E8%80%85%2F</url>
    <content type="text"><![CDATA[概述通常，我们不希望系统中存在长时间离线的持久订阅者，因为Broker需要为它们保留它们订阅的topic的所有消息。而且随着时间的推移，将会导致达到存储限制，从而导致系统变慢。 当然，你可以通过JConsole或Web Console等管理工具来手动取消不活跃的持久订阅者。但显然可以餐区更多措施来帮助管理。 过期消息一些应用程序发送的消息有一定的过期时间。如果这些消息存储在Broker上供离线的持久订阅者使用，我们需要在它们到期时将其删除。就像我们的队列一样，现在默认是每30秒检查一次这些消息，可以使用适当的目标策略进行调整。1&lt;policyEntry topic="&gt;" expireMessagesPeriod="300000"/&gt; 如上配置，broker每5分钟检查一次过期的消息。 移除不活跃的订阅者我们可以自动取消在一段时间内不活跃的持久订阅者。 配置示例如下：1&lt;broker name="localhost" offlineDurableSubscriberTimeout="86400000" offlineDurableSubscriberTaskSchedule="3600000"&gt; 属性 默认值 描述 offlineDurableSubscriberTimeout -1 我们删除非活动持久性订阅者的时间（以毫秒为单位）。 默认值-1，表示不删除它们 offlineDurableSubscriberTaskSchedule 300000 检查频率（以毫秒为单位） 上面的配置示例，表明broker会每小时检查并删除已离线1天的订阅者。 参考：http://activemq.apache.org/manage-durable-subscribers.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ的消息重发与死信处理]]></title>
    <url>%2F2019%2F03%2F20%2FActiveMQ%E7%9A%84%E6%B6%88%E6%81%AF%E9%87%8D%E5%8F%91%E4%B8%8E%E6%AD%BB%E4%BF%A1%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[概述在发生以下情形时，消息会给重发给客户端： 使用了一个事务性的会话且调用了rollback()方法。 在调用commit()方法前一个事务性的会话被关闭了。 一个会话使用CLIENT_ACKNOWLEDGE的ACK模式，且调用了Session.recover()方法。 一个客户端连接超时（可能正被执行的代码执行的时间超过配置的超时时间）。 客户端可以通过ActiveMQConnection.getRedeliveryPolicy() 或 ActiveMQConnectionFactory.getRedeliveryPolicyMap()来覆盖策略设置。 方法：12345RedeliveryPolicy policy = connection.getRedeliveryPolicy();policy.setInitialRedeliveryDelay(500);policy.setBackOffMultiplier(2);policy.setUseExponentialBackOff(true);policy.setMaximumRedeliveries(2); 当一个消息被redelivered超过maximumRedeliveries(缺省为6次，具体设置请参考后面的链接)次数时，会给broker发送一个”Poison ack”，这个消息被认为是a poison pill，这时broker会将这个消息发送到DLQ，以便后续处理。 缺省的死信队列是ActiveMQ.DLQ，所有不能投递的消息都会被发送到这个队列，这将会导致难以管理。你可以在activemq.xml这个配置文件的destinationPolicy配置individualDeadLetterStrategy ，它可以让给为一个给定的queue或topic指定特定的死信队列前缀。如果你希望所有的queue都拥有自己的死信队列，你可以使用通配符。 示例：1234567891011121314151617181920&lt;broker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;!-- 使用&gt;通配符为所有的queue设置下面的策略 你也可以指定具体的队列名--&gt; &lt;policyEntry queue="&gt;"&gt; &lt;deadLetterStrategy&gt; &lt;!-- queuePrefix:指定死信队列的前缀为DLQ. useQueueForQueueMessages=true，表示使用队列来保存死信 --&gt; &lt;individualDeadLetterStrategy queuePrefix="DLQ." useQueueForQueueMessages="true"/&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; 自动丢弃过期消息如果你只想丢弃过期的消息，不想发送到死信队列，你可以在一个死信队列策略中配置processExpired=false。123456789101112131415161718192021&lt;broker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;!-- 使用&gt;通配符来使所有的队列使用下面的策略 --&gt; &lt;policyEntry queue="&gt;"&gt; &lt;!-- Tell the dead letter strategy not to process expired messages so that they will just be discarded instead of being sent to the DLQ --&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processExpired="false" /&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; 非持久消息保存到死信队列默认情况下，ActiveMQ不会将不能投递的非持久消息放到死信队列。如果你希望将非持久消息存储到死信队列，你可以在死信队列的策略中设置processNonPersistent=&quot;true&quot;。1234567891011121314151617181920&lt;broker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;!-- Set the following policy on all queues using the '&gt;' wildcard --&gt; &lt;policyEntry queue="&gt;"&gt; &lt;!-- Tell the dead letter strategy to also place non-persisted messages onto the dead-letter queue if they can't be delivered. --&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processNonPersistent="true" /&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; 设置死信队列中消息的过期时间默认情况下，ActiveMQ永远不会使发送到DLQ的消息失效。 但是，在ActiveMQ 5.12中，deadLetterStrategy支持到期属性，其值以毫秒为单位。123456789101112131415&lt;broker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry queue="QueueWhereItIsOkToExpireDLQEntries"&gt; &lt;deadLetterStrategy&gt; &lt;.... expiration="300000"/&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; DLQ丢弃插件从ActiveMQ5.9开始，一个Destination的policyEntry支持丢弃的deadLetterStrategy。123&lt;deadLetterStrategy&gt; &lt;discarding/&gt;&lt;/deadLetterStrategy&gt; 这个与丢弃插件的功能相同，但这个是基于每个Destination的。丢弃插件支持正则表达式匹配，这在某些情况下很有用。 此插件允许全部或基于Java SE的正则表达式匹配的queue和topic，丢弃发送到DLQ中的消息。这在使用ConstantPendingMessageLimit策略或其他逐出规则，但不想有一个其他的消费者来清理DLQ时很有用。 下面是一个丢弃所有内容的一个基本配置：1234567&lt;beans&gt; &lt;broker&gt; &lt;plugins&gt; &lt;discardingDLQBrokerPlugin dropAll="true" dropTemporaryTopics="true" dropTemporaryQueues="true"/&gt; &lt;/plugins&gt; &lt;/broker&gt;&lt;/beans&gt; 下面是一个稍微复杂点的例子：1234567&lt;beans&gt; &lt;broker&gt; &lt;plugins&gt; &lt;discardingDLQBrokerPlugin dropOnly="MY.EXAMPLE.TOPIC.29 MY.EXAMPLE.QUEUE.87" reportInterval="1000"/&gt; &lt;/plugins&gt; &lt;/broker&gt;&lt;/beans&gt; 这个例子中，只针对指定的queue和topic有效。各个destination用空格隔开。reportInterval属性用于表示我们输出丢弃的消息的频率 - 使用0来禁用。 下面是一个使用正则表达式的例子：1234567&lt;beans&gt; &lt;broker&gt; &lt;plugins&gt; &lt;discardingDLQBrokerPlugin dropOnly="MY.EXAMPLE.TOPIC.[0-9]&#123;3&#125; MY.EXAMPLE.QUEUE.[0-9]&#123;3&#125;" reportInterval="3000"/&gt; &lt;/plugins&gt; &lt;/broker&gt;&lt;/beans&gt; 这里匹配的是以000~999结尾的目的地。 Broker消息重发插件默认情况下，在消息重新投递次数达到配置的最大投递次数（或默认的6次），broker会将消息放入DLQ。我们可以使用broker消息重发插件来改变这一行为。即在一定延迟后，将消息重新投递给原始Destination，如果达到最大重试次数，则放入DLQ。 1234567891011121314151617181920212223242526272829&lt;broker schedulerSupport="true"&gt; &lt;plugins&gt; &lt;!-- 重发策略，对于超过重发次数的消息将会被添加到DLQ --&gt; &lt;redeliveryPlugin fallbackToDeadLetter="true" sendToDlqIfMaxRetriesExceeded="true"&gt; &lt;redeliveryPolicyMap&gt; &lt;redeliveryPolicyMap&gt; &lt;redeliveryPolicyEntries&gt; &lt;!-- 重发机制，默认重发6，重发延迟基于backOff模式 --&gt; &lt;redeliveryPolicy queue="SpecialQueue" maximumRedeliveries="4" redeliveryDelay="10000"/&gt; &lt;/redeliveryPolicyEntries&gt; &lt;defaultEntry&gt; &lt;!-- 其他Destination的默认处理策略 --&gt; &lt;redeliveryPolicy maximumRedeliveries="4" initialRedeliveryDelay="5000" redeliveryDelay="10000"/&gt; &lt;/defaultEntry&gt; &lt;/redeliveryPolicyMap&gt; &lt;/redeliveryPolicyMap&gt; &lt;/redeliveryPlugin&gt; &lt;/plugins&gt; &lt;/broker&gt; sendToDlqIfMaxRetriesExceeded：如果为true，则在达到最大重试次数后，会发送到DLQ，否则会删除该消息。 参考：http://activemq.apache.org/message-redelivery-and-dlq-handling.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ常见问题]]></title>
    <url>%2F2019%2F03%2F19%2FActiveMQ%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.服务挂掉 设置mq的storeUsage为1M，生产者不断发送持久化消息，消费者每隔5秒接收1条消息。在达到配置的使用限制后，broker会停止producer。此时生产者阻塞，但消费者可正常连接并消费消息，等消息消费掉一部分，文件删除又腾出空间之后，生产者又可继续发送消息，服务自动恢复正常。activeMQ控制台输出如下：12345jvm 1 | INFO | Usage(default:store:queue://myQueue:store) percentUsage=99%, usage=1054753, limit=1048576,percentUsageMinDelta=1%;Parent:Usage(default:store) percentUsage=100%, usage=1054753, limit=1048576, percentUsageMinDelta=1%: Persistent store is Full, 100% of 1048576. Stopping producer (ID:QINCD125-D-11620-1552987305276-1:1:1:1) to prevent flooding queue://myQueue. See http://activemq.apache.org/producer-flow-control.html formore info (blocking for: 32s) 第一次是2s，第二次是32s，后面每次增加30s。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ之消息选择器（Message Selectors）]]></title>
    <url>%2F2019%2F03%2F19%2FActiveMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E9%80%89%E6%8B%A9%E5%99%A8%EF%BC%88Message%20Selectors%EF%BC%89%2F</url>
    <content type="text"><![CDATA[JMS Selectors用在获取消息的时候，可以基于消息属性和Xpath语法对消息进行过滤。JMS Selectors由SQL92语义定义。以下是个Selectors的例子：1consumer = session.createConsumer(destination, "JMSType = 'car' AND weight &gt; 2500"); 1：JMS Selectors表达式中，可以使用IN、NOT IN、LIKE等 2：需要注意的是，JMS Selectors表达式中的日期和时间需要使用标准的long型毫秒值 3：表达式中的属性不会自动进行类型转换，例如：1myMessage.setStringProperty("NumberOfOrders", "2"); 那么此时“NumberOfOrders &gt; 1” 求值结果会是false 4：Message Groups虽然可以保证具有相同message group的消息被唯一的consumer顺序处理，但是却不能确定被哪个consumer处理。在某些情况下，Message Groups可以和JMS Selector一起工作， 例如： 设想有三个consumers分别是A、B和C。你可以在producer中为消息设置三个message groups分别是“A”、“B”和“C”。然后令consumer A使用“JMXGroupID = ‘A’”作为selector。B和C也同理。这样就可以保证message group A的消息只被consumer A处理。需要注意的是，这种做法有以下缺点： （1）producer必须知道当前正在运行的consumers，也就是说producer和consumer被耦合到一起。 （2）如果某个consumer失效，那么应该被这个consumer消费的消息将会一直被积压在broker上。 下面我们使用JMS Selectors来实现消息分组功能 消息生产者 123456789MessageProducer producer = session.createProducer(destination);for (int i=0;i&lt;10;i++) &#123; TextMessage msg = session.createTextMessage("hello " + i); if (i % 2 == 0) msg.setStringProperty("JMSXGroupID","groupA"); else msg.setStringProperty("JMSXGroupID","groupB"); producer.send(msg);&#125; 消费者1 12345678MessageConsumer consumer = session.createConsumer(destination,"JMSXGroupID='groupA'");consumer.setMessageListener(msg -&gt; &#123; try &#123; System.out.println("Received msg:" + ((TextMessage)msg).getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125;&#125;); 消费者2 12345678MessageConsumer consumer = session.createConsumer(destination,"JMSXGroupID='groupB'");consumer.setMessageListener(msg -&gt; &#123; try &#123; System.out.println("Received msg:" + ((TextMessage)msg).getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125;&#125;); 消费者1控制台输出：12345Received msg:hello 0Received msg:hello 2Received msg:hello 4Received msg:hello 6Received msg:hello 8 消费者2控制台输出：12345Received msg:hello 1Received msg:hello 3Received msg:hello 5Received msg:hello 7Received msg:hello 9 参考：《ActiveMQ in Action》、ActiveMQ（23）：Consumer高级特性]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ请求回复]]></title>
    <url>%2F2019%2F03%2F16%2FActiveMQ%E8%AF%B7%E6%B1%82%E5%9B%9E%E5%A4%8D%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[JMS支持Request/Reply模式，在消息生产者发送消息时设置回复消息的目的地，在Consumer接收到消息后，可以回复消息。 示例代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** jms请求回复模式。producer发送消息到某个Destination，在发送时设置回复的目的地，consumer在接收到消息后可以在回复的目的地回复消息。* @author Donny* @email luckystar88@aliyun.com* @date 2019/03/16 17:39*/public class ReplyToMessage &#123; public static void main(String[] args) &#123; final String sendQueue = "testQueue"; final String replyQueue = "replyQueue"; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory("tcp://localhost:61616"); Connection connection = null; Session session = null; try &#123; connection = factory.createConnection(); connection.start(); session = connection.createSession(false,Session.AUTO_ACKNOWLEDGE); // 发送目的地 Queue sendQ = session.createQueue(sendQueue); Queue replyQ = session.createQueue(replyQueue); MessageProducer producer = session.createProducer(sendQ); TextMessage msg = session.createTextMessage("hello,this is a message."); // 设置消息回复的目的地 msg.setJMSReplyTo(replyQ); producer.send(msg); // 消息消费者，监听sendQ MessageConsumer consumer = session.createConsumer(sendQ); Session _session = session; consumer.setMessageListener(message -&gt; &#123; try &#123; System.out.println("Consumer received msg:" + ((TextMessage)(message)).getText()); // 回复消息 MessageProducer mp = _session.createProducer(replyQ); TextMessage replyMsg = _session.createTextMessage("hello,message is received."); mp.send(replyMsg); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;); // 监听回复的消息目的地 MessageConsumer replyMC = session.createConsumer(replyQ); replyMC.setMessageListener(message -&gt; &#123; try &#123; System.out.println("Consumer2 received reply msg:" +((TextMessage)(message)).getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;); System.in.read(); &#125; catch (JMSException | IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (connection != null) &#123; try &#123; connection.close(); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; if (session != null) &#123; try &#123; session.close(); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 控制打印如下：12Consumer received msg:hello,this is a message.Consumer2 received reply msg:hello,message is received.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
        <tag>jms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ顺序消费消息+消息分组]]></title>
    <url>%2F2019%2F03%2F16%2FActiveMQ%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%2B%E6%B6%88%E6%81%AF%E5%88%86%E7%BB%84%2F</url>
    <content type="text"><![CDATA[简介Queue中的消息是按照顺序发送给Consumers的。然而，当你有多个Consumer同时从相同的Queue提取消息时，顺序将不能得到保证。因为这些消息时被多个线程并发的处理。但是，有时候保证消息的顺序是很重要的。例如，你可能不希望插入订单操作结束之前执行更新订单的操作。那么我们可以通过Exclusive Consumer和Message Groups来实现这一目的。 独有消费者从ActiveMQ4.X版本开始支持ExclusiveConsumer（或者说是Exclusive Queues）。Broker会从多个Consumer中挑选一个Consumer来处理所有的消息，从而保证消息的有序处理。如果这个Consumer失效，那么Broker会自动切换到其他的Consumer。可以通过Destination的Option来创建一个Exclusive Consumer，如下：12queue = new ActiveMQQueue("Test.Queue?consumer.exclusive=true");consumer = session.createConsumer(queue); 另外，还可以给Consumer设置优先级，以便针对网络情况进行优化。如下：1queue = new ActiveMQQueue("Test.Queue?consumer.exclusive=true&amp;consumer.priority=10"); 消息分组从Apache官方文档的话说，是Exclusive Consumer功能的增强。逻辑上，可以看成是一种并发的Exclusive Consumer。JMS消息属性JMXGroupID被用来区分Message Group。Message Groups特性保证所有具有相同JMSGroupID的消息会被分发到相同的Consumer（只要这个Consumer保持Active）。另一方面，Message Groups也是一种负载均衡的机制。 在一个消息被分发到Consumer前，Broker会检查消息的JMSGroupID属性。如果存在，那么broker会检查是否有某个Consumer拥有这个Message Group。如果没有，那么broker会选择一个Consumer，并将它关联到这个Message Group。此后，这个Consumer会接收这个Message Group的所有消息。直到： Consumer被关闭。 Message Group被关闭。通过发送一个消息，并设置这个消息的JMSXGroupSeq为-1. 从4.1版本开始，ActiveMQ支持一个布尔字段JMSXGroupFirstForConsumer 。当某个message group的第一个消息被发送到consumer的时候，这个字段被设置。如果客户使用failover transport连接到broker。在由于网络问题等造成客户重新连接到broker的时候，相同message group的消息可能会被分发到不同与之前的consumer，因此JMSXGroupFirstForConsumer字段也会被重新设置。 创建一个Message Groups创建一个Message Groups，只需要在Message对象上设置属性即可。如下：1234Message message = session.createTextMessage("hello,world");message.setStringProperty("JMSXGroupID","GroupA");...producer.send(message); 关闭一个Message Groups关闭一个Message Group，也只需要在Message对象上设置相应的属性即可。如下：12message.setStringProperty("JMSXGroupID","GroupA");message.setIntProperty("JMSXGroupSeq", -1);]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ集群搭建]]></title>
    <url>%2F2019%2F03%2F16%2FActiveMQ%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[简述activemq提供了多种方式来保证activemq的可靠性。包括： 纯Master/Slave Shared File System Master Slave JDBC Master Slave Broker clusters-静态 Broker clusters-动态（基于组播，动态发现brokers） 但单纯的使用上面的一种没法既达到高可用，同时有具有负载均衡的能力。 生产环境集群搭建建议所以可以考虑Master/Slave+Broker clusters-静态来实现。Master/Slave保证了Slave复制master的数据，Broker clusters-静态实现了非消息生产者的broker拥有对外提供消费的能力。即在broker1上生产了消息，如果broker1与broker2配置了static network Connectors，那么客户端监听broker2也可以拿到broker1生产的消息。所以生产环境建议二者集合。生产环境： 如果数据量不大，可以考虑Zookeeper来搭建Master/Slave。由于ZK选举至少需要2N+1个节点，所以mq至少要3个节点。如果生产消息的broker挂掉，ZK会从其他的节点选择一个作为Master。客户端使用failover会自动连接到提升为Master的节点，消费挂掉的broker的消息没有问题。 数据量比较大，考虑Zookeeper+静态网络连接来实现高可用与负载均衡能力。比如2个ZK（假定分别为zk1和zk2），每个ZK分别管理1组（3台）MQ节点。这样启动全部的MQ节点，2组MQ节点中会分别有1台Master对外提供服务。然后2组MQ之间通过static network Connectors+duplex=true来实现failover功能。 配置1：这种配置，一个缺点就是没有保障ZK的高可用。 如果希望ZK也高可用，则每组ZK至少配置3个ZK节点（ZN+1原则）。比如下面的配置2组ZK+2组MQ。 作用 openwire端口 admin端口 zk端口 组 mq1 61616 8161 zk1,2,3的2181,2182,2183 Group1 mq2 61617 8162 zk1,2,3的2181,2182,2183 Group1 mq3 61618 8163 zk1,2,3的2181,2182,2183 Group1 mq4 61616 8161 zk4,5,6的2181,2182,2183 Group2 mq5 61617 8162 zk4,5,6的2181,2182,2183 Group2 mq6 61618 8163 zk4,5,6的2181,2182,2183 Group2 zk1 / / 2181 Group1 zk2 / / 2182 Group1 zk3 / / 2183 Group1 zk4 / / 2181 Group2 zk5 / / 2182 Group2 zk6 / / 2183 Group2 这里假定Group1和Group2是2台机器，ZK1和ZK2为2台机器。其中，mq1-3为Group1，zkAddress=zk1:2181,zk2:2182,zk3:2183.mq4-6为Group2，zkAddress=zk4:2181,zk5:2182,zk6:2183.注意：6台MQ的brokerName必须全部一样。 当然了，你还可以继续扩展，比如3组ZK+3组MQ，这样同时对外提供服务的MQ就是3台。 关键配置1.ZK集群搭建那一组ZK来说在该组ZK的根目录创建data目录，然后创建3个子目录，名字分别为1,2,3，在每个子目录下面创建myid文件，内容与目录名字相同（即如果属于目录1，则内容为1）。 在每个ZK节点的配置文件zoo.cfg中最后加入：123server.1=127.0.0.1:2887:3887server.2=127.0.0.1:2888:3888server.3=127.0.0.1:2889:3889 每个ZK节点的dataDir指向它所属的data目录。比如ZK1的dataDir=/usr/local/zookeeper/data/1。其中/usr/local/zookeeper是该组ZK集群的根目录。 2.ActiveMQ集群配置打开activemq.xml，修改或加入如下内容： 修改brokerName； 中的内容为：1234567891011&lt;persistenceAdapter&gt; &lt;!-- &lt;kahaDB directory="$&#123;activemq.data&#125;/kahadb"/&gt;--&gt; &lt;replicatedLevelDB directory="$&#123;activemq.data&#125;/leveldb" replicas="3" bind="tcp://0.0.0.0:0" zkAddress="127.0.0.1:2181,127.0.0.1:2181,127.0.0.1:2183" zkPassword="" zkPath="/activemq-cluster/leveldb-stores/group1" hostname="vm1" sync="local_disk"/&gt; 此处需注意：replicas是MQ节点的数量，需要为2N+1.zkAddress指定ZK集群的地址，多个地址用逗号分隔，zkPath保证不与其他ZK组的path一样（如果2组ZK在不同的机器可以忽略），否则会导致选举Master出现问题，因为各个ZK组都查找到了相同的节点。 修改transportConnector1234&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name="openwire" uri="tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600"/&gt; &lt;/transportConnectors&gt; 一个是修改openwrie的端口，然后把其他协议的注释掉。（这里根据需要，只保留使用的协议）。 增加static network Connector配置123&lt;networkConnectors&gt; &lt;networkConnector uri="static:(tcp://192.168.199.199:61619,tcp://192.168.199.199:61620,tcp://192.168.199.199:61621)" duplex="true" /&gt; &lt;/networkConnectors&gt; 这里的IP和端口是其他Group的IP和端口。因为你希望在Group1生产的数据在Group2的节点能够消费，反之亦然。所以这里配置的是其他组的IP和端口。另外，需要配置duplex=true。否则，比如Group1的mq1生产消息，然后停止mq1，此时消费者连接上Group2，是没法消费消息的。配置上duplex=true，就可以保证在Group2也能消费到Group1生产的消息。反之亦然。 修改每个mq的管理端口修改jetty.xml中的port即可。 应用程序配置程序使用failover来连接broker。比如： 1234567final static String uris = "failover:(tcp://192.168.199.199:61616,tcp://192.168.199.199:61617,tcp://192.168.199.199:61618," + "tcp://192.168.199.199:61619,tcp://192.168.199.199:61620,tcp://192.168.199.199:61621)" + "?randomize=true&amp;initialReconnectDelay=1000&amp;maxReconnectDelay=30000";final static String MQ_USERNAME = "admin";final static String MQ_PASSWORD = "admin"; 上面配置完毕后，先启动各个ZK，没问题再启动各个MQ节点。观察日志输出，每组ZK只会有一个是Master，其他是Slave。每组MQ只会有一个是Master，其他是Slave。 配置完毕后，将MQ的openwire的端口对外开放，程序就可以访问了。 集群测试 测试某组MQ节点之间数据是否正常（测试Master/Slave功能）；生产者和消费者都使用failover连接所有MQ节点，生产者发送消息。消息发送完毕后，将发送消息的MQ节点停掉，然后消费者连接发送消息的MQ所在组的其他MQ节点，看是否正常消费消息。比如Group1节点分别为mq1,mq2,mq3，假定发送消息的MQ节点是mq1，那么发送消息完毕后，停掉mq1.然后启动消费者，看消费者能否消费消息。这里生产者和消费者都使用failover连接mq1,mq2,mq3. 测试组间数据是否正常（测试Static NetWork Connector功能）。生产者与#1一致，发送消息后关闭该mq节点。消费者使用failover连接另外一组MQ，看是否能够消费消息。 各种MQ集群配置参考：ActiveMQ集群搭建详解]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Apache HttpClient进行https调用]]></title>
    <url>%2F2019%2F02%2F16%2F%E4%BD%BF%E7%94%A8Apache%20HttpClient%E8%BF%9B%E8%A1%8Chttps%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介本文使用的Apache HttpClient版本为4.5.6. 在使用Apache HttpClient执行https请求时，有时会遇到ssl相关的异常，这里介绍如何通过HttpClient执行https请求。 这里有2种方式：忽略ssl证书并信任任意连接 和 导入证书到秘钥库。 忽略ssl证书并信任任意连接ssl初始化时需要证书管理器(TrustManager)，我们这里使用了一个实现了X509TrustManager的证书管理器。它不做证书的验证，并信任任意的连接。然后通过HttpClients的setSSLSocketFactory()设置SSLSocketFactory即可。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class HttpClientFactory &#123; private final static CloseableHttpClient HTTP_CLIENT; static &#123; ConnectionSocketFactory plainsf = PlainConnectionSocketFactory.getSocketFactory(); LayeredConnectionSocketFactory sslsf = sslConnectionSocketFactory(); Registry&lt;ConnectionSocketFactory&gt; registry = RegistryBuilder.&lt;ConnectionSocketFactory&gt;create() .register("http", plainsf) .register("https", sslsf) .build(); connManager = new PoolingHttpClientConnectionManager(registry); // 设置最大连接数 connManager.setMaxTotal(1000); // 设置每个连接的路由数 connManager.setDefaultMaxPerRoute(100); // 定时关闭无效的连接 new IdleConnectionMonitorThread(connManager).start(); HTTP_CLIENT = HttpClients.custom() .setUserAgent(userAgent) .setSSLSocketFactory(sslsf) .setConnectionManager(connManager) .build(); &#125; /** * 获取Http客户端连接对象 * * @return Http客户端连接对象 */ public final static CloseableHttpClient getCloseableHttpClient() &#123; return HTTP_CLIENT; &#125; private static class HttpsTrustManager implements X509TrustManager &#123; @Override public void checkClientTrusted(X509Certificate[] arg0, String arg1) throws CertificateException &#123; // TODO Auto-generated method stub &#125; @Override public void checkServerTrusted(X509Certificate[] arg0, String arg1) throws CertificateException &#123; // TODO Auto-generated method stub &#125; @Override public X509Certificate[] getAcceptedIssuers() &#123; return new X509Certificate[]&#123;&#125;; &#125; &#125; private static SSLConnectionSocketFactory sslConnectionSocketFactory() &#123; return new SSLConnectionSocketFactory(sslContext(), SSLConnectionSocketFactory.BROWSER_COMPATIBLE_HOSTNAME_VERIFIER); &#125; private static SSLContext sslContext() &#123; SSLContext ctx = null; try &#123; ctx = SSLContexts.custom().useSSL().build(); ctx.init(null, new TrustManager[] &#123; new HttpsTrustManager() &#125;, new SecureRandom()); &#125; catch (KeyManagementException | NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; return ctx; &#125;&#125; 然后通过getCloseableHttpClient()拿到CloseableHttpClient，就可以执行https请求了（与http请求一样）。比如：12345678910111213public static String getPageContent(String url,String charset) &#123; HttpGet httpGet = new HttpGet(url); HttpResponse response = null; try &#123; response = getCloseableHttpClient().execute(httpGet); return EntityUtils.toString(response.getEntity(), charset == null ? "UTF-8" : charset); &#125; catch (IOException e) &#123; LOGGER.error("解析路径异常 url = " + url,e); &#125; finally &#123; close(httpGet, response); &#125; return null;&#125; 导入证书到秘钥库如果已经有证书，我们将证书导入秘钥库即可。1234567891011121314151617181920212223242526272829303132333435public class HttpClientFactory &#123; private static CloseableHttpClient client; public static HttpClient getHttpsClient() throws Exception &#123; if (client != null) &#123; return client; &#125; SSLContext sslcontext = getSSLContext(); SSLConnectionSocketFactory factory = new SSLConnectionSocketFactory(sslcontext, SSLConnectionSocketFactory.BROWSER_COMPATIBLE_HOSTNAME_VERIFIER); client = HttpClients.custom().setSSLSocketFactory(factory).build(); return client; &#125; public static void releaseInstance() &#123; client = null; &#125; private SSLContext getSSLContext() throws KeyStoreException, NoSuchAlgorithmException, CertificateException, IOException, KeyManagementException &#123; KeyStore trustStore = KeyStore.getInstance(KeyStore.getDefaultType()); FileInputStream instream = new FileInputStream(new File("my.keystore")); try &#123; trustStore.load(instream, "nopassword".toCharArray()); &#125; finally &#123; instream.close(); &#125; return SSLContexts.custom() .loadTrustMaterial(trustStore) .build(); &#125;&#125; 其实这2种方式也只有创建SSLContext不同。参考文章也说了生产环境还是建议使用第2种。 文章参考：https://prasans.info/2014/06/making-https-call-using-apache-httpclient/ 如果是使用Java的HttpClientConnection，则可以参考：http://www.devsumo.com/technotes/2014/01/java-trusting-https-server-certificates/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>httpclient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git回退到某次提交]]></title>
    <url>%2F2019%2F01%2F17%2Fgit%E5%9B%9E%E9%80%80%E5%88%B0%E6%9F%90%E6%AC%A1%E6%8F%90%E4%BA%A4%2F</url>
    <content type="text"><![CDATA[在工作中难免会遇到把不该提交的代码提交的情况，不过好在我们可以回退。 idea中的做法1如果你使用idea，那么通过简单的几部操作就可以回退到任意一次提交。 1.右键-&gt;git-&gt;Show History，列出所有的提交记录。 2.选中一条记录，点“Select In Git Log” 3.选中要回退到的提交记录，然后右键点击“Reset Current Branch to Here” 4.在弹出框选中“Mixed”，然后点”Reset”然后就会提示你success。然后代码就可以Revert或者在此基础上做修改了。 idea中的做法21.右键-&gt;get-&gt;Show History，列出所有的提交记录。2.选中要回退到的提交记录，右键“Copy Reversion Number”3.Git-&gt;Repository-&gt;Rest HEAD4.在弹出框中“To Commit”中填入刚刚复制的版本号，然后可以点下”Validate“来看下你是不是要回退到这个版本号。5.Reset Type选择Mixed，然后点Reset6.此时代码回退到了你复制的这个版本号执行git add 操作的状态，你可以修改或者提交。 使用git命令1.使用git log得到提交记录，然后复制你要回退到的版本号commit_id。2.执行git reset --mixed commit_id3.然后代码此时的状态在暂存区，即刚刚执行git add操作。这样你就可以Revert或者在此基础上做修改了。 关于git 回退几种模式的区别工作区 － 暂存区 － 本地仓库代码编写及修改是在工作区git add 将本地修改添加到暂存区git commit 将暂存区中的内容提交到本地仓库 hard模式三者的改变全都丢失，即代码的修改内容丢失 soft模式回退到git commit之前，此时处在暂存区。（即执行git add 命令后） mixed模式就等于 git reset HEAD 回退到工作去，即git add 之前。默认是mixed模式。参考：https://www.jianshu.com/p/2956652d32fa 参考：https://blog.csdn.net/qq_22638399/article/details/80847205]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐一个日志工具类]]></title>
    <url>%2F2019%2F01%2F16%2F%E6%8E%A8%E8%8D%90%E4%B8%80%E4%B8%AA%E6%97%A5%E5%BF%97%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[任何系统都少不了日志记录，方便了解系统运行情况，也为了方便排查问题。我们通常会在需要记录日志的类中定义一个Logger，如下代码：1private Logger logger = Logger.getLogger(NodeService.class); 但是在每个类中都这样定义一个Logger，工作量比较大，很繁琐。而且如果你用的Log4j，你后续想改成其他的日志实现，可能logger的定义都需要改，这就是一个很大的工作量了。所以为了少写代码，也为了维护方便，有必要定义一个日志工具类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * Created by Administrator on 2017/5/23. */public final class LoggerUtils &#123; /** * 是否开启Debug */ public static boolean isDebug = org.slf4j.LoggerFactory.getLogger(LoggerUtils.class).isDebugEnabled(); /** * Debug 输出 * @param clazz 目标.Class * @param message 输出信息 */ public static void debug(Class&lt;? extends Object&gt; clazz ,String message)&#123; if(!isDebug)return ; Logger logger = LoggerFactory.getLogger(clazz); logger.debug(message); &#125; /** * Debug 输出 * @param clazz 目标.Class * @param fmtString 输出信息key * @param values 输出信息value */ public static void fmtDebug(Class&lt;? extends Object&gt; clazz,String fmtString,Object...values)&#123; fmtDebug(clazz,null,fmtString,values); &#125; /** * Debug 输出 * @param clazz 目标.Class * @param fmtString 输出信息key * @param values 输出信息value */ public static void fmtDebug(Class&lt;? extends Object&gt; clazz,Exception e,String fmtString,Object...values)&#123; if(!isDebug)return ; if(StringUtils.isBlank(fmtString))&#123; return ; &#125; Logger logger = LoggerFactory.getLogger(clazz); if (e != null) &#123; if (values != null) &#123; logger.debug(fmtString,values,e); return; &#125; logger.debug(fmtString,e); &#125; else &#123; if (values != null) &#123; logger.debug(fmtString,values); return; &#125; logger.debug(fmtString); &#125; &#125; /** * Error 输出 * @param clazz 目标.Class * @param message 输出信息 * @param e 异常类 */ public static void error(Class&lt;? extends Object&gt; clazz ,String message,Exception e)&#123; Logger logger = LoggerFactory.getLogger(clazz); if(null == e)&#123; logger.error(message); return ; &#125; logger.error(message, e); &#125; /** * Error 输出 * @param clazz 目标.Class * @param message 输出信息 */ public static void error(Class&lt;? extends Object&gt; clazz ,String message)&#123; error(clazz, message, null); &#125; /** * 异常填充值输出 * @param clazz 目标.Class * @param fmtString 输出信息key * @param e 异常类 * @param values 输出信息value */ public static void fmtError(Class&lt;? extends Object&gt; clazz,Exception e,String fmtString,Object...values)&#123; if(StringUtils.isBlank(fmtString))&#123; return ; &#125; Logger logger = LoggerFactory.getLogger(clazz); if (e != null) &#123; if (values != null) &#123; logger.error(fmtString,values,e); return; &#125; logger.error(fmtString,e); &#125; else &#123; if (values != null) &#123; logger.error(fmtString,values); return; &#125; logger.error(fmtString); &#125; &#125; /** * 异常填充值输出 * @param clazz 目标.Class * @param fmtString 输出信息key * @param values 输出信息value */ public static void fmtError(Class&lt;? extends Object&gt; clazz, String fmtString, Object...values) &#123; if(StringUtils.isBlank(fmtString))&#123; return ; &#125; fmtError(clazz, null,fmtString,values); &#125; /** * Error 输出 * @param clazz 目标.Class * @param message 输出信息 * @param e 异常类 */ public static void info(Class&lt;? extends Object&gt; clazz ,String message,Exception e)&#123; Logger logger = LoggerFactory.getLogger(clazz); if(null == e)&#123; logger.info(message); return ; &#125; logger.info(message, e); &#125; /** * Error 输出 * @param clazz 目标.Class * @param message 输出信息 */ public static void info(Class&lt;? extends Object&gt; clazz ,String message)&#123; info(clazz, message, null); &#125; /** * 异常填充值输出 * @param clazz 目标.Class * @param fmtString 输出信息key * @param e 异常类 * @param values 输出信息value */ public static void fmtInfo(Class&lt;? extends Object&gt; clazz,Exception e,String fmtString,Object...values)&#123; if(StringUtils.isBlank(fmtString))&#123; return ; &#125; Logger logger = LoggerFactory.getLogger(clazz); if (values != null) &#123; if (e != null) &#123; logger.info(fmtString,values,e); return; &#125; logger.info(fmtString,values); &#125; else &#123; if (e != null) &#123; logger.info(fmtString,e); return; &#125; logger.info(fmtString); &#125; &#125; /** * 异常填充值输出 * @param clazz 目标.Class * @param fmtString 输出信息key * @param values 输出信息value */ public static void fmtInfo(Class&lt;? extends Object&gt; clazz, String fmtString, Object...values) &#123; if(StringUtils.isBlank(fmtString))&#123; return ; &#125; fmtInfo(clazz, null,fmtString,values); &#125;&#125; 这里使用的log4j，配置文件如下：12345678910111213141516171819202122232425log4j.rootLogger=info,stdout,ROLLING_FILE# SqlMap logging configuration...log4j.logger.com.ibatis=ERRORlog4j.logger.com.ibatis.common.jdbc.SimpleDataSource=ERRORlog4j.logger.com.ibatis.common.jdbc.ScriptRunner=ERRORlog4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=ERRORlog4j.logger.java.sql.Connection=ERRORlog4j.logger.org.apache=ERRORlog4j.logger.org.springframework=info# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d [%-5p] %c %x - %m%n#log4j.appender.stdout.Encoding=GBK# RollingFile output...log4j.appender.ROLLING_FILE=org.apache.log4j.RollingFileAppenderlog4j.appender.ROLLING_FILE.File=/usr/log/snatchRolling.loglog4j.appender.ROLLING_FILE.Append=truelog4j.appender.ROLLING_FILE.MaxFileSize=100MBlog4j.appender.ROLLING_FILE.MaxBackupIndex=10log4j.appender.ROLLING_FILE.layout=org.apache.log4j.PatternLayoutlog4j.appender.ROLLING_FILE.layout.ConversionPattern=%d [%-5p] %c %x - %m%n 使用就很简单了，在需要记录日志的类中使用LoggerUtils.info/debug/error即可，同时该日志工具类也是支持格式化的。即LoggerUtils中的fmtXXX方法.12345678910LoggerUtils.info(LoggerUtils.class,"hello");LoggerUtils.info(LoggerUtils.class,"hello",new NullPointerException("null"));LoggerUtils.fmtInfo(LoggerUtils.class,"hello &#123;&#125;","world");LoggerUtils.error(LoggerUtils.class,"hello");LoggerUtils.error(LoggerUtils.class,"hello",new NullPointerException("null1"));try &#123; int i= 1 / 0;&#125; catch (Exception e) &#123; LoggerUtils.fmtError(LoggerUtils.class,e,"error &#123;&#125;,22",122);&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用maven的mybatis-generator插件生成代码]]></title>
    <url>%2F2018%2F12%2F13%2F%E4%BD%BF%E7%94%A8maven%E7%9A%84mybatis-generator%E6%8F%92%E4%BB%B6%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[在有了数据库表结构后，我们可以使用maven的mybatis-generator插件来自动生成Mapper、实体类和DAO。 1.配置mybatis-generator插件打开项目的pom.xml文件，在&lt;plugins&gt;中增加mybatis-generator的plugin。123456789101112131415161718192021222324252627282930313233343536&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;!--指定mybatis-generator配置文件的位置--&gt; &lt;configurationFile&gt;src/main/resources/mybatis-generator.xml&lt;/configurationFile&gt; &lt;!--允许移动生成的文件--&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;!--允许覆盖文件--&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;mybatis generator&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--依赖 如果这里不写 可以在mybatis-generator的配置文件指定 一般在这里指定--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.46&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt;&lt;/plugins&gt; 2.编写mybatis-generator的配置文件mybatis-generator.xml：123456789101112131415161718192021222324252627282930313233343536&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;!-- 数据库驱动包位置 --&gt; &lt;!-- 由于在pom.xml中加入插件时已经配置数据库驱动包，所以此处不必配置了--&gt; &lt;!-- &lt;classPathEntry location="D:\generator\mysql-connector-java-5.1.34.jar" /&gt; --&gt; &lt;!--&lt;classPathEntry location="E:\Database\Oracle\jdbc\lib\ojdbc14.jar" /&gt;--&gt; &lt;context id="DB2Tables" targetRuntime="MyBatis3"&gt; &lt;commentGenerator&gt; &lt;property name="suppressAllComments" value="true" /&gt; &lt;/commentGenerator&gt; &lt;!-- 数据库链接URL、用户名、密码 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost:3306/miaosha?characterEncoding=utf8" userId="root" password="123456"&gt; &lt;!--&lt;jdbcConnection driverClass="oracle.jdbc.driver.OracleDriver" connectionURL="jdbc:oracle:thin:@localhost:orcl" userId="scott" password="tiger"&gt;--&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name="forceBigDecimals" value="false" /&gt; &lt;/javaTypeResolver&gt; &lt;!-- 生成模型的包名和位置 --&gt; &lt;javaModelGenerator targetPackage="com.tommy.dataobject" targetProject="src/main/java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;property name="trimStrings" value="true" /&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成的映射文件包名和位置 --&gt; &lt;sqlMapGenerator targetPackage="mapper" targetProject="src/main/resources/"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 生成DAO的包名和位置 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.tommy.dao" targetProject="src/main/java"&gt; &lt;property name="enableSubPackages" value="true" /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 要生成那些表(更改tableName和domainObjectName就可以) --&gt; &lt;table tableName="user_info" domainObjectName="UserInfo" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false" /&gt; &lt;table tableName="user_password" domainObjectName="UserPassword" enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false" /&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; mybatis-generator的详细配置说明，可以参考：https://www.jianshu.com/p/e09d2370b796 执行mybatis-generator的generate生成代码执行mybatis-generator的generate： 执行完毕后，工程中就多出了Mapper、实体类和DAO。 最后给一些小技巧： a) 建表时，字段名称建议用”_”分隔多个单词，比如:AWB_NO、REC_ID…，这样生成的entity，属性名称就会变成漂亮的驼峰命名，即：awbNo、recId b)oracle中，数值形的字段，如果指定精度，比如Number(12,2)，默认生成entity属性是BigDecimal型 ，如果不指定精度，比如:Number(9)，指默认生成的是Long型 c)oracle中的nvarchar/nvarchar2，mybatis-generator会识别成Object型，建议不要用nvarchar2，改用varchar2 参考：https://www.cnblogs.com/yjmyzz/p/4210554.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>maven</tag>
        <tag>mybatis-generator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven私服（nexus）搭建]]></title>
    <url>%2F2018%2F12%2F01%2Fmaven%E7%A7%81%E6%9C%8D%EF%BC%88nexus%EF%BC%89%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[一、为何要搭建maven私服1.有的公司开发电脑没法直接连外网，下载不了依赖；可以通过私服（私服服务器可以连接），开发电脑连接私服服务器下载依赖。2.项目协作。某个项目包含多个模块，开发人员A将模块打包提交到私服，其他人从私服获取该模块的依赖。 二、使用私服与不使用的区别1.不使用私服2.使用私服. 三、下载和安装nexus1.从https://www.sonatype.com/download-sonatype-trial选择给定系统下载。2.将下载的压缩包解压，得到2个目录。如图： 3.【非必须】修改端口（默认端口是8081，根据需要修改）打开nexus-2.5.1-bundle\nexus-2.5.1-01\conf\nexus.properties文件，修改端口 4.安装nexus服务进入到\nexus-2.5.1-bundle\nexus-2.5.1-01\bin\jsw\windows-x86-64（根据自己的系统选择）目录，执行install-nexus.bat来安装服务。安装后，在服务中科院看到nexus服务 5.【非必须】如果有中央仓库的索引文件，可以丢到下面的目录（先清空原有内容）索引文件位置：\nexus-2.5.1-bundle\sonatype-work\nexus\indexer\central-ctx，有了索引文件后，在nexus服务启动后，可以根据artifact id查找依赖。 6.启动nexus服务进入到\nexus-2.5.1-bundle\nexus-2.5.1-01\bin\jsw\windows-x86-64（根据自己系统选择），双击start-nexus.bat，直到窗口消失即启动成功。 7.浏览器输入http://localhost:8081/nexus即进入nexus的管理页面。点击右上角的“Log In”，输入用户名：admin，密码：admin123登录。 8.登录后，可以看到有如下的Repository 其中Central是中央仓库，Releases是自己开发的项目的发布仓库（release版本），Snapshots是快照版本仓库（一般开发环境开发项目的版本，比如我们新建的maven项目默认是0.0.1.SNAPSHOT），如果将它发布到仓库中，即是发布在Snapshots仓库。3rd parth是第三方的仓库。Public Repositories是我们下载依赖需要使用的仓库，在它的Configuration可以看到它包含了其他所有的仓库。 四、使用maven连接nexus私服1.指定本地仓库的位置打开%MAVEN_HOME%/conf/settings.xml文件，找到，修改本地仓库路径，默认是${user.home}/.m2/repository（在C盘，如果C盘空间紧张，可以指定其他位置）1.打开%MAVEN_HOME%/conf/settings.xml文件，找到增加一个mirror。123456&lt;mirror&gt; &lt;id&gt;Nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Team Nexus Repository&lt;/name&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public/&lt;/url&gt;&lt;/mirror&gt; 这里配置的url就是Public Repository的地址。因为它包含了其他的仓库。 3.配置阿里云的仓库(可以在nexus新增一个阿里云的repository)由于网络问题，可能有些依赖无法下载，或者下载速度很慢。我们可以使用阿里云的仓库来解决这个问题。我们在%MAVEN_HOME%/conf/settings.xml中增加一个阿里云的mirror，如下：123456&lt;mirror&gt; &lt;id&gt;Aliyun-Nexus&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Aliyun Nexus Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; 注意：这里配置为central，不要配置为*。如果有网络，可以按照上面的配置，每个人在自己的maven的settings.xml中增加上面的镜像即可。如果没有网络，可以在nexus中新增一个repository，repository type为：proxy。Url=http://maven.aliyun.com/nexus/content/groups/public/。2.IDE配置maven的路径和user settings file然后，在Public Repositories中，将阿里云的仓库移到central的前面，这样就会先从阿里云的仓库下载依赖，而不是maven中央仓库。不过，配置之后发现没法使用。访问阿里云的仓库url，提示然后访问https://maven.aliyun.com，里面有最新的仓库地址：不过，配置了仍然没有成功。不过配置到maven的settings.xml的中是OK的。 4.新建一个测试项目mytest，它依赖了spring-jdbc，版本为5.1.3.RELEASE。我们在pom.xml增加此依赖保存后，可以看到是通过阿里云仓库下载的。 五、将项目上传到nexus现在，假定需要将项目发布到nexus私服，该怎么做呢？ 1.打开项目的pom.xml,增加下面的配置12345678910&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/releases&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/snapshots&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 配置的内容在nexus的releases和snapshots的Summary中可以看到 2.配置%MAVEN_HOME%/conf/settings.xml，找到&lt;servers&gt;标签，增加nexus私服用户名和密码的配置。12345678910&lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; 注意：这里的id必须与&lt;distributionManagement&gt;中的repostory id一致。 3.在项目执行mvn:deploy命令即可。Eclipse：项目右键run as Maven Build，然后goal输入deploy，确定即可。 我们可以看到，项目被上传到了snapshots中，因为我们的项目版本为0.0.1.SNAPSHOTS，所以上传到了snapshots。然后我们在nexus的Snapshots仓库的Brown Index可以看到刚刚发布的包 我们将项目的版本号改为0.0.1，重新执行deploy，会发现发布到了nexus的releases仓库。 六、问题记录1.启动nexus失败，提示“The nexus service was launched, but failed to start.”我们可以在\nexus-2.5.1-bundle\nexus-2.5.1-01\logs\wrapper.log查看具体的错误信息。 我这里的问题是：我电脑安装了jdk7和jdk8，环境变量配置的是jdk8.我的nexus版本是2.5.1，它应该使用jdk7.找到\nexus-2.5.1-bundle\nexus-2.5.1-01\bin\jsw\conf\wrapper.conf，打开文件并搜索“wrapper.java.command=”，然后将wrapper.java.command设置为jdk7的执行路径。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UrlRewrite的配置与使用]]></title>
    <url>%2F2018%2F11%2F21%2FUrlRewrite%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[UrlRewrite就是我们通常说的地址重写，用户得到的全部都是经过处理后的URL地址。 优点一：提高安全性，可以有效的避免一些参数名、ID等完全暴露在用户面前，如果用户随便乱输的话，不符合规则的话直接会返回个404或错误页面，这比直接返回500或一大堆服务器错误信息要好的多 二：美化URL，去除了那些比如*.do之类的后缀名、长长的参数串等，可以自己组织精简更能反映访问模块内容的URL三：更有利于搜索引擎的收入，通过对URL的一些优化，可以使搜索引擎更好的识别与收录网站的信息 四：可以很方便的重用，提高网站的移植性。如果我们后台方法改动的话，可以保证前台的页面部分不用改。这样就提高了网站的移植性。缺点： 因为它是通过过滤器原理来实现的，就意味着又多了一道访问，会多少影响点访问速度的，这个可以忽略不计的。 使用范围地址重写一般是用于将动态地址伪静态。如果本身就是静态就没必要了。地址重写后网站制作者可以通过输入地址名直接访问。 springboot集成UrlRewrite添加maven依赖12345&lt;dependency&gt; &lt;groupId&gt;org.tuckey&lt;/groupId&gt; &lt;artifactId&gt;urlrewritefilter&lt;/artifactId&gt; &lt;version&gt;4.0.4&lt;/version&gt;&lt;/dependency&gt; 配置UrlRewrite过滤器12345678910111213@Configurationpublic class UrlRewriteFilterConfig &#123; @Bean public FilterRegistrationBean urlRewriteFilterRegistration () &#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(); filterRegistrationBean.setFilter(new org.tuckey.web.filters.urlrewrite.UrlRewriteFilter()); filterRegistrationBean.addUrlPatterns("/*"); filterRegistrationBean.addInitParameter("confPath", "WEB-INF/urlrewrite.xml"); filterRegistrationBean.addInitParameter("logLevel","INFO"); return filterRegistrationBean; &#125;&#125; 编写规则文件/WEB-INF/urlrewrite.xml 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;!DOCTYPE urlrewrite PUBLIC "-//tuckey.org//DTD UrlRewrite 2.6//EN" "http://tuckey.org/res/dtds/urlrewrite2.6.dtd"&gt;&lt;!-- Configuration file for UrlRewriteFilter http://tuckey.org/urlrewrite/ --&gt;&lt;urlrewrite&gt; &lt;rule&gt; &lt;note&gt;测试页面1&lt;/note&gt; &lt;from&gt;/sk.html&lt;/from&gt; &lt;to&gt;/urlrewritedemo/test1?tab=4&lt;/to&gt; &lt;/rule&gt; &lt;rule&gt; &lt;note&gt;测试页面2&lt;/note&gt; &lt;from&gt;/match_([-_A-Za-z0-9]+).html&lt;/from&gt; &lt;to&gt;/urlrewritedemo/getMatchByDate?tab=1&amp;amp;date=$1&lt;/to&gt; &lt;/rule&gt;&lt;/urlrewrite&gt; 我们配置了2条规则，from定义请求url，to定义对应的后台的请求url。可以结合正则表达式来实现复杂的url重写。 示例： 常用的&amp;要用 &amp;amp;来表示。$1,$2代表与你配置正规表达式/(\w+)/(\w+)/相对应的参数。 &lt;to type=&quot;forward&quot;&gt;中的type有两个值，默认的是 type=&quot;forward&quot;.连接外部的网站时用type=&quot;redirect&quot;。 参考：UrlRewrite 的配置和使用总结]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>UrlRewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux更新或删除jar中的文件]]></title>
    <url>%2F2018%2F11%2F21%2FLinux%E6%9B%B4%E6%96%B0%E6%88%96%E5%88%A0%E9%99%A4jar%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[增加/更新目录或文件如果用springboot将所有东西打成一个jar，要更新某个文件，再打包上传就很麻烦了。所以这个时候就需要将某个文件打到jar中。1jar uvf demo-0.0.1-SNAPSHOT.jar BOOT-INF/ 上面的命令是将BOOT-INF/目录下的所有目录和文件覆盖到demo-0.0.1-SNAPSHOT.jar中。也就是，如果demo-0.0.1-SNAPSHOT.jar中有某个文件，那么该文件会被覆盖，如果没有则会添加进去。 删除目录或文件17za d demo-0.0.1-SNAPSHOT.jar BOOT-INF/classes/mapper/IndexMapper.xml 上面的命令是从demo-0.0.1-SNAPSHOT.jar中删除IndexMapper.xml文件。该文件的位置是BOOT-INF/classes/mapper/IndexMapper.xml（jar包中的位置）。 注意：使用此命令，需要先安装7z。 安装方法：sudo yum install p7zip 参考：linux下安装7z命令及7z命令的使用、Jar命令+7z：创建，替换，修改，删除Jar, war, ear包中的文件]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Boxcryptor加密你的云盘]]></title>
    <url>%2F2018%2F11%2F15%2F%E4%BD%BF%E7%94%A8Boxcryptor%E5%8A%A0%E5%AF%86%E4%BD%A0%E7%9A%84%E4%BA%91%E7%9B%98%2F</url>
    <content type="text"><![CDATA[前言现在云盘大家都不陌生，有的人手好几个。经过上一次云盘的事件，目前剩下的也不多了。目前百度云、腾讯微云、天翼云盘、坚果云是用的比较多的。国外的云盘咱们就不讨论了，毕竟要翻墙，速度没保障。 在这些云盘中，百度云有2T的免费空间，基本一些大的视频或文件会存储在百度云。腾讯微云、天翼云空间也只有几G到10多G，对上传下载有限制，所以用的不多。最后一个要提到的就是坚果云，老实说因为不像其他3个云盘服务提供商都是大公司，所以心里没底。不过服务说实在的还是不错的。坚果云其实是一个同步工具，可以对指定的目录（可以随意指定多个）进行同步，同步的速度也很快，增量同步。它没有空间的限制，不过免费用户每个月上传流量1G，下载流量3G。如果只是基于办公需求已经足够。不过，使用云盘就不免担心个人隐私数据会不会被其他人看到。所以这里要介绍的就是如何加密你的云盘，上传到云盘上的数据都是经过加密的，只有你能解密。这里要介绍的是使用Boxcryptor加密存储在坚果云上的文件/目录。为什么是坚果云？因为它是目前国内唯一支持WebDAV协议的。下面废话不多说，说一说怎么加密数据到云盘。 PC客户端安装与配置从https://www.boxcryptor.com/en/download/下载PC客户端软件，下载完成后安装，一步一步直到完成即可。 下一步，注册账号 下一步，设置你的需要加密的文件夹路径 注意：这个路径必须是你坚果云同步目录中，这样坚果云才会把这个目录同步。 BoxCryptor会生成一个虚拟磁盘，双击打开即进入到你设置的目录。 打开这个虚拟磁盘，你就可以随意创建文件或目录，创建时会提示你是否加密，你可以选择加密也可以不加密。如果不加密那么你就可以直接在坚果云上查看该目录或文件。如果选择加密，对于文件Boxcryptor会自动在文件名后加.bc后缀。如果你打开带.bc后缀的文件，其实它是乱码显示的。 如果你要查看，在这台电脑，在Boxcryptor的虚拟磁盘，你打开就可以查看文件内容。 在其他机器上如何查看加密的内容？安装和配置客户端，登录即可。 移动端Boxcryptor有手机客户端，这里以iPhone为例，在AppStore查找boxcryptor，然后下载（免费）。PC端加密过的坚果云文件在其他设备查看都是需要安装Boxcryptor才可以访问，相当于Boxcryptor对这些文件上了一把锁，想要查看都是需要再通过Boxcryptor来进行解锁，移动端使用和电脑端有些区别，需要使用webDAV连接到坚果云，获取文件。 1、 打开你的坚果云网页端登录后查看账户信息-安全选项里，第三方应用管理处即可添加你的应用密码；或者坚果云手机端，iOS是在更多-第三方应用管理；安卓在设置-第三方应用管理。 2、在手机端安装登录后，在Files界面，选择最下方的WebDAV Advanced，与坚果云进行连接。 3、按照你的坚果云第三方应用管理里的信息，分别填写账号、应用密码、服务器地址，即可查看和访问坚果云里的加密文件。 搭建私有云用公有云总觉得不安全，数据在别人的服务器上。如果有这个担心，除了上面对文件加密上传外，还可以搭建私有云。参考：搭建私有云：OwnCloud、vps搭建owncloud 参考：如何使用Boxcryptor加密坚果云文件？]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>Boxcryptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用spring validation完成数据后端校验]]></title>
    <url>%2F2018%2F11%2F10%2F%E4%BD%BF%E7%94%A8spring%20validation%E5%AE%8C%E6%88%90%E6%95%B0%E6%8D%AE%E5%90%8E%E7%AB%AF%E6%A0%A1%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[前言数据的校验是交互式网站一个不可或缺的功能，前端的js校验可以涵盖大部分的校验职责，如用户名唯一性，生日格式，邮箱格式校验等等常用的校验。但是为了避免用户绕过浏览器，使用http工具直接向后端请求一些违法数据，服务端的数据校验也是必要的，可以防止脏数据落到数据库中，如果数据库中出现一个非法的邮箱格式，也会让运维人员头疼不已。我在之前保险产品研发过程中，系统对数据校验要求比较严格且追求可变性及效率，曾使用drools作为规则引擎，兼任了校验的功能。而在一般的应用，可以使用本文将要介绍的validation来对数据进行校验。简述JSR303/JSR-349，hibernate validation，spring validation之间的关系。JSR303是一项标准,JSR-349是其的升级版本，添加了一些新特性，他们规定一些校验规范即校验注解，如@Null，@NotNull，@Pattern，他们位于javax.validation.constraints包下，只提供规范不提供实现。而hibernate validation是对这个规范的实践（不要将hibernate和数据库orm框架联系在一起），他提供了相应的实现，并增加了一些其他校验注解，如@Email，@Length，@Range等等，他们位于org.hibernate.validator.constraints包下。而万能的spring为了给开发者提供便捷，对hibernate validation进行了二次封装，显示校验validated bean时，你可以使用spring validation或者hibernate validation，而spring validation另一个特性，便是其在springmvc模块中添加了自动校验，并将校验信息封装进了特定的类中。这无疑便捷了我们的web开发。本文主要介绍在springmvc中自动校验的机制。 引入依赖我们使用maven构建springboot应用来进行demo演示。123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 我们只需要引入spring-boot-starter-web依赖即可，如果查看其子依赖，可以发现如下的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;/dependency&gt; 验证了我之前的描述，web模块使用了hibernate-validation，并且databind模块也提供了相应的数据绑定功能。 构建启动类无需添加其他注解，一个典型的启动类1234567@SpringBootApplicationpublic class ValidateApp &#123; public static void main(String[] args) &#123; SpringApplication.run(ValidateApp.class, args); &#125;&#125; 创建需要被校验的实体类class Foo &#123;1234567891011121314151617 @NotBlank private String name; @Min(18) private Integer age; @Pattern(regexp = &quot;^1(3|4|5|7|8)\\d&#123;9&#125;$&quot;,message = &quot;手机号码格式错误&quot;) @NotBlank(message = &quot;手机号码不能为空&quot;) private String phone; @Email(message = &quot;邮箱格式错误&quot;) private String email; //... getter setter&#125; 使用一些比较常用的校验注解，还是比较浅显易懂的，字段上的注解名称即可推断出校验内容，每一个注解都包含了message字段，用于校验失败时作为提示信息，特殊的校验注解，如Pattern（正则校验），还可以自己添加正则表达式。 在@Controller中校验数据springmvc为我们提供了自动封装表单参数的功能，一个添加了参数校验的典型controller如下所示。123456789101112131415@Controllerpublic class FooController &#123; @RequestMapping("/foo") public String foo(@Validated Foo foo &lt;1&gt;, BindingResult bindingResult &lt;2&gt;) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return "fail"; &#125; return "success"; &#125;&#125; 值得注意的地方： 参数Foo前需要加上@Validated注解，表明需要spring对其进行校验，而校验的信息会存放到其后的BindingResult中。注意，必须相邻，如果有多个参数需要校验，形式可以如下。foo(@Validated Foo foo, BindingResult fooBindingResult ，@Validated Bar bar, BindingResult barBindingResult);即一个校验类对应一个校验结果。 校验结果会被自动填充，在controller中可以根据业务逻辑来决定具体的操作，如跳转到错误页面。 一个最基本的校验就完成了，总结下框架已经提供了哪些校验： 12345678910111213141516171819202122JSR提供的校验注解： @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator提供的校验注解： @NotBlank(message =) 验证字符串非null，且长度必须大于0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 校验实验我们对上面实现的校验入口进行一次测试请求：访问http://localhost:8080/foo?name=xujingfeng&amp;email=000&amp;age=19可以得到如下的debug信息： 实验告诉我们，校验结果起了作用。并且，可以发现当发生多个错误，spring validation不会在第一个错误发生后立即停止，而是继续试错，告诉我们所有的错误。debug可以查看到更多丰富的错误信息，这些都是spring validation为我们提供的便捷特性，基本适用于大多数场景。 你可能不满足于简单的校验特性，下面进行一些补充。 分组校验如果同一个类，在不同的使用场景下有不同的校验规则，那么可以使用分组校验。未成年人是不能喝酒的，而在其他场景下我们不做特殊的限制，这个需求如何体现同一个实体，不同的校验规则呢？ 改写注解，添加分组：123456789Class Foo&#123; @Min(value = 18,groups = &#123;Adult.class&#125;) private Integer age; public interface Adult&#123;&#125; public interface Minor&#123;&#125;&#125; 这样表明，只有在Adult分组下，18岁的限制才会起作用。 Controller层改写：123456789101112131415161718192021@RequestMapping("/drink")public String drink(@Validated(&#123;Foo.Adult.class&#125;) Foo foo, BindingResult bindingResult) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return "fail"; &#125; return "success";&#125;@RequestMapping("/live")public String live(@Validated Foo foo, BindingResult bindingResult) &#123; if(bindingResult.hasErrors())&#123; for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; //... &#125; return "fail"; &#125; return "success";&#125; drink方法限定需要进行Adult校验，而live方法则不做限制。 自定义校验业务需求总是比框架提供的这些简单校验要复杂的多，我们可以自定义校验来满足我们的需求。自定义spring validation非常简单，主要分为两步。 1 自定义校验注解我们尝试添加一个“字符串不能包含空格”的限制。123456789101112131415161718192021222324@Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER&#125;)@Retention(RUNTIME)@Documented@Constraint(validatedBy = &#123;CannotHaveBlankValidator.class&#125;)&lt;1&gt;public @interface CannotHaveBlank &#123; //默认错误消息 String message() default "不能包含空格"; //分组 Class&lt;?&gt;[] groups() default &#123;&#125;; //负载 Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; //指定多个时使用 @Target(&#123;FIELD, METHOD, PARAMETER, ANNOTATION_TYPE&#125;) @Retention(RUNTIME) @Documented @interface List &#123; CannotHaveBlank[] value(); &#125;&#125; 我们不需要关注太多东西，使用spring validation的原则便是便捷我们的开发，例如payload，List ，groups，都可以忽略。 自定义注解中指定了这个注解真正的验证者类。 2 编写真正的校验者类123456789101112131415161718192021222324public class CannotHaveBlankValidator implements &lt;1&gt; ConstraintValidator&lt;CannotHaveBlank, String&gt; &#123; @Override public void initialize(CannotHaveBlank constraintAnnotation) &#123; &#125; @Override public boolean isValid(String value, ConstraintValidatorContext context &lt;2&gt;) &#123; //null时不进行校验 if (value != null &amp;&amp; value.contains(" ")) &#123; &lt;3&gt; //获取默认提示信息 String defaultConstraintMessageTemplate = context.getDefaultConstraintMessageTemplate(); System.out.println("default message :" + defaultConstraintMessageTemplate); //禁用默认提示信息 context.disableDefaultConstraintViolation(); //设置提示语 context.buildConstraintViolationWithTemplate("can not contains blank").addConstraintViolation(); return false; &#125; return true; &#125;&#125; 所有的验证者都需要实现ConstraintValidator接口，它的接口也很形象，包含一个初始化事件方法，和一个判断是否合法的方法。123456public interface ConstraintValidator&lt;A extends Annotation, T&gt; &#123; void initialize(A constraintAnnotation); boolean isValid(T value, ConstraintValidatorContext context);&#125; ConstraintValidatorContext 这个上下文包含了认证中所有的信息，我们可以利用这个上下文实现获取默认错误提示信息，禁用错误提示信息，改写错误提示信息等操作。 一些典型校验操作，或许可以对你产生启示作用。 值得注意的一点是，自定义注解可以用在METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER之上，ConstraintValidator的第二个泛型参数T，是需要被校验的类型。 手动校验可能在某些场景下需要我们手动校验，即使用校验器对需要被校验的实体发起validate，同步获得校验结果。理论上我们既可以使用Hibernate Validation提供Validator，也可以使用Spring对其的封装。在spring构建的项目中，提倡使用经过spring封装过后的方法，这里两种方法都介绍下： Hibernate Validation：1234567891011Foo foo = new Foo();foo.setAge(22);foo.setEmail("000");ValidatorFactory vf = Validation.buildDefaultValidatorFactory();Validator validator = vf.getValidator();Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = validator.validate(foo);for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage());&#125; 由于依赖了Hibernate Validation框架，我们需要调用Hibernate相关的工厂方法来获取validator实例，从而校验。 在spring framework文档的Validation相关章节，可以看到如下的描述：12345Spring provides full support for the Bean Validation API. This includes convenient support for bootstrapping a JSR-303/JSR-349 Bean Validation provider as a Spring bean. This allows for a javax.validation.ValidatorFactory or javax.validation.Validator to be injected wherever validation is needed in your application. Use the LocalValidatorFactoryBean to configure a default Validator as a Spring bean:bean id=”validator” class=”org.springframework.validation.beanvalidation.LocalValidatorFactoryBean”The basic configuration above will trigger Bean Validation to initialize using its default bootstrap mechanism. A JSR-303/JSR-349 provider, such as Hibernate Validator, is expected to be present in the classpath and will be detected automatically. 上面这段话主要描述了spring对validation全面支持JSR-303、JSR-349的标准，并且封装了LocalValidatorFactoryBean作为validator的实现。值得一提的是，这个类的责任其实是非常重大的，他兼容了spring的validation体系和hibernate的validation体系，也可以被开发者直接调用，代替上述的从工厂方法中获取的hibernate validator。由于我们使用了springboot，会触发web模块的自动配置，LocalValidatorFactoryBean已经成为了Validator的默认实现，使用时只需要自动注入即可。12345678910111213141516@AutowiredValidator globalValidator; &lt;1&gt;@RequestMapping("/validate")public String validate() &#123; Foo foo = new Foo(); foo.setAge(22); foo.setEmail("000"); Set&lt;ConstraintViolation&lt;Foo&gt;&gt; set = globalValidator.validate(foo);&lt;2&gt; for (ConstraintViolation&lt;Foo&gt; constraintViolation : set) &#123; System.out.println(constraintViolation.getMessage()); &#125; return "success";&#125; 真正使用过Validator接口的读者会发现有两个接口，一个是位于javax.validation包下，另一个位于org.springframework.validation包下，注意我们这里使用的是前者javax.validation，后者是spring自己内置的校验接口，LocalValidatorFactoryBean同时实现了这两个接口。 此处校验接口最终的实现类便是LocalValidatorFactoryBean。 基于方法校验12345678910111213141516171819202122@RestController@Validated &lt;1&gt;public class BarController &#123; @RequestMapping("/bar") public @NotBlank &lt;2&gt; String bar(@Min(18) Integer age &lt;3&gt;) &#123; System.out.println("age : " + age); return ""; &#125; @ExceptionHandler(ConstraintViolationException.class) public Map handleConstraintViolationException(ConstraintViolationException cve)&#123; Set&lt;ConstraintViolation&lt;?&gt;&gt; cves = cve.getConstraintViolations();&lt;4&gt; for (ConstraintViolation&lt;?&gt; constraintViolation : cves) &#123; System.out.println(constraintViolation.getMessage()); &#125; Map map = new HashMap(); map.put("errorCode",500); return map; &#125;&#125; 为类添加@Validated注解 校验方法的返回值和入参 添加一个异常处理器，可以获得没有通过校验的属性相关信息 基于方法的校验，个人不推荐使用，感觉和项目结合的不是很好。 使用校验框架的一些想法理论上spring validation可以实现很多复杂的校验，你甚至可以使你的Validator获取ApplicationContext，获取spring容器中所有的资源，进行诸如数据库校验，注入其他校验工具，完成组合校验（如前后密码一致）等等操作，但是寻求一个易用性和封装复杂性之间的平衡点是我们作为工具使用者应该考虑的，我推崇的方式，是仅仅使用自带的注解和自定义注解，完成一些简单的，可复用的校验。而对于复杂的校验，则包含在业务代码之中，毕竟如用户名是否存在这样的校验，仅仅依靠数据库查询还不够，为了避免并发问题，还是得加上唯一索引之类的额外工作，不是吗？ 原文地址：https://blog.csdn.net/u013815546/article/details/77248003]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合EHCache]]></title>
    <url>%2F2018%2F11%2F07%2FSpringBoot%E6%95%B4%E5%90%88EHCache%2F</url>
    <content type="text"><![CDATA[Spring Cache简介Spring定义了CacheManager和Cache接口统一不同的缓存技术。其中CacheManager是Spring提供的各种缓存技术的抽象接口。而Cache接口包含缓存的各种操作，当然我们一般情况下不会直接操作Cache接口。 Spring针对不同的缓存技术，需要实现不同的cacheManager，Spring定义了如下的cacheManger实现：|CacheManger| 描述||- |:—:||SimpleCacheManager |使用简单的Collection来存储缓存，主要用于测试|ConcurrentMapCacheManager| 使用ConcurrentMap作为缓存技术（默认）|NoOpCacheManager |测试用|EhCacheCacheManager |使用Ehcache作为缓存技术，以前在HIbernate的时候经常用|GuavaCacheManager |使用google guava的GuavaCache作为缓存技术|HazelcastCacheManager |使用Hazelcast作为缓存技术|JCacheCacheManager |使用JCache标准的实现作为缓存技术，如Apache Commons JCS|RedisCacheManager |使用Redis作为缓存技术 常规的SpringBoot已经为我们自动配置了EhCache、Collection、Guava、ConcurrentMap等缓存，默认使用SimpleCacheConfiguration，即使用ConcurrentMapCacheManager。 SpringBoot整合EHCachepom.xml引入spring-boot-starter-cache和ehcache12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt;&lt;/dependency&gt; 配置ehcache.xml123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;ehcache xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ehcache.org/ehcache.xsd&quot; updateCheck=&quot;false&quot;&gt; &lt;diskStore path=&quot;java.io.tmpdir/Tmp_EhCache&quot;/&gt; &lt;defaultCache eternal=&quot;false&quot; maxElementsInMemory=&quot;1000&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;false&quot; timeToIdleSeconds=&quot;0&quot; timeToLiveSeconds=&quot;600&quot; memoryStoreEvictionPolicy=&quot;LRU&quot;/&gt; &lt;cache name=&quot;user&quot; eternal=&quot;false&quot; maxElementsInMemory=&quot;10000&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;false&quot; timeToIdleSeconds=&quot;0&quot; timeToLiveSeconds=&quot;0&quot; memoryStoreEvictionPolicy=&quot;LFU&quot;/&gt;&lt;/ehcache&gt; 需要说明的是，这里maxElementsInMemory属性是必须的。 配置application.yml12345spring: cache: type: ehcache ehcache: config: classpath:config/ehcache.xml 如果ehcache.xml在/resources下，则不用配置spring.cache.ehcache.config。 Spring Boot启动类增加@EnableCaching开启缓存1234567@SpringBootApplication@EnableCachingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 缓存注解说明 @CacheConfig(cacheNames = {“lemonCache”})：设置了ehcache的名称，这个名称就是ehcache.xml内的名称； @Cacheable：应用到读取数据的方法上，即可缓存的方法，如查找方法：先从缓存中读取，如果没有再调 用方法获取数据，然后把数据添加到缓存中，适用于查找； @CachePut：主要针对方法配置，能够根据方法的请求参数对其结果进行缓存，和 @Cacheable 不同的是，它每次都会触发真实方法的调用。适用于更新和插入； @CacheEvict：主要针对方法配置，能够根据一定的条件对缓存进行清空。适用于删除。 示例：1234567891011@CacheConfig(cacheNames = "user")public class UserServiceImpl implements UserService &#123; @Cacheable public UserDO get(String username) &#123; Map&lt;String,Object&gt; map = new HashedMap(1); map.put("username",username); UserDO user = list(map).get(0); return user; &#125;&#125; 与Shiro结合导致缓存不生效的问题基本确定是shiro框架与spring框架的BeanFactory有所冲突，导致注入shiro框架的类不能被spring正确初始化。 在我们自定义的Shiro Realm中注入的Service增加@Lazy。 参考：https://www.cnblogs.com/yueshutong/p/9381558.html 参考：https://www.cnblogs.com/yueshutong/p/9381540.html Spring Cache Key的生成使用Spring EL表达式，自定义生成策略参考：https://www.jianshu.com/p/2a584aaafad3 Spring Cache章节：https://docs.spring.io/spring/docs/5.0.8.RELEASE/spring-framework-reference/integration.html#cacheSpring Boot Cache章节：https://docs.spring.io/spring-boot/docs/2.0.4.RELEASE/reference/html/boot-features-caching.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌浏览器优化]]></title>
    <url>%2F2018%2F11%2F03%2F%E8%B0%B7%E6%AD%8C%E6%B5%8F%E8%A7%88%E5%99%A8%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[谷歌浏览器简约、速度快，但唯一一点太耗内存了。下面就简单说下优化方法。 停掉没用到插件扩展相信很多人安装了一大堆Chrome扩展，但有些扩展并不是经常用到，但会占用内存。我们打开谷歌的任务管理器可以看到： 通过图片可以看到，就截图中的几个插件就占用了几百兆的内存。所以有些插件暂时不用他就把它关闭掉，需要使用时再打开即可。 当然，你也可以打开谷歌的任务管理器将你想关闭的进程关闭。 关闭 Chrome 预读功能Chrome 预读功能可以提高网页打开速度，原理是在用户还没有点击某个链接的时候就已经提前开始加载了。例如会预读下一篇文章的内容，从功能上来说是个不错的体验，但对于内存小的用户来说，是越用越卡。 设置方法：在Chrome浏览器「设置」 → 「高级」，找到「借助联想查询访问，帮你在地址栏中自动填充未输完的搜索字词和网址」和「使用联想查服务更快速加载网页」关闭就可以了。 关闭 Google Chrome 后继续运行后台应用 和 硬件加速 使用Chrome自带的Automatic tab discarding功能当系统可用内存不足时，Automatic tab discarding功能会自动舍弃用户最不关心的标签页。需要指出的是，这里的”舍弃”并不是关闭，而是始终保持开启状态，当用户点击时会重新加载。在Chrome地址栏中输入：chrome://flags/#automatic-tab-discarding，回车后打开Automatic tab discarding功能设置，选择”Enabled”，重启Chrome浏览器就可以开启这个功能。在Chrome地址栏中输入：chrome://discards，回车就可以看到哪些标签页已经被舍弃了。你也可以在这里手动舍弃标签页。 使用The Great Suspender：让暂时不用的chrome标签页休眠节省内存！使用 Chrome 浏览器时开上10几个标签是常有的事，如果再开上更多标签而电脑硬件又过时的话，这时候就会感觉到卡了。The Great Suspender 这个 Chrome 扩展可以让你把不需要的标签进入睡眠模式以节省内存，保证流畅的浏览体验。与另一款标签管理工具 OneTab不同，OneTab是将临时不用的标签页浓缩到保存到一个独立的页面里，这样也能节省资源，也是个不错的选择。The Great Suspender 提供两种休眠方式： 手动休眠、或者一段时间不使用自动休眠。扩展还支持白名单，无论自动休眠还是手动休眠，白名单中的网站是不会休眠的。参考：http://chromecj.com/accessibility/2017-05/749.html 这个也是非常实用的，可以释放大量内存。]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome浏览器截长图]]></title>
    <url>%2F2018%2F11%2F01%2FChrome%E6%B5%8F%E8%A7%88%E5%99%A8%E6%88%AA%E9%95%BF%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[在要截图的页面，按F12，然后按CTRL+SHIFT+P，然后输入cfcs（Capture Full size screenshot），然后回车即可。 然后选择存储位置即可。 参考：https://sspai.com/post/42193]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极简图床+微博图床+github+外链访问]]></title>
    <url>%2F2018%2F11%2F01%2F%E6%9E%81%E7%AE%80%E5%9B%BE%E5%BA%8A%2B%E5%BE%AE%E5%8D%9A%E5%9B%BE%E5%BA%8A%2B%E5%A4%96%E9%93%BE%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[吐槽现在都流行使用markdown写博客，写文章，难免会需要显示图片。以往我们都是将图片上传到网站服务器，然后网站返回一个图片地址。 但是，如果你想搭建自己的博客，没有服务器，还想使用markdown写文章，那么就需要借助一些图床。 极简图床是一款非常方便好用的图床工具，可以绑定七牛云、阿里云OSS，还可以使用微博图床。 我在很早之前就申请了七牛云的测试域名，之前也一直绑定的七牛云，当时最近七牛云通知我测试域名要回收了。没辙只能考虑其他的存储方式了。 其实微博也是有图床功能，访问速度是没的说的，重要的是免费，这里就简单介绍下极简图床中怎么使用微博图床。 极简图床使用微博图床存储图片在极简图床的首页，可以看到Chrome插件的链接 点进去可以看到安装插件的方法以及插件的使用方法。不过这里需要说明的是你在安装好插件后刷新页面，然后在极简图床设置使用微博图床。 使用微博图床，你需要登陆微博。否则上传会提示你登陆微博。 这里建议你使用自己的微博小号去登陆，然后将突图片上传到这个账号的图床。不过要说明的是，其实你登陆自己的账号，在你的微博，相册等等地方都是看不到你上传的图片的。所以，如果就是一般的使用，用自己的微博账号也无所谓了。 微博小号的注册方法：https://jingyan.baidu.com/article/36d6ed1f9484b81bce488342.html 使用就非常简单了。 在首页，你可以截图然后粘贴，即会自动上传；也可以选择文件上传，上传完毕后，可以复制图片地址，也可以复制markdown格式。 还可以采集网络上的图片，不过要绑定七牛云账号？ 在安装好插件后，点一下插件可以看到 打开你想采集图片的网站，按ALT+1，即会自动采集图片，然后选择要保存的图片，点采集即可。 然后在极简图床的我的上传可以看到。 使用新浪微博图床在chrome浏览器添加新浪微博图床的扩展，直接使用新浪微博图床的api。扩展地址：谷歌商店 添加扩展后打开扩展即可以上传图片了。同样支持选择上传或粘贴上传，还包括多种格式的复制。参考：https://51.ruyo.net/2624.html 使用GitHub来做图床更新于2018.12.14 发现微博图床不能使用了，提示必须是新浪用户才能查看，即做了防盗链处理。找了一通，感觉还可以的是这个：https://tu.aixinxi.net/index.php，不过担心哪一天又不能使用了。所以最后找到使用GitHub来托管图片。大概就是在GitHub创建一个repository，然后本地clone仓库，将图片放到仓库，提交到GitHub。然后在GitHub查看图片，复制地址栏的url，将url中的blob替换为raw即可。比如图片：https://github.com/luckystar88/blog_img/blob/master/Snipaste_2018-12-14_11-57-45.png，替换blob为raw后为：https://github.com/luckystar88/blog_img/raw/master/Snipaste_2018-12-14_11-57-45.png，这个地址贴到你的博客即可。 参考：迁移博客图片者的福音：使用GitHub做免费不限流量图床]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse Springboot热部署]]></title>
    <url>%2F2018%2F10%2F27%2FEclipse%20Springboot%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[1.pom.xml增加spring-boot-devtools依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 2.spring-boot-maven-plugin插件配置fork=true1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt;&lt;/plugin&gt; 3.设置自动buildeclipse –&gt; Project –&gt; Build Automatically 要选中，不选中的话不起作用。4.页面热部署设置spring.thymeleaf.cache=false来实现 5.devtools的配置123456#热部署生效spring.devtools.restart.enabled: true#设置重启的目录#spring.devtools.restart.additional-paths: src/main/java#classpath目录下的WEB-INF文件夹内容修改不重启spring.devtools.restart.exclude: WEB-INF/** 6.解决js无法动态更新的问题1&lt;script type=&quot;text/javascript&quot; src=&quot;/js/appjs/system/sysDept/sysDept.js?ver=1&quot;&gt;&lt;/script&gt; 即增加?ver=1参考：http://www.cnblogs.com/TBhome/archive/2017/09/08/7493473.html 7.测试 修改类–&gt;保存：应用会重启 修改配置文件–&gt;保存：应用会重启 修改页面–&gt;保存：应用不会重启，但会重新加载，页面会刷新（原理是将spring.thymeleaf.cache设为false，参考:Spring Boot配置模板引擎） 参考：https://blog.csdn.net/liben0429/article/details/79011775、https://www.cnblogs.com/cx-code/p/8686453.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>eclipse</tag>
        <tag>STS</tag>
        <tag>热部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用MapStruct在实体间转换]]></title>
    <url>%2F2018%2F10%2F27%2F%E4%BD%BF%E7%94%A8MapStruct%E5%9C%A8%E5%AE%9E%E4%BD%93%E9%97%B4%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[简介MapStruct是一个代码生成器的工具类，简化了不同的Java Bean之间映射的处理，所以映射指的就是从一个实体变化成一个实体。在实际项目中，我们经常会将PO转DTO、DTO转PO等一些实体间的转换。在转换时大部分属性都是相同的，只有少部分的不同，这时我们可以通过mapStruct的一些注解来匹配不同属性，可以让不同实体之间的转换变的简单。使用MapStruct在编译时会生成响应的转换实现类，所以没有性能损耗。MapStruct官网地址： http://mapstruct.org/ 搭建开发环境 –基于Maven这里需要在配置文件pom.xml中进行如下配置：123456789101112131415161718192021222324252627282930313233343536373839404142434445...&lt;properties&gt; &lt;!-- &lt;org.mapstruct.version&gt;1.1.0.Beta1&lt;/org.mapstruct.version&gt;--&gt; &lt;org.mapstruct.version&gt;1.1.0.Final&lt;/org.mapstruct.version&gt;&lt;/properties&gt;...&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-jdk8&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt;--&gt; &lt;/dependency&gt; &lt;/dependencies&gt;...&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;annotationProcessorPaths&gt; &lt;path&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/path&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;... MapStruct实体间的转换下面我们就来看看如何使用MapStruct实现实体之间的映射转换。下面两个类非常相似，有一个号码属性名不一样及在PeopleDTO中有个User对象，而在People中则是两个字符串属性。 PeopleEntity.java12345678910public class PeopleEntity &#123; private Integer age; private String name; private String callNumber; private String address; private String emile; //constructor, getters, setters etc.&#125; PeopleDTO.java12345678public class PeopleDTO &#123; private String phoneNumber; private String address; private String emile; private User user; //constructor, getters, setters etc.&#125; User.java123456public class User &#123; private Integer age; private String name; //constructor, getters, setters etc.&#125; Mapper接口要生成一个PeopleDTO与PeopleEntity对象相互转换的映射器，我们需要定义一个mapper接口。像这两个实体类有些属性不一样时，我们可以通过@Mapping注解来进行转换. @Mapper注解标记这个接口作为一个映射接口，并且是编译时MapStruct处理器的入口。 只有在接口加上这个注解， MapStruct 才会去实现该接口。 @Mapper 里有个 componentModel 属性，主要是指定实现类的类型，一般用到两个 default：默认，可以通过 Mappers.getMapper(Class) 方式获取实例对象 spring：在接口的实现类上自动添加注解，@Component，可通过 @Autowired 方式注入。 @Mapping解决源对象和目标对象中，属性名字不同的情况。 Mappers.getMapper自动生成的接口的实现可以通过Mapper的class对象获取,从而让客户端可以访问Mapper接口的实现。 source：源属性 target：目标属性 dateFormat：String 到 Date 日期之间相互转换，通过 SimpleDateFormat，该值为SimpleDateFormat的日期格式 ignore: 忽略这个字段 @Mappings：配置多个@Mapping @MappingTarget 用于更新已有对象 @InheritConfiguration 用于继承配置这里只是列举了常用的字段和注解，详细的参考官方文档：http://mapstruct.org/documentation/stable/reference/html/ PeopleMapper.java12345678910111213141516171819202122232425262728@Mapperpublic interface PeopleMapper &#123; PeopleMapper INSTANCE = Mappers.getMapper(PeopleMapper.class); /** * PO转DTO * * @param entity PO * @return DTO */ @Mapping(target = "phoneNumber", source = "callNumber") @Mapping(target = "user.name", source = "name") @Mapping(target = "user.age", source = "age") PeopleDTO entityToDTO(PeopleEntity entity); /** * DTO转PO * * @param peopleDTO DTO * @param entity PO */ @Mapping(target = "callNumber", source = "phoneNumber") @Mapping(target = "name", source = "user.name") @Mapping(target = "age", source = "user.age") // @MappingTarget告诉MapStruct在现有对象（PeopleEntity）上进行更新，而不是new一个新对象。 void updateEntityFromDto(PeopleDTO peopleDTO, @MappingTarget PeopleEntity entity);&#125; 编译MapStruct MapStruct是以Java编译器插件的形式来处理注解，生成mapper接口的实现。因此在使用之前我们要手工编译或启动程序时IDEA也会帮我们编译了，这里最好还是手动编译。 12mvn compile// 有的IDEA是 mvnw compile 编译完后的实现类可以到target目录看到PeopleMapperImpl.Java,如下图： 这时你也可以点进看里面代码的实现PeopleMapperImpl.Java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class PeopleMapperImpl implements PeopleMapper &#123; public PeopleMapperImpl() &#123; &#125; public PeopleDTO entityToDTO(PeopleEntity entity) &#123; if(entity == null) &#123; return null; &#125; else &#123; PeopleDTO peopleDTO = new PeopleDTO(); User user = new User(); peopleDTO.setUser(user); user.setAge(entity.getAge()); user.setName(entity.getName()); peopleDTO.setPhoneNumber(entity.getCallNumber()); peopleDTO.setAddress(entity.getAddress()); peopleDTO.setEmile(entity.getEmile()); return peopleDTO; &#125; &#125; public void updateEntityFromDto(PeopleDTO peopleDTO, PeopleEntity entity) &#123; if(peopleDTO != null) &#123; entity.setName(this.peopleDTOUserName(peopleDTO)); entity.setCallNumber(peopleDTO.getPhoneNumber()); entity.setAge(this.peopleDTOUserAge(peopleDTO)); entity.setAddress(peopleDTO.getAddress()); entity.setEmile(peopleDTO.getEmile()); &#125; &#125; private String peopleDTOUserName(PeopleDTO peopleDTO) &#123; if(peopleDTO == null) &#123; return null; &#125; else &#123; User user = peopleDTO.getUser(); if(user == null) &#123; return null; &#125; else &#123; String name = user.getName(); return name == null?null:name; &#125; &#125; &#125; private Integer peopleDTOUserAge(PeopleDTO peopleDTO) &#123; if(peopleDTO == null) &#123; return null; &#125; else &#123; User user = peopleDTO.getUser(); if(user == null) &#123; return null; &#125; else &#123; Integer age = user.getAge(); return age == null?null:age; &#125; &#125; &#125;&#125; Mapper使用最后我们就来看看Mapper的使用12345678910111213141516171819202122232425@SpringBootApplicationpublic class MapperTestApplication &#123; private static final Logger LOGGER = LoggerFactory.getLogger(MapperTestApplication.class); public static void main(String[] args) &#123; //PO转DTO PeopleEntity peopleEntity = new PeopleEntity(18, "yoyo", "13215849", "shanghai ", "fdhf@163.com"); PeopleDTO peopleDTO = PeopleMapper.INSTANCE.entityToDTO(peopleEntity); //DTO转PO User user = new User(21, "jack"); PeopleDTO newP = new PeopleDTO("000000", "changsha ", "jack@163.com", user); PeopleEntity newEntity = new PeopleEntity(); PeopleMapper.INSTANCE.updateEntityFromDto(newP, newEntity); LOGGER.info("PO转DTO peopleEntity==&gt;" + peopleEntity.toString() + "\n peopleDTO==&gt;" + peopleDTO.toString()); LOGGER.info("DTO转PO PeopleDTO==&gt;" + newP.toString() + "\n peopleDTO==&gt;" + newEntity.toString()); SpringApplication.run(MapperTestApplication.class, args); &#125;&#125; 启动之后你可以在后台看到如下的输出123411:12:28.602 [main] INFO com.example.demo.MapperTestApplication - PO转DTO peopleEntity==&gt;PeopleEntity&#123;age=18, name=&apos;yoyo&apos;, callNumber=&apos;13215849&apos;, address=&apos;shanghai &apos;, emile=&apos;fdhf@163.com&apos;&#125; peopleDTO==&gt;PeopleDTO&#123;phoneNumber=&apos;13215849&apos;, address=&apos;shanghai &apos;, emile=&apos;fdhf@163.com&apos;, user=User&#123;age=18, name=&apos;yoyo&apos;&#125;&#125;11:12:28.604 [main] INFO com.example.demo.MapperTestApplication - DTO转PO PeopleDTO==&gt;PeopleDTO&#123;phoneNumber=&apos;000000&apos;, address=&apos;changsha &apos;, emile=&apos;jack@163.com&apos;, user=User&#123;age=21, name=&apos;jack&apos;&#125;&#125; peopleDTO==&gt;PeopleEntity&#123;age=21, name=&apos;jack&apos;, callNumber=&apos;000000&apos;, address=&apos;changsha &apos;, emile=&apos;jack@163.com&apos;&#125; 通过从上面后台输出的数据我们可以看出，对于属性名称不同的情况、以及属性类型不同都自动帮助我们转换了，是不是感觉很神奇，是不是感觉很强大.再也不用自己写大量的代码进行实体间的转换了。 本文转载于：https://blog.csdn.net/lx_yoyo/article/details/75061614]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>MapStruct</tag>
        <tag>对象转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis foreach批量操作]]></title>
    <url>%2F2018%2F10%2F26%2Fmybatis%20foreach%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[foreach属性 item循环体中的具体对象。支持属性的点路径访问，如item.age,item.info.details。具体说明：在list和数组中是其中的对象，在map中是value。该参数为必选。 collection要做foreach的对象，作为入参时，List&lt;?&gt;对象默认用list代替作为键，数组对象有array代替作为键，Map对象用map代替作为键。当然在作为入参时可以使用@Param(“keyName”)来设置键，设置keyName后，list,array,map将会失效。 除了入参这种情况外，还有一种作为参数对象的某个字段的时候。举个例子：如果User有属性List ids。入参是User对象，那么这个collection = “ids”如果User有属性Ids ids;其中Ids是个对象，Ids有个属性List id;入参是User对象，那么collection = “ids.id”上面只是举例，具体collection等于什么，就看你想对那个元素做循环。该参数为必选。 separator元素之间的分隔符，例如在in()的时候，separator=”,”会自动在元素中间用“,“隔开，避免手动输入逗号导致sql错误，如in(1,2,)这样。该参数可选。 openforeach代码的开始符号，一般是(和close=”)”合用。常用在in(),values()时。该参数可选。 closeforeach代码的关闭符号，一般是)和open=”(“合用。常用在in(),values()时。该参数可选。 index在list和数组中,index是元素的序号，在map中，index是元素的key，该参数可选。 举例实现 xx in ()123456789&lt;select id="countByUserList" resultType="int" parameterType="list"&gt; select * from t_user &lt;where&gt; id in &lt;foreach item="item" collection="list" separator="," open="(" close=")" index=""&gt; #&#123;item.id, jdbcType=NUMERIC&#125; &lt;/foreach&gt; &lt;/where&gt; &lt;/select&gt; sql效果：1select * from t_user WHERE id in ( ? , ? ) 批量插入数据（参数List）SQL效果：1insert into t_user select ?,? from dual union all select ?,? from dual 123456789101112&lt;insert id="addUserList"&gt; INSERT INTO DELIVER ( id,name ) &lt;foreach collection="userList" item="item" separator="UNION ALL"&gt; SELECT #&#123;item.id, jdbcType=NUMERIC&#125;, #&#123;item.name, jdbcType=VARCHAR&#125; FROM DUAL &lt;/foreach&gt;&lt;/insert&gt; 批量插入数据(参数Map)sql:1insert into t_user (key, value) values (?, ?) , (?, ?) 12345&lt;insert id="batchSaveUser"&gt; insert into t_user (key, value) values &lt;foreach item="item" index="key" collection="map" open="" separator="," close=""&gt;(#&#123;key&#125;, #&#123;item&#125;)&lt;/foreach&gt; &lt;/insert&gt; 其中Map的key是列名，value是字段值。 动态查询数据（根据列名不同）12345&lt;select id="dynamicQuery" resultType="int"&gt; select count(*) from t_user where &lt;foreach item="item" index="key" collection="map" open="" separator="AND" close=""&gt;$&#123;key&#125; = #&#123;item&#125;&lt;/foreach&gt; &lt;/select&gt; 一定要注意到$和#的区别，$的参数直接输出，#的参数会被替换为?，然后传入参数值执行。 批量插入数据（List参数）示例参数：List&lt;Map&lt;String,Object&gt;&gt; 这里想实现的功能是批量插入数据。生成的SQL如下：1insert into sys_outpatient_his(sys_id,his_id,is_receive,gmt_create) values (?,?,?),(?,?,?),(?,?,?) 123456789101112131415161718List&lt;Map&lt;String, Object&gt;&gt; items = new ArrayList&lt;&gt;(); Long sysId = 1L;Long hisId = 0L;short isReceive = 0;for (int i=0;i&lt;3;i++) &#123; isReceive = (short) (i == 1 ? 1:0); hisId = (long) (i+1); Map&lt;String, Object&gt; param = new HashMap&lt;&gt;(4); param.put("sysId", sysId); param.put("hisId", hisId); param.put("isReceive", isReceive); items.add(param);&#125;this.dao.batchSaveSysAndHisRelation(items); Mapper类：1void batchSaveSysAndHisRelation(@Param("params") List&lt;Map&lt;String,Object&gt;&gt; params); mybatis xml:1234567&lt;insert id="batchSaveSysAndHisRelation"&gt; insert into sys_outpatient_his(sys_id,his_id,is_receive,gmt_create) values &lt;foreach item="his" index="i" collection="params" open="" close="" separator=","&gt; (#&#123;his.sysId&#125;,#&#123;his.hisId&#125;,#&#123;his.isReceive&#125;,now()) &lt;/foreach&gt; &lt;/insert&gt; 遍历Map参数这里想实现的是根据sysId和hisIds删除数据，其中hisIds是要给数组。SQL如下：1delete from sys_outpatient_his where sys_id = ? and his_id in ( ? , ? , ? ) 调用代码：1234567Map&lt;String,Object&gt; params = new HashMap(2);params.put("sysId", 1L);Long[] ids = &#123;1L,2L,3L&#125;;params.put("hisIds", ids);this.dao.batchRemoveSysAndHisRelation(params); Mapper:1void batchRemoveSysAndHisRelation(@Param("params") Map&lt;String,Object&gt; params); mybatis xml:1234567&lt;delete id="batchRemoveSysAndHisRelation" parameterType="map"&gt;delete from sys_outpatient_his where sys_id = #&#123;params.sysId&#125; and his_id in &lt;foreach item="hisId" collection="params.hisIds" open="(" close=")" separator=","&gt; #&#123;hisId&#125; &lt;/foreach&gt;&lt;/delete&gt; 判断参数是否存在123&lt;if test="params.containsKey('sysId')"&gt; AND sysId = #&#123;sysId,jdbcType=VARCHAR&#125;)&lt;/if&gt; 如果不指定参数：123&lt;if test="_parameter.containsKey('sysId')"&gt; AND sysId = #&#123;sysId,jdbcType=VARCHAR&#125;)&lt;/if&gt; 参考：https://blog.csdn.net/wangyangbto/article/details/18049131 、https://blog.csdn.net/jason5186/article/details/40896043 foreach嵌套参考：https://blog.csdn.net/bidelinqi12/article/details/53121279]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装MariaDB数据库(mysql)]]></title>
    <url>%2F2018%2F10%2F25%2Fcentos7%E5%AE%89%E8%A3%85MariaDB%E6%95%B0%E6%8D%AE%E5%BA%93(mysql)%2F</url>
    <content type="text"><![CDATA[MariaDB数据安装从最新版本的linux系统开始(CentOs7），默认的是 Mariadb而不是mysql！ Linux版本查看：http://baijiahao.baidu.com/s?id=1601324352730835989&amp;wfr=spider&amp;for=pc 使用系统自带的repos安装很简单：123456789yum install mariadb mariadb-serversystemctl start mariadb ==&gt; 启动mariadbsystemctl enable mariadb ==&gt; 开机自启动mysql_secure_installation ==&gt; 设置 root密码等相关mysql -uroot -p123456 ==&gt; 测试登录！ 如果之前安装了mysql没成功，又安装的Mariadb，可能会不成功。需要先将原来的mysql和MariaDB卸载。参考：https://blog.csdn.net/sunny05296/article/details/56015884/ 数据库设置安装完成后，默认数据库用户名为root，密码为空。 然后可以通过下面的命令修改密码：1mysqladmin -uroot -p password &apos;1q2w3e&apos; 初始root密码为空，设置root密码为1q2w3e。然后就可以本地mysql -uroot -p1q2w3e登录了。 修改字符集123456789vim /etc/my.conf[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockcharacter-set-server=utf8collation-server=utf8_bin 配置远程访问首先配置允许访问的用户，采用授权的方式给用户权限1GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos;IDENTIFIED BY &apos;123456&apos; WITH GRANT OPTION; 说明：root是登陆数据库的用户，123456是登陆数据库的密码，*就是意味着任何来源任何主机反正就是权限很大的样子。 最后配置好权限之后不应该忘记刷新使之生效 1flush privileges; 再次访问就可以了吧。 注意关闭防火墙或允许mysql的端口对外访问。 安装新版本MariaDBcentos7默认自带的mariadb版本是5.5，如果要安装新版本，需要先下载旧版本。 卸载旧版本entos7下默认安装有mariadb数据库，但是是旧版本，在安装新版本前需要先把旧版本删除，有些系统还默认安装mysql，也必须删除，否则与mariadb会产生冲突，如下命令过程：1rpm -qa | grep mariadb 结果如下： 用命令yum删除以上三个：123yum remove mariadb-server-5.5.60-1.el7_5.x86_64yum remove mariadb-libs-5.5.60-1.el7_5.x86_64yum remove mariadb-5.5.60-1.el7_5.x86_64 ### 创建 MariaDB.repo在/etc/yum.repos.d目录（没有则创建）下新建mariadb.repo文件。文件内容：12345678910111213# MariaDB 10.2 CentOS repository list - created 2017-07-03 06:59 UTC# http://downloads.mariadb.org/mariadb/repositories/[mariadb]name = MariaDBbaseurl = https://mirrors.ustc.edu.cn/mariadb/yum/10.2/centos7-amd64gpgkey=https://mirrors.ustc.edu.cn/mariadb/yum/RPM-GPG-KEY-MariaDBgpgcheck=1 安装MariaDB1yum install MariaDB-server MariaDB-client 安装完成MariaDB，首先启动MariaDB1systemctl start mariadb 设置开机启动1systemctl enable mariadb 接下来进行MariaDB的相关简单配置输入以下命令：1mysql_secure_installation 先是设置密码，会提示先输入密码 Enter current password for root (enter for none):&lt;–初次运行直接回车 设置密码 Set root password? [Y/n] &lt;– 是否设置root用户密码，输入y并回车或直接回车 New password: &lt;– 设置root用户的密码 Re-enter new password: &lt;– 再输入一次你设置的密码 其他配置 Remove anonymous users? [Y/n] &lt;– 是否删除匿名用户，Y，回车 Disallow root login remotely? [Y/n] &lt;–是否禁止root远程登录,N，回车, Remove test database and access to it? [Y/n] &lt;– 是否删除test数据库，n,回车 Reload privilege tables now? [Y/n] &lt;– 是否重新加载权限表，回车 初始化MariaDB完成，接下来测试登录 测试登录1mysql -u root -p 回车输入密码 修改默认端口vi /etc/my.conf.d/server.cnf在[mysqld]下添加port=13306。保存后，重启mysql服务service mysql restart。 为指定数据库设置某个用户的权限创建用户testUser，数据库test2，将test2数据库的所有权限授权给testUser. 1234mysql -u xx -p;--登录mysqlCREATE USER &apos;test_user&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;--创建test_user用户grant all privileges on test_user.* to test2@&quot;%&quot; identified by &apos;123456&apos;;flush privileges; 参考：http://blog.sina.com.cn/s/blog_e7fdbcf30102yq3b.html、https://blog.csdn.net/lu8000/article/details/83148577]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot打包，分离依赖jar，配置文件]]></title>
    <url>%2F2018%2F10%2F25%2Fspringboot%E6%89%93jar%E5%8C%85%E5%88%86%E7%A6%BBlib%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[springboot工程，通常我们在pom.xml中配置了spring-boot-maven-plugin插件后，就可以将springboot工程打包为一个可执行Jar，然后通过java -jar xx.jar的方式就可以运行你，非常方便。 但是，该插件是件所有依赖的jar和资源文件都打到你要的jar包中，有时候我们可能想将资源文件和第三方依赖分开，不要打到jar中。比如在测试环境或线上更新某个class，如果要将整个包含第三方依赖和资源文件的jar上传，那是很大的，也是不必要的。这里我们想实现的效果如下： doctors-2.0.0.jar是我们最终打的jar包，它只包含我们自己写的java文件编译后的class。 resource是我们项目的资源文件 lib是项目依赖的第三方jar 现在我们借助4个maven插件来实现这一目的 完整pom如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&lt;plugins&gt; &lt;!--打包jar--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--不打包资源文件,exclude的目录不是src下面的，是以编译结果classes为根目录计算--&gt; &lt;excludes&gt; &lt;exclude&gt;/config/**&lt;/exclude&gt; &lt;exclude&gt;/META-INF/**&lt;/exclude&gt; &lt;exclude&gt;/mybatis/**&lt;/exclude&gt; &lt;exclude&gt;/public/**&lt;/exclude&gt; &lt;exclude&gt;/schema/**&lt;/exclude&gt; &lt;exclude&gt;/static/**&lt;/exclude&gt; &lt;exclude&gt;/templates/**&lt;/exclude&gt; &lt;exclude&gt;*.yml&lt;/exclude&gt; &lt;exclude&gt;*.xml&lt;/exclude&gt; &lt;exclude&gt;*.properties&lt;/exclude&gt; &lt;exclude&gt;*.json&lt;/exclude&gt; &lt;exclude&gt;*.bpmn&lt;/exclude&gt; &lt;/excludes&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!--MANIFEST.MF 中 Class-Path 加入前缀--&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;!--jar包不包含唯一版本标识--&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;!--指定入口类--&gt; &lt;mainClass&gt;com.doctors.Application&lt;/mainClass&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;!--MANIFEST.MF 中 Class-Path 加入资源文件目录--&gt; &lt;Class-Path&gt;./resources/&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--拷贝依赖 copy-dependencies--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt; $&#123;project.build.directory&#125;/lib/ &lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--拷贝资源文件 copy-resources--&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-resources&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/resources&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--spring boot repackage，依赖 maven-jar-plugin 打包的jar包 重新打包成 spring boot 的jar包--&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--重写包含依赖，包含不存在的依赖，jar里没有pom里的依赖--&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;null&lt;/groupId&gt; &lt;artifactId&gt;null&lt;/artifactId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;!--使用外部配置文件，jar包里没有资源文件--&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!--配置jar包特殊标识 配置后，保留原文件，生成新文件 *-run.jar --&gt; &lt;!--配置jar包特殊标识 不配置，原文件命名为 *.jar.original，生成新文件 *.jar --&gt; &lt;!--&lt;classifier&gt;run&lt;/classifier&gt;--&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;/plugins&gt; 参考：https://www.jianshu.com/p/dbdece9062b3 然后我们将生成的.jar文件、resources目录和lib目录拷贝到服务器上，使用java -jar xx.jar即可。可以使用nohup后台运行程序：1nohup java -jar xx.jar &amp; 参考：https://www.cnblogs.com/zery/p/7799005.html 一个注意点：排除资源目录，是以编译后的class目录开始计算的，不是src开始。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[外网ip注册dubbo服务]]></title>
    <url>%2F2018%2F10%2F12%2F%E5%A4%96%E7%BD%91ip%E6%B3%A8%E5%86%8Cdubbo%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[问题描述应用中使用了dubbo，在部署到服务器上时，如果服务提供方和消费方不在一个网段，发现消费方无法连接Provider，发现使用的Provider机器的内网IP地址。 有2种解决办法，下面依次说明。 解决办法1.修改hosts文件增加主机名与公网IP的映射dubbo在服务注册时默认使用的内网ip，如果需要在公网环境访问，需要让dubbo以公网ip注册服务。 1.通过hostname得到主机名；2.修改hosts文件，将公网ip映射到主机名；1234[root@iZj6cjcq027ejq3outzx5eZ logs]# vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6172.31.190.219 iZj6cjcq027ejq3outzx5eZ #将IP改成公网ip 改完后重启服务即可。 2.在dubbo服务的提供方配置host为公网IP。![/img/dubbo-provider.png] 如何服务同时能被内网和公网访问？在上面的解决方法中第2点，可以指定服务提供方的host，将该host指定为域名即可。这样内网的机器可以解析该域名为局域网地址 而外网机器可以解析域名为公网地址。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql innodb引擎count查询优化]]></title>
    <url>%2F2018%2F10%2F08%2Fmysql%20innodb%E5%BC%95%E6%93%8Ecount%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[使用mysql的innodb引擎执行count查询时发现速度很慢。一个将近800万条数据的表执行count(*)差不多40多秒时间。使用count(1)和count(主键)也基本差不多。表结构如下： 执行count(*)1SELECT COUNT(*) FROM sds_third_match_info; 耗时：57.733sec 执行count(1)1SELECT COUNT(1) FROM sds_third_match_info; 耗时：55.428sec 执行count(主键)1SELECT COUNT(id) FROM sds_third_match_info; 耗时：56.209sec 原因分析：InnoDB的索引是B+Tree。对主键索引来说：它只有在叶子节点上存储数据，它的key是主键，并且value为整条数据。对辅助索引来说：key为建索引的列，value为主键。 这给我们两个信息： 根据主键会查到整条数据 根据辅助索引只能查到主键，然后必须通过主键再查到剩余信息。 所以如果要优化count(*)操作的话，我们需要找一个短小的列，为它建立辅助索引。 我们在sport_data_type上建立一个普通索引1ALTER TABLE sds_third_match_info ADD INDEX idx_sporttype_stmi(sport_data_type); 然后根据索引列做count1SELECT COUNT(sport_data_type) FROM sds_third_match_info t; 现在耗时：2.649sec 如果在where条件中根据索引列过滤：1SELECT COUNT(sport_data_type) FROM sds_third_match_info t WHERE sport_data_type=1; 耗时：0.052sec 看看执行计划：EXPLAIN SELECT COUNT(sport_data_type) FROM sds_third_match_info t WHERE sport_data_type=1; 如果是count(*)则执行计划是全表扫描。 参考：高性能MySQL之Count统计查询、MySQL 大表的count()优化]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcached缓存介绍]]></title>
    <url>%2F2018%2F09%2F25%2FMemcached%E7%BC%93%E5%AD%98%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Memcached简介Memcached是一个高性能的服务器内存缓存软件。在早期版本的Memcached使用的是alloc来分配内存，存在内存碎片，在新版本的Memcached采用了Slab Allocator来分配内存。在MC启动时会要求制定一块内存区域，然后会划分为多个Slab，每个Slab默认大小为1M，可以指定。每个Slab又包含多个truck，每个Slab的truck大小不同，但同一个Slab的truck大小是一样的。在存入数据到MC时，MC会查找最合适的truck来存储数据。比如数据是100字节，现在有truck大小分别为64byte,128byte,144byte，那么会找到128byte的truck存储。不过仍然存在空间的浪费，比如这个例子中就浪费了28byte。所以保证合适大小的空间很重要，我们可以在MC启动时指定负载因子-f参数来指定，默认是1.25.通常情况下这都是一个比较合理的值，无需修改。另外避免空间浪费的一个处理方法是，将数据大小差不多的放入到相同的MC中。比如一个MC的truck大小为1M，另外一个为1K。那么将数据量在1M左右的都放入到1M的那个MC。 与Redis比较与Redis相比：1.MC只支持key/value，Redis支持key/value，list，set，map等6种数据结构； 2.都支持key的过期MC不主动检查item是否过期，只有在get时检查，但是检查到过期也不会删除，只是做一个标记。在有数据要set时该空间可以被重试使用。MC在分配空间时优先使用已经过期的key/value对的空间，如果分配的空间占满时，会使用LRU算法，删除最近最少使用的key。可以使用-M参数来启动MC，这样但MC内存耗尽时，会返回一个报错信息（对于完整数据缓存有用）。 Redis是主动监测，在key过期时会主动删除。 3.MC没有持久化功能，无法恢复数据；Redis可以定时保存数据到磁盘，Redis重启可以重新加载到内存。 应用场景1.将变化频率低的数据事先就放入MC中；比如商品分类、系统角色等等。 后续如有修改，修改数据库并同步到MC。这样所有用户的请求全部请求的MC，不会请求数据库。 2.热点数据缓存 3.集群会话共享 分布式缓存设计思想1.每台MC的内容不一样，所有的服务器内容加起来接近数据库的容量；2.通过在客户端程序或在负载均衡器上使用Hash算法，让同一内容始终分配到同一台MC。3.普通的HASH算法会导致MC节点宕机后数据发生流动，可能发生雪崩；4.采用一致性HASH算法可以使节点宕机对数据的流动降到最低。5.每个MC节点之间互不通信，数据独立存取。 安装Memcache安装libevent由于Memcached使用了libevent库，所以要先安装libevent。从https://github.com/libevent/libevent/releases获取最新稳定版本下载。这里下载的是libevent-2.1.8-stable.tar.gz。12345tar zxvf libevent-2.1.8-stable.tar.gzcd libevent-2.1.8-stable./configuremakemake install 问题：执行./configure时出错。错误信息：libevent error: no acceptable C compiler found in $PATH。解决办法：安装gcc，执行yum install gcc，然后再执行./configure。 安装Memcached从http://memcached.org/downloads下载最新稳定版本，这里下载的是memcached-1.5.10.tar.gz。12345tar -zxvf memcached-1.5.10.tar.gz cd memcached-1.5.10./configure make make install 验证是否安装成功memcached -h提示：memcached: error while loading shared libraries: libevent-2.1.so.6: cannot open shared object file: No such file or directory。解决：1find / -name &quot;libevent-2.1.so.6&quot; 可以找到12/usr/local/lib/libevent-2.1.so.6/data/tools/libevent-2.1.8-stable/.libs/libevent-2.1.so.6 将/usr/local/lib加到/etc/ld.so.conf中 然后执行ldconfig，然后再次执行memcached -h就正常了。 启动Memcached1memcached -m 64 -p 11211 -d -c 8192 -u root 相关参数可以使用memcached -h查看。本例中-m 64指定内存大小为64M，-p 11211指定端口，-d指定为守护进程，-c指定连接数，-u指定用户（在用root启动时需要指定）。 增加实例，只需修改启动的端口即可。下面新增一个实例1memcached -m 64 -p 11212 -d -c 8192 -u root 命令行客户端操作MC数据MC命令 添加数据(add) 12add key flag expiretime bytesvalue key : 给这个值设置一个名字 flag : 标志，是一个整数 expiretime : 有效期，以秒为单位，0表示没有延迟 bytes : 这是一个需要存储在memcached的数据的长度 value : 是一个需要存储的数据。数据需要将通过在新的一行后输入 注意：bytes要和value的长度一致，否则会出现CLIENT_ERROR bad data chunk错误 为一个新的或现有的键(key)设置一个值（set） 12set key flag expiretime bytesvalue 替换已存在的 key(键) 的 value(数据值)(replace) 12replace key flag expiretime bytesvalue 向已存在 key(键) 的 value(数据值) 后面追加数据(append) 12append key flag expiretime bytesvalue 向已存在 key(键) 的 value(数据值) 前面追加数据(prepend) 12prepend key flag expiretime bytesvalue 获取存储在 key(键) 中的 value(数据值)(get) 1get key 删除已存在的 key(键)(delete) 1delete key incr 与 decr 命令用于对已存在的 key(键) 的数字值进行自增或自减操作 12incr key increment_value decr key increment_value 清理缓存中的所有数据(flush_all) 12flush_all [time] - time : (可选) 在指定时间后执行清理缓存操作 stats / stats slabs / stats sizes / stats items 1234567891011stats 显示统计信息例如 PID(进程号)、版本号、连接数等 stats slabs 显示各个slab的信息，包括chunk的大小、数目、使用情况等 stats sizes 显示所有item的大小和个数 stats items 显示各个 slab 中 item 的数目和存储时长命令格式：gets key命令格式：cas key flags exptime bytes unique_cas_token [noreply]value gets / cas 12gets 获取带有 CAS 令牌的 value(数据值) cas 执行一个”检查并设置”的操作 参考MemCache 入门极简教程 通过Telnet来测试123456789101112131415161718192021// 添加数据add key001 0 10 5 // 回车hello// 获取数据get key001// 删除数据delete key001// 向value前追加数据prepend key001 0 0 3123// 向value后追加数据append key001 0 0 3123// 将key001的value替换为worldreplace key001 0 0 5world 通过nc测试123456789101112写入：printf &quot;set key001 0 0 5\r\nhello\r\n&quot; | nc 127.0.0.1 11211读取：printf &quot;get key001\r\n&quot; | nc 127.0.0.1 11211删除：printf &quot;delete key001\r\n&quot; | nc 127.0.0.1 11211# cas操作需要先根据gets key来获取CAS令牌# 1.获取令牌printf &quot;gets key001\r\n&quot; | nc 127.0.0.1 11211# 2.cas更新key的valueprintf &quot;cas key001 0 0 5 14 \r\nworld\r\n&quot; | nc 127.0.0.1 11211 Memcached客户端Xmemcached使用1.引入xmemcached的依赖12345&lt;dependency&gt; &lt;groupId&gt;com.googlecode.xmemcached&lt;/groupId&gt; &lt;artifactId&gt;xmemcached&lt;/artifactId&gt; &lt;version&gt;2.4.5&lt;/version&gt;&lt;/dependency&gt; 注意：xmemcached依赖slf4j，默认会打印一堆的Debug日志，可以引入slf4j和相关的日志实现的依赖，然后配置xmemcached的日志级别为info。比如log4j，可以配置log4j.logger.com.google=info。 2.基本使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697XMemcachedClientBuilder builder = new XMemcachedClientBuilder(AddrUtil.getAddresses("192.168.200.109:11211 192.168.200.109:11212"));builder.setSessionLocator(new KetamaMemcachedSessionLocator()); // 一致性哈希，使得某个key存的时候存都某个节点，取的时候也会从该节点获取MemcachedClient mc = builder.build();// 清空数据mc.flushAll();mc.add("hello",30,"你好，Memcached！");String value = mc.get("hello");System.out.println("hello=" + value);mc.delete("hello");value = mc.get("hello");System.out.println("hello==" + value);// 如果不存在key则创建，存在则覆盖valuemc.set("key001",0,"test key");// 更新过期时间mc.touch("key001",3);Thread.sleep(3000L);value = mc.get("key001");System.out.println("key001=====" + value);// cas操作，内部先通过gets命令拿到token，然后再执行cas操作。mc.set("abc",0,0);mc.cas("abc", 0, new CASOperation&lt;Integer&gt;() &#123; @Override public int getMaxTries() &#123; // cas重试次数 return 3; &#125; @Override public Integer getNewValue(long currentCAS, Integer currentValue) &#123; return 99; // 要设置的新值 &#125;&#125;);int casValue = mc.get("abc");System.out.println("abc=" + casValue);mc.add("hello",0,"world");if (mc.add("hello",10,"abcd")) &#123; System.out.println("key is exists");&#125;// 数字原则更新，类似java中的AtomicIntegerSystem.out.println(mc.incr("aaa",5,0)); // 对aaa加5，默认值为0（aaa不存在时）System.out.println(mc.decr("aaa",2)); // 对aaa减2// 或者使用CounterCounter counter = mc.getCounter("counter",0);System.out.println(counter.addAndGet(5));System.out.println(counter.decrementAndGet());// 命名空间String ns = "namespace";mc.withNamespace(ns, new MemcachedClientCallable&lt;Boolean&gt;() &#123; @Override public Boolean call(MemcachedClient memcachedClient) throws MemcachedException, InterruptedException, TimeoutException &#123; boolean result = memcachedClient.set("key1",0,"hello"); return result; &#125;&#125;);// 或者使用mc.beginWithNamespace(ns);mc.add("key2",20,"world");mc.add("key3",30,"你好");System.out.println("key3==&gt;" + mc.get("key3"));mc.endWithNamespace();value = mc.withNamespace(ns, new MemcachedClientCallable&lt;String&gt;() &#123; @Override public String call(MemcachedClient client) throws MemcachedException, InterruptedException, TimeoutException &#123; return client.get("key2"); &#125;&#125;);System.out.println("with namespace key2=" + value);value = mc.get("key1");System.out.println("key1=" + value);value = mc.get("key2");System.out.println("key2=" + value);value = mc.get("key3");System.out.println("key3=" + value);// 让命名空间的所有key都失效mc.invalidateNamespace(ns);value = mc.get("key1");System.out.println("key1=" + value);value = mc.get("key2");System.out.println("key2=" + value);value = mc.get("key3");System.out.println("key3=" + value);mc.shutdown(); 这里只是基本使用，可以查看下面的参考链接查看全部用法。 参考：Xmemcached 中文用户指南、Memcached的几种Java客户端（待实践） 参考：Memcached 教程 Memcached监控这里推荐使用MemAdmin，需要PHP环境。参考：windows下memadmin安装]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot国际化]]></title>
    <url>%2F2018%2F09%2F25%2Fspringboot%E5%9B%BD%E9%99%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[国际化（internationalization）是设计和制造容易适应不同区域要求的产品的一种方式。它要求从产品中抽离所有地域语言，国家/地区和文化相关的元素。换言之，应用程序的功能和代码设计考虑在不同地区运行的需要，其代码简化了不同本地版本的生产。开发这样的程序的过程，就称为国际化。 那么当我们使用Spring Boot如何进行国际化呢？那么当你读完这篇文章你会学到如下知识： (1) spring boot 加入thymeleaf； (2) 页面元素国际化； (3) spring boot默认国际化原理说明； (4) firefox浏览器修改区域语言； (5)chrome浏览器修改区域语言； (6)修改默认messages配置前缀； (7) 代码中如何获取国际化信息； (8) 优化代码获取国际化信息； (9) 区域解析器之AcceptHeaderLocaleResolver； (10) 会话区域解析器之SessionLocaleResolver； (11) Cookie区域解析器之CookieLocaleResolver； (12)固定的区域解析器之FixedLocaleResolver ； (13)使用参数修改用户的区域； 接下里我们看看这些具体应该怎么操作。 (1) spring boot 加入thymeleaf； Spring boot集成thymeleaf在http://www.vxzsk.com/440.html 这篇文章有介绍过，所以这里就不过多进行介绍了。在这里我们为之后的讲解做点基本准备。 模板文件resources/templates/hello.html :123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;title&gt;hello spring boot&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;欢迎你登录到阿里巴巴网站&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 这里没有特殊的代码，访问就是显示一些文字，这里还没加入国际化的相关东西，之后添加。 编写访问地址：com.kfit.controller.HelloController：1234567891011121314package com.kfit.controller; import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping; @Controllerpublic class HelloController &#123; @RequestMapping("/hello") public String hello()&#123; return "/hello"; &#125; &#125; 这里就是访问http://127.0.0.1:8080/hello就跳转到hell.html进行访问。 到这里准备工作就好了。 (2) 页面元素国际化； 我们观察hello.html里面的信息直接就是中文显示，所以我们现在的需求是当访问语言是zh的时候显示为中文，当语言为en的时候显示为英文，那么怎么操作呢？ 首先我们先定义国际化资源文件，spring boot默认就支持国际化的，而且不需要你过多的做什么配置，只需要在resources/下定义国际化配置文件即可，注意名称必须以messages开发。 我们定义如下几个文件： messages.properties （默认，当找不到语言的配置的时候，使用该文件进行展示）。 messages_zh_CN.properties（中文） messages_en_US.properties（英文） 具体的代码如下： messages.properties：1welcome = 欢迎你登录到 阿里巴巴 网站（default） messages_zh_CN.properties：1welcome = \u6b22\u8fce\u4f60\u767b\u5f55\u5230 \u963f\u91cc\u5df4\u5df4 \u7f51\u7ad9\uff08\u4e2d\u6587\uff09 对应的信息是： welcome = 欢迎你登录到 阿里巴巴 网站（中文） messages_en_US.properties：1welcome = welcome to login to alibaba website(English) 配置信息就这么简单，那么在前端展示怎么修改呢，修改hello.html文件，使用#{key}的方式进行使用messages中的字段信息：12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;title&gt;hello spring boot&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;&lt;label th:text="#&#123;welcome&#125;"&gt;&lt;/label&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 重新访问：http://127.0.0.1:8080/hello 应该显示： 欢迎你登录到 阿里巴巴 网站（中文） (3) spring boot默认国际化原理说明 在这里我们先打住下，简单说下原理： 第一个问题，为什么命名必须是messages开头，需要看一个源码文件： org.springframework.boot.autoconfigure.MessageSourceAutoConfiguration： 这里提取部分代码：123456789101112131415161718192021222324252627282930313233343536373839404142/** * &#123;@link EnableAutoConfiguration Auto-configuration&#125; for &#123;@link MessageSource&#125;. * * @author Dave Syer * @author Phillip Webb * @author Eddú Meléndez */@Configuration@ConditionalOnMissingBean(value = MessageSource.class, search = SearchStrategy.CURRENT)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Conditional(ResourceBundleCondition.class)@EnableConfigurationProperties@ConfigurationProperties(prefix = "spring.messages")public class MessageSourceAutoConfiguration &#123; private static final Resource[] NO_RESOURCES = &#123;&#125;; /** * Comma-separated list of basenames, each following the ResourceBundle convention. * Essentially a fully-qualified classpath location. If it doesn't contain a package * qualifier (such as "org.mypackage"), it will be resolved from the classpath root. */ private String basename = "messages"; /** * Message bundles encoding. */ private Charset encoding = Charset.forName("UTF-8"); /** * Loaded resource bundle files cache expiration, in seconds. When set to -1, bundles * are cached forever. */ private int cacheSeconds = -1; /** * Set whether to fall back to the system Locale if no files for a specific Locale * have been found. if this is turned off, the only fallback will be the default file * (e.g. "messages.properties" for basename "messages"). */ private boolean fallbackToSystemLocale = true;&#125; 看到没有，如果我们没有在application.properties中配置spring.messages属性，那么使用默认的messages，好了这个问题就这么简单解决了。 第二问题：为什么我看到的是中文（或者英文）呢？ 为了让web应用程序支持国际化，必须识别每个用户的首选区域，并根据这个区域显示内容。在Spring MVC应用程序中，用户的区域是通过区域解析器来识别的，它必须是实现LocaleResolver接口。Spring MVC提供了几个LocaleResolver实现，让你可以按照不同的条件来解析区域。除此之外，你还可以实现这个接口创建自己的区域解析器。如果没有做特殊的处理的话，Spring 采用的默认区域解析器是AcceptHeaderLocaleResolver。它通过检验HTTP请求的头部信息accept-language来解析区域。这个头部是由用户的wb浏览器底层根据底层操作系统的区域设置进行设定的。请注意，这个区域解析器无法改变用户的区域，因为它无法修改用户操作系统的区域设置。 既然无法修改，那么我们的代码怎么测试呢？请看如下内容？ (4) firefox浏览器修改区域语言； 打开firefox浏览器访问http://127.0.0.1:8080/hello （计算机系统语言是中文的），应该是看到如下信息： 欢迎你登录到 阿里巴巴 网站（中文） 那么我们修改我们的语言呢，在浏览器地址栏输入如下信息： about:config 回车进入一个警告页面，然后点击按钮【我保证会小心】（注：由于版本不一样，可能会有些不一样，但是操作是一样的）。 在搜索框输入accept，然后找到intl.accept_languages修改对应的值，我这里原本是： zh-cn, zh, en-us, en 为了看到效果，修改为： en-us, en 修改完之后，刷新http://127.0.0.1:8080/hello ，可以看到信息： welcome to login to alibaba website(English) 好了，没有什么特殊的需求的，记得把intl.accept_languages修改为原来的值。 (5)chrome浏览器修改区域语言； 我觉得firefox修改起来真是简单，chrome浏览器就稍微麻烦点了。 第一种方案就是下载插件：Quick Language Switcher，下载完插件之后，默认选项的比较少，你可以在扩展程序中，打开别的语言选项或者添加自定义的语言。这个只要插件下来来操作就很简单了，切换语言就会自动刷新页面，就能看到效果了，特别方便。注意的是：默认有一个English，这个使用的配置文件是：messages_en.properties,所以需要添加一个配置文件才能看到效果。 第二种方案是修改本地的一个配置文件，参考如下地址 http://stackoverflow.com/questions/7769061/how-to-add-custom-accept-languages-to-chrome-for-pseudolocalization-testing 但是我这里不管怎么修改，重启浏览器之后，就被重置回来了，也就是这种方案我这里没有配置成功。第一种方案肯定是可以的。 别的浏览器就自行尝试了，因为这不是我们这不是我们实际使用的重点，那么接下来才是重点哦。 (6)修改默认messages配置前缀； 我们在上面说了，默认的文件名称前缀是messages_xx.properties，那么如何修改这个名称和路径呢？ 这个也很简单，只需要修改application.properties文件即可加入如下配置：123456789########################################################### i18n setting.#########################################################指定message的basename，多个以逗号分隔，如果不加包名的话，默认从classpath路径开始，默认: messagesspring.messages.basename=i18n/messages#设定加载的资源文件缓存失效时间，-1的话为永不过期，默认为-1spring.messages.cache-seconds= 3600#设定Message bundles的编码，默认: UTF-8#spring.messages.encoding=UTF-8 上面各个参数都注释很清楚了，这里不多说了，那么我们这里是把文件放到了i18n下，那么我们在resources下新建目录i18n，然后复制我们创建的messages_xxx.properties文件到此目录下。为了区分这是读取了新的文件，我们可以在每个文件中—i18n以进行区分。 重新访问http://127.0.0.1:8080/hello 可以看到最新的效果了。 英文： welcome to login to alibaba website(English-en)–i18n 中文： 欢迎你登录到阿里巴巴网站（中文）–i18n (7) 代码中如何获取国际化信息； 以上讲的是在模板文件进行国际化，那么在代码中如何获取到welcome呢，这个比较简单，只要在需要的地方注入类： 12@Autowiredprivate MessageSource messageSource; 需要注意的是messageSource是 org.springframework.context.MessageSource 下的类。 那么怎么使用了，在使用前我们需要先知道一个知识点，如何得到当前请求的Locale 那么怎么获取呢，有两种获取方式： 第一种方式是：1Locale locale = LocaleContextHolder.getLocale(); 第二种方式是：1Locale locale1= RequestContextUtils.getLocale(request); 个人喜好第一种方式，因为不需要什么参数就可以获取到，第二种方式依赖于当前的request请求对象。 有了当前请求的Locale剩下的就简单了： 12String msg = messageSource.getMessage("welcome", null,locale);String msg2= messageSource.getMessage("welcome", null,locale1); 通过以上代码的其中一种方式就可以获取到messages_xxx.properties文件配置的welcome属性值了。切换区域获取的信息也是不一样的，打印信息如下：1234msg=欢迎你登录到阿里巴巴网站（中文）--i18nmsg2欢迎你登录到阿里巴巴网站（中文）--i18nmsg=welcome to login to alibaba website(English-en)--i18nmsg2welcome to login to alibaba website(English-en)--i18n 8) 优化代码获取国际化信息； 学习是永无止境的，活到老学到老。查看上面的代码你会发现这个是实际中使用起来的时候还是不是很方面，ok,没有关系，这个小节我们就对上面的代码优化下， 自定义我们自己的MessageSource，具体代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.kfit.common; import java.util.Locale;import javax.annotation.Resource;import org.springframework.context.MessageSource;import org.springframework.context.i18n.LocaleContextHolder;import org.springframework.stereotype.Component; @Componentpublic class LocaleMessageSourceService &#123; @Resource private MessageSource messageSource; /** * @param code ：对应messages配置的key. * @return */ public String getMessage(String code)&#123; return getMessage(code,null); &#125; /** * * @param code ：对应messages配置的key. * @param args : 数组参数. * @return */ public String getMessage(String code,Object[] args)&#123; return getMessage(code, args,""); &#125; /** * * @param code ：对应messages配置的key. * @param args : 数组参数. * @param defaultMessage : 没有设置key的时候的默认值. * @return */ public String getMessage(String code,Object[] args,String defaultMessage)&#123; //这里使用比较方便的方法，不依赖request. Locale locale = LocaleContextHolder.getLocale(); return messageSource.getMessage(code, args, defaultMessage, locale); &#125; &#125; 在这个代码中我封装了3个常用的方法，那么应该怎么调用呢？也很简单，在需要的地方使用如下代码进行注入： 12@Resourceprivate LocaleMessageSourceService localeMessageSourceService; 在需要的地方使用如下代码进行调用：1String msg3 = localeMessageSourceService.getMessage("welcome"); 这个代码比之前的代码使用起来爽多了，还有很多神妙之处，大家自己发现吧。 (9) 区域解析器之AcceptHeaderLocaleResolver； 看到上面，大家会认为国际化也就到此了，但是我告诉大家这之后才是spring的强大之处呢，考虑的多么周到呢。 我们在之前说过，我们只所以可以看到国际化的效果是因为有一个区域解析器在进行处理。默认的区域解析器就是AcceptHeaderLocaleResolver。我们简单说明这个解析器： Spring采用的默认区域解析器是AcceptHeaderLocaleResolver。它通过检验HTTP请求的accept-language头部来解析区域。这个头部是由用户的web浏览器根据底层操作系统的区域设置进行设定。请注意，这个区域解析器无法改变用户的区域，因为它无法修改用户操作系统的区域设置。 好了，这个默认的介绍到这里，因为这个我们无法改变，所以这种默认的设置在实际中使用的比较少。所以你如果看到当前还无法满足的需求的话，那么接着往下看，博主已经帮你都想到了。 (10) 会话区域解析器之SessionLocaleResolver； 会话区域解析器也就是说，你设置完只针对当前的会话有效，session失效，还原为默认状态。那么这个具体怎么操作呢？具体操作起来也是很简单的，我们需要在我们的启动类App.java（按你的实际情况进行修改）配置区域解析器为SessionLocaleResolver，具体代码如下： 1234567@Beanpublic LocaleResolver localeResolver() &#123; SessionLocaleResolver slr = new SessionLocaleResolver(); //设置默认区域, slr.setDefaultLocale(Locale.CHINA); return slr;&#125; 其实到这里我们就完事了，你可以通过setDefaultLocale()设置默认的语言，启动就访问http://127.0.0.1:8080/hello 进行查看，是不是已经实现国际化了。 到这里当然还不是很完美，还需要在进一步的优化了，那么怎么在页面中进行切换呢？那么假设页面上有两个按钮【切换为中文】、【切换为英文】就可以进行切换了。接下来一起来实现下：在hello.html添加如下代码： 123456789&lt;form action="/changeSessionLanauage" method="get"&gt; &lt;input name="lang" type="hidden" value="zh" /&gt; &lt;button&gt;切换为中文&lt;/button&gt;&lt;/form&gt; &lt;form action="/changeSessionLanauage" method="get"&gt; &lt;input name="lang" type="hidden" value="en" /&gt; &lt;button&gt;切换为英文&lt;/button&gt;&lt;/form&gt; 这里就是两个表单，切换语言，那么/changeSessionLanauage怎么编写呢，看如下代码： 123456789101112@RequestMapping("/changeSessionLanauage")public String changeSessionLanauage(HttpServletRequest request,String lang)&#123; System.out.println(lang); if("zh".equals(lang))&#123; //代码中即可通过以下方法进行语言设置 request.getSession().setAttribute(SessionLocaleResolver.LOCALE_SESSION_ATTRIBUTE_NAME, new Locale("zh", "CN")); &#125;elseif("en".equals(lang))&#123; //代码中即可通过以下方法进行语言设置 request.getSession().setAttribute(SessionLocaleResolver.LOCALE_SESSION_ATTRIBUTE_NAME, new Locale("en", "US")); &#125; return "redirect:/hello";&#125; 这部分代码最核心的部分就是如何设置会话的区域，也就是如下代码： 1request.getSession().setAttribute(SessionLocaleResolver.LOCALE_SESSION_ATTRIBUTE_NAME, new Locale("en", "US")); 这个代码就可以把当前会话的区域进行切换了，是不是很简单。以上代码你会发现只针对会话的设置，我们在这里在优化下，针对下面讲的Cookie也会作用到，这样这个代码就很智能了，代码修改为如下： 1234567891011@RequestMapping("/changeSessionLanauage")public String changeSessionLanauage(HttpServletRequest request,HttpServletResponse response,String lang)&#123; System.out.println(lang); LocaleResolver localeResolver = RequestContextUtils.getLocaleResolver(request); if("zh".equals(lang))&#123; localeResolver.setLocale(request, response, new Locale("zh", "CN")); &#125;elseif("en".equals(lang))&#123; localeResolver.setLocale(request, response, new Locale("en", "US")); &#125; return "redirect:/hello";&#125; 在这里使用:1LocaleResolver localeResolver = RequestContextUtils.getLocaleResolver(request); 获取当前使用的区域解析器LocaleResolver 调用里面的方法 setLocale 设置即可，这样的代码就是不管是会话还是cookie区域解析器都是一样的代码了。 (11) Cookie区域解析器之CookieLocaleResolver； Cookie区域解析器也就是说，你设置完针对cookie生效，session失效。那么这个具体怎么操作呢？我们需要在我们的启动类App.java（按你的实际情况进行修改）配置区域解析器为CookieLocaleResolver（SessionLocaleResolver部分请注释掉），具体代码如下： 12345678@Beanpublic LocaleResolver localeResolver() &#123; CookieLocaleResolver slr = new CookieLocaleResolver(); //设置默认区域, slr.setDefaultLocale(Locale.CHINA); slr.setCookieMaxAge(3600);//设置cookie有效期. returnslr;&#125; 其实到这里我们就完事了，你可以通过setDefaultLocale()设置默认的语言，启动就访问http://127.0.0.1:8080/hello 进行查看，是不是已经实现国际化了。 到这里当然还不是很完美，还需要在进一步的优化了，那么怎么在页面中进行切换呢？ 这里主要是用到了，这个部分我们在(10)中已经进行配置了，所以到这里已近是可以进行使用了，点击页面中的按钮进行体验。 (12)固定的区域解析器之FixedLocaleResolver ； 一直使用固定的Local, 改变Local 是不支持的 。既然无法改变，那么不…好了，还是简单介绍下如何使用吧，还是在App.java进行编码： 1234567891011/** * cookie区域解析器; * @return */@Beanpublic LocaleResolver localeResolver() &#123; FixedLocaleResolver slr = new FixedLocaleResolver (); //设置默认区域, slr.setDefaultLocale(Locale.US); returnslr;&#125; (13)使用参数修改用户的区域； 除了显式调用LocaleResolver.setLocale()来修改用户的区域之外，还可以将LocaleChangeInterceptor拦截器应用到处理程序映射中，它会发现当前HTTP请求中出现的特殊参数。其中的参数名称可以通过拦截器的paramName属性进行自定义。如果这种参数出现在当前请求中，拦截器就会根据参数值来改变用户的区域。 只需要在App.java中加入：123456789101112@Bean public LocaleChangeInterceptor localeChangeInterceptor() &#123; LocaleChangeInterceptor lci = new LocaleChangeInterceptor(); // 设置请求地址的参数,默认为：locale // lci.setParamName(LocaleChangeInterceptor.DEFAULT_PARAM_NAME); returnlci; &#125; @Overridepublic void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(localeChangeInterceptor());&#125; 注意这个是可以和会话区域解析器以及Cookie区域解析器一起使用的，但是不能和FixedLocaleResolver一起使用，否则会抛出异常信息。 本文来自 吸引力的觉悟 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/u012100371/article/details/78199568?utm_source=copy]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome系浏览器显示完整地址]]></title>
    <url>%2F2018%2F09%2F21%2FChrome%E7%B3%BB%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%BE%E7%A4%BA%E5%AE%8C%E6%95%B4%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[在浏览器输入chrome://flags/回车，找到Omnibox UI Hide Steady-State URL Scheme and Trivial Subdomains，设置为Disabled，然后重启浏览器。如果回车之后变成了搜索，则复制，然后在浏览器输入栏鼠标右键，选择粘贴并转到即可。]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown表格]]></title>
    <url>%2F2018%2F09%2F16%2Fmarkdown%E8%A1%A8%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[markdown表格格式12345标题一|标题二|标题三|标题四- |:---|---:|:---:xxxxxxxxx|xxxxxxxxx|xxxxxxxxx|xxxxxxxxxxxxxxxxxxxxxxx|xxxxxxxxxxxxxx|xxxxxxxxxxxxxx|xxxxxxxxxxxxxxxxxxxxxxx|xxxxxxxxx|xxxxxxxxx|xxxxxxxxx 显示效果： 标题一 标题二 标题三 标题四 xxxxxxxxx xxxxxxxxx xxxxxxxxx xxxxxxxxx xxxxxxxxxxxxxx xxxxxxxxxxxxxx xxxxxxxxxxxxxx xxxxxxxxxxxxxx xxxxxxxxx xxxxxxxxx xxxxxxxxx xxxxxxxxx 1.两竖线|中间为一个单元格，每行列数即为每行竖线数-1；2.行数-1为表格行数，因为第二行为配置行，配置表格显示用，并不显示出来；3.上面的标题二、标题三、标题四分别为左对齐、右对齐和居中显示。4.内容和|之间的多余空格会被忽略，每行第一个|和最后一个|可以省略，-的数量至少有一个。5.至少与前面空一行，否则表格无法显示 单元格内换行使用&lt;br&gt;标签。]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 8的CompletableFuture]]></title>
    <url>%2F2018%2F09%2F15%2FJDK8%E4%B9%8BCompletableFuture%2F</url>
    <content type="text"><![CDATA[JDK1.5开始提供了Future类，用来描述一个异步计算的结果。可以通过isDone()方法来判断操作是否执行完毕。你也可以调用get方法阻塞调用的线程，等待执行结束。或者使用cancel方法取消任务的执行。比如：123456789101112131415161718192021ExecutorService executor = Executors.newCachedThreadPool();Future&lt;Double&gt; doubleFuture = executor.submit(new Callable&lt;Double&gt;() &#123; @Override public Double call() throws Exception &#123; // 一个耗时的操作 return doSomethingLongComputation(); &#125;&#125;);// do something else.try &#123; Double result = doubleFuture.get(1, TimeUnit.SECONDS); System.out.println("result-&gt;" + result);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125; catch (TimeoutException e) &#123; e.printStackTrace();&#125; 可以看到，我们向线程池提交一个任务，线程池立即返回了一个Future。然后我们可以继续做自己的事情，不必等待任务执行完毕。在自己的事情做完后，调用Future的get方法等待任务执行完毕，并返回结果。调用get()即为等待任务执行完毕，不论多久；而它的带超时时间的重载方法则在指定的时间之内等待执行结果，避免无限期等待下去。实际使用，建议使用带超时时间的get方法。 不过Future接口有它的局限性。比如： 将两个异步结束的结果合并为一个——这2个异步计算相互独立，同时第二个又依赖第一个的结果。 等待Future集合的所有任务执行完毕。 仅等待Future结合中最快结束的任务完成。（比如访问了2个提供相同服务的服务器） 通过编程方式完成一个Future任务的执行——以手工设定异步执行结果。 响应Future的完成事件——在Future的任务执行完毕时会受到通知，然后使用Future计算的结果进行下一步操作。 java 8提供的CompltableFuture继承Future，在Future的基础上实现了如上描述的功能。 以异步的方式执行任务借助CompletableFuture的supplyAsync方法实现异步执行。12345678List&lt;Shop&gt; shops = ...;String productName = ...;// 使用supplyAsync以异步的方式计算商品价格List&lt;CompletableFuture&lt;String&gt;&gt; futures = shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync(() -&gt; String.format("%s price is %.2f", shop.getName(), shop.getPrice(productname)))) .collect(Collectors.toList());// 调用join方法等待任务都执行完毕List&lt;String&gt; results = futures.stream().map(f -&gt; f.join()).collect(Collectors.toList()); 上面异步方法和Stream的parallelStream都是默认使用的是通用线程池，线程数为处理器个数。你可以通过Runtime.getRuntime().availableProcessors();得到。比如我的电脑是4核，那么就是使用的是4个线程的线程池。如果商家过多会导致执行效率较低。 幸好，supplyAsync还有还有一个带Executor参数的版本，可以指定执行器。12345678910// 指定创建的线程数最多100个，如果商家数目不多余100个，就创建商家数目的线程。ExecutorService executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100), (r) -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); // 使用守护线程，这种方式不会阻止程序的关闭 return thread;&#125;);List&lt;CompletableFuture&lt;String&gt;&gt; futures = shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync(() -&gt; String.format("%s price is %.2f", shop.getName(), shop.getPrice(productname)), executor)) .collect(Collectors.toList());List&lt;String&gt; results = futures.stream().map(f -&gt; f.join()).collect(Collectors.toList()); 线程池大小的估算《java并发编程实战》中，指出线程池大小与处理器的利用率之比可以使用下面的公式进行估算：N(threads) = N(cpu) * U(cpu) * (1 + W/C)其中： N(cpu)是处理器的核的数目，可以通过Runtime.getRuntime().availableProcessors()得到。 U(cpu)是期望的CPU利用率（值介于0和1之间） W/C是等待时间与计算时间的比率在本例中，99%的时间都在等待商店的响应，所以估算出的W/C比率为100.这意味着你期望的CPU利用率是100%。你需要创建一个有400个线程的线程池。但是，在实际操作中，如果你创建的线程数比商店的数目更多，反而是一种浪费，因为线程池中有些线程根本没有用到。所以，基于这种考虑将线程池的数目与你要查询的商店的数目设定为一个值，这个每个商店都对应一个服务线程。不过，为了避免商店数目过多导致服务器超负荷而崩溃，你需要设置一个上限，比如这里的100个线程。 将2个异步执行的结果合并为一个我们假定商店提供了查询商品价格的服务getPrice，它会返回商品的价格和折扣代码，另外还提供了查询扣后价的方法。另外提供了Quote类用于将getPrice返回的结果进行封装。 商家提供的getPrice方法如下：1234567public String getPrice1(String product) &#123; double price = caculatePrice(product); Discount.Code code = Discount.Code.values()[random.nextInt(Discount.Code.values().length)]; // 返回结果包括商品名称、商品价格和折扣代码，是一个字符串，它们用冒号隔开； return String.format("%s:%.2f:%s",name,price,code);&#125; Quote类的主要方法如下：1234567public static Quote parse(String s) &#123; String[] split = s.split(":"); String shopName = split[0]; Double price = Double.parseDouble(split[1]); Discount.Code code = Discount.Code.valueOf(split[2]); return new Quote(shopName,price,code);&#125; 折扣类代码大致如下：1234567891011121314151617181920212223242526272829303132333435363738public class Discount &#123; /** * 折扣代码和折扣率 */ public enum Code &#123; NONE(0),SILVER(5),GOLD(10),PLATINUM(15),DIAMOND(20); private final int percentage; Code(int percentage) &#123; this.percentage = percentage; &#125; &#125;; /** * 申请折扣 * @param quote * @return */ public static String applyDiscount(Quote quote) &#123; return String.format("%s price is %.2f",quote.getShopName(),Discount.apply(quote.getPrice(),quote.getCode())); &#125; public static double apply(Double price,Code code) &#123; delay(); return price * (100 - code.percentage)/100; &#125; private static void delay() &#123; try &#123; long time = 500 + new Random().nextInt(2000); Thread.sleep(time); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 我们需要实现的逻辑是：1.查询商品的价格，得到商品名称、价格、折扣代码；2.将1中的结果进行封装，得到Quote；3.利用Discount的applyDiscount方法计算折扣价。可以看到，第1步可以异步执行，而第2步只是简单的封装，不涉及远程服务和I/O操作，所以没必要使用异步。第3步由于需要联系远程Discount服务，根据折扣代码得到折扣率，所以它也以异步的方式执行。我们的代码大致如下：123456789101112ExecutorService executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100), (r) -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); return thread;&#125;);List&lt;CompletableFuture&lt;String&gt;&gt; futures = shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync(() -&gt; shop.getPrice1(product), executor)) // 返回Stream&lt;Future&lt;String&gt;&gt; .map(future -&gt; future.thenApply(Quote::parse)) // 返回Stream&lt;Future&lt;Quote&gt;&gt; .map(future -&gt; future.thenCompose(quote -&gt; CompletableFuture.supplyAsync(() -&gt; Discount.applyDiscount(quote), executor))) .collect(Collectors.toList());List&lt;String&gt; results = futures.stream().map(CompletableFuture::join).collect(Collectors.toList()); thenApply有点类似于JavaScript中的回调函数，它在Future结果计算完成后，将结果作为参数回调这个函数。它不会阻塞线程。所以这里的意思就是在拿到商店的商品名称、价格、折扣代码后，将其封装为一个Quote对象。 thenCompose用于连接2个CompletableFuture，它会将第一个Future的结果作为参数传递给第2个Future。所以这里将第2个map的结果quote作为参数传递给了第2个Future，用于计算折后价。 将2个Future合并起来，无论他们是否有依赖如果你希望将2个完全不相干的CompletableFuture的结果整合，那么可以使用CompletableFuture的thenCombine方法。 比如，你可以以异步的方式查询某个商店商品的价格，同时你可以以异步的方式从远程汇率服务查询欧元和美元的汇率，然后将商品的价格乘以当时的汇率，得到以美元计价的商品价格。123456Future&lt;Double&gt; future = CompletableFuture.supplyAsync(() -&gt; shop.getPrice(product)) // 异步查询商品价格 .thenCombine( // 异步计算汇率 CompletableFuture.supplyAsync(() -&gt; exchangeService.getRate(Money.EUR, Money.USD)), (price, rate) -&gt; price * rate //执行的合并操作 ); 响应Future的完成事件比如，我们要查询100个商店的某件商品的价格，可能某个商店的服务或者网络问题，导致查询耗时很久，如果按照之前的方式等待所有的任务执行完毕，那么给人的体验就不好。比如假定某个商店查询价格耗时100秒，那么用户可能看到页面上在这100秒内都是一片空白。其实，我们可以对CompletableFuture的complete做出响应，使用它的thenAccept方法可以在任务执行完毕收收到通知，方法的参数为Future执行的结果。这样只要有任务执行完毕，就会立即显示出来。比如：123456789101112131415161718ExecutorService executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100), (r) -&gt; &#123; Thread thread = new Thread(r); thread.setDaemon(true); return thread;&#125;);long start = System.nanoTime();CompletableFuture[] futures = shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync(() -&gt; shop.getPrice1(product),executor)) .map(future -&gt; future.thenApply(Quote::parse)) .map(future -&gt; future.thenCompose(quote -&gt; CompletableFuture.supplyAsync(() -&gt; Discount.applyDiscount(quote),executor))) .map(future -&gt; future.thenAccept(s -&gt; &#123; // 这里一旦Future执行完毕，立即会调用该方法 System.out.println(s + " (done in " + (System.nanoTime() - start ) / 1_000_000 + "msecs.)"); &#125;)) .toArray(length -&gt; new CompletableFuture[length]);CompletableFuture.allOf(futures).join();System.out.println("All shops have now responded in " + (System.nanoTime() - start ) / 1_000_000 + "msecs."); 结果如下：1234567JustByIt price is 135.63 (done in 1636msecs.)BestPrice price is 72.03 (done in 2009msecs.)BuyItAll price is 126.38 (done in 2442msecs.)LetsSaveBig price is 139.40 (done in 3069msecs.)MyFavoriteShop price is 115.09 (done in 3167msecs.)All shops have now responded in 3168msecs.Done in 3263 msecs 注意：这里用到了CompletableFuture的allOf方法，这里在所有任务执行完毕后，输出了一句话，表示任务完成。 仅等待Future结合中最快结束的任务完成上面的例子使用了allOf方法，表示等待一组Future执行完毕。如果只是希望某个任务执行完毕即结束，那么可以使用anyOf方法。 通过编程方式完成一个Future任务的执行假定在调用一个方法时，希望以异步的方式执行，我们在方法中使用一个线程来处理计算，然后立即返回了一个Future。那么我们可以计算完毕后，使用CompletableFuture的complete方法设置任务执行结果。 示例代码：123456789101112// 异步方法public Future&lt;Double&gt; getPriceAsync(String product) &#123; CompletableFuture&lt;Double&gt; future = new CompletableFuture&lt;&gt;(); new Thread()&#123; @Override public void run() &#123; double price = caculatePrice(product); future.complete(price); &#125; &#125;.start(); return future;&#125; CompletableFuture与异常处理在上面的代码中，如果执行caculatePrice方法出现异常，会导致调用CompletableFuture的get方法永远等待下去。异常被限制在计算商品价格的线程范围，最后会杀死该线程，所以调用Future的get会一直等待。 当然，你可以使用带超时参数的get的重载方法来避免无限期等待，最终抛出一个TimeoutException，但这样你并不知道执行任务的线程到底出现了什么问题。 为了解决这个问题，你可以使用CompletableFuture的completeExceptionally将异常抛出。1234567891011121314151617181920public Future&lt;Double&gt; getPriceAsync(String product) &#123; CompletableFuture&lt;Double&gt; future = new CompletableFuture&lt;&gt;(); new Thread()&#123; @Override public void run() &#123; double price = caculatePrice(product); try &#123; // 这里对0做除法并不会抛出异常，在不在线程中使用会抛出异常 //System.out.println(price / 0); // 数组越界会抛出异常 int[] arr = &#123;&#125;; System.out.println(arr[1]); future.complete(price); &#125; catch (Exception e) &#123; future.completeExceptionally(e); &#125; &#125; &#125;.start(); return future;&#125; 比如，上面我们认为模拟了一个数组下标越界的异常。调用future的get方法的客户端会立即得到一个异常，get方法就不会无限期等待了。另外，调用get方法时，始终建议使用带超时参数的重载方法，避免无限等待。 另外，注意：CompletableFuture的所有异步方法都使用了同样的错误管理机制，你不用再花大力气去处理异常了。 参考《java8实战》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 8 新的日期和时间API]]></title>
    <url>%2F2018%2F09%2F14%2FJDK8%E6%96%B0%E7%9A%84%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4API%2F</url>
    <content type="text"><![CDATA[LocalDate、LocalTime、Instant、Duration和Period使用LocalDate和LocalTimeLocalDate是一个不可变对象，提供了简单的日期，不包含时间，也没有附带任何时区相关的信息。你可以通过静态方法of创建一个LocalDate实例。LocalDate提供了很多实用的方法来读取常用的值，比如年份、月份、星期几等。12345678910LocalDate date = LocalDate.of(2014,3,18);int year = date.getYear(); // 2014Month month = date.getMonth(); // MARCHint day = month.dayOfMonth(); // 18DayOfWeek dow = date.getDayOfWeek(); // TUESDAYint len = date.lengthOfMonth(); // 31(days in March)boolean leap = date.isLeapYear(); // false// 也可以通过工厂方法从系统时钟获取当前日期LocalDate today = LocalDate.now(); 你还可以传递一个TemporalField参数拿到同样的信息。TemporalField是一个接口，定义了如何访问tempoal对象某个字段的值。ChronoFIeld枚举实现了这个接口，所以你可以用get方法得到枚举元素的值。123int year = date.get(ChronoField.YEAR);int month = date.get(ChronoField.MONTH_OF_YEAR);int day = date.get(ChronoField.DAY_OF_MONTH); 可以使用LocalTime来表示时间，可以使用of重载的两个工厂方法创建它的实例。第一个重载函数接收小时和分钟，第2个重载函数同时还接受秒。同LocalDate一样，LocalTime也提供了一些getter方法来访问这些变量的值。12345678LocalTime time = LocalTime.of(16,55,32);int hour = time.getHour();int minute = time.getMinute();int second = time.getSecond();int _hour = time.get(ChronoField.HOUR_OF_DAY);LocalTime _time = LocalTime.now(); 合并日期和时间这个符合类名叫LocalDateTime，它同时表示了日期和时间，但不带时区信息。你可以直接创建，也可以通过合并日期和时间对象构造。12345678LocalDateTime dt1 = LocalDateTime.of(2018,9,15,16,50,30); // 直接创建LocalDateTime dt2 = LocalDateTime.of(date,time); // 复合LocalDate和LocalTimeLocalDateTime dt3 = date.atTime(13,59,39); // 通过日期指定时间LocalDateTime dt4 = time.atDate(date); // 通过时间指定日期LocalDateTime dt5 = date.atTime(time);LocalDate date = dt1.toLocalDate(); // 得到LocalDateLocalTime time = dt1.toLocalTime(); // 得到LocalTime 机器的日期和时间格式java.time.Instant是给机器使用的，包含秒和纳秒构成的数字，它是以Unix元年时间（UTC时区1970年1月1日午夜时分）开始所经历的秒数进行计算。你可以向静态方法ofEpochSecond传递一个代表秒数的值创建一个实例。它还有一个增强版本的方法，它接收第二个以纳秒为单位的参数，对传入的描述进行调整。重载的版本会调整纳秒参数，确保保存的纳秒分片在0到999 999 999之间。下面的这些调用会返回几乎相同的Instant对象。1234Instant.ofEpochSecond(3);Instant.ofEpochSecond(3,0);Instant.ofEpochSecond(2,1_000_000_000); // 2秒之后再加上100万纳秒（1秒）Instant.ofEpochSecond(4,-1_000_000_000); // 4秒之前的100万纳秒（1秒） 日期/时间间隔表示2个日期/时间的间隔，可以使用Duration或Period。12345678910111213141516171819202122LocalTime time1 = LocalTime.of(15,23);LocalTime time2 = LocalTime.of(5,29);Duration d1 = Duration.between(time1,time2);LocalDate date1 = LocalDate.now();LocalDate date2 = LocalDate.of(2019,1,1);Duration d2 = Duration.between(date1,date2);LocalDateTime dateTime1 = LocalDateTime.of(date1,time1);LocalDateTime dateTime2 = LocalDateTime.of(date2,time2);Duration d3 = Duration.between(dateTime1,dateTime2);Instant instant1 = Instant.ofEpochSecond(3);Instant instant2 = Instant.ofEpochSecond(5,2_000_000_000);Duration d4 = Duration.between(instant1,instant2);Duration threeMiniutes = Duration.ofMinutes(3);Duration _threeMinutes = Duration.of(3, ChronoUnit.MINUTES);Period tenDyas = Period.ofDays(10);Period threeWeeks = Period.ofWeeks(3);Period twoYearsSixMonthsOneDay = Period.of(2,6,1); 日期-时间内中表示时间间隔的通用方法 方法名 是否静态方法 方法描述 between 是 创建两个时间点之间的interval from 是 由一个临时节点创建interval of 是 由它的组成部分创建interval parse 是 由字符串创建interval addTo 否 创建该interval的副本，并将其叠加到某个指定的temporal对象 get 否 读取该interval的状态 isNegative 否 检查该interval是否是负值，不包含0 iszero 否 检查该interval的时长是否为0 minus 否 通过减去一定的时间创建该interval的副本 multipliedBy 否 将interval的值乘以某个标量创建该interval的副本 negated 否 以忽略某个时长的方式创建该interval的副本 plus 否 以增加某个指定时长的方式创建该interval的副本 subtrctFrom 否 从指定的temporal对象中减去该interval 上面介绍的这些日期-时间对象都是不可变的，是为了更好的支持函数式编程，确保线程安全，保持领域模式一致性。 操作、解析和格式化日期如果已经有了一个LocalDate对象，如果想要修改日期，可以使用它的withAttribute和with方法，会创建一个副本，并按照需要修改的属性。123456LocalDate _date1 = LocalDate.of(2019,5,15);LocalDate _date2 = _date1.withYear(2018); // 2018-05-15// 使用withAttribute方法LocalDate _date3 = _date1.withDayOfMonth(20); // 2019-05-20// 使用with方法LocalDate _date4 = _date1.with(ChronoField.MONTH_OF_YEAR,2); // 2019-02-15 上面是比较直接的修改方式，也可以以相对方式修改日期，比如：12LocalDate _date5 = _date1.plusYears(1); // 2020-05-15LocalDate _date6 = _date1.minusWeeks(1); // 2019-05-08 表示时间点的日期-时间类的通用方法 方法名 是否静态方法 方法描述 from 是 根据传入的Temporal对象创建实例 now 是 根据系统时钟创建Temporal实例 of 是 由Temporal对象的某个部分创建该对象的实例 parse 是 由字符串创建Temporal对象的实例 atOffset 否 将Temporal对象和某个时区偏移相结合 atZone 否 将Temporal对象和某个时区相结合 format 否 使用某个指定的格式器将Temporal对象转换为字符串 get 否 读取Temporal对象某一部分的值 minus 否 通过将当前Temporal对象减去一定的时长创建副本 plus 否 通过将当前Temporal对象增加一定的时长创建副本 with 否 以该Temporal对象为模板，将某些状态进行修改创建该对象的副本。 使用TemporalAdjuster前面的日期操作都是相对比较直接的，你还可使用TemporalAdjuster来进行一些更复杂的操作。比如：1LocalDate _date7 = _date1.with(nextOrSame(DayOfWeek.SUNDAY)); // 2019-05-19 TemporalAdjuster的工厂方法 方法名 方法描述 dayOfWeekInMonth 创建一个新的日期，它的值为同一个月中每一周的第几天 firstDayOfMonth 创建一个新的日期，它的值为当月的第一天 firstDayOfNextMonth 创建一个新的日期，它的值为下个月的第一天 firstDayOfNextYear 创建一个新的日期，它的值为明年的第一天 firstDayOfYear 创建一个新的日期，它的值为当年的第一天 firstInMonth 创建一个新的日期，它的值为同一个月中，第一个符合星期几要求的值 lastDayOfMonth 创建一个新的日期，它的值为当月的最后一天 lastDayOfNextMonth 创建一个新的日期，它的值为下个月的最后一天 lastDayOfNextYear 创建一个新的日期，它的值为明年的最后一天 lastDayOfYear 创建一个新的日期，它的值为当年的今年的最后一天 lastInMonth 创建一个新的日期，它的值为同一个月中，最后一个符合星期几要求的值 next/previous 创建一个新的日期，并将其值设定为日期调整后/前，第一个符合指定星期几要求的日期 nextOrSame/preivousOrSave 创建一个新的日期，并将其值设定为日期调整后/前，第一个符合指定星期几要求的日期。如果该日期已经符合要求，直接返回该对象 如果上面的方法还不能满足你的要求，实现自己的TemporalAdjuster也很简单。实现TemporalAdjuster的adjustInto接口即可。下面实现一个自定义的TemporalAdjuster，能够计算明天的日期，并过滤掉周六周日。12345678910111213141516171819class NextWorkingDayAdjuster implements TemporalAdjuster &#123; @Override public Temporal adjustInto(Temporal temporal) &#123; DayOfWeek dayOfWeek = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK)); int dayToAdd = 1; if (dayOfWeek == DayOfWeek.FRIDAY) &#123; dayToAdd = 3; &#125; else if (dayOfWeek == DayOfWeek.SATURDAY) &#123; dayToAdd = 2; &#125; return temporal.plus(dayToAdd, ChronoUnit.DAYS); &#125;&#125;NextWorkingDayAdjuster adjuster = new NextWorkingDayAdjuster();LocalDate _date8 = _date1.with(adjuster); 日期解析和格式化java8日期格式化的类在java.time.format包中，其中最重要的类是DateTimeFormatter。DateTimeFormatter提供了大量的预定义格式的DateTimeFormatter。比如：格式化：12String s1 = _date1.format(DateTimeFormatter.BASIC_ISO_DATE);String s2 = _date1.format(DateTimeFormatter.ISO_LOCAL_DATE); 解析：1LocalDate dd1 = LocalDate.parse("20190112",DateTimeFormatter.BASIC_ISO_DATE); 这些DateTimeFormmater的实例都是线程安全的，所以你能够以单例的形式创建Formatter实例，并在多个线程之间共享。 你还可以通过DateTimeFormatter的ofPattern方法创建。比如：1DateTimeFormatter formatter = DateTimeFormatter.ofPattern("dd/MM/yyyy"); 另外，你还可以通过DateTimeFormatterBuilder来创建。比如12345678BASIC_ISO_DATE = new DateTimeFormatterBuilder() .parseCaseInsensitive() .appendValue(YEAR, 4) .appendValue(MONTH_OF_YEAR, 2) .appendValue(DAY_OF_MONTH, 2) .optionalStart() .appendOffset("+HHMMss", "Z") .toFormatter(ResolverStyle.STRICT, IsoChronology.INSTANCE); 处理不同的时区新的java.time.ZoneId是对老的java.util.TimeZone的替代，大大简化了时区处理的操作。你可以按照ZoneId.of(地区ID标识)来得到指定时区。1ZoneId romeZone = ZoneId.of("Europe/Rome"); 或者通过toZoneId()来将老的时区对象转换为ZoneId。1ZoneId zoneId = TimeZone.getDefault().toZoneId(); 有了ZoneId，你可以将它和LocalDate、LocalDateTime或Instant整合起来，构造为一个ZoneDateTime实例，它代表了相对于指定时区的时间点。123ZonedDateTime zonedDateTime = date.atStartOfDay(zoneId);zonedDateTime = dateTime1.atZone(romeZone);zonedDateTime = instant.atZone(romeZone); ZoneOffset是ZoneId的一个子类，表示的是当前时间与伦敦格林尼治子午线时间的差异。比如纽约落后于伦敦5小时，可以使用下面的方式表示:123ZoneOffset zoneOffset = ZoneOffset.of("-05:00"); // 美国东部时间偏移量LocalDateTime localDateTime = LocalDateTime.of(2018,9,19,15,30,29);OffsetDateTime offsetDateTime = OffsetDateTime.of(localDateTime,zoneOffset); -05:00的偏差实际上对应的是美国东部标准时间。注意：这种方式定义的ZoneOffset没有考虑夏令时的影响，所以大多数情况下，不推荐使用。 参考《java8实战》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决idea卡顿问题]]></title>
    <url>%2F2018%2F09%2F13%2F%E8%A7%A3%E5%86%B3idea%E5%8D%A1%E9%A1%BF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[idea非常好用，但比较吃内存。建议内存至少8G。通过下面的设置来提升idea的速度。 vm参数设置设置idea.exe.vmoptions/idea64.exe.vmoptions的vm参数123-Xms2000m-Xmx2000m-Xverify:none -Xverify：none 关闭Java字节码验证，从而加快了类装入的速度，并使得在仅为验证目的而启动的过程中无需装入类，缩短了启动时间。一般8G内存建议设置2-3G，-Xms和-Xms设置一样大，一样大可以使IDEA启动时初始堆内存就直接到最大，以免中途扩容影响启动速度。 禁用不使用的插件插件介绍：参考：http://kailing.pub/idea/IntelliJ-IDEA.html。Git：Git（分布式版本控制工具）插件，需本地安装 Git。Subversion：SVN 插件，新版本支持 Subversion1.8ClearCase：IBM Rational 的 SCM 管理工具插件。CVS：CVS 插件。hg4idea：Mercurial 插件，与 Git 类似的分布式版本控制工具。Perforce：Perfoce 插件，商业的版本控制工具。TFS：Team Foundation Server 插件，微软的客户端-服务器源代码管理系统。Visual SourceSafe：VSS 插件，微软的客户端的源代码管理系统。Application Servers Views：配置应用服务器插件。Database：数据库插件，可用于管理 MySQL、Oracle、SQLite 等。Freemarker：支持 freemarker 语法插件。Java EE: Batch Applications：新版本增加的功能，支持 Java EE 7 批处理编程模型(JSR- 352)。Java EE: Bean Validator：支持 Java EE 6 的数据验证模型(JSR-303)。Java EE: Contexts and Denpendency Injection：支持 Java EE6 的依赖注入模型(JSR-299)。Java EE: EJB, JPA, Servlets：EJB、JPA、Servlet 的插件。Java EE: JMS, JSON Processing, Concurrency Transaction：JMS, JSON, Transaction 等的 插件。Java EE: RESTful Web Services： JAX-RS 插件。Java EE: Web Services： JAX-WS 插件。Java Server Pages： JSP 插件。Persistence Frameworks：持久化(JPA、Hibernate)插件。Spring Batch： Spring 批处理框架的插件。Spring Data：Spring 数据访问框架(Mongodb、Redis、Hadoop)插件。Spring Security：Spring 安全框架的插件。Spring：Spring 插件Spring Web Services：Spring Web Services 插件。Spring-AOP and @AspectJ：Spring-AOP 和切面语言的插件。SQL：SQL 插件CoffeeScript：CoffeeScript 插件，基于 Javascript 之上的一门编程语言。dmServer：dmServer 插件，基于 OSGi 的模块化部署的 java 服务器。Google App Engine：GAE 插件，用于创建 GAE 项目。GWT：GWT 插件，支持 GWT 代码提示、编译、组件开发等。Hibernate：Hibernate 插件，支持 Hibernate 代码提示、反向生成代码等。Java EE: Java Server Faces：JSF 插件，支持 JSF 语法。Java EE: WebSockets：13 版本新功能，支持 Java EE WebSockets(JSR-356)。JBoss Seam Pageflow：Jboss Seam PageFlow 插件。Jboss Seam Pages：Jboss Seam Page 插件。Playframework：Playframework 插件，一个 full-stack 的 Java web 框架。Spring Integration Patterns：Spring 企业应用集成框架插件。Spring OSGi：Spring OSGi 插件。Spring Roo Console：Spring Roo 控制台，支持 Spring Roo 命令提示等。Spring Web Flow：Spring 工作流插件。Struts 1.x：Struts1 插件，支持 Struts1 语法提示，结构化显示 Action、Form 等。Struts 2：Struts2 插件，支持 Struts2 语法(Xml、Tag)提示，结构化显示 Action 等。Tapestry：Tapestry 插件，一个 MVC 与模板技术结合的 Java 框架。Vaddin：Vaddin 插件，一个基于 GWT 的 Web RIA 框架。Velocity：Velocity 插件，支持 Velocity 语法提示。Resin：Resin 插件。Tomcat and TomEE：Tomcat 或 TomEE 服务器插件，TomEE 是经过 J2EE 6 认证的Tomcat 企业版本Cloud Foundry：VMware 主导基于 Spring 的开源 PaaS 云计算平台。CloudBees：基于 Tomcat 和 MySQL 的开源 PaaS 云计算平台。Geronimo：Apache 的 J2EE 服务器。GlassFish：Sun 的 J2EE 服务器。Heroku：Heroku 是一个商业的 Rails 的 PaaS 云计算平台。Jboss：Jboss 服务器插件。Jetty：轻量级的 Servlet 服务器。JSR45：兼容 JSR-45 的所有应用服务器，JSR-45(Debugging Support for Other Languages) 为那些非 JAVA 语言写成，却需要编译成 JAVA 代码，运行在 JVM 中的程序，提 供了一个进行调试的标准机制。OpenShift：红帽的开源 PaaS 云计算平台。WebLogic：Oracle 的商业 J2EE 服务器。WebSphere：IBM 的商业 J2EE 服务器。CSS：CSS 插件，可以直接显示 css 配色的颜色。HTML Tools：Html 插件，支持 emmet 快速编写 html 代码。Inspection-JS：JS 代码检测，目前还没见过哪个 IDE 对 JS 的支持有这么智能。JavaScript Debugger：js 调试器，需 chrome 安装 Debugger 插件才可以支持。Javascript Intention Power Pack：补充上面 JS 代码检测的不足。Javascript：Javascript 插件。QuirksMode：用于检测 CSS 和 HTML 的主流浏览器兼容性问题。W3C Validators：W3C 标准检测插件。Flash/Flex：Flash/Flex 开发插件。LESS：LESS 插件，LESS 是一个 CSS 预处理器，通过简单的语法和变量对 CSS 进行扩 展。SASS：SASS 语法支持，SASS 扩展了 CSS，使用特定的语法来编写 CSS。Stylus：Stylus 插件，Stylus 是一个 CSS 预处理器。Ant：Ant 插件。AspectJ：AspectJ 切面框架插件。Byte Code Viewer：java 字节码反编译查看插件。Commander：提供了左右两个用于查看项目结构的插件，可用于项目结构对比或导 航。Copyright：版权声明插件，保证版权信息的一致。Coverage：查看代码覆盖率插件。Cucumber for Java：Java 的 Cucumber 插件，Cucumber 是一个 BDD 驱动的自动化测 试工具。DSM Analysis：架构可视化插件，战士模块间的依赖信息。Eclipse：支持导入 eclipse 结构的项目。Emma：检测代码覆盖率插件Gherkin：Gherkin 语言插件，Cucumber 要用到。Github：Github 集成插件。IntelliLang：主要用于注解语法的注入验证、正则表达式语法检查等Junit：Junit 单元测试插件。Maven：Maven 插件。Maven Integration Extension：Maven 依赖分析图插件。Properties：属性文件(.properties)编辑插件。Refactor-X：Xml 代码格式化插件。Remote Hosts Access：远程主机访问，支持 ftp/ssh。REST Client：用于访问 REST Web Service 的客户端插件。SSH Remote Run：支持通过 Terminal 运行 SSH 脚本。Structural Search：支持通过语法表达式进行搜索或替换。Task Management：任务管理插件，支持 YouTrack, JIRA, Lighthouse, Pivotal Tracker, GitHub, Redmine,Trac 等问题跟踪系统。Terminal：终端命令插件。TestNG-J：TestNG 插件。Time Tracking：任务管理插件中使用到的时间跟踪功能。Type Migration：类型重构优化插件，对不够完善的代码提示重构，比如，静态方法 通过对象来调用而不是通过类调用等等。UML：UML 插件。XpathView+XSLT：Xpath 和 XSLT，支持高亮、分析，自动补全等。XSLT-Debugger：XSLT 调试工具。ZKM-Unscramble：分析 Java 堆栈跟踪插件。Android Designer：安卓 UI 设计器Android：安卓插件ASP：ASP 编辑器CFML：ColdFusion 标记语言插件，ColdFusion 是一个动态 Web 服务器，其 CFML 是 一个类似 JSTL 的程序语言。Cucumber for Groovy：Groovy 的 Cucumber 插件，Cucumber 是一个 BDD 驱动的自 动化测试工具。Gradle：Gradle 插件，Gradle 是一个类似 Maven 的 Java 构建工具。Grails：Grails 插件，Grails 是 Rails 的 Groovy 实现。Groovy：Groovy 插件，Groovy 是一种基于 JVM 的动态脚本语言。GuiceyIDEA：Guice 插件，Guice 是 Google 开发的 Java IOC 框架。HAML：HAML 插件，HAML 是一种 Rails 下的模板语言。IDEtalk：IDEA 的即时通讯工具，用处不大。J2ME：J2ME 插件。JavaFX：JavaFX 插件，JavaFX 是 Sun 发布的 RIA 技术。Jboss Drools：Drools 插件，Drools 是一种 Java 业务规则引擎。Jboss jBPM：jBPM 插件，jBPM 是一种 Java 工作量引擎。Osmorc：OSGi 插件。Plugin DevKit：IDEA 插件开发工具。UI Designer：Swing UI 设计插件。UI Designer(Core)：Swing UI 设计插件。YAML：YAML 插件，YAML 是一种数据序列化格式。 移除不使用的模块点击模块，右键，Remove Module即可（不会删除本地文件）。这其实是很重要的一点，若是一个project下有太多的module，则idea scan file index就会很久。 其他优化单词拼写检查Settings-&gt;Editor-&gt;Inspections-&gt;Spelling勾选检查，去勾选不检查单词拼写。Settings-&gt;Editor-&gt;Inspections-&gt;General-&gt;Duplicated Code，不进行重复代码检查。你也可以Inspections不勾选任何东西。 目前的配置推荐我目前安装的idea2017.2，编辑器使用的字体是JejaVu Sans Mono，13号字体。 显示效果如下：]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有道云笔记安全问题]]></title>
    <url>%2F2018%2F09%2F12%2F%E6%9C%89%E9%81%93%E4%BA%91%E7%AC%94%E8%AE%B0%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[有道云笔记是我个人一直在用的一款笔记软件，不过突然发现一个安全问题。哪怕你的文件上了锁，在有道云笔记的数据目录仍然可以看到。 所以，在公司离职的时候记得卸载软件并清空数据目录。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 8使用Optional取代null]]></title>
    <url>%2F2018%2F09%2F12%2FJDK8%E4%BD%BF%E7%94%A8Optional%E5%8F%96%E4%BB%A3null%2F</url>
    <content type="text"><![CDATA[在前面的章节中我们已经使用过Optional了，这里介绍Optional的更多用法。 假定有如下数据模型：1234567891011121314151617181920212223public class Person &#123; private Car car; public Car getCar() &#123; return car; &#125;&#125;public class Car &#123; private Insurance insurance; public Insurance getInsurance() &#123; return insurance; &#125;&#125;public class Insurance &#123; private String name; public String getName() &#123; return name; &#125;&#125; 那么，下面这段代码有什么问题？123public String getCarInsuranceName(Person person) &#123; return person.getCar().getInsurance().getName();&#125; person可能为空，ca也可能为空，insurance也可能为空，任何一个对象为空都会抛出空指针异常。 所以，常规做法我们需要做空值判断。1234567891011121314public String getCarInsuranceName(Person person) &#123; if (null != person) &#123; Car car = person.getCar(); if (null != car) &#123; Insurance insurance = car.getInsurance(); if (null != insurance) &#123; return insurance.getName(); &#125; &#125; &#125; return null;&#125; 可以看到N多层次的空值判断，这种方式不具备可扩展性，可读性也不好。 下面我们使用java 8提供的Optional来解决这个问题。数据模型修改如下：1234567891011121314151617181920212223public class Person &#123; private Optional&lt;Car&gt; car; public Optional&lt;Car&gt; getCar() &#123; return car; &#125;&#125;public class Car &#123; private Optional&lt;Insurance&gt; insurance; public Optional&lt;Insurance&gt; getInsurance() &#123; return insurance; &#125;&#125;public class Insurance &#123; private String name; public String getName() &#123; return name; &#125;&#125; 根据车主获取保险公司名字的方法123456public String getCarInsuranceName(Optional&lt;Person&gt; person) &#123; return person.flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse("unknown");&#125; Person、Car、Insurance任意一个对象为空，结果都会返回unknown。very简洁有木有？ Optional入门创建Optional对象 声明一个空的Optional 1Optional&lt;Person&gt; optPerson = Optional.empty(); 根据非空值创建 12Person person = new Person();Optional&lt;Person&gt; optional = Optional.of(person); 如果person为null，会立即抛出空指针异常，而不是等到访问person的属性时才返回一个错误。 可接受null的Optional1Optional&lt;Person&gt; optional = Optional.ofNullable(person); 如果person为null，那么得到的optional就是空对象。 使用map从Optional提取和转换值从insurance公司提取公司的名称，提取名称前，你需要检查insurance是否为null，代码如下：1234String name = null;if (null != insurance) &#123; name = insurance.getName();&#125; 为了支持这种模式，Optional提供了map方法。12Optional&lt;Insurance&gt; optInsurance = Optional.ofNullable(insurance);Optional&lt;String&gt; name = optInsurance.map(Insurance::getName); 使用flatMap链接Optional对象在之前使用流时使用了它的flatMap方法，它接受一个函数作为参数，返回值是另一个流。这个方法会应用到流中的每个元素，最终形成一个新的流的流。但是flatMap会用流的内容替换每个新生成的流，即方法生成的各个流会被合并或者扁平化为一个单一的流。如果我们使用Optional.map从Optional提取Insurance的name会编译不通过。123456public String getCarInsuranceName(Optional&lt;Person&gt; person) &#123; return person.map(Person::getCar) .map(Car::getInsurance) .map(Insurance::getName) .orElse("unknown");&#125; 因为person.map(Person::getCar)返回的是一个Optional&lt;Optional&gt;对象，所以它调用map(Car::getInsurance)是非法的。但是我们可以借助Optional.flatMap来实现，如文章最开始所述。 2个Optional的组合假定有一个方法，接收一个Person和Car对象，并以此为条件对外提供服务进行查询，通过一些业务逻辑，返回满足该组合的最便宜的保险公司。12345public Insurance findCheapestInsurance(Person person,Car car) &#123; // 不同保险公司提供的查询服务 // 对比所有数据 return cheapestCompany;&#125; 假设我们需要一个Null-safe版本的方法，接收2个参数Optional和Optional，返回一个Optional对象。如果传入的任意一个参数为空，那么返回一个空的Optional。由于Optional提供了一个isPersent方法，所以可能的实现如下：123456public Insurance nullSafeFindCheapestInsurance(Optional&lt;Person&gt; person,Optional&lt;Car&gt; car) &#123; if (person.isPresent() &amp;&amp; car.isPresent()) &#123; return Optional.of(findCheapestInsurance(person.get(),car.get())); &#125; return Optional.empty();&#125; 但实际上，我们完全可以使用flatMap和map来实现。123public Optional&lt;Insurance&gt; nullSafeFindCheapestInsurance(Optional&lt;Person&gt; person, Optional&lt;Car&gt; car) &#123; return person.flatMap(p -&gt; car.map(c -&gt; findCheapestInsurance(p, c)));&#125; 使用filter剔除特定的值filter方法接收一个谓词作为参数，如果Optional对象的值存在，并且符合谓词的条件，filter方法就返回其值，否则就返回一个空的Optional对象。示例：12Optional&lt;Insurance&gt; optInsurance = ...;optInsurance.filter(insurance -&gt; "CambriadeInsurance".equals(insurance.getName())).ifPersent(System.out::println); 示例2：找出年龄大于或等于minAge参数的Person所对应的保险公司列表。1234567public String getCarInsuranceName(Optional&lt;Person&gt; person,int minAge) &#123; return person.filter(p -&gt; p.getAge() &gt;= minAge) .flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse("Unknown");&#125; 使用Optional的实战示例使用Optional封装可能的null值假设你有一个Map&lt;String,Object&gt;方法，访问由key索引的值时，如果map中没有与key关联的值，就会返回一个null。1Object value = map.get(key); 你可以使用Optional封装map的返回值1Optional&lt;Object&gt; value = Optional.ofNullable(map.get(key)); 每次你希望安全的将潜在的null的对象进行转换，将其转换为Optional对象时，就可以考虑使用这种方法。 异常与Optional由于某种原因，函数无法返回值，这时除了返回null，还可能抛出一个异常，比如Integer.parseInt。 你可以使用Optional对操作结果进行包装1234567public Optional&lt;Integer&gt; stringToInt(String str) &#123; try &#123; return Optional.of(Integer.parseInt(str)); &#125; catch (NumberFormatException e) &#123; return Optional.empty(); &#125;&#125; 你可以将很多类似的操作封装在一个工具类中，比如叫OptionalUtility。以后就可以直接调用OptionalUtility.stringToInt，就能将字符串转换为一个Optional，而无需记住你在其中封装了笨重的try/catch逻辑了。 注意：不推荐使用基础类型的Optional，比如OptionalInt,OptionalLong,OptionalDouble等等，因为它们不支持map、flatMap和filter等方法，而这些确实Optional中最有用的方法。 综合示例：从属性中读取一个int属性值（属性不存在则返回0）123456public int readDuration(Properties p, String key) &#123; return Optional.ofNullable(p.getProperty(key)) .flatMap(OptionalUtility::stringToInt) .filter(i -&gt; i &gt; 0) .orElse(0);&#125; 参考《java8实战》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[notepad++突然崩溃，保存的文件没了怎么办]]></title>
    <url>%2F2018%2F09%2F12%2Fnotepad%2B%2B%E7%AA%81%E7%84%B6%E5%B4%A9%E6%BA%83%EF%BC%8C%E4%BF%9D%E5%AD%98%E7%9A%84%E6%96%87%E4%BB%B6%E6%B2%A1%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[Notepad++是一款功能强大、界面友好且易于使用的编辑器，平时少不了与它打交道。 不过，最近使用它编辑文件时，notepad++突然崩溃，而且之前已经保存过的文件内容也被清空了。不过好在notepad++默认启用了文件定时备份，可以在备份目录找到丢失的文件。 如果你的notepad++没有开启文件备份，建议打开，以防万一。另外，建议文件修改完毕后立即关闭它。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK8之用流收集数据]]></title>
    <url>%2F2018%2F09%2F11%2FJDK8%E4%B9%8B%E7%94%A8%E6%B5%81%E6%94%B6%E9%9B%86%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[收集器简介收集器非常有用，用它来可以简洁而灵活的定义collect用来生成结果集合的标准。对流调用collect方法会对流中的每个元素触发规约操作。一般来说，收集器会对元素应用一个转换函数，并将结果累积在一个数据结构中，从而产生这一过程的最终输出。 规约和汇总在将流中的项目合并成一个结果时，一般会使用收集器（Stream的collect）。这个结果可以是任何类型，可以复杂如一棵树的多级映射，或是简单如一个整数。假定有如下菜单：1234567891011List&lt;Dish&gt; menu = Arrays.asList( new Dish("pork", false, 800, Dish.Type.MEAT), new Dish("beef", false, 700, Dish.Type.MEAT), new Dish("chicken", false, 400, Dish.Type.MEAT), new Dish("french fries", true, 530, Dish.Type.OTHER), new Dish("rice", true, 300, Dish.Type.OTHER), new Dish("season fruit", true, 120, Dish.Type.OTHER), new Dish("pizza", false, 300, Dish.Type.OTHER), new Dish("prawns", false, 300, Dish.Type.FISH), new Dish("salmon", false, 450, Dish.Type.FISH)); 在下面的所有示例中，假定你已经导入了Collectors的所有静态工厂方法1import static java.util.stream.Collectors.*; 查找流中的最大值和最小值假如你想找出菜中热量最高的菜和热量最低的菜，可以使用Collectors.maxBy和Collectors.minBy这2个收集器。它们接收一个Comparator参数来比较流中的元素。比如找出菜单中热量最多的菜12345// 创建比较器Comparator&lt;Dish&gt; dishComparator = Comparator.comparingInt(Dish::getCalories);// 根据热量比较，找出最大热量的菜Optional&lt;Dish&gt; maxCaloriesDish = menu.stream().collect(maxBy(dishComparator));maxCaloriesDish.ifPresent(System.out::println); 汇总求和Collectors类专门为汇总提供了一个工厂方法：Collectors.summingInt。它接收一个把对象映射为求和所需的int的函数，并返回一个收集器。该收集器在传递给普通的collect方法后即自行我们需要的汇总操作。 比如计算菜的总热量1int totalCalories = menu.stream().collect(summingInt(Dish::getCalories)); 在遍历流时，会将每道菜都映射为其热量，然后把数字累加到一个累加器（这里初始值为0）。 Collectors的summingLong和summingDouble方法与summingInt用法一样，用于处理long和double的情况。 求平均值使用Collectors.averageInt/averageLong,averageDouble来求平均数。 比如，求所有菜平均的热量。1double avgCalories = menu.stream().collect(averagingDouble(Dish::getCalories)); 一次性获得多个汇总值如果你想一次性获取到多个汇总的结果，比如一次性获取到最大值、最小值，平均值，求和的结果等等，可以使用Collectors.summarizingInt方法。12IntSummaryStatistics summaryStatistics = menu.stream().collect(summarizingInt(Dish::getCalories));System.out.println(summaryStatistics); 输出结果如下：1IntSummaryStatistics&#123;count=9, sum=3900, min=120, average=433.333333, max=800&#125; 连接字符串Collectors.joining方法会将流中的每个元素应用toString()方法，然后将所得到的字符串连接在一起。 比如将菜单中所有菜名连接起来：12String menuNames = menu.stream().map(Dish::getName).collect(joining());System.out.println(menuNames); // 使用joining()无参数的方法只会将结果连接在一起 输出结果：1porkbeefchickenfrench friesriceseason fruitpizzaprawnssalmon 可以发现，可读性并不好，幸好提供了重载方法。我们可以提供一个分隔符。12menuNames = menu.stream().map(Dish::getName).collect(joining(","));System.out.println(menuNames); // 用逗号分隔的菜肴名称 输出结果：1pork,beef,chicken,french fries,rice,season fruit,pizza,prawns,salmon 广义的规约汇总我们之前讨论的所有收集器，都是一个可以用reducing工厂方法定义的规约过程的特殊情况而已。比如使用reducing方法来计算菜单的总热量：1int totalCalories = menu.stream().collect(reducing(0, Dish::getCalories, (i, j) -&gt; i + j)); 它需要3个参数： 第一个参数是规约操作的起始值，也是流中没有元素时的返回值； 第二个参数是将菜肴转换为一个表示其所含热量的int。 第三个参数是一个BinaryOpeartor，将2个项目累积成一个同类型的值。在这里是对2个int求和。 也可以使用下面的单参数的reducing方法来计算菜品的总热量。1Optional&lt;Dish&gt; totalCaloriesDish = menu.stream().collect(reducing((d1,d2) -&gt; d1.getCalories() &gt; d2.getCalories() ? d1 : d2)); 你可以把单参数的reducing方法看做一个三参数的特殊情况。它把流中的第一个元素作为起点，把恒等函数（即一个函数仅仅返回你参数本身）作为一个转换函数。这也就意味着把单参数的reducing方法传递给一个collect方法，收集器就没有起点，所以会返回一个Optional对象。 分组Collectors提供了groupingBy方法来对元素进行分组。 比如按照类别对菜肴进行分组：12Map&lt;Dish.Type, List&lt;Dish&gt;&gt; byTypeDishes = menu.stream().collect(groupingBy(Dish::getType));System.out.println(byTypeDishes); 输出结果：12345678910111213&#123;OTHER=[Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;, Dish&#123;name=&apos;rice&apos;, vegetarian=true, calories=300, type=OTHER&#125;, Dish&#123;name=&apos;season fruit&apos;, vegetarian=true, calories=120, type=OTHER&#125;, Dish&#123;name=&apos;pizza&apos;, vegetarian=false, calories=300, type=OTHER&#125;], FISH=[Dish&#123;name=&apos;prawns&apos;, vegetarian=false, calories=300, type=FISH&#125;, Dish&#123;name=&apos;salmon&apos;, vegetarian=false, calories=450, type=FISH&#125;], MEAT=[Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;, Dish&#123;name=&apos;beef&apos;, vegetarian=false, calories=700, type=MEAT&#125;, Dish&#123;name=&apos;chicken&apos;, vegetarian=false, calories=400, type=MEAT&#125;]&#125; 多级分组要实现多级分组，可以使用Collectors.groupingBy的双参数的重载方法，它除了普通的分类函数外，还接受一个collector类型的第2个参数。那么进行二级分组的话，可以把一个内层的groupingBy传递给外层的groupingBy，并定义一个为流中项目分类的二级标准。 比如按类别和热量等级分组：123456789101112// 定义400以下为低热量，700以下为一般，700以上为高热量public enum CaloricLevel &#123;DIET, NORMAL, FAT&#125;大分组为类别，小分组为热量Map&lt;Dish.Type, Map&lt;CaloricLevel, List&lt;Dish&gt;&gt;&gt; dishesByTypeCaloriesLevel = menu.stream().collect(groupingBy(Dish::getType, groupingBy(dish -&gt; &#123; if (dish.getCalories() &lt;= 400) &#123; return CaloricLevel.DIET; &#125; else if (dish.getCalories() &lt;= 700) &#123; return CaloricLevel.NORMAL; &#125; return CaloricLevel.FAT;&#125;)));System.out.println(dishesByTypeCaloriesLevel); 输出结果（格式化后）：12345678910111213141516&#123;OTHER=&#123; DIET=[Dish&#123;name=&apos;rice&apos;, vegetarian=true, calories=300, type=OTHER&#125;, Dish&#123;name=&apos;season fruit&apos;, vegetarian=true, calories=120, type=OTHER&#125;, Dish&#123;name=&apos;pizza&apos;, vegetarian=false, calories=300, type=OTHER&#125;], NORMAL=[Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;]&#125;, FISH=&#123; DIET=[Dish&#123;name=&apos;prawns&apos;, vegetarian=false, calories=300, type=FISH&#125;], NORMAL=[Dish&#123;name=&apos;salmon&apos;, vegetarian=false, calories=450, type=FISH&#125;]&#125;, MEAT=&#123; DIET=[Dish&#123;name=&apos;chicken&apos;, vegetarian=false, calories=400, type=MEAT&#125;], NORMAL=[Dish&#123;name=&apos;beef&apos;, vegetarian=false, calories=700, type=MEAT&#125;], FAT=[Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;]&#125;&#125; 按子组收集数据我们把第二个groupingBy传递给外层收集器来实现多级分组，但进一步讲，传递给第一个收集器的第二个收集器可以是任意类型，而不一定是一个groupingBy。比如，要统计菜单中每种菜有多少种，可以传递counting收集器作为groupingBy收集器的第二个收集器。12Map&lt;Dish.Type, Long&gt; typesCount = menu.stream().collect(groupingBy(Dish::getType, counting()));System.out.println(typesCount); 输出结果：1&#123;OTHER=4, FISH=2, MEAT=3&#125; 再比如，查找每个菜品类型热量最高的菜12Map&lt;Dish.Type, Optional&lt;Dish&gt;&gt; maxCaloricByType = menu.stream().collect(groupingBy(Dish::getType, maxBy(Comparator.comparingInt(Dish::getCalories))));System.out.println(maxCaloricByType); 输出结果（格式化后）：1234567&#123;OTHER=Optional[Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;], FISH=Optional[Dish&#123;name=&apos;salmon&apos;, vegetarian=false, calories=450, type=FISH&#125;], MEAT=Optional[Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;]&#125; 将收集器的结果转换为另一种类型分组操作的Map结果中的每个值上包装的Optional没什么用，你可以使用Collectors.collectingAndThen收集器去掉Optional。该方法接收2个参数——要转换的收集器和转换方法，并返回另一个收集器。这个收集器相当于旧收集器的一个包装，collect操作的最后一步就是将返回值用转换方法做一个映射。123456把收集器的结果转换为另一种类型（比如去掉上面的Optional）Map&lt;Dish.Type, Dish&gt; maxCaloricByTypeDishes = menu.stream() .collect(groupingBy(Dish::getType, collectingAndThen( maxBy(Comparator.comparingInt(Dish::getCalories)), Optional::get)));System.out.println(maxCaloricByTypeDishes); 输出结果（格式化后）：1234567891011121314151617181920&#123;OTHER=Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;, FISH=Dish&#123;name=&apos;salmon&apos;, vegetarian=false, calories=450, type=FISH&#125;, MEAT=Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;&#125;``### Collectors.mapping常常和groupingBy一起使用的另一个收集器是mapping方法生成的。它接收2个参数：一个函数对流中的元素做变换，另一个则将变换的结果对象收集起来。其目的是在累加之前对每个输入元素应用一个映射函数，这样就可以让特定类型元素的收集器适应不同类型的对象。比如想知道每种类型的Dish中有哪些CaloricLevel。```javaMap&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; byTypeCaloricDishes = menu.stream().collect(groupingBy(Dish::getType, mapping(dish -&gt; &#123; if (dish.getCalories() &lt;= 400) &#123; return CaloricLevel.DIET; &#125; else if (dish.getCalories() &lt;= 700) &#123; return CaloricLevel.NORMAL; &#125; return CaloricLevel.FAT;&#125;, toSet())));System.out.println(byTypeCaloricDishes); 输出结果：1&#123;OTHER=[DIET, NORMAL], FISH=[DIET, NORMAL], MEAT=[DIET, NORMAL, FAT]&#125; 分区分区是分组的特殊情况，由一个谓词（返回一个布尔值的函数）作为分类函数，它称分区函数。分区函数返回一个布尔值，则意味着得到的分组Map的键类型是Boolean，于是它最多可以分为2组——true是一组，false是一组。 比如将菜单按照素食和非素食分开：1234// 1.按素菜 OR 荤菜分组// true表示素菜；false为非素菜Map&lt;Boolean, List&lt;Dish&gt;&gt; partitionedMenu = menu.stream().collect(partitioningBy(Dish::isVegetarian));System.out.println(partitionedMenu + "\n"); 输出结果（格式化后）：123456789101112&#123;false=[Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;, Dish&#123;name=&apos;beef&apos;, vegetarian=false, calories=700, type=MEAT&#125;, Dish&#123;name=&apos;chicken&apos;, vegetarian=false, calories=400, type=MEAT&#125;, Dish&#123;name=&apos;pizza&apos;, vegetarian=false, calories=300, type=OTHER&#125;, Dish&#123;name=&apos;prawns&apos;, vegetarian=false, calories=300, type=FISH&#125;, Dish&#123;name=&apos;salmon&apos;, vegetarian=false, calories=450, type=FISH&#125;], true=[Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;, Dish&#123;name=&apos;rice&apos;, vegetarian=true, calories=300, type=OTHER&#125;, Dish&#123;name=&apos;season fruit&apos;, vegetarian=true, calories=120, type=OTHER&#125;]&#125; 分区的好处分区的好处在于分区函数保留了true和false2套流元素列表。比如上面的例子中，要得到素菜列表，使用partitionedMenu.get(true)即可。 partitionBy方法还有一个重载版本，可以传递第2个收集器。 比如，按是否素菜分区，再根据Type分组：1234// 分区+分组// 先按是否素菜分区，然后将同类别的菜放到一起Map&lt;Boolean, Map&lt;Dish.Type, List&lt;Dish&gt;&gt;&gt; vegetarianDishesByType = menu.stream().collect(partitioningBy(Dish::isVegetarian, groupingBy(Dish::getType)));System.out.println(vegetarianDishesByType + "\n"); 输出结果（格式化）：1234567891011121314&#123;false=&#123; OTHER=[Dish&#123;name=&apos;pizza&apos;, vegetarian=false, calories=300, type=OTHER&#125;], FISH=[Dish&#123;name=&apos;prawns&apos;, vegetarian=false, calories=300, type=FISH&#125;, Dish&#123;name=&apos;salmon&apos;, vegetarian=false, calories=450, type=FISH&#125;], MEAT=[Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;, Dish&#123;name=&apos;beef&apos;, vegetarian=false, calories=700, type=MEAT&#125;, Dish&#123;name=&apos;chicken&apos;, vegetarian=false, calories=400, type=MEAT&#125;]&#125;, true=&#123; OTHER=[Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;, Dish&#123;name=&apos;rice&apos;, vegetarian=true, calories=300, type=OTHER&#125;, Dish&#123;name=&apos;season fruit&apos;, vegetarian=true, calories=120, type=OTHER&#125;]&#125;&#125; 查找素菜和非素菜中热量最高的菜123456// 找到素菜和非素菜卡路里含量最高的菜Map&lt;Boolean, Dish&gt; mostCaloricPartitionedByVegetarian = menu.stream() .collect(partitioningBy(Dish::isVegetarian, collectingAndThen(maxBy(comparingInt(Dish::getCalories)), Optional::get)));System.out.println(mostCaloricPartitionedByVegetarian + "\n"); 输出结果：1&#123;false=Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;, true=Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;&#125; 找出素菜和非素菜的数量12Map&lt;Boolean, Long&gt; partitionedByVegetarianCount = menu.stream().collect(partitioningBy(Dish::isVegetarian, counting()));System.out.println(partitionedByVegetarianCount + "\n"); 输出结果：1&#123;false=6, true=3&#125; 按是否为素菜分组，找出热量在500以上和500一下的菜12Map&lt;Boolean, Map&lt;Boolean, List&lt;Dish&gt;&gt;&gt; twoPartitionedDishes = menu.stream().collect(partitioningBy(Dish::isVegetarian, partitioningBy(d -&gt; d.getCalories() &gt; 500)));System.out.println(twoPartitionedDishes + "\n"); 输出结果：123456789101112&#123; false=&#123; false=[Dish&#123;name=&apos;chicken&apos;, vegetarian=false, calories=400, type=MEAT&#125;, Dish&#123;name=&apos;pizza&apos;, vegetarian=false, calories=300, type=OTHER&#125;, Dish&#123;name=&apos;prawns&apos;, vegetarian=false, calories=300, type=FISH&#125;, Dish&#123;name=&apos;salmon&apos;, vegetarian=false, calories=450, type=FISH&#125;], true=[Dish&#123;name=&apos;pork&apos;, vegetarian=false, calories=800, type=MEAT&#125;, Dish&#123;name=&apos;beef&apos;, vegetarian=false, calories=700, type=MEAT&#125;] &#125;, true=&#123; false=[Dish&#123;name=&apos;rice&apos;, vegetarian=true, calories=300, type=OTHER&#125;, Dish&#123;name=&apos;season fruit&apos;, vegetarian=true, calories=120, type=OTHER&#125;], true=[Dish&#123;name=&apos;french fries&apos;, vegetarian=true, calories=530, type=OTHER&#125;] &#125;&#125; 找出给定数字范围内的质数和非质数12345Map&lt;Boolean, List&lt;Integer&gt;&gt; primeNumbers = IntStream.rangeClosed(2, 10).boxed().collect(partitioningBy(i -&gt; isPrime(i)));private static boolean isPrime(int i) &#123; return IntStream.range(2, i).noneMatch(n -&gt; i % n == 0);&#125; Collectors类的静态工厂方法 工厂方法 返回类型 用于 toList List 把流中所有项目收集到一个List toSet Set 把流中所有项目收集到一个Set，删除重复项 toCollection Collection 把流中所有项目收集到给定的供应源创建的集合 counting Long 计算流中元素的个数 summingInt Integer 对流中项目的一个整数属性求和 averagingInt Double 计算流中项目Integer 属性的平均值 summarizingInt IntSummaryStatistics 收集关于流中项目Integer 属性的统计值，例如最大、最小、总和与平均值 joining` String 连接对流中每个项目调用toString 方法所生成的字符串 maxBy Optional 一个包裹了流中按照给定比较器选出的最大元素的Optional，或如果流为空则为Optional.empty() minBy Optional 一个包裹了流中按照给定比较器选出的最小元素的Optional，或如果流为空则为Optional.empty() reducing 归约操作产生的类型 从一个作为累加器的初始值开始，利用BinaryOperator 与流中的元素逐个结合，从而将流归约为单个值 collectingAndThen 转换函数返回的类型 包裹另一个收集器，对其结果应用转换函数 groupingBy Map&lt;K, List&gt; 根据项目的一个属性的值对流中的项目作问组，并将属性值作为结果Map 的键 partitioningBy Map&lt;Boolean,List&gt; 根据对流中每个项目应用谓词的结果来对项进行分区 收集器接口前面已经使用了很多Collector接口实现的收集器，像toList,groupingBy等。 下面看下Collector接口的定义：1234567public interface Collector&lt;T, A, R&gt; &#123; Supplier&lt;A&gt; supplier(); BiConsumer&lt;A, T&gt; accumulator(); BinaryOperator&lt;A&gt; combiner(); Function&lt;A, R&gt; finisher(); Set&lt;Characteristics&gt; characteristics();&#125; T是流中要手机的项目的类型。A是累加器的类型，累加器是在收集过程中用于累积部分结果的对象。R是收集操作得到的对象的类型。例如，你可以实现一个ToListCollector类，将Stream中的所有元素收集到List中，它的签名如下：1class ToListCollector&lt;T&gt; implements Collector&lt;T,List&lt;T&gt;,List&lt;T&gt;&gt; 建立新的结果容器：supplier方法supplier方法必须返回一个结果为空的Supplier，也就是一个无参数函数，在调用时它会创建一个空的累加器实例，供数据收集过程使用。 将元素天剑到结果容器：accumulator方法accumulator方法会返回执行规约操作的函数。当遍历到流中第n个元素时，这个函数执行时会有2个参数：保存规约结果的累加器，还有第n个元素本身。 对结果容器应用最终转换：finisher方法在遍历完流后，finisher方法必须返回在累积过程的最后要调用的一个函数，以便将累加器对象转换为整个集合操作的最终结果。 合并2个结果容器：combiner方法combiner方法会返回一个供规约操作使用的函数，它定义了对流的各个部分进行并行处理时，各个子部分规约说的的累加器要如何合并。 characteristics方法characteristics方法会返回一个不可变的Characteristics集合，他定义了收集器的行为，尤其是关于流是否可以并行规约，以及可以使用哪些优化的提示。Characteristics是一个包含三个项目的枚举： UNORDERED——规约结果不受流中项目的遍历和累积顺序的影响。 CONCURRENT——accumulator函数可以从多个线程同时调用，且该收集器可以并行规约流。如果收集器没有标为UNORDERED，那它仅在用于无序数据源时才可进行并行规约。 IDENTITY_FINISH——这表明完成器方法返回的函数时一个恒等函数，可以跳过。这种情况下，累加器对象会直接用做规约过程的最终结果。这也意味着，将累加器A不加检查的转换为R也是安全的。 我们开发的ToListCollector是IDENTIFY_FINISHE的，因为用来累积流中元素的List已经是我们要的最终结果，用不着进一步转换了。 实现自己的收集器下面实现一个自己的ToListCollector123456789101112131415161718192021222324252627282930313233static class ToListCollector&lt;T&gt; implements Collector&lt;T,List&lt;T&gt;,List&lt;T&gt;&gt; &#123; @Override public Supplier&lt;List&lt;T&gt;&gt; supplier() &#123; // 建立新的结果容器 return () -&gt; new ArrayList&lt;T&gt;(); &#125; @Override public BiConsumer&lt;List&lt;T&gt;, T&gt; accumulator() &#123; // 将元素追加到结果容器 return (List,item) -&gt; List.add(item); &#125; @Override public BinaryOperator&lt;List&lt;T&gt;&gt; combiner() &#123; // 合并2个结果容器 return (list1,list2) -&gt; &#123; list1.addAll(list2); return list1; &#125;; &#125; @Override public Function&lt;List&lt;T&gt;, List&lt;T&gt;&gt; finisher() &#123; // 对结果容器进行最终转换 return Function.identity(); &#125; @Override public Set&lt;Characteristics&gt; characteristics() &#123; return Collections.unmodifiableSet(EnumSet.of(Characteristics.IDENTITY_FINISH,Characteristics.CONCURRENT)); &#125;&#125;// 使用自定义的收集器List&lt;Dish&gt; dishes = menu.stream().collect(new ToListCollector&lt;Dish&gt;()); 参考《java8实战》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK8之Stream]]></title>
    <url>%2F2018%2F09%2F08%2FJDK8%E4%B9%8BStream%2F</url>
    <content type="text"><![CDATA[本文介绍java 8 Stream API提供的诸多操作，利用这些操作可以让你快速的完成复制的数据查询，如筛选、切片、映射、查找、匹配和规约。包括一些特殊流的用法：数值流、文件流、数组流，无限流。 筛选和切片用谓词筛选Stream接口提供了filter方法，该方法接收一个谓词作为参数，并返回一个包含所有符合谓词的元素的流。 比如，筛选出所有的素菜：1List&lt;Dish&gt; dishes = menu.stream().filter(Dish::isVegetarian).collect(toList()); 元素去重Stream还支持distinct方法，它会返回不重复的元素的流（根据元素的hashCode和equals方法）。例如，筛选出下面列表中的所有不重复的偶数：1234List&lt;Integer&gt; numbers = Arrays.asList(1,2,5,2,6,3,3,2,4);numbers.stream() .filter(i -&gt; i % 2 == 0) .distinct() // 根据元素的hashcode和equals方法过滤重复元素 截断流Stream还支持limit方法，返回一个不超过给定长度的流。所需的长度作为参数传递给limit。如果流是有序的，则最多会返回前n个元素。比如，筛选出热量超过300卡路里的头三道菜：1234List&lt;Dish&gt; highCaloriesTop3 = menu.stream() // 由菜单得到一个流 .filter(dish -&gt; dish.getCalories() &gt; 300) // 接收Lambda，从流中排除某些元素 .limit(3) // 截断流，使元素不超过指定数量 .collect(Collectors.toList()); // 将流转换为其他形式 跳过元素Stream还支持skip方法，返回一个扔掉了前n个元素的流。如果流中元素不足n个，则返回空流。比如，找出超过300卡路里的菜，但忽略前2道。1234List&lt;Dish&gt; highCalories = menu.stream() .filter(dish -&gt; dish.getCalories() &gt; 300) .skip(2) .collect(Collectors.toList()); 映射对流中的每个元素应用函数Stream支持map方法，接收一个函数作为参数，会对流中的每个元素应用该函数，并映射为一个新的元素。比如，获取每道菜的名称：1List&lt;String&gt; dishNames = menu.stream().map(Dish::getName).collect(toList()); 流的扁平化流支持flatMap方法，可以将流中的每个值都转换为一个流，然后把所有的流连接起来形成一个流。 例1：给定如下单词列表[‘Hello’,’World’]，如何得到不重复的字符？1234567List&lt;String&gt; strings = Arrays.asList("Hello", "World");// Arrays::stream将一个数组转换为一个流List&lt;String&gt; words = strings.stream() .map(s -&gt; s.split("")) // 得到字符数组 .flatMap(Arrays::stream) // 将字符数组中的每个元素都换成另外一个流，然后把所有的流连接起来形成一个新的流 .distinct() .collect(Collectors.toList()); 上面如果只是使用map方法，只能得到2个字符数组，而使用flatMap就可以将数组中的每个元素映射为一个流，然后把所有的流合起来形成一个新的流。 例2：给定2个数字列表，[1,2,3],[4,5]，如何返回所有的数对？[(1,4),(1,5),(2,4),(2,5),(3,4),(3,5)]12345List&lt;Integer&gt; numList1 = Arrays.asList(1, 2, 3);List&lt;Integer&gt; numList2 = Arrays.asList(4, 5);List&lt;int[]&gt; nums = numList1.stream() .flatMap(i -&gt; numList2.stream().map(j -&gt; new int[]&#123;i, j&#125;)) .collect(Collectors.toList()); 查找和匹配查找谓词是否至少匹配一个元素使用anyMatch()方法。比如，菜单中是否有素菜？1boolean isExistVegetarian = menu.stream().anyMatch(d -&gt; d.isVegetarian()); 检查谓词是否匹配所有元素使用allMatch()方法。 比如，是否所有的菜卡路由都小于1000？1boolean allLess1000 = menu.stream().allMatch(d -&gt; d.getCalories() &lt; 1000); 检查谓词是否券都不匹配所有元素使用noneMatch，与allMatch对应。 比如，是否是否所欲的菜卡路由都是小于1000？1boolean allLess1000 = menu.stream().noneMatch(d -&gt; d.getCalories() &gt;= 1000); 查找元素findAny()方法返回当前流中的任意元素，可以和其他流操作结合使用。 比如，找一道素菜（随便哪一道）：1Optional&lt;Dish&gt; dish = menu.stream().filter(Dish::isVegetarian).findAny(); 注意：findAny()返回的是一个Optional。它是一个容器类，代表一个值存在或不存在。用来解决null值问题。 常用方法如下： isPresent 包含值的时候返回true，否则返回false； ifPresent(Consumer block) 在存在值时执行给定的代码块。 get 在存在值时返回值，否则抛出一个NoSuchElement异常 orElse(T other) 在存在值时返回值，否则返回一个默认值。 比如，打印一道素菜的名称：123456789101112menu.stream().filter(Dish::isVegetarian).findAny().ifPresent(d -&gt; System.out.println(d.getName()));``` ## 规约### 元素求和使用for-each求和```javaList&lt;Integer&gt; numbers = Arrays.asList(1,2,3,9);int sum = 0;for (int x:numbers) &#123; sum += x;&#125; 使用reduce()方法1int sum = numbers.stream().reduct(0,(a,b) -&gt; a+b); 第1个参数：初始值第2个参数：一个BinaryOperator ，将2个元素结合起来产生一个新值。 求和过程：首先，0作为Lambda的第1个参数(a)，从流中获取到1作为第2个参数，0+1=1，它成为了新的累积值。然后，在用累积值和下一个元素调用Lambda，产生新的累积值3。 综合示例有如下交易和交易员，计算下面8个问题。交易员12345678910111213141516171819202122232425public class Trader &#123; private final String name; private final String city; public Trader(String name, String city) &#123; this.name = name; this.city = city; &#125; public String getName() &#123; return name; &#125; public String getCity() &#123; return city; &#125; @Override public String toString() &#123; return "Trader&#123;" + "name='" + name + '\'' + ", city='" + city + '\'' + '&#125;'; &#125;&#125; 交易123456789101112131415161718192021222324252627282930313233public class Transaction&#123; private final Trader trader; private final int year; private final int value; public Transaction(Trader trader, int year,int value) &#123; this.value = value; this.year = year; this.trader = trader; &#125; public Trader getTrader() &#123; return trader; &#125; public int getYear() &#123; return year; &#125; public int getValue() &#123; return value; &#125; @Override public String toString() &#123; return "Transaction&#123;" + "trader=" + trader + ", year=" + year + ", value=" + value + '&#125;'; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445Trader raoul = new Trader("Raoul","Cambridge");Trader mario = new Trader("Mario","Milan");Trader alan = new Trader("Alan","Cambridge");Trader brian = new Trader("Brian","Cambridge");List&lt;Transaction&gt; transactions = Arrays.asList( new Transaction(brian,2011,300), new Transaction(raoul,2012,1000), new Transaction(raoul,2011,400), new Transaction(mario,2012,710), new Transaction(mario,2011,700), new Transaction(alan,2012,950));// 找出2011年发生的所有交易，并按交易额排序（从低到高）transactions.stream().filter(t -&gt; t.getYear() == 2011).sorted(Comparator.comparing(Transaction::getValue)).forEach(System.out::println);System.out.println("1.=======================");// 交易员都在哪些不同的城市工作过transactions.stream().map(t -&gt; t.getTrader().getCity()).distinct().forEach(System.out::println);System.out.println("2.=======================");// 查找所有来自剑桥的交易员，并按姓名排序transactions.stream().filter(t -&gt; "Cambridge".equals(t.getTrader().getCity())).map(t -&gt; t.getTrader().getName()).distinct().sorted().forEach(System.out::println);// 或者transactions.stream().map(t -&gt; t.getTrader()).filter(t -&gt; t.getCity().equals("Cambridge")).distinct().sorted(Comparator.comparing(Trader::getName)).forEach(System.out::println);System.out.println("3.=======================");// 返回所有交易员的姓名字符串，按字母顺序排序transactions.stream().map(t -&gt; t.getTrader().getName()).distinct().sorted().forEach(System.out::println);System.out.println("4.=======================");// 有没有交易员是在米兰工作的transactions.stream().filter(t -&gt; "Milan".equals(t.getTrader().getCity())).findAny().ifPresent(System.out::println);System.out.println("5.=======================");// 打印生活在剑桥的交易员的所有交易额transactions.stream().filter(t -&gt; "Cambridge".equals(t.getTrader().getCity())).map(t -&gt; t.getValue()).reduce(Integer::sum).ifPresent(System.out::println);//或 mapToInt转化为int流，然后用IntStream的sum求和transactions.stream().filter(t -&gt; "Cambridge".equals(t.getTrader().getCity())).mapToInt(Transaction::getValue).sum();System.out.println("6.=======================");// 所有交易额中，最高的交易额是多少transactions.stream().map(t -&gt; t.getValue()).reduce(Integer::max).ifPresent(System.out::println);System.out.println("7.=======================");// 找到交易额最少的交易transactions.stream().filter(t -&gt; t.getValue() == transactions.stream().map(a -&gt; a.getValue()).reduce(Integer::min).get()).forEach(System.out::println);// 或transactions.stream().reduce((t1,t2) -&gt; t1.getValue() &lt; t2.getValue() ? t1 : t2).ifPresent(System.out::println);// 或transactions.stream().min(Comparator.comparing(Transaction::getValue)).ifPresent(System.out::println); 数值流原始类型流特化在java 8中，引入了3个原始类型特化流接口：IntStream,DoubleStream和LongStream，分别将流中的元素特化为int,double和long，从而避免暗含的装箱（int-&gt;Integer）成本。每个接口都带有常用数值规约的方法，比如对数值就和的sum，找到最大元素的max。还有在必要时将它们转换为流对象的方法。 映射到数值流将流转换为特化版本的常用方法是mapToInt，mapToDouble和mapToLong。这些方法和前面说的流工作方式一样，只是返回的是一个特化流，而不是Stream。例如，使用mapToInt对菜单中所有菜肴的卡路里求和。123int sum = menu.stream() .mapToInt(Dish::getCalories) // 转换为IntStream&lt;T&gt; .sum(); // 使用IntStream&lt;T&gt;提供的sum方法求和。 转换到对象流有了数值流，你还可以将数值流转换回对象流。将原始流转换为对象流，可以使用boxed方法。12IntStream is = menu.stream().mapToInt(Dish::getCalories);Stream&lt;Integer&gt; s = is.boxed(); OptionalIntIntStream/DoubleStream/LongStream对max、min等计算返回的是OptionalInt/OptionalDouble/OptionalLong。之前说过Optional的用法，这些OptionalXXX用法是一样的。比如，求最大值：123// OptionalIntOptionalInt max = transactions.stream().mapToInt(Transaction::getValue).max();max.ifPresent(System.out::println); 数值范围在java 8中，IntStream和LongStream提供了range()和rangeClosed()用于生成一定范围内的数字。range不包括结束值，rangeClosed包括结束值。比如，求1到100有多少个偶数？1IntStream.rangeClosed(1,100).filter(i -&gt; i % 2 == 0).count(); 数值流应用：勾股数勾股数满足：aa+bb=c*c，a,b,c均为正数。比如(3,4,5)即为一组有效的勾股数。下面使用IntStream来计算100内的勾股数。123456789101112131415IntStream.rangeClosed(1,100) .boxed() .flatMap(a -&gt; IntStream.rangeClosed(a,100) // 从a开始，避免出现重复的数据，比如[3,4,5]和[4,3,5] .filter(b -&gt; Math.sqrt(a*a+b*b) % 1 == 0) // a的平方+b的平方开平方根是整数 .mapToObj(b -&gt; new int[]&#123;a,b,(int)Math.sqrt(a*a+b*b)&#125;)) // 返回符合条件的int数组 .forEach(i -&gt; System.out.println(i[0] + "," + i[1] + "," + i[2]));// 上面的方案导致计算了2次平方根，方案2先生成a*a+b*b开平方后的结果，然后再过滤掉不符合要求的数System.out.println("========方案2===========");IntStream.rangeClosed(1,100) .boxed() .flatMap(a -&gt; IntStream.rangeClosed(a,100) .mapToObj(b -&gt; new double[] &#123;a,b,Math.sqrt(a*a+b*b)&#125;)) .filter(a -&gt; a[2] % 1 == 0) .forEach(a -&gt; System.out.println(a[0] + "," + a[1] + "," + a[2])); 构建流由值创建流可以使用静态方法Stream.of，来创建一个流，它可以接收任意数量的参数。比如，创建一个字符串流。1Stream&lt;String&gt; s = Stream.of("Java 8" ,"Lambda","In","Action"); 由数组创建流可以使用静态方法Arrays.stream来从数组创建一个流，它接收一个数组作为参数。比如：12int[] numbers = &#123;1,3,4,6,3,9&#125;;int sum = Arrays.stream(numbers).sum(); // 对数组元素求和 由文件创建流java中用于处理文件等I/O操作的NIO API已更新，以便使用Stream API。java.nio.file.Files中很多静态方法都会返回一个流。比如一个很有用的方法Files.lines，它返回一个由指定文件中各行构成的字符串流。比如：计算文件中有多少个不重复的单词。123456789// 由文件生成流String path = TraderDemo.class.getClassLoader().getResource("").getPath() + "data.txt";// 统计文件中不重复的单词数量try (Stream&lt;String&gt; lines = Files.lines(Paths.get(path.substring(1)), Charset.forName("utf-8")))&#123; long count = lines.flatMap(line -&gt; Arrays.stream(line.split(" "))).distinct().count(); System.out.println("distinct words count:" + count);&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 由函数生成流：创建无限流Stream API提供了2个静态方法从函数生成流：iterate和generate，这2个操作可以创建无限流。一般来说，应该使用limit(n)来加以限制，否则会无穷无尽的计算下去。 iterate比如：12// 从0开始，生成10个数，每个数是前面的数加2Stream.iterate(0,n -&gt; n+2).limit(10).forEach(System.out::println); // 0,2,4,6,8... iterate方法接收一个初始值（在这里是0），还有一个依次应用在每个产生的新值上的Lambda。 利用iterate实现斐波那契数列12345// 斐波那契数列（0,1,1,2,3,5,8,13,21,34,55...)除最开始的2个数字0和1外，后续的每个数字是前2个数字之和。// 生成前20个元素(0,1),(1,1),(1,2),(2,3),(3,5),(5,8)...Stream.iterate(new int[]&#123;0,1&#125;,a -&gt; new int[]&#123;a[1],a[0] + a[1]&#125;).limit(20).forEach(a -&gt; System.out.println("(" + a[0] + "," + a[1] + ")"));// 只打印数字Stream.iterate(new int[]&#123;0,1&#125;,a-&gt;new int[]&#123;a[1],a[0]+a[1]&#125;).limit(20).map(a -&gt; a[0]).forEach(System.out::println); generate与iterate类似，可以生成无限流。但它不是依次对每个新生成的值应用Lambda. 例如，创建5个随机的0到1的数1Stream.generate(Math::random).limit(5).forEach(System.out::println); 如果用generate来实现斐波那契数列，则要这么写1234567891011121314// 使用generate上下行斐波那契数列，不推荐，只是演示IntSupplier fib = new IntSupplier() &#123; // 使用匿名类保存状态（前一项和当前项） int prev = 0; int curr = 1; @Override public int getAsInt() &#123; int oldPrev = prev; int nextVal = prev + curr; prev = curr; curr = nextVal; return oldPrev; &#125;&#125;;IntStream.generate(fib).limit(10).forEach(System.out::println);]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK8之Lambda]]></title>
    <url>%2F2018%2F09%2F06%2FJDK8%E4%B9%8BLambda%2F</url>
    <content type="text"><![CDATA[前言在开始之前，我们来看一个例子。 jdk8之前的代码（匿名类）：123456Comparator&lt;Apple&gt; appleComparator = new Comparator&lt;Apple&gt;() &#123; @Override public int compare(Apple o1, Apple o2) &#123; return o1.getWeight().compareTo(o2.getWeight()); &#125;&#125;; Jdk8的代码（Lambda表达式）：1Comparator&lt;Apple&gt; appleComparator1 = (Apple a1,Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight()); 上面2段代码是等价的。一对比，发现使用Lambda表达式的代码真是简洁不少。 Lambda表达式的特性 匿名没有像普通函数一样有一个明确的名称。 函数和普通方法一样，都有参数列表、函数主体、返回值，还可能有要抛出的异常列表。 传递Lambda表达式可以作为参数传递给方法或存储在变量中。 简洁无需像匿名类那样写很多模板代码。 在上面的例子中，(Apple a1,Apple a2)中a1,a2即是参数，-&gt;用于区分参数列表和函数主体，a1.getWeight().compareTo(a2.getWeight());则是函数主体，执行结果即是返回值。 函数式接口函数式接口就是只定义一个抽象函数的接口，比如《JDK8行为参数化传递代码》中定义的ApplePredicate即是函数式接口。Runnable、Callable、Comparator都是函数式接口。 函数式接口是干嘛的？Lambda表达式允许直接以内联的形式为函数式接口的抽象方法提供实现，并把整个表达式作为函数式接口的实例。 函数描述符函数式接口的抽象方法的前面基本上就是Lambda表达式的签名。这种抽象方法叫做函数描述符。例如，Runnable可以看做是一个没有参数也没有返回值的签名。因为它只有一个抽象方法run()，该方法不接受参数，也不返回（void）。（Apple a1,Apple a2) -&gt; int就是一个接收2个Apple对象作为参数，并且返回int的函数。 只有在使用函数式接口的时候才能使用Lambda表达式。 使用函数式接口函数式接口很有用，因为抽象方法的签名可以描述Lambda表达式的签名。所以，为了应用不同的Lambda表达式，你需要一套能够描述常见函数描述符的函数式接口。在java API中，Runnable、Callable、Comparator都是函数式接口。在java 8中，在java.util.function中还新加了一些新的函数式接口。 Predicatejava.util.function.Predicate定义了一个名为test的抽象方法，参数为泛型T对象，并返回一个Boolean。与我们在《JDK8行为参数化传递代码》中定义了ApplePredicate一样，那么现在就可以直接使用它了，无需自己定义了。举例：123456789101112131415private static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; p) &#123; List&lt;T&gt; result = new ArrayList&lt;&gt;(); if (null != list &amp;&amp; !list.isEmpty()) &#123; for (T t : list) &#123; if (p.test(t)) &#123; result.add(t); &#125; &#125; &#125; return result;&#125;List&lt;String&gt; strings = Arrays.asList("string", "strings", "Strings", "String", "Str");List&lt;String&gt; upperCaseStrings = filter(strings, s -&gt; s.charAt(0) &gt;= 65 &amp;&amp; s.charAt(0) &lt;= 90); Consumerjava.util.function.Consumer定义了一个名为accept的抽象方法，参数为泛型T对象，无返回值。示例：12345678910private static &lt;T&gt; void consumerFilter(List&lt;T&gt; list, Consumer&lt;T&gt; c) &#123; if (null != list &amp;&amp; !list.isEmpty()) &#123; for (T t:list) &#123; c.accept(t); &#125; &#125;&#125;List&lt;String&gt; strings = Arrays.asList("string", "strings", "Strings", "String", "Str");consumerFilter(strings,s -&gt; System.out.println(s)); Functionjava.util.function.Funciton定义了一个名为apply的抽象方法，接受泛型T对象，并返回一个R对象。如果你需要定义一个Lambda，将输入对象的信息映射到输出，就可以使用这个接口。举例：1234567891011121314private static &lt;T,R&gt; Map&lt;T,R&gt; functionFilter(List&lt;T&gt; list, Function&lt;T,R&gt; f) &#123; Map&lt;T,R&gt; result = new HashMap&lt;&gt;(); if (null != list &amp;&amp; !list.isEmpty()) &#123; for (T t:list) &#123; result.put(t,f.apply(t)); &#125; &#125; return result;&#125;// key=原始字符串，value=字符串长度Map&lt;String,Integer&gt; stringIntegerMap = functionFilter(strings,s -&gt; s.length());System.out.println(stringIntegerMap); 常用的函数式接口 函数式接口 函数描述符 原始类型特化 Predicate T-&gt;boolean IntPredicate,LongPredicate,DoublePredicate Consumer T-&gt;void IntConsumer,LongConsumer,DoubleConsumer Function T-&gt;R IntFunction,IntToDoubleFunction,LongFunction,IntToLongFunction,LongToIntFunction,DoubleFunction,ToIntFunction,ToDoubleFunction,ToLongFunction Supplier ()-&gt;T BooleanSupplier,IntSupplier,LongSupplier,DoubleSupplier BiPredicate&lt;L,R&gt; (L,R)-&gt;boolean BiConsumer&lt;T,U&gt; (T,U)-&gt;void ObjIntConsumer,ObjLongConsumer,ObjDoubleConsumer BiFunction&lt;T,U,R&gt; (T,U)-&gt;R ToIntBiFunction&lt;T,U&gt;,ToLongBiFunction&lt;T,U&gt;,ToDoubleBiFunction&lt;T,U&gt; BinaryOperator (T,T)-&gt;T IntBinaryOperator,LongBinaryOperator,DoubleBinaryOperator UnaryOperator T-&gt;T IntUnaryOperator,LongUnaryOperator,DoubleUnaryOperator 类型检查、类型推断和限制类型检查Lambda表达式的类型是从使用Lambda的上下文推断出来的。上下文即为接受它传递的方法的参数或接受它的值的局部变量。上下文中Lambda表达式需要的类型为目标类型。从调用的filter方法的参数找到函数式接口，由于每个函数式接口都只能有一个抽象方法，所以类型就都确定了。 类型推断通过类型检查我们可以知道函数描述符，所以就可以推断出lambda的签名，这样java编译器就可以推断出lambda表达式的参数类型，这样就可以在lambda表达式中省略参数类型了。所以：1List&lt;Apple&gt; greenApples = filter(apples,(Apple a) -&gt; &quot;green&quot;.equals(a.getColor())); 可以简化为：1List&lt;Apple&gt; greenApples = filter(apples,a -&gt; &quot;green&quot;.equals(a.getColor())); 但有时候显示的写出参数类型更易读，有时候去掉则更易读。需要根据实际情况作出选择。 方法引用方法引用可以让你重复的使用现有的方法定义，并像Lambda一样传递它们。有些情况下，比Lambda更易读。 当你需要使用方法引用时，目标引用放在分隔符::前，方法的名称放在后面。比如Apple::getWeight就是引用了Apple类中定义的getWeight方法。但是，注意不需要括号，因为你还没有实际调用这个方法。方法引用时Lambda表达式的快捷写法。 Lambda和等效的方法引用的例子 函数式接口 函数描述符 (Apple a) -&gt; a.getWeight() Apple::getWeight (str,i) -&gt; str.substring(i) String::substring (String s) -&gt; System.out.println(s) System.out::println () -&gt; Thread.currentThread().dumpStack() Thread.currentThread::dumpStack 复合Lambda表达式的有用方法许多函数式接口，比如Predicate、Function、Comparator都提供了进行复合的方法。这样你就可以将多个简单的Lambda表达式复合成更复杂的表达式。 比较器复合有如下Comparator1Comparator&lt;Apple&gt; c = Comparator.comparing(Apple::getWeight); 1.逆序现在想逆序显示呢？你不用再重新创建一个Comparator，因为Comparator提供了一个默认方法reverse()可以使给定的Comparator逆序。因此，结合前面的Comparator即可。1apples.sort(comparing(Apple::getWeight).reversed()); 2.比较器链在上面的例子中，如果要比较的2个苹果的重量一样，那么哪个苹果应该排在前面呢？你可能需要再提供一个Comparator来进一步比较。比如，先根据重量排序，如果重量一样则再根据国家排序。这个时候，Comparator中的thenComparing()方法就派上用场了。12Comparator&lt;Apple&gt; comparator = Comparator.comparing(Apple::getWeight);apples.sort(comparator.reversed().thenComparing(Apple::getCountry)); 谓词复合谓词接口包括三个方法：negate、add和or，让你可以重用已有的Predicate来创建更复杂的谓词。比如有如下谓词：1234// 红苹果Predicate&lt;Apple&gt; redApplePredicate = (Apple apple) -&gt; "red".equals(apple.getColor());// 不是红色的苹果Predicate&lt;Apple&gt; nonRediApplePredicate = redApplePredicate.negate(); 使用add()方法来创建一个既是红色又是一个重的苹果：123// 红苹果Predicate&lt;Apple&gt; redApplePredicate = (Apple apple) -&gt; "red".equals(apple.getColor());Predicate&lt;Apple&gt; redAndWeightPredicate = redApplePredicate.and((Apple a) -&gt; a.getWeight() &gt; 150); 使用or()方法来创建一个150克以上的红苹果，或是绿苹果。123// 红苹果Predicate&lt;Apple&gt; redApplePredicate = (Apple apple) -&gt; "red".equals(apple.getColor());Predicate&lt;Apple&gt; redAndHeavyApplesOrGreen = redApplePredicate.and((Apple a) -&gt; a.getWeight() &gt; 150).or((Apple a) -&gt; "green".equals(a.getColor())); 函数复合你还可以将Function接口所代表的Lambda表达式复合起来。Function接口提供了addThen和compose2个默认方法，它们都会返回Function的一个实例。 比如，有一个函数f，给数字加1，另一个函数g给数字乘以2.你可以将它们组合成一个函数h，先给数字加1，再将结果乘以2.12345Function&lt;Integer,Integer&gt; f = x -&gt; x+1;Function&lt;Integer,Integer&gt; g = x -&gt; x*2;Function&lt;Integer,Integer&gt; h = f.andThen(g);int result = h.apply(1);System.out.println(result); // 4 使用compose，先把给定的函数用作compose的参数里面的那个函数，然后再把函数本身用于结果。比如上面的例子使用compose的话，就是f(g(x))，而addThen则是g(f(x))。1234Function&lt;Integer,Integer&gt; f = x -&gt; x+1;Function&lt;Integer,Integer&gt; g = x -&gt; x*2;Function&lt;Integer,Integer&gt;h = f.compose(g);System.out.println(h.apply(1)); // 3]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK8行为参数化传递代码]]></title>
    <url>%2F2018%2F09%2F06%2FJDK8%E8%A1%8C%E4%B8%BA%E5%8F%82%E6%95%B0%E5%8C%96%E4%BC%A0%E9%80%92%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[在软件开发中，需求总是不断变化的，在这里介绍使用行为参数化传递代码来应对不断变化的需求。 版本1：要求筛选出颜色为绿色的苹果12345678910111213141516171819public class Apple &#123; private String color; private double weight; public Apple(String color, double weight) &#123; this.color = color; this.weight = weight; &#125; // 省略getter/settter... @Override public String toString() &#123; return "Apple&#123;" + "color='" + color + '\'' + ", weight=" + weight + '&#125;'; &#125;&#125; 按照jdk8之前的代码，写法大致如下：123456789101112private static List&lt;Apple&gt; filterByColor(List&lt;Apple&gt; apples) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); if(null != apples &amp;&amp; !apples.isEmpty()) &#123; for(Apple apple:apples) &#123; if ("green".equals(apple.getColor())) &#123; result.add(apple); &#125; &#125; &#125; return result;&#125; 假定现在想根据颜色查找苹果，不限定绿色。 版本2：查找指定颜色的苹果：123456789101112private static List&lt;Apple&gt; filterByColor(List&lt;Apple&gt; apples,String color) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); if(null != apples &amp;&amp; !apples.isEmpty()) &#123; for(Apple apple:apples) &#123; if (color.equals(apple.getColor())) &#123; result.add(apple); &#125; &#125; &#125; return result;&#125; 将颜色当做参数即可。 那么，如果要按照重量来筛选呢？ 版本3：查找重苹果123456789101112private static List&lt;Apple&gt; filterByColor(List&lt;Apple&gt; apples) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); if(null != apples &amp;&amp; !apples.isEmpty()) &#123; for(Apple apple:apples) &#123; if (apple.getWeight() &gt; 150) &#123; result.add(apple); &#125; &#125; &#125; return result;&#125; 后面可能会有其他需求，比如查找重量超过300G的红苹果等等需求。此时，你会发现根据颜色查找和根据重量来查找仅仅1行代码不同，其余部分均相同。也就是说好多代码都重复了。那么有没有一种方法来应对这种不断变动的需求，减少重复代码呢？ 版本4：使用策略模式那么，如果熟悉设计模式，可以想到使用策略模式。每次变动的不过是筛选苹果的策略不同。 我们将选择逻辑抽象出一个接口：123public interface ApplePredicate&lt;Apple&gt; &#123; boolean test(Apple t);&#125; 绿苹果的策略：123456public class GreenApplePredicate implements ApplePredicate&lt;Apple&gt; &#123; @Override public boolean test(Apple t) &#123; return "green".equals(t.getColor()); &#125;&#125; 重苹果的策略：123456public class WeightApplePredicate implements ApplePredicate&lt;Apple&gt; &#123; @Override public boolean test(Apple t) &#123; return t.getWeight() &gt; 150; &#125;&#125; 筛选苹果的方法：123456789101112private static List&lt;Apple&gt; filterByCondition(List&lt;Apple&gt; apples,ApplePredicate&lt;Apple&gt; p) &#123; List&lt;Apple&gt; result = new ArrayList&lt;&gt;(); if(null != apples &amp;&amp; !apples.isEmpty()) &#123; for(Apple apple:apples) &#123; if (p.test(apple)) &#123; result.add(apple); &#125; &#125; &#125; return result;&#125; 使用：1234// 筛选绿色苹果List&lt;Apple&gt; greenApples = filterByCondition(apples,new GreenApplePredicate();// 筛选重的苹果List&lt;Apple&gt; heavyApples = filterByCondition(apples,new WeightApplePredicate(); 如果要筛选出其他条件的苹果，我们就新建一个ApplePredicate的实现类即可。比如要筛选出红色且重量在150克以上的苹果。123456789public class WeightAndRedApplePredicate implements ApplePredicate&lt;Apple&gt; &#123; @Override public boolean test(Apple t) &#123; return &quot;red&quot;.equals(t.getColor()) &amp;&amp; t.getWeight() &gt; 150; &#125;&#125;// 使用：List&lt;Apple&gt; redAndHeavyApples = filterByCondition(apples,new WeightAndRedApplePredicate()); 参数行为化的好处是：你可以把要迭代筛选的逻辑和集合中每个元素的应用的行为分开。这样你可以重复使用一个方法，给它不同的行为来达到不同的目的。 版本5：使用匿名类虽然通过模板策略，我们将苹果筛选的逻辑和迭代的逻辑分开了，但是每次都需要新建一个筛选策略也是很麻烦的。熟悉GUI事件处理的可能知道，我们可以使用匿名类来创建不同的策略对象。绿色的苹果123456List&lt;Apple&gt; greenApples = filterByCondition(apples, new ApplePredicate&lt;Apple&gt;() &#123; @Override public boolean test(Apple t) &#123; return "green".equals(t.getColor()); &#125;&#125;); 重苹果123456List&lt;Apple&gt; greenApples = filterByCondition(apples, new ApplePredicate&lt;Apple&gt;() &#123; @Override public boolean test(Apple t) &#123; return t.getWeight() &gt; 150; &#125;&#125;); 很快，你就发现，使用匿名类还是不够好。我们对比绿苹果和重苹果的代码，发现就一行代码不同。那么有没有版本传递给filterByCondition方法的只有真正的逻辑代码？ 版本6：java8提供行为参数化的支持，它允许你定义一个代码块来表示一个行为，然后作为参数去传递它。我们使用java8的lambda来实现上面的逻辑。绿苹果1List&lt;Apple&gt; greenApples = filterByCondition(apples,(Apple apple) -&gt; "green".equals(apple.getColor())); 重苹果1List&lt;Apple&gt; heavyApples = filterByCondition(apples,(Apple apple) -&gt; apple.getWeight() &gt; 150); 一行代码即搞定！ 还可以将lambda表达式的参数去掉。1List&lt;Apple&gt; heavyApples = filterByCondition(apples,apple -&gt; apple.getWeight() &gt; 150); 这样后面不论要怎么筛选苹果，我们改lambda表达式即可。 注：文中例子参考《Java8实战》。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK8中新增的LongAdder]]></title>
    <url>%2F2018%2F09%2F04%2FJDK8%E4%B8%AD%E6%96%B0%E5%A2%9E%E7%9A%84LongAdder%2F</url>
    <content type="text"><![CDATA[前言在JDK1.5开始就新增了并发的Integer/Long的操作工具类AtomicInteger和AtomicLong。在JDK8中又新增了LongAdder，这是一个针对Long类型的数据的操作工具类。那么既然已经有了AtomicLong，为何又要新增LongAdder这么一个类呢？ LongAdder的实现原理我们知道，AtomicLong的实现原理是：利用底层操作系统的CAS来保证原子性，在一个死循环内不断执行CAS操作，直到操作成功。不过，CAS操作的一个问题是在并发量比较大的时候，可能很多次的执行CAS操作都不成功，这样性能就受到较大影响。那我们知道，在ConcurrentHashMap中，对Map分割成多个segment，这样多个Segment的操作就可以并行执行，从而可以提高性能。在JDK8中，LongAdder与ConcurrentHashMap类似，将内部操作数据value分离成一个Cell数组，每个线程访问时，通过Hash等算法映射到其中一个Cell上。计算最终的数据结果，则是各个Cell数组的累计求和。 LongAdder提供的方法 add()：增加指定的数值； increament()：增加1； decrement()：减少1； intValue()/floatValue()/doubleValue()：得到最终计数后的结果 sum()：求和，得到最终计数结果 sumThenReset()：求和得到最终计数结果，并重置value。 示例代码1234567891011121314151617181920212223public class LongAdderTest &#123; static java.util.concurrent.atomic.LongAdder count = new LongAdder(); static class AddThread implements Runnable &#123; @Override public void run() &#123; for (int i = 0; i &lt; 100000; i++) &#123; count.increment(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(new AddThread()); Thread t2 = new Thread(new AddThread()); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(count.intValue() == 200000); &#125;&#125; 注意事项在并发较低时LongAdder使用casBase()方法直接修改value，以达到和AtomicLong基本相当的性能；在并发较高时，自动拆分为Cell数组，并自动扩容，分散热点，以保证性能。 LongAdder原理分析：https://blog.csdn.net/u011392897/article/details/60480108 LongAdder与AtomicLong性能对比测试：https://blog.csdn.net/li396864285/article/details/78246357]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java7 ForkJoin框架详解]]></title>
    <url>%2F2018%2F08%2F30%2FJava7%20ForkJoin%E6%A1%86%E6%9E%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。Fork/Join框架要完成两件事情： 1.任务分割：首先Fork/Join框架需要把大的任务分割成足够小的子任务，如果子任务比较大的话还要对子任务进行继续分割 2.执行任务并合并结果：分割的子任务分别放到双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都放在另外一个队列里，启动一个线程从队列里取数据，然后合并这些数据。 在Java的Fork/Join框架中，使用两个类完成上述操作 1.ForkJoinTask:我们要使用Fork/Join框架，首先需要创建一个ForkJoin任务。该类提供了在任务中执行fork和join的机制。通常情况下我们不需要直接集成ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了两个子类： a.RecursiveAction：用于没有返回结果的任务 b.RecursiveTask:用于有返回结果的任务 2.ForkJoinPool:ForkJoinTask需要通过ForkJoinPool来执行 任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务(工作窃取算法)。 Fork/Join框架的实现原理 ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成，ForkJoinTask数组负责将存放程序提交给ForkJoinPool，而ForkJoinWorkerThread负责执行这些任务。 示例代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * Fork/Join是jdk7新增的并行计算框架，采用工作窃取算法，将一个大的任务拆分为多个小的任务，最终汇总各个小的任务的计算结果。 * 比如计算1-100之类数字相加的和，假定阀值为30（即开始位置和结束位置相减&lt;=30即可进行计算），如果&gt;30则进行拆分。 * 计算过程如下： * 拆分为1-50,51-100 * 1-50拆分为1-25,26-50 * 51-100拆分为51-75,76-100 * 计算1-25的和，计算26-50的和==》合并为结果1 * 计算51-75的和，计算76-100的和==》合并为结果2 * 合并结果1，2 * @author Donny * @version 1.0 * @date 2018/08/25 */public class FormJoinDemo &#123; static class ComputeTask extends RecursiveTask&lt;Long&gt; &#123; private final static int THREAD_HOLD = 100; private int[] data; private int start; private int end; public ComputeTask(int[] data, int start, int end) &#123; this.data = data; this.start = start; this.end = end; &#125; @Override protected Long compute() &#123; Long sum = 0L; // 如果任务足够小，那么直接计算 if (end - start &lt;= THREAD_HOLD) &#123; for (int i = start; i &lt; end; i++) &#123; sum += data[i]; &#125; System.out.println(String.format("Compute %d ~ %d = %d", start, end, sum)); &#125; else &#123; // 如果任务过大，则一分为二 int middle = (end + start) / 2; System.out.println(String.format("Split %d~%d ==&gt; %d~%d,%d~%d", start, end, start, middle, middle + 1, end)); ComputeTask left = new ComputeTask(data, start, middle); ComputeTask right = new ComputeTask(data, middle + 1, end); invokeAll(left, right);// 注意：这里使用invokeAll，而不要使用left.fork()和right.fork() Long leftSum = left.join(); Long rightSum = right.join(); sum = leftSum + rightSum; System.out.println(String.format("Result = %d + %d ==&gt; %d", leftSum, rightSum, sum)); &#125; return sum; &#125; &#125; public static void main(String[] args) &#123; ForkJoinPool pool = new ForkJoinPool(); int[] data = new int[1000]; fillData(data); Long sum = pool.invoke(new ComputeTask(data, 0, data.length)); System.out.println("Fork/join sum:" + sum); &#125; private static void fillData(int[] data) &#123; for (int i = 0; i &lt; data.length; i++) &#123; data[i] = i; &#125; &#125;&#125; 上面的代码使用Fork/Join框架来计算一个元素个数为1000的数组的和。 执行结果如下：1234567891011121314151617181920212223Split 0~1000 ==&gt; 0~500,501~1000Split 501~1000 ==&gt; 501~750,751~1000Split 0~500 ==&gt; 0~250,251~500Split 501~750 ==&gt; 501~625,626~750Split 0~250 ==&gt; 0~125,126~250Compute 0 ~ 125 = 7750Compute 126 ~ 250 = 23250Result = 7750 + 23250 ==&gt; 31000Split 251~500 ==&gt; 251~375,376~500Compute 251 ~ 375 = 38750Compute 376 ~ 500 = 54250Result = 38750 + 54250 ==&gt; 93000Result = 31000 + 93000 ==&gt; 124000Split 751~1000 ==&gt; 751~875,876~1000Compute 751 ~ 875 = 100750Compute 876 ~ 1000 = 116250Result = 100750 + 116250 ==&gt; 217000Compute 626 ~ 750 = 85250Compute 501 ~ 625 = 69750Result = 69750 + 85250 ==&gt; 155000Result = 155000 + 217000 ==&gt; 372000Result = 124000 + 372000 ==&gt; 496000Fork/join sum:496000 这里要注意的是：在拆分任务时不要调用fork()方法将任务推给别的线程执行，而使用invokeAll()。 这是因为执行compute()方法的线程本身也是一个Worker线程，当对两个子任务调用fork()时，这个Worker线程就会把任务分配给另外两个Worker，但是它自己却停下来等待不干活了！这样就白白浪费了Fork/Join线程池中的一个Worker线程 原因参考：https://www.liaoxuefeng.com/article/001493522711597674607c7f4f346628a76145477e2ff82000 Fork/Join实现介绍：https://blog.csdn.net/yinwenjie/article/details/71524140]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper客户端curator使用]]></title>
    <url>%2F2018%2F07%2F28%2Fzookeeper%E5%AE%A2%E6%88%B7%E7%AB%AFcurator%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[curator简介curator是Netflix开源的一个zookeeper客户端，在原生API接口上进行了包装，解决了很多ZooKeeper客户端非常底层的细节开发。同时内部实现了诸如Session超时重连，Watcher反复注册、分布式计数器、分布式锁等功能，实现了Fluent风格的API接口，是使用最广泛的zookeeper客户端之一。Curator使用的链式编程风格。如果只需要zookeeper连接管理和重试功能可以只引入curator-framework。 官网地址：http://curator.apache.org/ curator包含下面几个模块，对于大多数人来说引入curator-recipes即可。 兼容性Apache Curator旨在与ZooKeeper 3.5+一起使用。 但是，它也与ZooKeeper 3.4.x兼容。详情：http://curator.apache.org/zk-compatibility.html curator基本使用curator依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt;&lt;/dependency&gt; 我这里版本比较低，官网版本已经到3.5+了。 创建连接12345678910111213// 重试策略，重试间隔时间为1秒，重试次数为10次。curator管理了zookeeper的连接，在操作zookeeper的过程中出现连接问题会自动重试。RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000,10);// 通过工厂创建连接CuratorFramework cf = CuratorFrameworkFactory.builder() .connectString(ZOOKEEPER_ADDRESS) // zookeeper地址 .retryPolicy(retryPolicy) // 重试策略 .connectionTimeoutMs(15000) // 连接超时时间，默认15秒 .sessionTimeoutMs(5000) // 会话超时时间ms，默认60秒 .build();// 打开连接cf.start();System.out.println("state:" + cf.getState()); 也可以这样创建：1CuratorFramework cf = CuratorFrameworkFactory.newClient(ZOOKEEPER_ADDRESS,5000,15000,retryPolicy); 创建节点1234cf.create() .creatingParentsIfNeeded() // 自动创建父节点 .withMode(CreateMode.PERSISTENT) // 模式：持久/临时/有序/无序 .forPath("/lock/ms10000","10000".getBytes()); // 指定路径和数据 检查节点是否存在1Stat stat = cf.checkExists().forPath("/lock/ms10000"); 获取节点数据1String nodeData = new String(cf.getData().forPath("/lock/ms10000")); 修改节点数据1cf.setData().forPath("/lock/ms10000","ms-10001".getBytes()); 获取子节点12345List&lt;String&gt; nodes = cf.getChildren().forPath("/lock");System.out.println("/lock的子节点为：");for (String node : nodes) &#123; System.out.println(node);&#125; 删除子节点1234cf.delete() .guaranteed()//保障机制，若未删除成功，只要会话有效会在后台一直尝试删除 .deletingChildrenIfNeeded()//若当前节点包含子节点 .forPath("/lock"); 异步绑定回调方法比如创建节点时绑定一个回调函数，该回调函数可以输出服务器的状态码和事件类型。还可以加入一个线程池进行优化操作。1234567891011ExecutorService pool = Executors.newCachedThreadPool();cf.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).inBackground(new BackgroundCallback() &#123; @Override public void processResult(CuratorFramework cf, CuratorEvent ce) throws Exception &#123; System.out.println("code:" + ce.getResultCode()); System.out.println("type:" + ce.getType()); System.out.println("线程为:" + Thread.currentThread().getName()); &#125;&#125;, pool).forPath("/super/c3","c3内容".getBytes()); 节点监听1234567891011121314RetryPolicy retry = new ExponentialBackoffRetry(1000, 3);CuratorFramework client = CuratorFrameworkFactory.newClient("127.0.0.1:2181", 5000, 5000, retry);client.start();final NodeCache cache = new NodeCache(client,"/node_1");cache.start();cache.getListenable().addListener(new NodeCacheListener() &#123; @Override public void nodeChanged() throws Exception &#123; byte[] res = cache.getCurrentData().getData(); System.out.println("data: " + new String(res)); &#125;&#125;); 子节点监听123456789101112131415161718192021final PathChildrenCache cache = new PathChildrenCache(client,"/node_1",true);cache.start();cache.getListenable().addListener(new PathChildrenCacheListener() &#123; @Override public void childEvent(CuratorFramework curator, PathChildrenCacheEvent event) throws Exception &#123; switch (event.getType()) &#123; case CHILD_ADDED: System.out.println("add:" + event.getData()); break; case CHILD_UPDATED: System.out.println("update:" + event.getData()); break; case CHILD_REMOVED: System.out.println("remove:" + event.getData()); break; default: break; &#125; &#125;&#125;); ACL权限12345678910111213141516171819202122232425RetryPolicy retry = new ExponentialBackoffRetry(1000, 3);CuratorFramework client = CuratorFrameworkFactory.newClient("127.0.0.1:2181", 5000, 5000, retry);client.start();//ACL有IP授权和用户名密码访问的模式ACL aclRoot = new ACL(Perms.ALL,new Id("digest",DigestAuthenticationProvider.generateDigest("root:root")));List&lt;ACL&gt; aclList = new ArrayList&lt;ACL&gt;();aclList.add(aclRoot);String path = client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL) .withACL(aclList) .forPath("/node_3/node_ACL","2".getBytes());System.out.println(path);CuratorFramework client1 = CuratorFrameworkFactory.builder().connectString("192.168.0.3:2181") .sessionTimeoutMs(5000)//会话超时时间 .connectionTimeoutMs(5000)//连接超时时间 .authorization("digest","root:root".getBytes())//权限访问 .retryPolicy(retry) .build();client1.start();String re = new String(client1.getData().forPath("/node_3/node_ACL"));System.out.println(re); 分布式锁在http://curator.apache.org/getting-started.html有说明，核心代码就2行。123456789101112InterProcessMutex lock = new InterProcessMutex(client, lockPath);if ( lock.acquire(maxWait, waitUnit) ) // 尝试在规定的时间内获取锁&#123; try &#123; // do some work inside of the critical section here &#125; finally &#123; lock.release(); // 释放锁 &#125;&#125; 这里来一个例子。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class CuratorTest &#123; private final static String ZOOKEEPER_ADDRESS = "127.0.0.1:2181"; public static void main(String[] args) throws Exception &#123; // 重试策略，重试间隔时间为1秒，重试次数为10次。curator管理了zookeeper的连接，在操作zookeeper的过程中出现连接问题会自动重试。 RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000,10); // 通过工厂创建连接 CuratorFramework cf = CuratorFrameworkFactory.builder() .connectString(ZOOKEEPER_ADDRESS) .connectionTimeoutMs(15000) .retryPolicy(retryPolicy) .sessionTimeoutMs(5000) .build(); // 或者这样创建连接 // CuratorFramework cf = CuratorFrameworkFactory.newClient(ZOOKEEPER_ADDRESS,5000,15000,retryPolicy); // 打开连接 cf.start(); System.out.println("=======================state:" + cf.getState()); String orderNo = "10001"; // 模拟数据库操作 DB db = new DB(); ExecutorService executorService = Executors.newFixedThreadPool(5); // 这里有3个线程同时执行同一个订单号的操作 executorService.submit(new DistributedWorkerThread(cf,db,orderNo)); executorService.submit(new DistributedWorkerThread(cf,db,orderNo)); executorService.submit(new DistributedWorkerThread(cf,db,orderNo)); executorService.shutdown(); Thread.sleep(15000); cf.close(); &#125; static class DB &#123; private List&lt;String&gt; orders = new ArrayList&lt;&gt;(); public void add(String order) &#123; if (!exist(order)) &#123; this.orders.add(order); &#125; &#125; public boolean exist(String order) &#123; return this.orders.contains(order); &#125; &#125; static class DistributedWorkerThread implements Runnable &#123; private CuratorFramework cf; private String orderNo; private DB db; public DistributedWorkerThread(CuratorFramework cf,DB db,String orderNo) &#123; this.cf = cf; this.db = db; this.orderNo = orderNo; &#125; public void run() &#123; String lockNode = "/lock/ms"+orderNo; InterProcessMutex lock = new InterProcessMutex(cf,lockNode); try &#123; if (lock.acquire(10, TimeUnit.SECONDS)) &#123; // 这里也可以不指定时间，就是一直等直到获取到锁。 try &#123; if (db.exist(orderNo)) &#123; System.out.println(Thread.currentThread().getName() + "订单已存在！"); return; &#125; System.out.println(Thread.currentThread().getName() + "在这里执行你的业务代码..orderNo:" + orderNo); this.db.add(orderNo); Thread.sleep(1500L); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.release(); System.out.println(Thread.currentThread().getName() + "执行完毕！"); &#125; &#125; else &#123; System.out.println(Thread.currentThread().getName() + "未获取到锁.."); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 我们看下日志：123456pool-3-thread-3在这里执行你的业务代码..orderNo:10001pool-3-thread-3执行完毕！pool-3-thread-1订单已存在！pool-3-thread-1执行完毕！pool-3-thread-2订单已存在！pool-3-thread-2执行完毕！ Curator分布式锁的分析：https://blog.csdn.net/qiangcuo6087/article/details/79067136 Leader选举http://curator.apache.org/getting-started.html示例12345678910111213LeaderSelectorListener listener = new LeaderSelectorListenerAdapter()&#123; public void takeLeadership(CuratorFramework client) throws Exception &#123; // this callback will get called when you are the leader // do whatever leader work you need to and only exit // this method when you want to relinquish leadership &#125;&#125;LeaderSelector selector = new LeaderSelector(client, path, listener);selector.autoRequeue(); // not required, but this is behavior that you will probably expectselector.start(); 问题1.java.io.IOException: Xid out of order. Got Xid 3 with err -101 expected Xid 2 for a packet with details12345java.io.IOException: Xid out of order. Got Xid 3 with err -101 expected Xid 2 for a packet with details: clientPath:null serverPath:null finished:false header:: 2,15 replyHeader:: 0,0,-4 request:: &apos;/lock/ms10000,#3130303030,v&#123;s&#123;31,s&#123;&apos;world,&apos;anyone&#125;&#125;&#125;,0 response:: at org.apache.zookeeper.ClientCnxn$SendThread.readResponse(ClientCnxn.java:892) at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:101) at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363) at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1214) 参考：https://blog.csdn.net/xiaojiahao_kevin/article/details/51203083 参考：https://blog.csdn.net/qq_15370821/article/details/73692288,&lt;&gt;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea日志乱码问题解决]]></title>
    <url>%2F2018%2F07%2F25%2Fidea%E6%97%A5%E5%BF%97%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[使用System.out.pringln()输出中文到控制台显示正常，但使用日志组件则显示为乱码。 1.修改idea.exe.vmoptions，增加字符集设置找到idea安装目录（可以桌面找到idea图标，右键选择属性，点查找目标）。 增加-Dfile.encoding=utf-8。保存，然后重启idea。2.日志配置中增加字符集设置。比如log4j:12345# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d [%t] %c %x - %m%nlog4j.appender.stdout.Encoding=GBK 这是控制台日志的字符集设置（最后一行），如果发现日志文件是乱码，在文件的日志配置中增加字符集设置。参考：https://blog.csdn.net/u011133135/article/details/72123196 3.在idea设置中找到file encoding，将所有的字符集都设置为UTF-8 4.idea Run/Debug Configuration的VM OPTIONS增加字符集设置 一般经过上面的设置，问题即可解决。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo-admin安装与使用]]></title>
    <url>%2F2018%2F07%2F24%2Fdubbo-admin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在dubbo加入apache后，github地址也变了。dubbo-admin需要从https://github.com/apache/incubator-dubbo-ops下载。将项目克隆到本地后，可以看到dubbo-admin模块。 值得注意的是，最新的dubbo-admin集成了springboot，可以打包为jar运行。 下载后的项目名称为incubator-dubbo-ops，cmd到在该模块下，执行mvn package -DskipTests=true，将dubbo-admin打成jar包。 打包完成后，我们会在dubbo-admin/target下看到dubbo-admin的jar包 注意：dubbo-admin的端口默认是7001，dubbo注册中心的地址是本机的2181端口，还有其他的一些配置。如下：根据个人情况，将配置修改后，重新打包。最后使用java -jar dubbo-admin-xxx.jar即可启动。 PS：注意先打开本机的zookeeper。 启动后，浏览器输入http://localhost:7001即可访问，默认的用户名密码输入root，即进入首页。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot集成dubbo]]></title>
    <url>%2F2018%2F07%2F21%2Fspringboot%E9%9B%86%E6%88%90dubbo%2F</url>
    <content type="text"><![CDATA[前言dubbo是一个分布式的高性能Java RPC服务治理框架。由于之前dubbo不更新没怎么用它。不过现在已经成为Apache的一员了，所以就不用担心这个问题了。 dubbo官网：http://dubbo.apache.org，还有中文版，不错。 模块划分：这里将接口和用到的bean放在dubbo-interface，服务提供方dubbo-provider，服务消费方dubbo-consumer。 具体使用1.项目结构 父pom.xml1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.donny&lt;/groupId&gt; &lt;artifactId&gt;springboot-dubbo-demo&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;dubbo-interface&lt;/module&gt; &lt;module&gt;dubbo-provider&lt;/module&gt; &lt;module&gt;dubbo-consumer&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt;&lt;/project&gt; 2.dubbo-interface这里定义一个UserService，并提供2个方法。1234public interface UserService &#123; String sayHello(String name); List&lt;User&gt; findAllUsers();&#125; 1234567891011121314151617181920212223242526272829303132333435363738public class User implements Serializable&#123; private Long id; private String name; private int age; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "User&#123;" + "id=" + id + ", name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;&#125; PS:注意User要实现序列化接口。 3.dubbo-providerpom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;springboot-dubbo-demo&lt;/artifactId&gt; &lt;groupId&gt;com.donny&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;name&gt;dubbo-provider&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.donny&lt;/groupId&gt; &lt;artifactId&gt;dubbo-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.2&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml12345678910server: port: 8080dubbo: registry: address: localhost:2181logging: level: root: info dubbo-provider.xml123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name="dubbo-provider" /&gt; &lt;!-- 注册中心服务地址 --&gt; &lt;dubbo:registry id="zookeeper" protocol="zookeeper" address="$&#123;dubbo.registry.address&#125;" /&gt; &lt;!-- 用dubbo协议在30001 --&gt; &lt;dubbo:protocol name="dubbo" port="30001" /&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface="com.donny.service.UserService" ref="userService" version="1.0" registry="zookeeper"/&gt; &lt;!-- 具体服务接口的实现 --&gt; &lt;bean id="userService" class="com.donny.service.UserServiceImpl" /&gt;&lt;/beans&gt; UserService实现123456789101112131415161718192021222324252627282930public class UserServiceImpl implements UserService &#123; @Override public String sayHello(String name) &#123; return "Hello," + name; &#125; @Override public List&lt;User&gt; findAllUsers() &#123; List&lt;User&gt; users = new ArrayList&lt;User&gt;(3); User user0 = new User(); user0.setId(1L); user0.setName("张三"); user0.setAge(18); users.add(user0); User user1 = new User(); user1.setId(2L); user1.setName("李四"); user1.setAge(28); users.add(user1); User user2 = new User(); user2.setId(3L); user2.setName("王五"); user2.setAge(38); users.add(user2); return users; &#125;&#125; Springboot主类123456789@SpringBootApplication@ImportResource("classpath:dubbo-provider.xml")public class DubboProviderApp&#123; public static void main( String[] args ) throws IOException &#123; SpringApplication.run(DubboProviderApp.class,args); System.in.read(); // 为保证服务一直开着，利用输入流的阻塞来模拟 &#125;&#125; 4.dubbo-consumerpom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;springboot-dubbo-demo&lt;/artifactId&gt; &lt;groupId&gt;com.donny&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;dubbo-consumer&lt;/artifactId&gt; &lt;name&gt;dubbo-consumer&lt;/name&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.donny&lt;/groupId&gt; &lt;artifactId&gt;dubbo-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.2&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml123456server: port: 8081dubbo: registry: address: localhost:2181 dubbo-consumer.xml123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;!-- 消费方应用名 --&gt; &lt;dubbo:application name="dubbo-consumer" /&gt; &lt;!-- 注册中心服务地址 --&gt; &lt;dubbo:registry id="zookeeper" protocol="zookeeper" address="$&#123;dubbo.registry.address&#125;" /&gt; &lt;!-- 引用UserService服务--&gt; &lt;dubbo:reference id="userService" interface="com.donny.service.UserService" check="false" version="1.0" url="" registry="zookeeper" protocol="dubbo" timeout="15000"/&gt;&lt;/beans&gt; Springboot主类123456789@SpringBootApplication@ImportResource("classpath:dubbo-consumer.xml")public class DubboConsumerApp&#123; public static void main( String[] args ) &#123; SpringApplication.run(DubboConsumerApp.class,args); &#125;&#125; 测试类123456789101112131415161718192021222324252627@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = DubboConsumerApp.class)public class DubboConsumerTest&#123; @Autowired private UserService userService; @Test public void testSayHello() &#123; String result = userService.sayHello("jack"); System.out.println(result); assertEquals(result,"Hello,jack"); &#125; @Test public void testFindAllUers() &#123; List&lt;User&gt; users = this.userService.findAllUsers(); if (null != users &amp;&amp; !users.isEmpty()) &#123; for (User user : users) &#123; System.out.println(user); &#125; &#125; assertNotNull(users); assertEquals(users.size(),3); &#125;&#125; PS:这里注册中心使用的zookeeper。 5.使用dubbo-spring-boot-starterspringboot提供了非常多的starter，要用什么就使用spring-boot-starter-xxx即可。dubbo也提供了相应的starter。dubbo-spring-boot-starter的github地址：https://github.com/alibaba/dubbo-spring-boot-starter。使用还是比较简单的，这里不再赘述。 dubbo-spring-boot-starter的使用也可以参考这篇：https://blog.csdn.net/romantic112/article/details/79687942。 参考：https://blog.csdn.net/qq_27384769/article/details/79465781 代码地址：https://gitee.com/tommy88/springboot-dubbo-demo]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列32——Spring Cloud Config的高可用]]></title>
    <url>%2F2018%2F07%2F20%2Fspringcloud%E7%B3%BB%E5%88%9732%E2%80%94%E2%80%94Config%20Server%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言Spring Cloud Config Server的高可用涉及到3个——Git仓库、RabbitMQ（Kafka）、Config Server本身3个的高可用。因为Config Server依赖Git仓库和RabbitMQ（Kafka），所以必须保证Git仓库和RabbitMQ（Kafka）也是高可用的。这里只介绍Config Server本身的高可用。 Config Server的高可用也分为2种：Config Server未注册到Eureka Server上 、Config Server注册到了Eureka Server上。 Config Server的高可用Config Server未注册到Eureka Server上这种情况在Spring Cloud中称之为“Config First Bootstrap”。可以使用一个负载均衡软件（如nginx）来做高可用，Cloud Config Client URI指向Nginx。 Config Server注册到了Eureka Server上这种情况，在Spring Cloud中称之为“Discovery First Bootstrap”。实现Config Server的高可用很简单，只需要将多个Config Server注册到Eureka server即可。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列31——Spring Cloud Config配置属性刷新之自动刷新]]></title>
    <url>%2F2018%2F07%2F20%2Fspringcloud%E7%B3%BB%E5%88%9731%E2%80%94%E2%80%94Spring%20Cloud%20Config%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7%E8%87%AA%E5%8A%A8%E5%88%B7%E6%96%B0%2F</url>
    <content type="text"><![CDATA[前言在前面一节中，我们通过执行/refresh端点来手动刷新配置，但是如果微服务的数量太多，一个一个刷新就很麻烦也很慢。本节介绍使用Spring Cloud Bus实现批量刷新和自动刷新。 使用Spring Cloud Bus实现配置批量刷新Spring Cloud Bus依赖rabbitmq或kafka，这里我们使用rabbitmq。 1.rabbitmq的安装与使用进入rabbitmq的下载页面下载安装包（这里使用windows），下载地址为：http://www.rabbitmq.com/download.html 在下载页面的右侧有各个系统的安装方法。 windows的地址为：http://www.rabbitmq.com/install-windows.html rabbitmq依赖Erlang，所以在安装rabbitmq之前需要安装Erlang。 在http://www.rabbitmq.com/which-erlang.html这个页面给出了每个rabbitmq应该安装的Erlang版本。 我们下载的是3.7.7的版本，推荐的Erlang版本是21.0.x 。 erlang的下载地址为：http://erlang.org/download/ csdn下载地址：https://download.csdn.net/download/qq_24118265/10186110 下载完毕后，就依次安装Erlang和rabbitmq即可。 安装完毕后，可以看到rabbitmq已经作为服务启动了。 2.开启RabbitMQ网页端控制台1.设置ERLANG_HOME环境变量； 2.到$rabbitmq_home/sbin$执行： 1rabbitmq-plugins.bat enable rabbitmq_management 如图： 3.重新开启rabbitmq服务。 4.浏览器访问http://localhost:15672，用户名和密码默认都是guest。 3.Cloud Config Client修改 增加spring-cloud-starter-bus-amqp依赖； 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 增加rabbitmq配置 123456spring: rabbitmq: host: localhost port: 5672 username: guest password: guest 如此就大功告成了！ 下面进行测试。 启动Config Server和2个Cloud Client（为了测试批量刷新配置）。在Cloud Client启动时，控制台可以看到有一个端点/bus/refresh，我们用它可以批量刷新配置。我们将git仓库配置文件的一个配置项做修改： 1my.custom.message=Hello,This is new value!!! 我们使用curl执行刷新命令： 1curl -X POST http://localhost:8080/bus/refresh 然后访问Cloud Config Client，看看是否配置更新。 可以看到，2个Cloud Config Client应用配置都已经刷新！ 观察2个Cloud Config Client，可以看到如下日志： 至此就实现了批量配置刷新。 我们到RabbitMQ的控制台的Exchanges，可以看到springCloudBus。 刷新某个Cloud Config Client如果要刷新某个Cloud Config Client的配置，可以使用/bus/refresh?destination=customers:9000。其中，customers:这里是ApplicationContext ID，9000是服务的端口。 但是，如果在BUS上已经有了这个ID，则会刷新这个ID的配置，其他的会被忽略。即如果在不同的机器上部署了同样的Cloud Config Client应用，ID一样，端口一样，IP不一样，则只会有一个服务配置属性会被刷新。 解决办法就是制定spring.application.index，不过这样就很麻烦了，每个同类的微服务（ID相同）都需要指定不同的index。不过可以指定spring.application.index=${random.long}来使用随机生成的数字作为index。不过，很明显似乎是一个设计缺陷，为什么不增加一个host参数？ 刷新某个Cloud Config Client服务的所有实例这个比较简单了，使用/bus/refresh?destination=customers:**即可，customers指应用的id。 参考Spring Cloud Bus章节：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/single/spring-cloud.html#_spring_cloud_bus 配置自动刷新这个要借助于Git管理软件提供的WebHooks钩子，可以指定一个地址，在提交到Git仓库时自动触发请求这个地址。 比如gitee.com 上面的URL就指定为刷新地址，如http://localhost:8080/bus/refresh，密码随意了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列29——Spring Cloud Config与Eureka配合使用]]></title>
    <url>%2F2018%2F07%2F19%2Fspringcloud%E7%B3%BB%E5%88%9729%E2%80%94%E2%80%94Spring%20Cloud%20Config%E4%B8%8EEureka%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言在之前说到的Spring Cloud Config Client程序中都是通过spring.cloud.config.uri 指定Config Server的地址。这种方式Spring Cloud称之为“Config First Bootstrap”。除此之外，还支持一种服务发现的方式，Spring Cloud称之为“Discovery First Bootstrap”。本文将说明如何通过Eureka发现Config Server的服务。 Spring Cloud Config与Eureka配合使用1.Config Server改造既然是通过Eureka服务发现来帮助Config Client定位到Config Server，那么必须先将Config Server注册到Eureka上。 a.添加Eureka的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; b.在配置文件指定eureka的serviceUri 123456789spring: application: name: cloud-config-servereureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true 注意需要指定Config Server的serviceId（spring.application.name），后面客户端从Eureka是根据serviceId查找Config Server的。 3.在Spring Boot主类增加@EnableEurekaClient 2.Config Client改造a.添加Eureka的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; b.配置文件增加Config Server的服务发现配置 123456789101112spring: application: name: cloud-config-client cloud: config: name: cloud-config profile: $&#123;config.profile:dev&#125; discovery: enabled: true service-id: cloud-config-server username: user password: password123 上面的配置中，discovery.enabled指定是否启用服务发现，service-id指定服务id。 在上一节中说到有2种方式配置会用户名和密码，但如果使用服务发现的话，就只能使用这种单独指定username和password的形式了。 3.在Spring Boot主类增加@EnableEurekaClient 然后依次启动Eureka Server，Config Server和Config Client即可。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列30——Spring Cloud Config配置属性刷新之手动刷新]]></title>
    <url>%2F2018%2F07%2F19%2Fspringcloud%E7%B3%BB%E5%88%9730%E2%80%94%E2%80%94Spring%20Cloud%20Config%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7%E5%88%B7%E6%96%B0%E4%B9%8B%E6%89%8B%E5%8A%A8%E5%88%B7%E6%96%B0%2F</url>
    <content type="text"><![CDATA[前言在以往的应用中，如果要更改应用的配置，要让配置生效必须重启应用程序。在Spring Cloud Config中我们可以刷新配置属性而不用重启应用。 这1节说明在Spring Cloud Config如何手动刷新配置属性。 手动刷新配置属性1.需要引入spring boot-actuator依赖（用到/refresh端点） 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 2.在Bean上增加@RefreshScope注解 比如： 12345678910111213@Controller@RequestMapping("/user")@RefreshScopepublic class UserController &#123; @Value("$&#123;my.custom.message&#125;") private String customeMessage; @GetMapping("/customMsg") @ResponseBody public String getCustomeMessage() &#123; return this.customeMessage; &#125;&#125; Ok，准备工作完毕！ 先来看看my.custom.message原来的配置 现在我们修改git仓库中配置文件的my.custom.message的配置项。 我们将value修改为： 1my.custom.message=Hello,This message is changed!!! 现在通过/refresh刷新配置属性。 返回结果表示my.custom.message配置有更新。 现在在访问/user/customeMsg 可以看到，已经使用了刚刚更新的配置。 注意1.默认spring-boot-acturator开启了安全认证，这里作为演示将其关闭（management.security.enabled=false）。 2.如果有很多个微服务，使用手动刷新配置的方式就不太合适了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列28——Spring Cloud Config之认证]]></title>
    <url>%2F2018%2F07%2F18%2Fspringcloud%E7%B3%BB%E5%88%9728%E2%80%94%E2%80%94Spring%20Cloud%20Config%E4%B9%8BSecurity%2F</url>
    <content type="text"><![CDATA[Config Server端1.添加spring-boot-starter-security依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 2.在配置文件配置用户名和密码1234567security: basic: enabled: true user: # 默认为user name: user password: password123 security.basic.enabled默认为true，security.user.name默认为user，security.user.password默认是随机生成的一串文字，在启动的时候从控制台可以看到。 然后在访问Config Server时会要求输入用户名和密码。 输入上面配置文件中配置的用户名和密码后就可以访问了。 Config Client端config server端增加认证后，config client也需要做一定的配置。 有2种方式配置用户名和密码。 第1种方式： 12spring.cloud.config.username=userspring.cloud.config.password=password123 第2种方式： 1spring.cloud.config.uri=http://user:password123@127.0.0.1:$&#123;config.port:8888&#125; PS:如果这2种方式都配置了，生效的是第1种方式。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列27——Spring Cloud Config之非对称加密]]></title>
    <url>%2F2018%2F07%2F17%2Fspringcloud%E7%B3%BB%E5%88%9727%E2%80%94%E2%80%94Spring%20Cloud%20Config%E4%B9%8B%E5%8A%A0%E8%A7%A3%E5%AF%862%2F</url>
    <content type="text"><![CDATA[前言在上一节说了Spring Cloud Config的对称加密，也可以使用非对称加密。公钥用于加密，私钥用于解密。这一节就说说非对称加密的用法。 使用1.生成秘钥这里以Spring Cloud官网文档给的例子来说明。 打开CMD窗口，粘贴并执行下面的命令： 1keytool -genkeypair -alias mytestkey -keyalg RSA -dname &quot;CN=Web Server,OU=Unit,O=Organization,L=City,S=State,C=US&quot; -keypass changeme -keystore server.jks -storepass letmein 执行完毕后，会发现该目录下生成了一个server.jks的文件。将该文件复制到classpath。 注意：Spring Cloud官网官网给的代码是Linux下执行的（带有\表示换行），windows下需要所有代码在一行。 2.bootstrap.yml在Spring Cloud Config Server的应用的bootstrap.yml增加下面的配置，指定非对称加密的配置。 123456encrypt: keyStore: location: classpath:/server.jks password: letmein alias: mytestkey secret: changeme location:指定密钥文件的位置。 password指定密钥库的密码(获取keystore信息所需的密码) 。 alias指定别名 secret指定私钥的密码。 这些信息都是从第1步生成秘钥的指令中获取。 3.测试启动Spring Cloud Config Server应用。 1.加密 2.解密 后面的使用与上一节一致，不再赘述。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列26——Spring Cloud Config之加解密]]></title>
    <url>%2F2018%2F07%2F17%2Fspringcloud%E7%B3%BB%E5%88%9726%E2%80%94%E2%80%94Spring%20Cloud%20Config%E4%B9%8B%E5%8A%A0%E8%A7%A3%E5%AF%86%2F</url>
    <content type="text"><![CDATA[前言在《springcloud系列25——SpringCloud配置管理》中介绍了以Git为首的作为配置仓库的示例。但是我们的配置项都是以明文的形式保存在Git仓库中。虽然我们可以创建私有的仓库，然后配置仓库的用户名和密码。但是如果账号被破解了呢？所以，本节要介绍的是如何加密你的配置项。这里首先介绍对称加密在Spring Cloud Config的用法。 前提在Spring Cloud Config中使用加解密功能，需要在你的JVM中安装有一个没有加密强度限制的JCE（JDK自带的私有强度限制的）。 注：JCE全称为Java Cryptography Extension 。 具体做法如下：1.从oracle下载无加密强度限制的JCE；oracle JCE的下载地址：http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip 2.复制2个策略文件替换JDK自带的策略文件。解压后，可以看到2个策略文件 找到jdk/jre/lib/security，然后覆盖这2个文件。 使用在Config Server所在的应用增加秘钥的配置（配置到bootstrap.yml）： 12encrypt: key: foo 然后重启Config Server应用。 Spring Cloud会我们提供了相应的加密和解密的端点。1.加密 2.解密 我们通过Spring Cloud提供的加密端点对配置信息进行加密，然后提交到GIT仓库。 需要注意的是，加密的信息前面必须有{cipher}前缀。 现在，我们来请求我们刚刚上传的加密的配置文件。 可以看到，Spring Cloud Config已经自动为我们解密了！ 客户端使用在上面也已经看到了，我们请求加密的配置，Spring Cloud Config为我们自动解密了，所以Cloud Config Client不需要做任何修改。 问题1.配置encrypt.key=foo必须配置到bootstrap.yml中，不能配置到application.yml，否则无法加密。会返回如下错误 1234&#123; &quot;description&quot;:&quot;No key was installed for encryption service&quot;, &quot;status&quot;:&quot;NO_KEY&quot;&#125; 2.yml配置文件加密项需要使用引号，而Properties文件则不能用引号引起来。 yml配置示例： 1234spring: datasource: username: dbuser password: '&#123;cipher&#125;FKSAJDFGYOS8F7GLHAKERGFHLSAJ' 可以参考：https://blog.csdn.net/chenxyz707/article/details/80487733 Spring Cloud Config官方文档：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/single/spring-cloud.html#_spring_cloud_config]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列25——SpringCloud配置管理]]></title>
    <url>%2F2018%2F07%2F14%2Fspringcloud%E7%B3%BB%E5%88%9725%E2%80%94%E2%80%94SpringCloud%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[springcloud官方文档 为什么要统一管理配置？1、集中管理 2、不同环境不同配置 3、运行期间动态调整配置 4、自动刷新 Spring Cloud简介为了解决上面的4个问题，spring cloud提供了spring cloud config组件。 Spring Cloud Config为分布式系统外部化配置提供了服务器端和客户端的支持，它包括Config Server和Config Client两部分。由于Config Server和Config Cleint都实现了对Spring Environment和PropertySource抽象的映射，因此，Spring Cloud非常适合Spring应用程序，当然也可与任何其他语言编写的应用程序配合使用。 Config Server是一个可横向扩展、集中式的配置服务器，它用于集中管理应用程序各个环境下的配置，默认使用Git存储配置内容(也可使用Subversion、本地文件系统或Vault存储配置),因此可以方便的实现对配置的版本控制与内容审计。 Config Client 是Config Server的客户端，用于操作存储在Config Server中的配置属性。 springcloud架构图下面是从网上弄的一张架构图 . 每个微服务有一个Spring Cloud Client，从Spring Cloud Config Server获取配置信息，Spring Cloud Config Server从Git仓库拉取配置。 Spring Cloud Config Server基础使用1.maven依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 2.Spring Boot主类增加@EnableConfigServer注解 123456789@SpringBootApplication@EnableConfigServerpublic class App&#123; public static void main( String[] args ) &#123; SpringApplication.run(App.class, args); &#125;&#125; 3.application.yml配置 12server.port=8888spring.cloud.config.server.git.uri=https://gitee.com/tommy88/springcloud-demos.git spring.cloud.config.server.git.uri配置Git仓库地址。 spring cloud config server提供了下面的映射规则： 12345/&#123;application&#125;/&#123;profile&#125;[/&#123;label&#125;]/&#123;application&#125;-&#123;profile&#125;.yml/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml/&#123;application&#125;-&#123;profile&#125;.properties/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties {application}会被spring.config.name注入，{profile}是环境信息，比如dev/test/product。{label}是一个可选的git标签，默认是master。 如果查找aaa项目的application-dev.yml，输入匹配路径/aaa/dev。如果application-dev.yml存在，则返回；如果不存在，则会返回application.yml的内容。 Git仓库配置详解Spring Cloud Config支持Git/SVN/文件系统等，默认使用的是Git。这里介绍Git在Spring Cloud Config Server中的一些配置。 1.Git uri中的通配符Spring Cloud Config Server支持带有{application}和{profile}（和{label}的占位符的git存储库URL（如果需要），但请记住，无论如何都要将标签应用为git标签）。 所以，你可以一个应用一个仓库，比如： 123456spring: cloud: config: server: git: uri: https://github.com/myorg/&#123;application&#125; 比如有2个Git Repo，分别为aaa和bbb。比如获取aaa的dev环境的配置，通过上面的配置可以通过/aaa/dev，同理bbb的dev环境的配置则为/bbb/dev。 你也可以配置{profile}通配符，比如： 123456spring: cloud: config: server: git: uri: https://github.com/myorg/&#123;application&#125;-&#123;profile&#125; 2.模式匹配通过{application}和{profile}的模式匹配，可以支持更复杂的需求。模式格式是带有{application}/{profile}通配符的使用逗号分隔的列表。 例如： 1234567891011121314spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo repos: simple: https://github.com/simple/config-repo special: pattern: special*/dev*,special*/test* uri: https://github.com/special/config-repo local: pattern: local* uri: file:/home/configsvc/config-repo 如果没有指定模式，则会使用/*，即匹配所有模式。 spring.cloud.config.server.git.uri是默认的git uri，如果{application}/{profile}没有匹配到任何模式，则会使用默认的git uri。 在上面的例子中，simple/模式只匹配simple应用的所有环境。special则匹配special开头的dev和test环境的配置。`local/`匹配任何以local开头任意profile的配置。 在上面的例子中，/special/dev会匹配到special-dev.yml，/special/default则会匹配到默认的application.yml。即上面说的，如果没有匹配到，会使用默认的git uri。 上面的配置中，repos其实是一个数组。所以如果使用yml也可以下面这样配置： 1234567891011121314151617spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo repos: development: pattern: - '*/development' - '*/staging' uri: https://github.com/development/config-repo staging: pattern: - '*/qa' - '*/production' uri: https://github.com/staging/config-repo 3.搜索路径每个Git repo还可以选择将配置文件存储在子目录中，搜索这些目录的模式可以指定为searchPaths。 1234567spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo searchPaths: foo,bar* 在这个例子中，Spring Cloud Config Server将会在/config-repo，/config-repo/foo和/config-repo/bar*开头的位置查找。 4.clondOnStart默认情况下，Spring Cloud Config Server会在第一次请求配置时克隆远程仓库。可以配置在应用启动时就克隆远程仓库，这样首次请求配置就会快一些响应。 比如： 123456789101112131415161718spring: cloud: config: server: git: uri: https://git/common/config-repo.git repos: team-a: pattern: team-a-* cloneOnStart: true uri: http://git/team-a/config-repo.git team-b: pattern: team-b-* cloneOnStart: false uri: http://git/team-b/config-repo.git team-c: pattern: team-c-* uri: http://git/team-a/config-repo.git 在上面的配置中，team-a的配置在应用启动时就会从远程仓库克隆。其他的仓库在首次请求配置时从远程仓库克隆。 上面的cloneOnStart也可以配置为全局，即在spring.cloud.config.server.git.cloneOnStart=true。配置了全局的cloneOnStart，则子repo没有配置时使用全局配置，如果子repo配置了，则使用子repo的配置。 设置cloneOnStart为true有助于在Spring Cloud Config Server启动时快速识别配资源的错误，比如仓库URI错误。这样就不至于在首次请求配置时才去检查到配置错误。 5.配置Git仓库的用户名和密码如果git仓库时私有的，那么就需要用户名和密码才能访问。在配置git仓库URI时指定username和password即可。 12345678spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo username: trolley password: strongpassword 6.搜索路径中的通配符Spring Cloud Config Server还支持带有{application}和{profile}（以及{label}的占位符的搜索路径。 例如： 1234567spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo searchPaths: '&#123;application&#125;' 在仓库中搜索与目录同名的文件（包括顶级目录/）。通配符在带占位符的搜索路径中也有效（搜索中包含任何匹配的目录）。 7.强制从Git仓库拉取更新如前所述，Spring Cloud Config Server会克隆远程git存储库，并且如果本地副本变得脏了（例如，OS进程更改了文件夹内容），那么Spring Cloud Config Server无法从远程存储库更新本地副本。 为了解决这个问题，有一个强制拉动属性，如果本地副本很脏，它将使Spring Cloud Config Server从远程存储库强行拉取。 例： 1234567spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo force-pull: true 如果您有多个存储库配置，则可以为每个存储库配置force-pull属性。 例： 12345678910111213141516171819spring: cloud: config: server: git: uri: https://git/common/config-repo.git force-pull: true repos: team-a: pattern: team-a-* uri: http://git/team-a/config-repo.git force-pull: true team-b: pattern: team-b-* uri: http://git/team-b/config-repo.git force-pull: true team-c: pattern: team-c-* uri: http://git/team-a/config-repo.git force-pull默认值是false。 8.删除Git存储库中未跟踪的分支由于Spring Cloud Config Server在签出分支到本地存储库后具有远程git存储库的克隆（例如，通过标签获取属性），它将永久保留此分支或直到下一个服务器重新启动（这将创建新的本地存储库）。 因此可能存在删除远程分支但仍然可以获取其本地副本的情况。 如果Spring Cloud Config Server客户端服务以–spring.cloud.config.label = deletedRemoteBranch启动，那么它将从deletedRemoteBranch本地分支获取属性，但不从master获取属性。 为了保持本地存储库分支的清洁和远程 - 可以设置deleteUntrackedBranches属性。 它将使Spring Cloud Config Server强制从本地存储库中删除未跟踪的分支。 例： 1234567spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo deleteUntrackedBranches: true deleteUntrackedBranches默认值为false。 Spring Cloud Config Client基础使用可以参考springcloud系列13——实现分布式配置管理一节有使用的demo。 1.maven依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 2.bootstrap.properties 123spring.cloud.config.uri=http://127.0.0.1:$&#123;config.port:8888&#125;spring.cloud.config.name=cloud-configspring.cloud.config.profile=$&#123;config.profile:dev&#125; 指定spring cloud config server的地址，应用名称和环境。 然后就可以使用配置属性了。如果是配置文件中使用，使用${配置项name}即可，比如： 12345#DB Configuration:spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = $&#123;mysqldb.datasource.url&#125;spring.datasource.username = $&#123;mysqldb.datasource.username&#125;spring.datasource.password = $&#123;mysqldb.datasource.password&#125; 如果是在java属性中，使用@Value(“${配置项那么}”)即可。 注意：config server的uri的配置必须配置在bootstrap文件中，否则会出错。比如你config server应用端口为8080，你config server的uri配置为http://localhsot:8080，实际启动时会发现是8888端口。 这是因为bootstrap文件也有一个端口，默认为8888，在应用启动时会先读取bootstrap的配置。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul的过滤器]]></title>
    <url>%2F2018%2F07%2F07%2Fspringcloud%E7%B3%BB%E5%88%9724%E2%80%94%E2%80%94Zuul%E7%9A%84%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Zuul的过滤器Zuul过滤器简介spring cloud Zuul包含了对请求的路由和过滤2个功能。路由功能负责将请求转发到具体的微服务上，而过滤器负责对请求的处理过程进行干预，是实现权限校验、服务聚合等功能的基础。 在实际运行时，路由映射和请求转发是由几个不同的过滤器完成的。每一个进入zuul的http请求都会经过一系列的过滤器处理链得到请求响应并返回给客户端。 spring cloud zuul包含4种类型的过滤器。 pre过滤器。在请求被路由之前调用。Zuul请求微服务之前。比如请求身份验证，选择微服务实例，记录调试信息等。 route过滤器。负责转发请求到微服务。原始请求在此构建，并使用Apache HttpClient或Netflix Ribbon发送原始请求。 post过滤器。在route和error过滤器之后被调用。可以在响应添加标准HTTP Header、收集统计信息和指标，以及将响应发送给客户端等。 error过滤器。在处理请求发生错误时被调用。 除了默认的Filter，Zuul还允许我们创建自定义的过滤器类型。比如，我们可以自定义一个STATIC类型的过滤器，它在Zuul中生成响应，而不是将请求转发给具体的微服务。 Zuul请求的生命周期如下： 参考Netflix Zuul wiki 自定义Zuul过滤器新建模块microservice-gateway-zuul-filter。 添加Zuul和Eureka客户端的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; application.yml: 123456789101112131415161718192021222324spring: application: name: microservice-gateway-zuul-filterserver: port: 8809eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: truezuul: routes: user1: path: /user/** serviceId: microservice-springcloud-user stripPrefix: falselogging: level: com.netflix: debug 定义一个pre类型的过滤器，记录请求的URI。 1234567891011121314151617181920212223242526public class MyZuulPreFilter extends ZuulFilter &#123; private final static Logger LOGGER = org.slf4j.LoggerFactory.getLogger(MyZuulPreFilter.class); @Override public String filterType() &#123; return "pre"; // 指定过滤器类型 &#125; @Override public int filterOrder() &#123; return 0; // 过滤器顺序，数字越小越先执行 &#125; @Override public boolean shouldFilter() &#123; return true; // 是否使用该过滤器。 &#125; // 过滤器具体执行的操作 @Override public Object run() &#123; HttpServletRequest request = RequestContext.getCurrentContext().getRequest(); String requestUri = request.getRequestURI(); LOGGER.info("请求的URI：&#123;&#125;",requestUri); return null; &#125;&#125; spring boot主类： 1234567891011121314@SpringBootApplication@EnableZuulProxypublic class ZuulFilterApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(ZuulFilterApplication.class,args); &#125; @Bean public MyZuulPreFilter myZuulPreFilter() &#123; return new MyZuulPreFilter(); &#125;&#125; 测试： 启动Eureka Server、user模块和microservice-gateway-zuul-filter。 我们通过Zuul的host和port访问user模块的/sample/1. 我们看下控制台。 我们只是简单记录一下请求的URI。更多的用法可以参考netflix-core包中的ZuulFilter实现。 Zuul过滤器的详细使用可以参考：https://www.jianshu.com/p/ff863d532767]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列23——非JVM语言支持之sidebar]]></title>
    <url>%2F2018%2F07%2F07%2Fspringcloud%E7%B3%BB%E5%88%9723%E2%80%94%E2%80%94%E9%9D%9EJVM%E8%AF%AD%E8%A8%80%E6%94%AF%E6%8C%81%E4%B9%8Bsidebar%2F</url>
    <content type="text"><![CDATA[Sidebar简介Sidecar是作为一个代理的服务来间接性的让其他语言可以使用Eureka等相关组件。通过与Zuul的来进行路由的映射，从而可以做到服务的获取，然后可以使用Ribbon，Feign对服务进行消费，以及对Config Server的间接性调用。 你是否想要在非jvm的语言中利用（间接性使用）Eureka，Ribbon以及Config Server？Spring Cloud Netflix Sidecar的设计灵感来自Netflix Prana。它包含一个简单的http api去获取一个已知服务的所有实例(例如主机和端口)。你也可以通过嵌入的Zuul代理(Zuul中有一个代理功能)对代理的服务进行调用，Zuul从Eureka服务注册中心获取所有的路由记录(route entries)。通过host发现(host lookup)或者Zuul代理可以直接访问Spring Cloud Config。非jvm需要应该实现一个健康检查，Sidecar能够以此来报告给Eureka注册中心该应用是up还是down状态。在你的项目中使用Sidecar，需要添加依赖，其group为org.springframework.cloud，artifact id为spring-cloud-netflix-sidecar。(这是以maven依赖的方式) 启用Sidecar，创建一个Spring Boot应用程序，并在在应用主类上加上@EnableSidecar注解。该注解包含@EnableCircuitBreaker, @EnableDiscoveryClient以及@EnableZuulProxy。Run the resulting application on the same host as the non-jvm application. (这句不太会翻译，我的理解为：在与非jvm应用程序相同的主机上运行生成的应用程序)注：这里的生成应该是通过代理产生的服务。 配置Sidecar，在application.yml中添加sidecar.port和sidecar.health-uri。sidecar.port属性是非jre程序监听的端口号，这就是Sidecar可以正确注册应用到Eureka的原因。sidecar.health-uri是非jre应用提供的一个对外暴露的可访问uri地址，在该地址对应的接口中需要实现一个模仿Spring Boot健康检查指示器的功能。它需要返回如下的json文档。(注：通过返回一个json，其用status字段来标识你的应用的服务状态，是up还是down，sidecar会将该状态报告给eureka注册中心从而实现你的服务的状态可用情况。简单的说就是用来控制sidecar代理服务的状态！) health-uri-document.(heal-uri指向的接口地址需要返回的json文档)123&#123; &quot;status&quot;:&quot;UP&quot;&#125; 这里是一个Sidecar应用程序的application.yml配置示例：application.yml123456789server: port: 5678spring: application: name: sidecarsidecar: port: 8000 health-uri: http://localhost:8000/health.json API DiscoveryClient.getInstances()所对应的访问方式是/hosts/{serviceId}，这是访问/hosts/customers后的响应示例，它返回了两个不同主机上的实例(可以看到主机地址不一样)。非jre程序可以访问这个api，如果sidecar的端口号为5678，那么完整url则为：http://localhost:5678/hosts/{serviceId}. /hosts/customers.12345678910111213141516[ &#123; &quot;host&quot;: &quot;myhost&quot;, &quot;port&quot;: 9000, &quot;uri&quot;: &quot;http://myhost:9000&quot;, &quot;serviceId&quot;: &quot;CUSTOMERS&quot;, &quot;secure&quot;: false &#125;, &#123; &quot;host&quot;: &quot;myhost2&quot;, &quot;port&quot;: 9000, &quot;uri&quot;: &quot;http://myhost2:9000&quot;, &quot;serviceId&quot;: &quot;CUSTOMERS&quot;, &quot;secure&quot;: false &#125;] Zuul代理会自动为每个在Eureka注册中心上的服务添加路由到/serviceId上，所以上面那个customers的服务可以通过/customers访问。非Jre应用可以通过http://localhost:5678/customers来访问Customer Service(假设Sidecar的监听端口为5678) 如果Config Server注册到了Eureka，非jre应用就可以通过Zuul代理访问它。如果ConfigServer的serviceId为configserver并且Sidecar的端口为5678，那么可以通过http://localhost:5678/configserver 的方式来访问Config Server。 非Jvm应用可以利用Config Server的能力来获取Config Server返回的YAML文档，通过访问 http://sidecar.local.spring.io:5678/configserver/default-master.yml 就可以获取到类似下面的YAML文档结果12345678eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ password: passwordinfo: description: Spring Cloud Samples url: https://github.com/spring-cloud-samples 如上是对spring cloud sidebar相关章节的翻译。spring cloud sidebar官方文档：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/multi/multi__polyglot_support_with_sidecar.html 译文参考：https://www.cnblogs.com/YrlixJoe/p/7509655.html 使用Sidebar将nodejs应用引入spring cloud这里提供了一个nodejs应用，代码如下：123456789101112131415161718192021222324252627282930// 引入Http模块var http = require('http');// 引入path模块var path = require('path');// 引入url模块var url = require('url');// 创建Servervar server = http.createServer(function(req,res) &#123; // 获得请求路径 var pathname = url.parse(req.url).pathname; res.writeHeader(200,&#123;'Content-Type': 'application/json;charset=utf-8'&#125;); if (pathname == '/') &#123; res.end(JSON.stringify(&#123;'index' : '欢迎来到首页！'&#125;)); &#125; // /health.json返回&#123;status:'UP'&#125; else if (pathname == '/health.json') &#123; res.end(JSON.stringify(&#123;'status' : 'UP'&#125;)); &#125; // 其他情况返回404 else &#123; res.end('404'); &#125;&#125;);server.listen(8050,function() &#123; console.log('nodejs is listening on port 8050.');&#125;); 有如下映射关系：123localhost:8050/ ==&gt; &#123;&apos;index&apos; : &apos;欢迎来到首页！&apos;&#125;localhost:8050/health.json ==&gt; &#123;&apos;status&apos; : &apos;UP&apos;&#125;locahost:8050/其他请求 ==&gt; 404 在Sidebar的介绍中，我们知道需要非jvm应用提供spring boot的健康指标功能，上面/health.json即提供的此功能。 创建模块microservice-sidecar 加入依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-sidecar&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; spring boot主类增加@EnableSidecar123456789@SpringBootApplication@EnableSidecarpublic class SidecarApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(SidecarApplication.class,args); &#125;&#125; application.yml增加sidecar配置1234567891011121314151617spring: application: name: microservice-sidecarserver: port: 8807eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: truesidecar: port: 8050 health-uri: http://localhost:8050/health.json 启动Eureka server，zuul和microservice-sidecar，以及nodejs的应用。 然后通过http://zuulHost:zuulPort/microservice-sidecar就可以访问nodejs应用的[http://localhsot:8050/](http://localhsot:8050/)。 通过zuul访问nodejs的服务 nodejs服务 注意事项：1.非jvm应用需要与sidecar部署在同一台机器上。如果不想部署在同一台机器，可以配置${eureka.instance.hostName}。 2.每个非jvm应用都需要有一个对应的sidecar应用。这应该是最大的一个问题，sidecar是与业务无关的，如果有很多非jvm的应用，会导致大量的sidecar应用。具体使用时需要评估。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何既快速又优雅的写博客：Typora + MPic]]></title>
    <url>%2F2018%2F07%2F07%2F%E5%A6%82%E4%BD%95%E6%97%A2%E5%BF%AB%E9%80%9F%E5%8F%88%E4%BC%98%E9%9B%85%E7%9A%84%E5%86%99%E5%8D%9A%E5%AE%A2%EF%BC%9ATypora%20%2B%20MPic%2F</url>
    <content type="text"><![CDATA[下载与安装Typora，一款简单到极致的MarkDown编辑器 https://www.typora.io/ MPic，一款支持多种上传方式且自动生成MarkDown链接的图床工具 http://mpic.lzhaofu.cn/ 创建七牛云空间一、注册并登录七牛云 https://portal.qiniu.com/signup/choice 选择个人账户，需要注意的是个人网站可以填写博客地址。 二、实名认证 https://portal.qiniu.com/identity/personal 三、创建空间 https://portal.qiniu.com/create 添加对象存储 命名空间，点击创建 得到该空间的外链域名 点击面板中的密钥管理 记录AK，SK的值，以备后续填写 四、设置MPic 进入设置账号，填写上述得到的信息，点击保存 五、几种上传方式 将本地图片直接拖拽到窗口上传 选中本地图片，Ctrl+C，直接上传 使用QQ截图，Ctrl+Alt+A，复制图片后上传 参考：https://blog.csdn.net/u011262253/article/details/78834824]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列22——Zuul简介及代码示例]]></title>
    <url>%2F2018%2F07%2F05%2Fspringcloud%E7%B3%BB%E5%88%9722%E2%80%94%E2%80%94Zuul%E7%AE%80%E4%BB%8B%E5%8F%8A%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[Zuul简介spring cloud官方文档地址：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/multi/multi__router_and_filter_zuul.html 路由是微服务架构的组成部分。 例如，/可以映射到您的Web应用程序，/ api/users映射到用户服务，/api/shop映射到商店服务。 Zuul是Netflix基于JVM的路由器和服务器端负载均衡器。 Netflix使用Zuul进行以下操作：认证洞察压力测试金丝雀测试动态路由服务迁移负载脱落安全静态响应处理主动/主动流量管理 Zuul的规则引擎允许任何JVM语言编写规则和过滤器，内置支持Java和Groovy。 配置属性zuul.max.host.connections已被两个新属性zuul.host.maxTotalConnections和zuul.host.maxPerRouteConnections取代，它们分别默认为200和20。 所有路由的默认Hystrix隔离模式（ExecutionIsolationStrategy）是SEMAPHORE。 如果首选此隔离模式，则可以将zuul.ribbonIsolationStrategy更改为THREAD。 代码示例这里新建一个模块microservice-gateway-zuul。 1.引入zuul和eureka client的依赖：12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; spring cloud文档有说，Zuul starter没有包含discovery client，所以我们在上面增加了eureka client的依赖。 2.在Spring boot的主类上增加注解@EnableZuulProxy123456789@SpringBootApplication@EnableZuulProxypublic class ZuulApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(ZuulApplication.class,args); &#125;&#125; 3.application.yml配置12345678910111213spring: application: name: microservice-gateway-zuulserver: port: 8808eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true 测试1.启动Eureka server；2.启动user微服务；3.启动zuul模块。 在user模块，有/sample/1获取用户信息的接口。 浏览器请求http://10.41.3.149:8808/microservice-springcloud-user/sample/1。 可以看到，请求成功。我们看Zuul模块的控制台日志，可以看到下面的日志：1Mapped URL path [/microservice-springcloud-user/**] onto handler of type [class org.springframework.cloud.netflix.zuul.web.ZuulController] 自定义请求路径通过Eureka server中的serviceID可以请求成功，但名字太长，如何自定义？ 比如我们想通过/user/sample/1访问，如何做到？ 在application.yml增加下面的配置：123zuul: routes: microservice-springcloud-user: /user/** Zuul忽略某些服务比如有user和movie2个服务，但我只想Zuul代理user服务。1234zuul: ignoredServices: '*' routes: microservice-springcloud-user: /user/** ignoredServices:*忽略所有的服务，然后在routes中指定了user，所以最终就是Zuul代理user服务。 或者：12345zuul: # 多个服务id之间用逗号分隔 ignoredServices: microservice-springcloud-movie routes: microservice-springcloud-user: /user/** Zuul指定path和serviceId12345678zuul: routes: # 下面的user1只是一个标识，保证唯一即可 user1: # 映射的路径 path: /user/** # 服务id serviceId: microservice-springcloud-user 上面的配置意思是：让Zuul代理microservice-springcloud-user，路径为/user/**，user1可以随便写，只要保证唯一即可。 然后通过http://10.41.3.149:8808/user/sample/1请求即可。 Zuul指定path+url除了上面说的指定path+serviceId外，还可以使用path+url的配置。123456zuul: routes: user1: path: /user/** # url为user服务的url url: http://10.41.3.149:7902 然后通过http://10.41.3.149:8808/user/sample/1请求即可。 Zuul指定可用服务的负载均衡在spring cloud的文档中有写，如果使用上面的path+url配置，不会作为HystrixCommand执行，也不会使用Ribbon对多个URL进行负载均衡。 要实现此目的，您可以使用静态服务器列表指定serviceId。1234567891011121314zuul: routes: user1: path: /user/** serviceId: microservice-springcloud-user# 在Ribbon中禁用eurekaribbon: eureka: enabled: falsemicroservice-springcloud-user: ribbon: listOfServers: localhost:7901,localhost:7902 如上，需要在ribbon中禁用Eureka。然后指定了2个user服务，端口分别为7901，7902。 仍然是通过http://localhost:8808/user/sample/1来访问。访问多次，可以在控制台看到SQL打印，是轮询调用7901和7902的。 Zuul使用正则表达式指定路由规则您可以使用regexmapper在serviceId和路由之间提供约定。 它使用名为groups的正则表达式从serviceId中提取变量并将它们注入路由模式。 将user服务id修改为123spring: application: name: microservice-springcloud-user-v1 zuul模块application.yml12345678910111213spring: application: name: microservice-gateway-zuulserver: port: 8808eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true Zuul主类：1234567891011121314151617@SpringBootApplication@EnableZuulProxypublic class ZuulApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(ZuulApplication.class,args); &#125; @Bean public PatternServiceRouteMapper serviceRouteMapper() &#123; // 第一个参数：servicePattern，第2个参数routePattern return new PatternServiceRouteMapper( "(?&lt;name&gt;^.+)-(?&lt;version&gt;v.+$)", "$&#123;version&#125;/$&#123;name&#125;"); &#125;&#125; 上面的PatternServiceRouteMapper意思是myusers-v1将映射为/v1/myusers/**。 接受任何正则表达式，但所有命名组必须同时出现在servicePattern和routePattern中。 如果servicePattern与serviceId不匹配，则使用默认行为。比如user的serviceId为microservice-springcloud-user，那么实际上最终是通过http://localhost:zuul端口/microservice-springcloud-user/**来访问。 在上面的示例中，serviceId“myusers”将映射到路由“/myusers/**”（在未检测到版本时）默认情况下禁用此功能，仅适用于已发现的服务。 然后浏览器可以通过[http://localhost:zuul端口]/v1/microservice-springcloud-user/sample/1来访问user服务。 为所有映射增加前缀要为所有映射添加前缀，请将zuul.prefix设置为值，例如/ api。 在默认情况下转发请求之前，会从请求中删除代理前缀（使用zuul.stripPrefix = false关闭此行为）。 在application.yml增加12zuul: prefix: /api 然后通过http://localhost:Zuul端口/api/microservice-springcloud-user/sample/1来访问。 上面是一种全局的设置方式。可以通过zuul.stripPrefix=true/false来设置在请求具体的服务时是否剥离前缀。比如访问/api/sample/1，如果zuul.stripPrefix设置为true（默认为true），则实际请求用户服务的是/sample/1，相反请求路径是/api/sample/1. 您还可以关闭从各个路由中剥离特定于服务的前缀，例如：假定user服务中指定了context-path为/user，我们访问/sample/1是通过/user/sample/1来访问的。现在我想通过http://localhost:zuul端口/user/sample/1来访问，可以这样做：12345zuul: routes: microservice-springcloud-user: path: /user/** stripPrefix: false 或者：123456zuul: routes: microservice-springcloud-user: prefix: /user path: /** stripPrefix: false stripPrefix是剥离前缀的意思，设置为false就是不剥离前缀，Zuul默认是剥离前缀的。比如我们设置path=/user/**，比如访问/user/sample/1，实际请求用户服务的是/sample/1。 stripPrefix比较实用的场景是服务带有context-path。 zuul.stripPrefix仅适用于zuul.prefix中设置的前缀。 它对给定路由的路径中定义的前缀没有任何影响。 Zuul忽略指定的路径上面说过了，通过ignoredServices可以指定忽略某些服务，这是比较粗粒度的控制。如果想细粒度的控制忽略某些路径，可以通过下面的方式：1234zuul: ignoredPatterns: /**/admin/** routes: users: /myusers/** 这意味着所有诸如“/myusers/101”之类的请求将被转发到“users”服务上的“/101”。 但包括“/admin/”在内的请求则不会处理。 Zuul指定路由的顺序1234567zuul: routes: microservice-springcloud-user: path: /user/** stripPrefix: false legacy: path: /** 上面配置的意思是/user**的请求转发到microservice-springcloud-user去处理，其他的请求按默认的方式处理（即通过http://zuulHost:zuulPort/服务名/请求路径）。比如我们启动了microservice-springcloud-user和microservice-springcloud-movie-feign-without-hystrix2个服务。 通过Zuul访问microservice-springcloud-user,可以这样访问： 通过Zuul访问microservice-springcloud-movie-feign-without-hystrix需要如下方式访问： 如果你需要保证路由的顺序，则需要使用YAML文件，因为使用属性文件就会丢失顺序。所以，如果你用properties文件配置，可能会导致/user/**访问不到microservice-springcloud-user。 Zuul Http ClientZuul默认使用的是Apache的http client。之前使用的是RestClient。如果你还是想使用RestClient，可以设置ribbon.restclient.enabled=true；如果你想使用OkHttp3，可以设置ribbon.okhttp.enabled=true。 如果要自定义Apache HTTP客户端或OK HTTP客户端，请提供ClosableHttpClient或OkHttpClient类型的bean。 Cookie和敏感的Headers在同一系统中的服务之间共享Headers是可以的，但您可能不希望敏感Headers向下游泄漏到外部服务器。您可以在路由配置中指定忽略的Headers列表。 Cookie起着特殊的作用，因为它们在浏览器中具有明确定义的语义，并且它们始终被视为敏感。如果您的代理的消费者是浏览器，那么下游服务的cookie也会给用户带来问题，因为它们都会混乱（所有下游服务看起来都来自同一个地方）。 如果您对服务的设计非常小心，例如，如果只有一个下游服务设置了cookie，那么您可以让它们从后端一直流到调用者。此外，如果您的代理设置了cookie并且您的所有后端服务都是同一系统的一部分，那么简单地共享它们就很自然（例如使用Spring Session将它们链接到某个共享状态）。除此之外，由下游服务设置的任何cookie都可能对调用者不是很有用，因此建议您（至少）将“Set-Cookie”和“Cookie”放入敏感的标头中不属于您的域名。即使对于属于您域的路由，在允许cookie在它们与代理之间流动之前，请仔细考虑它的含义。 可以将敏感报头配置为每个路由的逗号分隔列表，例如，123456zuul: routes: users: path: /myusers/** sensitiveHeaders: Cookie,Set-Cookie,Authorization url: https://downstream 这是sensitiveHeaders的默认值，因此除非您希望它不同，否则无需进行设置。注： 这是Spring Cloud Netflix 1.1中的新功能（在1.0中，用户无法控制Headers，所有Cookie都在所有方向上流动）。 sensitiveHeaders是黑名单，默认不为空，因此要使Zuul发送所有Headers（“忽略”的Headers除外），您必须将其明确设置为空列表。 如果要将cookie或授权Headers传递给后端，则必须执行此操作。 例：123456zuul: routes: users: path: /myusers/** sensitiveHeaders: url: https://downstream 也可以通过设置zuul.sensitiveHeaders来全局设置敏感的Headers。 如果在路由上设置了sensitiveHeaders，则会覆盖全局sensitiveHeaders设置。 忽略Headers除了每个路由规则上面的敏感头部信息设置，我们还可以在网关与外部服务交互的时候，用一个全局的设置zuul.ignoredHeaders，去除那些我们不想要的http头部信息(包括请求和响应的)。在默认情况下，zuul是不会去除这些信息的。如果Spring Security不在类路径上的话，它们就会被初始化为一组众所周知的“安全”头部信息（例如，涉及缓存），这是由Spring Security指定的。在这种情况下，假设请求网关的服务也会添加头部信息，我们又要得到这些代理头部信息，就可以设置zuul.ignoreSecurityHeaders为false，同时保留Spring Security的安全头部信息和代理的头部信息。当然，我们也可以不设置这个值，仅仅获取来自代理的头部信息。 路由端点Actuator提供了一个可以查看路由规则的端点/routes，我们在Zuul中引入Actuator依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 再把安全验证关闭，让我们可以访问到这个端点：123management: security: enabled: false 这里，遗留请求的路由规则会影响到我们访问这个端点，先注释掉这个路由规则：12#legacy: #path: /** 重启Zuul项目，我们便能看到zuul网关的路由规则了 如果想知道路由的详细细节，可以增加参数?format=details Strangulation Patterns (绞杀者模式)迁移现有应用程序或API时的常见模式是“扼杀”旧的端点，慢慢地用不同的实现替换它们。 Zuul代理是一个有用的工具，因为可以使用它来处理来自旧端点的客户端的所有流量，但重定向一些请求到新的端点。 1234567891011121314zuul: routes: first: path: /first/** url: http://first.example.com second: path: /second/** url: forward:/second third: path: /third/** url: forward:/3rd # 本地的转发 legacy: # 老系统的请求 path: /** url: http://legacy.example.com 在这个例子中，我们正在扼杀“遗留”应用程序，该应用程序映射到与其他模式之一不匹配的所有请求。 /first/中的路径已被提取到具有外部URL的新服务中。 并转发/second/中的路径，以便可以在本地处理它们，例如， 使用正常的Spring @RequestMapping。 /third/**中的路径也被转发，但具有不同的前缀（即/third/foo被转发到/3rd/foo）。 忽略的模式不会被完全忽略，它们只是不由代理处理（因此它们也可以在本地有效转发）。 通过Zuul上传文件新建一个模块microservice-file-upload，该模块用于文件上传。application.yml12345678910111213server: port: 9999spring: application: name: microservice-file-uploadeureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true 上传文件的Controller1234567891011121314151617181920212223242526@Controller@RequestMapping("/file")public class FileUploadController &#123; @RequestMapping(value = "/upload",method = RequestMethod.POST) @ResponseBody public String uploadFile(@RequestParam("file") MultipartFile file) throws IOException &#123; String uploadDir = "E:/test/"; String originName = file.getOriginalFilename(); String uploadPath = uploadDir+originName; File destDir = new File(uploadDir); if (!destDir.exists()) &#123; destDir.mkdirs(); &#125; File dest = new File(uploadPath); if (dest.exists()) &#123; dest.delete(); &#125; file.transferTo(dest); System.out.println("文件上传路径：" + uploadPath); return uploadPath; &#125;&#125; 这里将服务注册到Eureka，是为了后面使用Zuul代理文件上传功能。 这里用curl测试。1curl -F &quot;file=@d:/luckystar88/books/java_bloomfilter.rar&quot; http://localhost:9999/file/upload 可以看到，请求成功。 刚刚上传的文件大小14Kb，我们上传一个大点的文件（文件大小18.9M）。 出错，看错误信息，提示文件大小19M，超过了配置的最大大小10M。 解决办法：123456789spring: application: name: microservice-file-upload http: multipart: # 单个文件大小 max-file-size: 1024Mb # 总上传数据的大小 max-request-size: 2048Mb 配置上面2项设置文件大小即可。 重新上传： 现在我们使用Zuul测试。 修改Zuul的application.yml1234zuul: routes: microservice-file-upload: path: /upload-api/** 将/upload-api/**的请求交给microservice-file-upload处理。 启动Eureka Server，Zuul和file-upload模块。1curl -F &quot;file=@d:/360极速浏览器下载/111.mp4&quot; http://localhost:8808/zuul/upload-api/file/upload 可以看到上传成功。 我们准备一个大点的文件（175M）测试下上传超时。1curl -F "file=@C:\Users\Administrator\Downloads\Spring+Cloud微服务实战.pdf" http://localhost:8808/zuul/upload-api/file/upload 可以看到Zuul报超时了。 解决办法：在Zuul增加配置：1234hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 重新请求，可以看到上传成功了（文件名乱码就暂时不管了）。 禁用Zuul Filters默认会使用很多filters，可采用如下方式禁止1zuul.SendResponseFilter.post.disable=true Zuul的回退当Zuul中给定路径的电路跳闸时，您可以通过创建ZuulFallbackProvider类型的bean来提供回退响应。 在此bean中，您需要指定回退所针对的路由ID，并提供ClientHttpResponse作为回退返回。 我们创建一个模块microservice-gateway-zuul-fallback。application.yml12345678910111213141516171819spring: application: name: microservice-gateway-zuul-fallbackserver: port: 8808eureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: truezuul: routes: microservice-springcloud-user: path: /user/** stripPrefix: false 由于在microservice-springcloud-user服务中指定了context-path，所以这里设置stripPrefix=false。 spring boot主类：123456789@SpringBootApplication@EnableZuulProxypublic class ZuulFallbackApplication&#123; public static void main( String[] args ) &#123; SpringApplication.run(ZuulFallbackApplication.class,args); &#125;&#125; 回退类：1234567891011121314151617181920212223242526272829303132333435363738394041424344@Componentpublic class UserFallbackProvider implements ZuulFallbackProvider &#123; @Override public String getRoute() &#123; return "microservice-springcloud-user"; &#125; @Override public ClientHttpResponse fallbackResponse() &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return HttpStatus.BAD_REQUEST; &#125; @Override public int getRawStatusCode() throws IOException &#123; return HttpStatus.BAD_REQUEST.value(); &#125; @Override public String getStatusText() throws IOException &#123; return HttpStatus.BAD_REQUEST.getReasonPhrase(); &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream((getRoute() + "==》fallback").getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125; 回退的类中指定了路由为microservice-springcloud-user，同时指定了响应码，响应内容，响应类型等信息。 测试： 启动Eureka server，microservice-springcloud-user和microservice-gateway-zuul-fallback。 user服务正常时访问： 关闭user服务，再次访问： 通过/routes访问路由信息： 注意：FallbackProvider类中的routes必须与配置文件中的一致。 如果想为所有的路由设置一个默认的fallback，可以创建一个ZuulFallbackProvider类型的Bean，并且getRoute返回*或null。 比如：1234567891011121314151617181920212223242526272829303132333435363738394041424344@Componentpublic class MyFallbackProvider implements ZuulFallbackProvider &#123; @Override public String getRoute() &#123; return "*"; &#125; @Override public ClientHttpResponse fallbackResponse() &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return HttpStatus.OK; &#125; @Override public int getRawStatusCode() throws IOException &#123; return 200; &#125; @Override public String getStatusText() throws IOException &#123; return "OK"; &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream("fallback".getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125; 如果您想根据失败原因选择响应，请使用FallbackProvider，它将取代未来版本中的ZuulFallbackProvder。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Componentpublic class MyFallbackProvider implements FallbackProvider &#123; @Override public String getRoute() &#123; return "*"; &#125; @Override public ClientHttpResponse fallbackResponse(final Throwable cause) &#123; if (cause instanceof HystrixTimeoutException) &#123; return response(HttpStatus.GATEWAY_TIMEOUT); &#125; else &#123; return fallbackResponse(); &#125; &#125; @Override public ClientHttpResponse fallbackResponse() &#123; return response(HttpStatus.INTERNAL_SERVER_ERROR); &#125; private ClientHttpResponse response(final HttpStatus status) &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return status; &#125; @Override public int getRawStatusCode() throws IOException &#123; return status.value(); &#125; @Override public String getStatusText() throws IOException &#123; return status.getReasonPhrase(); &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream("fallback".getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列20——Turbine聚合各个节点的hystrix.stream]]></title>
    <url>%2F2018%2F07%2F03%2Fspringcloud%E7%B3%BB%E5%88%9720%E2%80%94%E2%80%94Turbine%E8%81%9A%E5%90%88%E5%90%84%E4%B8%AA%E8%8A%82%E7%82%B9%E7%9A%84hystrix.stream%2F</url>
    <content type="text"><![CDATA[前言我们在之前讲过，在单个的Hystrix的应用中，我们使用/hystrix.stream可以查看监控数据，如果想以图表的形式更直观的查看监控数据，再结合dashboard就可以了。 但是，如何同时监控多个应用或集群呢？我们需要使用springcloud提供的Turbine，它是将各个应用的/hystrix.stream进行聚合的组件。我们在dashboard中输入/turbine.stream即可查看所有监控应用的健康情况。 turbine的官方文档：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/multi/multi__hystrix_timeouts_and_ribbon_clients.html#_turbine Turbine的使用这里新建模块microservice-springcloud-turbine。单纯的使用turbine是很简单的。 1.引入turbine和Eureka的依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-turbine&lt;/artifactId&gt;&lt;/dependency&gt; 2.配置turbine12345678910111213141516turbine: aggregator: # 指定聚合哪些集群，多个使用&quot;,&quot;分割，默认为default。 cluster-config: default # 配置监控的服务id，多个服务以逗号分隔 app-config: microservice-springcloud-movie-feign-with-hystrix,microservice-springcloud-movie-feign-without-hystrix clusterNameExpression: new String(&quot;default&quot;)eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instanceId: $&#123;spring.application.name&#125;:$&#123;vcap.application.instance_id:$&#123;spring.application.instance_id:$&#123;random.value&#125;&#125;&#125; turbine配置参数： 1.turbine.app-config=ribbon-consumer指定了要监控的应用名字为ribbon-consumer2.turbine.cluster-name-expression=”default”,表示集群的名字为default3.turbine.combine-host-port=true表示同一主机上的服务通过host和port的组合来进行区分，默认情况下是使用host来区分，这样会使本地调试有问题 3.在启动类增加@EnableTurbine123456789@SpringBootApplication@EnableTurbinepublic class TurbineApp&#123; public static void main( String[] args ) &#123; SpringApplication.run(TurbineApp.class,args); &#125;&#125; 4.Dashboard的使用在《springcloud系列16——Hystrix Health Indicator及Metrics Stream》已经说过了。 测试a.启动Eureka Server应用；b.启动user服务，因为要监控的应用使用它；c.启动microservice-springcloud-movie-feign-with-hystrix,microservice-springcloud-movie-feign-without-hystrix这2个服务，其中microservice-springcloud-movie-feign-with-hystrix修改配置的端口启动2个服务；d.启动turebine应用；e.启动dashboard应用。 测试步骤：1.检查microservice-springcloud-movie-feign-with-hystrix,microservice-springcloud-movie-feign-without-hystrix这2个服务的/hystrix.stream是否能够访问； 2.检查/turbine.stream是否可以访问； 3.分别访问microservice-springcloud-movie-feign-with-hystrix,microservice-springcloud-movie-feign-without-hystrix这2个服务的/user/1请求（依赖user的服务），然后看/turbine.stream是否输出了类似下面的数据：12: pingdata: &#123;&quot;reportingHostsLast10Seconds&quot;:3,&quot;name&quot;:&quot;meta&quot;,&quot;type&quot;:&quot;meta&quot;,&quot;timestamp&quot;:1530633245374&#125; 如上，表示10秒内上报的主机数量为3. 4./访问dashboard应用的/hystrix，输入/turbine.stream的地址。可以看到下面的页面 参数说明： 5.将user服务关闭，频繁刷新某个服务，然后看dashboard可以看到，显示断路器1个打开，2个关闭。因为我们只是访问了1个服务，所以其他没访问的2个服务断路器状态还是关闭的。 如果我另外一个服务也频繁访问让断路器打开，在dashboard页面就会看到2个处理打开状态。 不过有个问题，我将某个服务关闭，dashboard仍然显示的3个Hosts，但你看/turbine.stream，其实上报的hosts只有2个。 问题hystrix.stream 404 问题参考：http://www.voidcc.com/content/spring-boot-hystrix-stream-404。 Feign是对Hystrix支持的，所以不用增加Hystrix的依赖。但是，如果要使用dashboard则需要引入hystrix的依赖。12345&lt;!-- 整合hystrix，其实feign中自带了hystrix，引入该依赖主要是为了使用其中的hystrix-metrics-event-stream，用于dashboard --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 并且在Application类中增加如下代码123456789@Bean public ServletRegistrationBean getServlet() &#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings("/hystrix.stream"); registrationBean.setName("HystrixMetricsStreamServlet"); return registrationBean; &#125; 这样启动后通过http://ip:port/hystrix.stream即可访问。 PS：这里springcloud使用的是1.4.2.RELEASE版本。 Turbine.stream的reportingHostsLast10Seconds为0启动Turbine的应用后，可以通过http://ip:port/turbine.stream来查看Turbine收集监控数据。turbine的作用是聚合各个/hystrix.stream的监控数据，在单个的hystrix.stream都正常后，turbine.stream收集的上报的hosts的数量却一直是0. 123: ping: pingdata: &#123;&quot;reportingHostsLast10Seconds&quot;:0（这里一直是0）,&quot;name&quot;:&quot;meta&quot;,&quot;type&quot;:&quot;meta&quot;,&quot;timestamp&quot;:1530627942212&#125; Turbine需要注册Eureka。所以需要引入Eureka的依赖，并配置eureka.client.url。1.引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 2.配置eureka.client.url1234567eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instanceId: $&#123;spring.application.name&#125;:$&#123;vcap.application.instance_id:$&#123;spring.application.instance_id:$&#123;random.value&#125;&#125;&#125; 然后收集数据就正常了。在dashboard输入turbine.stream的地址即可看到监控数据。 使用RequestLine一直触发的fallbackmicroservice-springcloud-movie-feign-without-hystrix服务依赖user服务，user服务已经启动了，但访问microservice-springcloud-movie-feign-without-hystrix的/user/1时仍然返回的fallback的处理结果。 这是因为我的FeignClient中configuration使用了默认的Contract。12345678910111213@Configurationpublic class Configuration1 &#123;// @Bean// public Contract feignContract() &#123;// return new feign.Contract.Default();// &#125; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 注释掉默认的Contract即可。 集群配置可以参考：https://blog.csdn.net/luosai19910103/article/details/70820904/ turbine如何聚合设置了context-path的hystrix数据：http://blog.didispace.com/spring-cloud-tips-4/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列19——Feign使用fallbackFactory属性打印fallback异常]]></title>
    <url>%2F2018%2F06%2F30%2Fspringcloud%E7%B3%BB%E5%88%9719%E2%80%94%E2%80%94Feign%E4%BD%BF%E7%94%A8fallbackFactory%E5%B1%9E%E6%80%A7%E6%89%93%E5%8D%B0fallback%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[在FeignClient中，我们通过制定fallback，可以在服务不可用时自动调用fallback制定的处理方法。 但如果如果希望同时知道发生回退的原因呢？ 可以使用fallbackFactory属性。 下面以microservice-springcloud-movie-feign-with-hystrix模块来说明。 1.定义一个实现FallbackFactory的类12345678910111213141516171819202122@Componentpublic class UserFeignClientHystrixFallbackFactory implements FallbackFactory&lt;UserFeignClient&gt;&#123; private Logger logger = LoggerFactory.getLogger(UserFeignClientHystrixFallbackFactory.class); @Override public UserFeignClient create(Throwable throwable) &#123; logger.error("fallback reason:&#123;&#125;",throwable.getMessage()); return new UserFeignClient() &#123; @Override public User findUserById(Long userId) &#123; User user = new User(); user.setId(-1L); return user; &#125; &#125;; &#125;&#125; 如上，在发生回退时使用logger记录了回退的原因（异常），并返回了一个UserFeignClient，该实例重写了findUserById方法。 达到的效果就是在发生回退时，先打印回退原因，然后返回下面自定义的处理。 2.FeignClient类指定fallbackFactory属性。123456// 不要同时使用fallback和fallbackFactory@FeignClient(name = "microservice-springcloud-user"/*,fallback = UserHystrixClientFallback.class*/,fallbackFactory = UserFeignClientHystrixFallbackFactory.class)public interface UserFeignClient &#123; @RequestMapping(value = "/sample/&#123;userId&#125;", method = RequestMethod.GET) User findUserById(@PathVariable("userId") Long userId);&#125; 测试1.启动Eureka Server；2.启动user服务；3.启动microservice-springcloud-movie-feign-with-hystrix。 浏览器访问/user/1，访问正常 关闭user服务，再次访问/user/1可以看到，返回的是我们fallbackFactory中指定的处理方法的结果。 看控制台打印的异常信息是null 但实际上错误原因是TimeoutException，如下 现在多次刷新/user/1，使断路器打开。然后再次访问/user/1 现在回退的原因是断路器打开了。 注意fallback和fallbackFactory只能指定一个，如果2个都指定了，生效的是fallback。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列18——全局和单个禁用Feign Client对Hystrix的支持]]></title>
    <url>%2F2018%2F06%2F30%2Fspringcloud%E7%B3%BB%E5%88%9718%E2%80%94%E2%80%94%E5%85%A8%E5%B1%80%E5%92%8C%E5%8D%95%E4%B8%AA%E7%A6%81%E7%94%A8Feign%20Client%E5%AF%B9Hystrix%E7%9A%84%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[全局禁用这个比较简单，在application.yml中配置：123feign: hystrix: enabled: false 加上这段配置就可以了。 禁用某个Feign Client对Hystrix的支持1.新建一个配置类12345678910111213@Configurationpublic class Configuration2&#123; //Configuration2里面加上这个就禁用了UserFeignClient2的Hystrix @Bean @Scope("prototype") public Feign.Builder feignBuilder() &#123; //feignBuilder方法默认返回HystrixFeign.Builder也就是说Feign默认支持Hystrix //现在改成Feign.Builder就禁用了Hystrix的支持 return Feign.builder(); &#125;&#125; 2.在FeignClient的注解上加入configturation123456@FeignClient(name = "microservice-springcloud-movie",configuration = Configuration2.class,fallback = UserHystrixClientFallback2.class)public interface UserFeignClient2&#123; @RequestMapping(value = "/user/list") List&lt;User&gt; showUserList();&#125; 禁用单个Hystrix的示例代码说明：模块名：microservice-springcloud-movie-feign-without-hystrix 该模块创建了2个Feign Client，Feign Client1支持Hystrix，Feign Client2不支持Hystrix。 application.yaml1234567891011121314151617181920212223242526272829server: port: 7801spring: application: name: microservice-springcloud-movie-feign-without-hystrixeureka: client: healthcheck: enabled: true serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.application.name&#125;:$&#123;spring.cloud.client.ipAddress&#125;:$&#123;spring.application.instance_id:$&#123;server.port&#125;&#125;# 启用feign对Hystrix的支持feign: hystrix: enabled: true#设置全局的超时时间hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 5000 主类：12345678910@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class MovieAppFeignWithoutHystrix&#123; public static void main( String[] args ) &#123; SpringApplication.run(MovieAppFeignWithoutHystrix.class,args); &#125;&#125; 12345@FeignClient(name = "microservice-springcloud-user",fallback = UserHystrixClientFallback.class)public interface UserFeignClient &#123; @RequestMapping(value = "/sample/&#123;userId&#125;",method = RequestMethod.GET) User findUserById(@PathVariable("userId") Long userId);&#125; 123456@FeignClient(name = "microservice-springcloud-movie",configuration = Configuration2.class,fallback = UserHystrixClientFallback2.class)public interface UserFeignClient2&#123; @RequestMapping(value = "/user/list") List&lt;User&gt; showUserList();&#125; 1234567891011@Componentpublic class UserHystrixClientFallback implements UserFeignClient&#123; @Override public User findUserById(Long userId) &#123; User user = new User(); user.setId(0L); return user; &#125;&#125; 12345678910@Componentpublic class UserHystrixClientFallback2 implements UserFeignClient2&#123; @Override public List&lt;User&gt; showUserList() &#123; System.out.println("UserHystrixClientFallback2.showUserList() called."); return null; &#125;&#125; 12345678910111213@Configurationpublic class Configuration2&#123; //Configuration2里面加上这个就禁用了UserFeignClient2的Hystrix @Bean @Scope("prototype") public Feign.Builder feignBuilder() &#123; //feignBuilder方法默认返回HystrixFeign.Builder也就是说Feign默认支持Hystrix //现在改成Feign.Builder就禁用了Hystrix的支持 return Feign.builder(); &#125;&#125; 12345678910111213141516171819@RestControllerpublic class MovieController &#123; @Autowired private UserFeignClient userFeignClient; @Autowired private UserFeignClient2 userFeignClient2; @GetMapping("/user/&#123;userId&#125;") public User findUserById(@PathVariable Long userId) &#123; return this.userFeignClient.findUserById(userId); &#125; @GetMapping("/user/list") public List&lt;User&gt; listUser() &#123; return this.userFeignClient2.showUserList(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738public class User &#123; private Long id; private String username; private String name; private BigDecimal balance; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public BigDecimal getBalance() &#123; return balance; &#125; public void setBalance(BigDecimal balance) &#123; this.balance = balance; &#125;&#125; 测试：1.启动eurake server；2.启动user服务；3.启动movie服务；4.启动microservice-springcloud-movie-feign-without-hystrix。 浏览器访问/user/1，正常： 浏览器访问/user/list，正常： 关闭movie服务，再次访问/user/list提示连接超时，说明Feign Client2的Hystrix是失效的。 关闭user服务，再次访问/user/1返回的是我们定义的回退方法的结果，说明Feign Client1的Hystrix是生效的。 如上，就达到了禁用某个Feign Client对Hystrix支持的效果。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列17——Feign的Hystrix支持]]></title>
    <url>%2F2018%2F06%2F29%2Fspringcloud%E7%B3%BB%E5%88%9717%E2%80%94%E2%80%94Feign%E7%9A%84Hystrix%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[Feign的Hystrix支持springcloud官方文档参考：17.4 Feign Hystrix Support. 如果Hystrix在类路径上并且feign.hystrix.enabled = true，Feign将用断路器包装所有方法。 如果只是想某个Feign Client禁用Hystrix，可以创建一个普通的Feign.Builder，并将scope设置为prototype。 例如：12345678@Configurationpublic class FooConfiguration &#123; @Bean @Scope("prototype") public Feign.Builder feignBuilder() &#123; return Feign.builder(); &#125;&#125; Feign Hystrix的回退（fallbacks）Hystrix支持回退的概念：当断路器打开或出现错误时将执行默认的代码路径。 要为给定的@FeignClient启用回退，请将fallback属性设置为实现回退的类名称。 您还需要将您的实现声明为Spring bean。 示例代码：这里以movie模块修改，新的模块名为microservice-springcloud-movie-feign-with-hystrix。 1.为Feign启用hystrix修改application.yml123feign: hystrix: enabled: true 2.编写FeignClient，并设置fallbacks12345@FeignClient(name = "microservice-springcloud-user",fallback = UserHystrixClientFallback.class)public interface UserFeignClient &#123; @RequestMapping(value = "/sample/&#123;userId&#125;", method = RequestMethod.GET) User findUserById(@PathVariable("userId") Long userId);&#125; 3.创建回退类1234567891011@Componentpublic class UserHystrixClientFallback implements UserFeignClient&#123; @Override public User findUserById(Long userId) &#123; User user = new User(); user.setId(0L); return user; &#125;&#125; 4.测试1.启动Eureka Server；2.启动User服务；3.启动microservice-springcloud-movie-feign-with-hystrix。 启动后，浏览器访问/user/1，得到正确响应。将user服务关闭，连续刷新20次以上，再次访问得到的结果是user的id为0，即我们的Fallback类中实现的方法。结果与springcloud系列15——hystrix简介及简单代码示例一节的一致。 代码结构： 这里要注意代码结构，否则在启动时会出现一些问题。应用启动类如下：12345678910@SpringBootApplication@ComponentScan(&#123;"com.tommy.springcloud","com.tommy.config.fallback"&#125;)@EnableFeignClients("com.tommy.config.feign")public class MovieAppWithFeignAndHystrix&#123; public static void main( String[] args ) &#123; SpringApplication.run(MovieAppWithFeignAndHystrix.class,args); &#125;&#125; springboot扫描的类要与feign的分开。同时Fallback的类也要被springboot扫描到。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud官方文档中文翻译版]]></title>
    <url>%2F2018%2F06%2F25%2Fspringcloud%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91%E7%89%88%2F</url>
    <content type="text"><![CDATA[https://springcloud.cc/spring-cloud-netflix.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列16——Hystrix Health Indicator及Metrics Stream]]></title>
    <url>%2F2018%2F06%2F25%2Fspringcloud%E7%B3%BB%E5%88%9716%E2%80%94%E2%80%94Hystrix%20Health%20Indicator%E5%8F%8AMetrics%20Stream%2F</url>
    <content type="text"><![CDATA[传播安全上下文或使用Spring Scopes参考springcloud官方文档：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/single/spring-cloud.html#_propagating_the_security_context_or_using_spring_scopes。 springcloud原文： If you want some thread local context to propagate into a @HystrixCommand the default declaration will not work because it executes the command in a thread pool (in case of timeouts). You can switch Hystrix to use the same thread as the caller using some configuration, or directly in the annotation, by asking it to use a different “Isolation Strategy”. 翻译： 如果你想要一些线程本地上下文传播到@HystrixCommand，默认声明将不起作用，因为它在线程池中执行命令（在超时的情况下）。 您可以使用某种配置将Hystrix切换为与调用方使用相同的线程，或者直接在注释中请求它使用不同的“隔离策略”。比如：123456@HystrixCommand(fallbackMethod = "stubMyService", commandProperties = &#123; @HystrixProperty(name="execution.isolation.strategy", value="SEMAPHORE") &#125;)... springcloud原文： The same thing applies if you are using @SessionScope or @RequestScope. You will know when you need to do this because of a runtime exception that says it can’t find the scoped context. You also have the option to set the hystrix.shareSecurityContext property to true. Doing so will auto configure an Hystrix concurrency strategy plugin hook who will transfer the SecurityContext from your main thread to the one used by the Hystrix command. Hystrix does not allow multiple hystrix concurrency strategy to be registered so an extension mechanism is available by declaring your own HystrixConcurrencyStrategy as a Spring bean. Spring Cloud will lookup for your implementation within the Spring context and wrap it inside its own plugin. 翻译： 如果使用@SessionScope或@RequestScope，则同样适用。 你需要知道，只有在产生一个运行时异常，并且它告诉你无法找到范围内的上下文时，你才应该这样做。 您也可以选择将hystrix.shareSecurityContext属性设置为true。 这样做会自动配置一个Hystrix并发策略插件钩子，他可以将SecurityContext从主线程传输到Hystrix命令使用的钩子。 Hystrix不允许注册多个hystrix并发策略，因此通过将自己的HystrixConcurrencyStrategy声明为Spring bean，可以使用扩展机制。 Spring Cloud将在Spring上下文中查找您的实现，并将其包装在自己的插件中。 健康指标spring-boot的actuator提供了/health端点来查看Hystrix状态。使用也很简单，在pom.xml增加依赖即可：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 因为在公网环境，有些敏感数据不适合直接查看。所以，默认情况下，访问类似http://localhost:8081/metrics会看到下面的错误： 所以，建议对这些查看敏感数据的使用跟应用不同的端口。示例如下：12345management: security: enabled: false # 关闭安全检查 port: 1101 # 管理端口 context-path: /admin # 管理上线文路径 如果在公网环境，建议在防火墙上做下限制，仅允许8081进来，1101用于内网访问即可，这样相对比较安全，也不用繁琐的输入密码。 在应用启动时的控制台日志，我们可以看到，spring-boot-acturator提供了非常多的指标。 springboot-acturator的相关内容参考：http://www.cnblogs.com/yjmyzz/p/spring-boot-actuator-tutorial.html。 配置了springboot-actuator后，我们可以通过/health来查看Hystrix的健康状态。 这个表示hystrix的断路器未打开。 我们将user服务关闭，然后疯狂刷新/user/1多次（20次）以上，再次访问/admin/health。 会看到：可以看到，hystrix的状态是CIRCUIT_OPEN，标识断路器打开了。 Hystrix监控/health端点只能看到断路器的整体状态，但对细节展示不详细。从上面我们会看到一个/hystrix.stream的端点，访问该端点可以看到详细的数据。页面会一直持续刷新，可以看到最新数据。 Hystrix Dashboard通过/hystrix.stream可以实时看到最新的监控数据，但密密麻麻的文字，看起来不太方便。spring cloud提供了一个hystrix-dashboard的功能，可以以图形化界面展示这些数据。 使用步骤如下：a.添加spring-cloud-starter-hystrix-dashboard的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; b.在启动类上增加@EnableHystrixDashboard注解123456789101112131415@SpringBootApplication@EnableCircuitBreaker@EnableHystrixDashboardpublic class MovieHystrixApp&#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main( String[] args ) &#123; SpringApplication.run(MovieHystrixApp.class,args); &#125;&#125; c.重新启动movie-hystrix模块d.浏览器输入movie-hystrix应用端口/hystrix，可以看到下面的页面 输入下面的信息：其实就是制定/hystrix.stream的地址，刷新的间隔。 然后就可以看到下面的界面：可以看到，此时断路器开关是关闭的。 我们停止user模块的服务，并且狂刷页面一会儿。可以看到，此时断路器打开了。 这显然比纯文字友好多了。还有一个问题，如果有多个hystrix.stream地址同时监控，或者把多个地址的数据汇总起来，该怎么弄？github上有一个turbine ,就是专门为解决这个问题的，大家可以自行研究下。 参考：https://www.cnblogs.com/yjmyzz/p/spring-cloud-hystrix-tutorial.html。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列15——hystrix简介及简单代码示例]]></title>
    <url>%2F2018%2F06%2F25%2Fspringcloud%E7%B3%BB%E5%88%9715%E2%80%94%E2%80%94hystrix%E7%AE%80%E4%BB%8B%E5%8F%8A%E7%AE%80%E5%8D%95%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[Hystrix简介在微服务中，有服务A、B，C，D4个微服务。其中，C依赖D，A和B依赖C。那么当D出现问题时，会导致C不可用，进而导致A和B也不可用。这就是产生了雪崩效应。 hystrix语义为“豪猪”，它身上有很多刺，具有自我保护的能力。hystrix的出现即为解决雪崩效应。 关于Hystrix的原理可用参考：https://www.jianshu.com/p/e07661b9bae8。 spring cloud hystrix相关内容参考：http://cloud.spring.io/spring-cloud-static/Edgware.SR3/single/spring-cloud.html#_circuit_breaker_hystrix_clients。 简单代码示例新增模块microservice-springcloud-movie-hystrix。该模块是从microservice-springcloud-movie拷贝过去的。 在pom.xml增加hystrix依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 在App启动类增加@EnableCircuitBreaker注解：1234567891011121314@SpringBootApplication@EnableCircuitBreakerpublic class MovieHystrixApp&#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main( String[] args ) &#123; SpringApplication.run(MovieHystrixApp.class,args); &#125;&#125; Controller：1234567891011121314151617@RestControllerpublic class MovieController &#123; @Autowired private RestTemplate restTemplate; @GetMapping("/user/&#123;userId&#125;") @HystrixCommand(fallbackMethod = "getUserFallback") public User getUser(@PathVariable Long userId) &#123; return restTemplate.getForObject("http://microservice-springcloud-user/sample/" + userId,User.class); &#125; public User getUserFallback(Long userId) &#123; User user = new User(); user.setId(0L); return user; &#125;&#125; fallbackMethod指定服务调用失败时的处理方法为getUserFallback。 注意：fallbackMethod指定的方法必须与原方法有相同的方法签名。 测试1.启动EurekaServer App；2.启动microservice-springcloud-user；3.启动microservice-springcloud-movie-hystrix。 浏览器请求http://127.0.0.1:8761/。第一次执行会发现调用了fallbackMethod指定的方法，返回的user的id为0. 后面刷新，返回的都是正常的调用user模块的。 我们将user服务关闭，再刷新页面。此时页面有一定的等待，并返回的是fallbackMethod指定的数据，user的id为0. 后面刷新页面20次，然后继续刷新，发现虽然返回的user的id还是0，但是没有等待。过几秒后，刷新页面又有等待，过一会儿又没有了。 原因在spring cloud的文档中已经说到： A service failure in the lower level of services can cause cascading(级联) failure all the way up to the user. When calls to a particular service is greater than circuitBreaker(断路器).requestVolumeThreshold (default: 20 requests) and failue percentage is greater than circuitBreaker.errorThresholdPercentage (default: &gt;50%) in a rolling window defined(定义) by metrics(度量标准).rollingStats.timeInMilliseconds (default: 10 seconds), the circuit(电路) opens and the call is not made. In cases of error and an open circuit a fallback(撤退) can be provided by the developer. 翻译过来的意思就是： 在较低级别的服务中的服务故障可能导致级联故障一直到用户。当对特定服务的调用大于circuitBreaker.requestVolumeThreshold（默认值：20请求）和故障率大于circuitBreaker.errorThresholdPercentage阈值百分比（默认值：50%）在metrics.rollingStats.timeInMilliseconds指定的时间内（默认10秒）。断路器打开并且不进行服务的调用。在错误和电路打开的情况下，开发人员可以提供回退。 所以，在10秒后，20次请求，有50%的故障率，Hystrix会执行开发人员提供的fallback方法。 但是Hystrix有它的监控方法，所以隔一定的时间（默认5秒），Hystrix会检查服务是否可用，如果不可用，则继续打开断路器开关，并按指定的回退方法处理；如果服务恢复正常，则执行服务调用。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列14——Eureka、Ribbon和Feign常见问题和解决]]></title>
    <url>%2F2018%2F06%2F22%2Fspringcloud%E7%B3%BB%E5%88%9714%E2%80%94%E2%80%94Eureka%E3%80%81Ribbon%E5%92%8CFeign%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[1.修改System Status的Environment和Data Center如图： 增加如下配置：123eureka: environment: product datacenter: spring cloud 或者在启动时使用-Deureka.datacenter=spring cloud这种方式来指定。 2.Eureka配置instanceId显示IP12345eureka: instance: instance-id: # 显示应用名称：ip地址：端口号 $&#123;spring.application.name&#125;:$&#123;spring.cloud.client.ipAddress&#125;:$&#123;server.port&#125; 3.Consider defining a bean of type ‘com.tommy.config.feign.UserFeignClient’ in your configuration.参考：https://www.jianshu.com/p/551c7c251f91 在@EnableFeignClients注解上增加UserFeignClient所在的package。即：1@EnableFeignClients(&#123;"com.tommy.config.feign"&#125;) 4.使用RestTemplate调用服务提供方返回List的服务问题这里是在百度云视频第18节中看到的，比如服务提供方定义了一个接口返回List，调用方使用RestTemplate调用时返回的并不是List。 即下面的代码是错误的：1List&lt;User&gt; list = this.restTemplate.getForObject("http://microservice-springcloud-user/user/list",List.class); 应该改成123User[] users = this.restTemplate.getForObject("http://microservice-springcloud-user/user/list",User[].class);List&lt;User&gt; list = Arrays.asList(users); 不过，我本地测试没有出现这个问题。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客从github迁移到gitee]]></title>
    <url>%2F2018%2F06%2F09%2Fhexo-blog-from-github-to-gitee%2F</url>
    <content type="text"><![CDATA[gitee感觉做的不错，而且是国内的，速度要比github快不少。所以将博客从github迁移到gitee。1.在gitee.com修改个性地址：比如这里最后是tommy88。 2.在gitee.com创建一个public项目，名称为上面的tommy88. 3.打开git bash，进入到博客目录。在git Bash中，输入：1ssh-keygen -t rsa -C &quot;username&quot; (注：username为你git上的用户名) 后面一直回车，直到结束。 打开生成的id_rsa.pub文件，复制公钥到gitee的ssh key。 配置完毕后，使用下面的命令测试一下SSH Key1ssh -T git@gitee.com 后面你使用hexo d直接就提交到gitee仓库中了。 4.修改hexo的_config.ymlDeploy部分修改为gitee的地址1234deploy: type: git repo: git@gitee.com:tommy88/tommy88.git branch: master 5.博客内容提交到gitee后，开启gitee pages。部署后，会显示一个网站地址，这个地址就是你的博客地址。 6.将博客源代码托管到gitee参考https://tommy88.gitee.io/2017/08/26/hexo-github-personal-blog/文章中的将博客文章、配置与主题设置备份到osc章节。 注意：如果之前备份过，这里由于修改了个性地址，会导致仓库地址发生变化，本地再次执行git push origin master命令时会提示 到博客根目录下的.git文件夹，打开config文件，修改gitee地址 将url修改为最新的地址 再次push就成功了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty自定义编码器和解码器（粘包处理）]]></title>
    <url>%2F2018%2F06%2F08%2Fnetty-custom-decoder-and-encoder%2F</url>
    <content type="text"><![CDATA[这里的实现方式是：将消息分为两部分，也就是消息头和消息尾，消息头中写入要发送数据的总长度，通常是在消息头的第一个字段使用int值来标识发送数据的长度。首先我们写一个Encoder，我们继承自MessageToByteEncoder ，把对象转换成byte，继承这个对象，会要求我们实现一个encode方法：1234567@Overrideprotected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception &#123; byte[] body = convertToBytes(msg); //将对象转换为byte，伪代码，具体用什么进行序列化，你们自行选择。可以使用我上面说的一些 int dataLength = body.length; //读取消息的长度 out.writeInt(dataLength); //先将消息长度写入，也就是消息头 out.writeBytes(body); //消息体中包含我们要发送的数据&#125; 那么当我们在Decode的时候，该怎么处理发送过来的数据呢?这里我们继承ByteToMessageDecoder方法，继承这个对象，会要求我们实现一个decode方法1234567891011121314151617181920public void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) &#123; if (in.readableBytes() &lt; HEAD_LENGTH) &#123; //这个HEAD_LENGTH是我们用于表示头长度的字节数。 由于上面我们传的是一个int类型的值，所以这里HEAD_LENGTH的值为4. return; &#125; in.markReaderIndex(); //我们标记一下当前的readIndex的位置 int dataLength = in.readInt(); // 读取传送过来的消息的长度。ByteBuf 的readInt()方法会让他的readIndex增加4 if (dataLength &lt; 0) &#123; // 我们读到的消息体长度为0，这是不应该出现的情况，这里出现这情况，关闭连接。 ctx.close(); &#125; if (in.readableBytes() &lt; dataLength) &#123; //读到的消息体长度如果小于我们传送过来的消息长度，则resetReaderIndex. 这个配合markReaderIndex使用的。把readIndex重置到mark的地方 in.resetReaderIndex(); return; &#125; byte[] body = new byte[dataLength]; // 嗯，这时候，我们读到的长度，满足我们的要求了，把传送过来的数据，取出来吧~~ in.readBytes(body); // Object o = convertToObject(body); //将byte数据转化为我们需要的对象。伪代码，用什么序列化，自行选择 out.add(o); &#125; 下面来一个示例（实例只做了字符串的处理，其他自定义对象的处理参考上面）。服务端（接收端）：12345678910111213141516171819202122232425262728public class Server &#123; public static void main(String[] args) &#123; NioEventLoopGroup boss = new NioEventLoopGroup(); NioEventLoopGroup worker = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(boss,worker) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; // 添加自定义的解码器 socketChannel.pipeline().addLast(new MyCustomMessageDecoder()); socketChannel.pipeline().addLast(new ServerMessageHandler()); &#125; &#125;); try &#123; ChannelFuture future = bootstrap.bind(9999).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; boss.shutdownGracefully(); worker.shutdownGracefully(); &#125; &#125;&#125; 自定义的消息解码器：123456789101112131415161718192021222324252627282930313233343536373839public class MyCustomMessageDecoder extends ByteToMessageDecoder &#123; // 消息头：发送端写的是一个int，占用4字节。 private final static int HEAD_LENGTH = 4; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; // if (in.readableBytes() &lt; HEAD_LENGTH) &#123; return; &#125; // 标记一下当前的readIndex的位置 in.markReaderIndex(); // 读取数据长度 int dataLength = in.readInt(); // 我们读到的消息体长度为0，这是不应该出现的情况，这里出现这情况，关闭连接。 if (dataLength &lt; 0) &#123; ctx.close(); &#125; //读到的消息体长度如果小于我们传送过来的消息长度，则resetReaderIndex. 这个配合markReaderIndex使用的。把readIndex重置到mark的地方 if (in.readableBytes() &lt; dataLength) &#123; in.resetReaderIndex(); return; &#125; // 将缓冲区的数据读到字节数组 byte[] body = new byte[dataLength]; in.readBytes(body); //将byte数据转化为我们需要的对象。伪代码，用什么序列化，自行选择 Object msg = convertToObj(body); out.add(msg); &#125; private Object convertToObj(byte[] body) &#123; return new String(body,0,body.length); &#125;&#125; Server端的消息处理器：1234567891011121314151617public class ServerMessageHandler extends ChannelInboundHandlerAdapter &#123; private int messageCount = 0; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String _msg = (String) msg; System.out.println("["+(++messageCount)+"]接收到消息：" + _msg); // 注意：业务异常需要处理，不能不管，否则会调用exceptionCaught() &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 客户端代码：12345678910111213141516171819202122232425262728293031public class Client&#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.SO_SNDBUF,10) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.SO_BACKLOG, 1024) .handler(new LoggingHandler(LogLevel.INFO)) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; // 增加自定义编码器 socketChannel.pipeline().addLast(new MyCustomMessageEncoder()); socketChannel.pipeline().addLast(new ClientMessageHandler()); &#125; &#125;); try &#123; ChannelFuture future = bootstrap.connect("127.0.0.1", 9999).sync(); future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 自定义的消息编码器：123456789101112131415public class MyCustomMessageEncoder extends MessageToByteEncoder&lt;Object&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception &#123; // 要发送的数据 // 这里如果是自定义的类型，msg即为自定义的类型，需要转为byte[] byte[] body = ((ByteBuf)msg).array(); // 数据长度 int dataLength = body.length; // 缓冲区先写入数据长度 out.writeInt(dataLength); // 再写入数据 out.writeBytes(body); &#125;&#125; 客户端的消息处理器：123456789101112131415161718192021public class ClientMessageHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; String msg = "hello,world"; byte[] data; ByteBuf buf; for (int i=0;i&lt;100;i++) &#123; data = (msg+i).getBytes(); buf = Unpooled.copiedBuffer(data); ctx.writeAndFlush(buf); &#125; System.out.println("100条 消息发送完毕"); ctx.close(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 运行效果客户端： 服务端： 参考：https://blog.csdn.net/AlbertFly/article/details/51533992]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ajax跨域问题]]></title>
    <url>%2F2018%2F06%2F02%2Ffix-ajax-crossdomain-problem%2F</url>
    <content type="text"><![CDATA[什么是Ajax跨域问题这里通过一个示例来说明。我们这里准备了2个Springboot工程。crossdomain-server:端口：8080 对外提供的接口如下：1234567891011@RestController@RequestMapping("/test")public class TestController &#123; @RequestMapping("/get") public ResultBean get() &#123; System.out.println("TestController.get()."); return new ResultBean("hello,justin"); &#125;&#125; 通过浏览器请求http://localhost:8080/test/get得到如下结果：crossdomain-client:端口：8081提供了一个简单的页面，用于Ajax请求crossdomain-server的接口。123456789101112131415161718&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;script type="text/javascript" src="/jquery.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;a href="#" onclick="get1();"&gt;get请求&lt;/a&gt; &lt;script type="text/javascript"&gt; function get1() &#123; $.getJSON("http://localhost:8080/test/get",function(json) &#123; alert(json); &#125;); &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 但是点击“get请求”后，发现控制台报错了。如下： 这个就是Ajax跨域问题。 Ajax跨域的原因产生跨域是由于浏览器的安全策略，JavaScript只能访问和操作自己域下的资源，不能访问和操作其他域下的资源。跨域问题是针对JS和ajax的，html本身没有跨域问题，比如a标签、script标签、甚至form标签（可以直接跨域发送数据并接收数据）等。所谓的同源，指的是域名、协议、端口均相等。 解决Ajax跨域的方式1.jsonp我们对crossdomain-server做些修改：a.增加ControllerAdvice12345678@ControllerAdvicepublic class JsonpAdvice extends AbstractJsonpResponseBodyAdvice &#123; public JsonpAdvice() &#123; super("callback"); &#125; &#125; b.页面Ajax请求方式改为jsonp12345678910111213141516171819202122232425// 每个测试用例的超时时间jasmine.DEFAULT_TIMEOUT_INTERVAL = 1000;var base = "http://localhost:8080/test";// 测试模块describe("ajax跨域",function() &#123; it("jsonp请求",function(done) &#123; var result; $.ajax(&#123; url:base+"/get", dataType:"jsonp", success:function(callback) &#123; result = callback; expect(result).toEqual(&#123; "data": "hello,justin" &#125;) // 校验完成，通知jasmine框架 done(); &#125; &#125;); &#125;);&#125;); 浏览器输入http://localhost:8081可以看到测试通过， 看下jsonp请求： 这里使用了jasmine测试框架，具体使用方法可以执行百度。jasmine的github地址为：https://jasmine.github.io，可以在release中下载。使用可以参考：https://jasmine.github.io/2.3/introduction.html。 jsonp虽然可以解决跨域问题，但jsonp只支持get请求，而且还需要修改前后台代码。jsonp为什么只支持get，不支持post？jsonp不是使用xhr发送的，是使用动态插入script标签实现的，当前无法指定请求的method，只能是get。调用的地方看着一样，实际上和普通的ajax有2点明显差异：1. 不是使用xhr 2.服务器返回的不是json数据，而是js代码。 2.被调用方修改以支持跨域我们这里使用Filter，在响应中增加Access-Control-Allow-Origin。123456789101112131415@SpringBootApplicationpublic class CrossdoaminServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CrossdoaminServerApplication.class, args); &#125; @Bean public FilterRegistrationBean crossFilter() &#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.addUrlPatterns("/*"); bean.setFilter(new CrossFilter()); return bean; &#125;&#125; 1234567891011121314151617181920212223public class CrossFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; // 允许http://localhost:8081域访问 resp.addHeader("Access-Control-Allow-Origin", "http://localhost:8081"); chain.doFilter(request, response); &#125; @Override public void destroy() &#123; &#125;&#125; crossdomain-client前端测试点：12345678910111213141516171819202122232425262728293031323334353637// 测试模块describe("ajax跨域",function() &#123; it("get请求",function(done) &#123; var result; $.getJSON(base+"/get",function(json)&#123; result = json; expect(result).toEqual(&#123; "data": "hello,justin" &#125;) // 校验完成，通知jasmine框架 done(); &#125;); &#125;); it("jsonp请求",function(done) &#123; var result; $.ajax(&#123; method:"post", url:base+"/get", dataType:"jsonp", success:function(callback) &#123; result = callback; expect(result).toEqual(&#123; "data": "hello,justin" &#125;) // 校验完成，通知jasmine框架 done(); &#125; &#125;); &#125;);&#125;); 测试结果： 可以将Access-Control-Allow-Origin设置为*，这样任何域都可以访问。同时可以通过Access-Control-Allow-Methods指定允许访问的方法。如允许GET请求：12// 同样可以将Access-Control-Allow-Methods设置为*，表示允许所有方法。resp.addHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;GET&quot;); 带cookie的跨域我们在crossdomain-server增加一个测试方法：12345@GetMapping("/getCookie")public ResultBean getCookie(@CookieValue(name="cookie1") String cookie1) &#123; System.out.println("TestController.getCookie().cookie1=" + cookie1); return new ResultBean("cookie:" + cookie1);&#125; 然后浏览器访问crossdomain-server的任意一个请求，使用document.cookie=&quot;cookie1=justin&quot;来增加一个名为cookie1，值为justin的cookie。 crossdomain-client增加一个测试用例：12345678910111213141516171819202122it("getCookie请求",function(done) &#123; var result; $.ajax(&#123; type:"get", url:base+"/getCookie", xhrFields: &#123; // 默认情况下，跨源请求不提供凭据(cookie、HTTP认证及客户端SSL证明等)。通过将withCredentials属性设置为true，可以指定某个请求应该发送凭据。如果服务器接收带凭据的请求，会用下面的HTTP头部来响应。 withCredentials: true &#125;, success:function(json) &#123; result = json; expect(result).toEqual(&#123; "data": "cookie:justin" &#125;) // 校验完成，通知jasmine框架 done(); &#125; &#125;);&#125;); 我们访问http://localhsot:8081，可以看到，请求是成功的（statuscode=200），请求也带上了cookie。但jasmine提示失败。我们看下浏览器控制台：提示信息很明确了：提示我们响应头需要设置Access-Control-Allow-Credentials为true。我们到CrossFilter设置一下：1resp.addHeader("Access-Control-Allow-Credentials", "true"); ok，加上以后再次请求就成功了。 注意：这里不能设置Access-Control-Allow-Origin为*，否则会报下面的错误：但是，我们不可能只有一个跨域的站，怎么处理？我们观察浏览器的请求，可以发现，如果是跨域请求，会有Origin请求头，我们后台根据这个请求头设置即可。12345String url = req.getHeader("Origin");if (!StringUtils.isEmpty(url)) &#123; resp.addHeader("Access-Control-Allow-Origin", url); resp.addHeader("Access-Control-Allow-Credentials", "true");&#125; 错误：Missing cookie ‘cookie1’ for method parameter of type String最后发现是jquery版本太低，这里使用了jquery1.11.3后ok了。 带自定义请求头的跨域访问在crossdomain-server增加一个请求方法：12345@GetMapping("/customHeader")public ResultBean getCustomHeader(@RequestHeader("X-My-Header") String myHeader) &#123; System.out.println("TestController.getCustomHeader().myHeader=" + myHeader); return new ResultBean("header:" + myHeader);&#125; 在crossdomain-client增加一个测试用例：123456789101112131415161718192021it("getCustomeHeader请求",function(done) &#123; var result; $.ajax(&#123; type:"get", url:base+"/customHeader", headers:&#123; 'X-My-Header':'justin' &#125;, success:function(json) &#123; result = json; expect(result).toEqual(&#123; "data": "header:justin" &#125;) // 校验完成，通知jasmine框架 done(); &#125; &#125;);&#125;); 测试发现报错了意思我们的Access-Control-Allow-Headers响应头没有包含这个自定义的请求头，所以我们在CrossFilter加上1resp.addHeader("Access-Control-Allow-Headers", "Content-Type,X-My-Header"); 再次请求，成功。 与Access-Control-Allow-Origin一样，我们也可以对Access-Control-Allow-Headers进行动态设置。我们观察customHeader的预检命令的请求头中有Access-Control-Request-Headers:x-my-header。1234String headers = req.getHeader("Access-Control-Request-Headers");if (!StringUtils.isEmpty(headers)) &#123; resp.addHeader("Access-Control-Allow-Headers", headers);&#125; 预检命令我们在crossdomain-server增加一个postJson方法：12345@PostMapping("/postJson")public ResultBean postJson(@RequestBody User user) &#123; System.out.println("TestController.postJson()"); return new ResultBean("hello," + user.getName());&#125; 在crossdomain-client增加一个测试用例：1234567891011121314151617181920it("postJson请求",function(done) &#123; var result; $.ajax(&#123; type:"post", url:base+"/postJson", contentType:"application/json;charset=utf-8", data:JSON.stringify(&#123;name:"justin"&#125;), success:function(json) &#123; result = json; expect(result).toEqual(&#123; "data": "hello,justin" &#125;) // 校验完成，通知jasmine框架 done(); &#125; &#125;);&#125;); 浏览器访问发现postJson失败了，如图：而且，我要请求的是一个post请求的/postJson请求，但实际浏览器是发出了一个OPTIONS请求，这个就是预检命令。 看下浏览器的控制台：意思是我们的响应头Access-Control-Allow-Headers中没有找到请求头Content-Type。 所以，我们修改一下代码，增加Content-Type。我们在crossdomain-server的CrossFilter中增加：1resp.addHeader("Access-Control-Allow-Headers", "Content-Type"); 这次请求成功了可以看到postJson实际发送了2个请求，第一个是OPTIONS，它返回200后，浏览器再次发送了我们要请求的。 简单请求：请求方法为GET，POST，HEAD。且请求header中无自定义请求头，且Content-type为下面几种：text/plain,multipart/form-data,application/x-www-form-urlencoded. 非简单请求：put,delete方法的Ajax请求发送json格式的Ajax请求带自定义请求头的Ajax请求比如一个post的json请求，实际浏览器先发出一个OPTIONS预检命令，然后才发送的POST请求。可以在Filter中增加请求头Access-Control-Max-Age:3600(数字秒）来缓存预检命令的结果，这样在指定的时间内浏览器不会再次发送预检命令。 3.服务器代理使用nginx解决跨域我们使用nginx帮我们对请求做了转发，将b.com的请求转发到http://localhost:8080，同时设置了相关的响应头。 1.修改本机hosts文件，将b.com映射到127.0.0.1；1127.0.0.1 b.com 2.在nginx.conf文件最后（最后一个}上面）增加：1include vhost/*.conf; 3.在nginx.conf同级目录增加vhost目录，并在下面创建b.com.conf文件。b.com.conf文件内容如下：123456789101112131415161718192021222324252627server&#123; # 监听80端口 listen 80; # 监控的域名 server_name b.com; # 拦截所有请求 location /&#123; # 将请求转发给http://localhost:8080/ proxy_pass http://localhost:8080/; # 允许访问所有的方法 add_header Access-Control-Allow-Methods *; # 设置预检命令的有效期 add_header Access-Control-Max-Age 3600; # 允许凭据 add_header Access-Control-Allow-Credentials true; # 使用$http_orgin获取请求头orgin的值 add_header Access-Control-Allow-Origin $http_origin; # 使用$http_access_control_request_headers获取请求头Access-Control-Request-Headers的值 add_header Access-Control-Allow-Headers $http_access_control_request_headers; # 如果是预检命令，直接返回200OK if ($request_method = OPTIONS)&#123; return 200; &#125; &#125;&#125; 4.crossdomain-server修改注释掉CrossFilter的使用代码。1234567// @Bean// public FilterRegistrationBean crossFilter() &#123;// FilterRegistrationBean bean = new FilterRegistrationBean();// bean.addUrlPatterns("/*");// bean.setFilter(new CrossFilter());// return bean;// &#125; 5.crossdomain-client修改将http://localhost:8080改成http://b.com12var base = "http://b.com/test";` 6.测试cmd切换到ningx所在目录，使用nginx -t先测试一下配置是否正确，没问题执行start nginx启动nginx服务。 所有请求都访问ok。 4.Spring框架解决方案在Controller上增加@CrossOrigin注解即可。 5.调用方解决跨域——隐藏跨域这里仍然借助nginx来实现。原理就是在调用方的页面请求使用相对路径，让浏览器认为跨域的请求（crossdomain-server）和调用发（crossdomain-client）是在同一个域（crossdomain-client的域）。而在nginx中，将跨域的请求转发给实际的被调用方（crossdomain-server）。 a.修改hosts，增加本机IP到a.com的映射；1127.0.0.1 a.com b.在nginx的conf目录新建vhost目录，并在该目录下新建文件a.com.conf，文件内容如下：12345678910111213141516server&#123; # 监听80端口 listen 80; # 监控a.com server_name a.com; # 将所有请求转发到http://localhost:8081/ location /&#123; proxy_pass http://localhost:8081/; &#125; # 将/crossdomain-server请求转发到http://localhost:8080/ location /crossdomain-server&#123; proxy_pass http://localhost:8080/; &#125;&#125; c.nginx.conf修改在文件最后（大括号上面）增加下面的配置：1include vhost/*.conf; 将vhost下面的所有.conf结尾的文件都加载进来。 d.crossdomain-server修改去掉TestController上的@CrossOrigin注解。 e.crossdomain-client修改将var base = &quot;http://localhost:8080/test&quot;;修改为var base = &quot;/crossdomain-server/test&quot;;。 测试：浏览器输入a.com，回车所有请求全部成功。 总结Ajax跨域的解决方法有很多，使用时要根据实际的情况选择合适的解决方法。 可以参考慕课网的课程https://www.imooc.com/video/16571讲的很详细。 代码：https://gitee.com/qincd/crossdomain-demo]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Metrics+Influxdb+Grafana监控系统并图表展示]]></title>
    <url>%2F2018%2F05%2F15%2Fuse-metrics-influxdb-grafana-monitor-system%2F</url>
    <content type="text"><![CDATA[Metrics即度量的意思，我们对系统做监控、统计等就需要用到Metrics。metrics地址：https://github.com/dropwizard/metrics。文档地址：https://metrics.dropwizard.io/4.0.0/。 本文使用的metrics-core和metrics-influxdb版本如下：metrics-core=4.0.0metrics-influxdb=0.8.0jdk版本1.8 使用metrics统计controller的访问数maven依赖添加metrics-core12345&lt;dependency&gt; &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt; &lt;artifactId&gt;metrics-core&lt;/artifactId&gt; &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt;&lt;/dependency&gt; 定义Metric配置12345678910111213141516171819202122@Configurationpublic class MetricsConfig &#123; @Bean public MetricRegistry metricRegistry() &#123; MetricRegistry registry = new MetricRegistry(); // 输出到控制台 ConsoleReporter reporter = ConsoleReporter.forRegistry(registry) .convertRatesTo(TimeUnit.SECONDS) .convertRatesTo(TimeUnit.SECONDS) .build(); reporter.start(5,TimeUnit.SECONDS); return registry; &#125; @Bean public Meter userControllerMeter(MetricRegistry registry) &#123; Meter meter = registry.meter("userControllerMeter"); return meter; &#125;&#125; 测试Controller：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Controller@RequestMapping(value = "/user")public class UserController &#123; @Autowired @Qualifier("userControllerMeter") private Meter userControllerMeter; /** * 存储用户信息的List。 */ private Map&lt;String,String&gt; userInfos = new HashMap&lt;String,String&gt;(5) &#123;&#123; put("test","测试用户"); put("root","root用户"); put("admin","管理员"); &#125;&#125;; @RequestMapping(value = "/get") public ModelAndView test(ModelAndView mv, @RequestParam String userid) &#123; userControllerMeter.mark(); String user = getUserById(userid); mv.setViewName("/test"); mv.addObject("user",user); return mv; &#125; /** * 模拟一个获取用户信息的操作。 * @param userid * @return */ private String getUserById(String userid) &#123; if (StringUtils.isEmpty(userid)) &#123; return null; &#125; // 这里模拟是一个耗时的操作，比如从其他系统获取用户信息。 long sleepTime = (long) (Math.random()*10*1000+1); try &#123; Thread.sleep(sleepTime); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return userInfos.get(userid); &#125;&#125; 在浏览器中输入http://localhost:8081/user/get?userid=test，并访问多次。控制台输出：可以看到，Meters统计了总的访问次数，当前的频率（每秒多少次），1分钟内、5分钟内、15分钟内的频率。 使用Metrics统计某个方法的调用时间这里我们统计调用UserController中1.MetricsConfig增加：12345@Beanpublic Timer getUserTime(MetricRegistry registry) &#123; Timer timer = registry.timer("getUserTimeTimer"); return timer;&#125; 2.UserController修改12345678@Autowired@Qualifier("getUserTime")private Timer getUserTime;// 统计调用getUserById耗费的时间Timer.Context context = getUserTime.time();String user = getUserById(userid);context.stop(); 在浏览器中输入http://localhost:8081/user/get?userid=test，并访问多次。控制台输出：可以看到，Timer统计了总的调用次数，当前的调用次数（每秒多少次）、1分钟、5分钟、15分钟，最小耗时，最大耗时，平均耗时，75%的调用耗时，95%,98%,99%的调用耗时。 Metrics数据的可视化这里以Influxdb和Grafana来构建一个实时的监控界面。处理流程如下：采集数据（Metrics）——&gt;存储数据（InfluxDB）——&gt;展示数据（Grafana）。 安装InfluxDB12wget http://dl.influxdata.com/influxdb/releases/influxdb-0.12.2-1.x86_64.rpmyum localinstall influxdb-0.12.2-1.x86_64.rpm 安装后启动服务：1service influxdb start 启动成功后，浏览器输入ip:8083访问。到设置中，可以看到http端口为8086，用户名和密码为空，这里我们设置用户名和密码都为root。 安装Grafana参考：https://blog.csdn.net/syshzbtt/article/details/71574204。12wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.2.0-1.x86_64.rpm sudo yum localinstall grafana-4.2.0-1.x86_64.rpm 安装后启动服务：1service grafana-server start 浏览器输入IP:3000访问，用户名和密码为admin。 将数据收集到Influxdb前面我们将数据直接输出到控制台，我们制定的Metrics Reporter为ConsoleReporter，这里写入Influxdb，需要引入一个依赖：12345&lt;dependency&gt; &lt;groupId&gt;com.github.davidb&lt;/groupId&gt; &lt;artifactId&gt;metrics-influxdb&lt;/artifactId&gt; &lt;version&gt;$&#123;metrics.influxdb.version&#125;&lt;/version&gt;&lt;/dependency&gt; MetricsConfig修改：我们将收集到的统计数据发送到InfluxDB123456789ScheduledReporter reporter = InfluxdbReporter.forRegistry(registry) // influxdb的ip,port，用户名,密码,数据库 .protocol(InfluxdbProtocols.http("192.168.200.99",8086,"root","root","my-influxdb")) .convertRatesTo(TimeUnit.SECONDS) .convertDurationsTo(TimeUnit.MILLISECONDS) .filter(MetricFilter.ALL) .skipIdleMetrics(false) .build();reporter.start(5,TimeUnit.SECONDS); 我们到InfluxDB的管理页面创建一个数据库点击Create Database，在Query中填入CREATE DATABASE &quot;my-influxdb&quot;然后回车，数据库就创建好了。 在Grafana的管理页面新建一个DataSource， 在Home页面，New一个dashboard点Graph点Panel Title点Edit点General可以修改标题在Metrics中，点SQL可以可视化编辑SQL。A From后面的default是默认数据源（在上面新建数据源时可以指定为默认数据源，或自己指定为你上面创建数据源名称），userControllerMeter是表名。在上面MetricsConfig中指定的名称，我们也可以在Influxdb中根据它来查询。如图：第二行field(value)即我们要监控的指标，这里对应的就是count字段，ALIAY BY即是字段的别名，图表中显示用。点空白处，如果图表还是没数据，将日期显示范围扩大。这样，就可以看到如下的图表 遇到的问题：1Caused by: java.lang.UnsupportedClassVersionError: com/justin/metrics/config/MetricsConfig : Unsupported major.minor version 52.0 (unable to load class com.justin.metrics.config.MetricsConfig)。 我的metrics-demo模块用的jdk7，引入的metrics-influxdb版本是0.8.2（mvn仓库最低就是这个版本），但0.8.2使用的jdk8编译的，所以有这个问题。但是，将metrics-demo模块的jdk改成1.8后，还是有这个问题。最后更改整个project的版本为1.8解决。 这里只是作为一个演示，这是偏运维的东西，但作为开发人员还是有必要了解一下。 参考：https://www.jianshu.com/p/e4f70ddbc287、https://www.jianshu.com/p/fadcf4d92b0e。 源代码：https://gitee.com/qincd/my-test-projects/下metrics-demo模块。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xshell评估过期或免费使用]]></title>
    <url>%2F2018%2F05%2F15%2Fxshell-expiration-of-assessment-or-free-use%2F</url>
    <content type="text"><![CDATA[xshell出现下面的评估过期的错误 解决办法：进入https://www.netsarang.com/download/free_license.html页面，点击“Download”，这个页面是Free License的。 然后填入下面的个人信息（邮箱要正确） 然后会给你发送一封邮件，进入邮件点击链接下载软件，进行安装。安装的即为Free for Home/School版本，就可以免费使用了。 默认现在的软件安装后是需要License的。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea修改背景色]]></title>
    <url>%2F2018%2F05%2F12%2Fidea-background-settings%2F</url>
    <content type="text"><![CDATA[首先，护眼的颜色RGB分别为199,237,204,16进制为#C7EDCC。 编辑器区域背景色的设置在Idea的settings-&gt;Editor-&gt;Colors&amp;Fonts-&gt;General中，将Default Text的背景色设置为上面的颜色。 控制台区域背景色设置在idea的settings-&gt;Editor-&gt;Color&amp;Fonts-&gt;Console Colors将Console background设置为上面的颜色。 左侧项目列表的背景色设置如果只进行上面的设置，会发现左侧项目列表背景色没变。我们需要通过设置windows窗口的背景色来实现。 这里以windows7为例，进入个性化，选择“窗口颜色”，选择“高级外观设置”，选择“窗口”，然后点“颜色”下拉框，点“其他颜色”，然后输入上面的RGB值，然后点“添加到自定义颜色”，最后确定即可。 idea还有一点设置，将主题设置为windows。 最后效果图：]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻量级的java HTTP Server——NanoHttpd]]></title>
    <url>%2F2018%2F05%2F11%2FNano-httpd-simple-usage%2F</url>
    <content type="text"><![CDATA[NanoHTTPD是一个免费、轻量级的(只有一个Java文件) HTTP服务器,可以很好地嵌入到Java程序中。支持 GET, POST, PUT, HEAD 和 DELETE 请求，支持文件上传，占用内存很小。github地址：https://github.com/NanoHttpd/nanohttpd。 maven依赖：12345&lt;dependency&gt; &lt;groupId&gt;org.nanohttpd&lt;/groupId&gt; &lt;!-- &lt;groupId&gt;com.nanohttpd&lt;/groupId&gt; for 2.1.0 and earlier --&gt; &lt;artifactId&gt;nanohttpd&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt;&lt;/dependency&gt; 官网demo：1234567891011121314151617181920212223242526272829303132333435363738 package com.example; import java.io.IOException;import java.util.Map;import fi.iki.elonen.NanoHTTPD;// NOTE: If you're using NanoHTTPD &gt;= 3.0.0 the namespace is different,// instead of the above import use the following:// import org.nanohttpd.NanoHTTPD;public class App extends NanoHTTPD &#123; public App() throws IOException &#123; super(8080); start(NanoHTTPD.SOCKET_READ_TIMEOUT, false); System.out.println("\nRunning! Point your browsers to http://localhost:8080/ \n"); &#125; public static void main(String[] args) &#123; try &#123; new App(); &#125; catch (IOException ioe) &#123; System.err.println("Couldn't start server:\n" + ioe); &#125; &#125; @Override public Response serve(IHTTPSession session) &#123; String msg = "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello server&lt;/h1&gt;\n"; Map&lt;String, String&gt; parms = session.getParms(); if (parms.get("username") == null) &#123; msg += "&lt;form action='?' method='get'&gt;\n &lt;p&gt;Your name: &lt;input type='text' name='username'&gt;&lt;/p&gt;\n" + "&lt;/form&gt;\n"; &#125; else &#123; msg += "&lt;p&gt;Hello, " + parms.get("username") + "!&lt;/p&gt;"; &#125; return newFixedLengthResponse(msg + "&lt;/body&gt;&lt;/html&gt;\n"); &#125;&#125; 运行App，浏览器打开http://localhost:8080/ 即可看到效果。 输入username，然后回车： 这样一个简单的登录功能就完成了。 问题：如果form中指定action为post，你会发现后台session获取不到参数。解决办法：12session.parseBody(new HashMap());params = session.getParms(); 意思也就是，对于post请求，你需要先调用parseBody()方法，直接传一个简单的新构造的map就行了，然后再调用getParams()方法。参考：https://blog.csdn.net/obguy/article/details/53841559。 示例代码：https://gitee.com/qincd/my-test-projects/tree/master/test1下的com.tommy.core.test.nanohttpd包下。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过java反射实现简易的springmvc]]></title>
    <url>%2F2018%2F05%2F10%2Fwrite-springmvc-by-java-reflect%2F</url>
    <content type="text"><![CDATA[通过java反射实现的简易的spring ioc和springmvc的一部分功能，很多东西没有考虑进去，只是提供一种思路。简易实现spring的ioc和springmvc. 思路：模仿SpringMVC定义如下几个注解。@Service:Service层注解；@Controller：Controller注解；@Autowired：自动注入依赖；@RequestMapping：定义请求的url映射。假定我们又UserController，定义如下：12345678910111213141516171819@Contorller("user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping("/add") public String add(User user) &#123; userService.insert(user); return "/user"; &#125; @RequestMapping(value = "/showUserList.htm") public ModelAndView showUserList(HttpServletRequest request,HttpServletResponse response) &#123; ModelAndView mv = new ModelAndView("/list"); List&lt;User&gt; users = userService.getAll(); mv.addObject("users",users); return mv; &#125;&#125; 我们在系统启动时，就根据配置的basePackage扫描该基础包下所有的@Service和@Controller的类。1.springioc部分，解决依赖注入问题定义HashMap&lt;String,Object&gt;维护类的全限定名与实例对象的关系，将所有注解了@Service和@Controller的类初始化。然后扫描所有注解的类，扫描所有的Field，如果是被@Autowired注解，则从上面的Map中取出实例对象进行设置。–》依赖注入 如果被@Autowired注解的是接口，则会遍历所有的@Service和@Controller的对象，找出其实现类，并注入。 2.springmvc部分，遍历所有上面的Map中的对象，如果是@Controller注解的类，则：a.读取@Controller的value，即得到上面示例URL中的/user部分。b.遍历所有的方法，如果是被@RequestMapping注解，则取出其value，即示例中的/add部分。 3.定义DispatcherServlet，作为所有请求的入口类通过request.getRequestURI()获取到请求的uri，比如/myspring-mvc/user/add。通过request.getContextPath()获取到上下文名称，将uri中项目上下文去掉，即得到/user/add。然后通过上面的springmvc部分的Map可以获取到Method，通过method.invoke方法调用Controller类的处理方法。可以参考Springmvc返回String或ModelAndView渲染页面。如果返回String，即视图名称，可以根据String是否包括forward或redirect关键字，像springmvc一样进行forward或redirect处理。数据则根据request进行设置即可。 本例测试： 错误的URL测试：http://localhost:8081/myspring-mvc/test/index2.htm url可以随意写，只要不是/test/index.htm和/test/showUserList.htm都可以。 不带数据的测试：http://localhost:8081/myspring-mvc/test/index.htm 带数据的测试：http://localhost:8081/myspring-mvc/test/showUserList.htm，效果： 这里只是简易版本的实现，还有很多因素没有考虑，仅仅是结合反射来实现一个简易版的springmvc功能。 源代码：https://gitee.com/qincd/my-test-projects下的myspring-mvc模块。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对视频播放url进行Blob加密]]></title>
    <url>%2F2018%2F05%2F05%2Fvideo-url-blob-encrypt%2F</url>
    <content type="text"><![CDATA[在知乎上看到一个视频，准备下载下来，结果下载不了，复制地址发现是blob://xxx。知乎帖子：https://www.zhihu.com/question/62753680/answer/382455062。 百度发现是对视频地址进行了blob加密，文章地址：https://blog.csdn.net/qq_36688143/article/details/79162013。 下面是使用Java Servlet+html5 video结合实现的一个对视频地址进行blob加密的示例。代码参考上文链接。后台Servlet:123456789101112131415161718192021222324252627282930313233343536373839404142434445public class MyBlobVideoServlet extends HttpServlet &#123; @Override protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; File file = new File("C:\\Users\\Administrator\\Desktop\\102_d41c7dd69f5eba69800d5c3401a3c384_1.mp4"); String fileName = file.getName(); String userAgent = req.getHeader("User-Agent").toLowerCase(); if (userAgent.indexOf("firefox") != -1) &#123; resp.addHeader("Content-Disposition", "attachment;filename=" + new String(fileName.getBytes("GB2312"), "ISO-8859-1")); &#125; else &#123; resp.addHeader("Content-Disposition", "attachment;filename=" + URLEncoder.encode(fileName, "UTF-8")); &#125; //设置response编码 resp.setCharacterEncoding("UTF-8"); resp.addHeader("Content-Length", "" + file.length()); //设置输出文件类型 resp.setContentType("video/mpeg4"); FileInputStream fis = null; OutputStream os = null; try &#123; //获取response输出流 os = resp.getOutputStream(); fis = new FileInputStream(file); byte[] buffer = new byte[1024]; int len; while ((len = fis.read(buffer)) != -1) &#123; // 输出文件 os.write(buffer,0,len); &#125; &#125; catch (Exception e) &#123; if (null != fis) &#123; fis.close(); &#125; if (null != os) &#123; os.flush(); os.close(); &#125; &#125; &#125;&#125; 页面：1234567891011121314151617181920212223242526272829&lt;html&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=gbk"&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;blob video demo&lt;/h2&gt;&lt;video id="sound" width="500" height="300" controls="controls"&gt;&lt;/video&gt;&lt;script type="text/javascript"&gt; //创建XMLHttpRequest对象 var xhr = new XMLHttpRequest(); //配置请求方式、请求地址以及是否同步 xhr.open('POST', '/play', true); //设置请求结果类型为blob xhr.responseType = 'blob'; //请求成功回调函数 xhr.onload = function (e) &#123; if (this.status == 200) &#123;//请求成功 //获取blob对象 var blob = this.response; //获取blob对象地址，并把值赋给容器 document.getElementById('sound').src=URL.createObjectURL(blob); &#125; &#125;; xhr.send();&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 效果展示： 代码：https://gitee.com/qincd/my-test-projects下blob-video模块。 不过，知乎的对视频做了切割。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Maven生成项目很慢的问题]]></title>
    <url>%2F2018%2F05%2F05%2Fmaven-generate-project-too-slow%2F</url>
    <content type="text"><![CDATA[如上图标红部分，加上archetypeCatalog=internal，不加这个参数，在maven生成骨架的时候将会非常慢，有时候会直接卡住。 来自网上的解释：archetypeCatalog表示插件使用的archetype元数据，不加这个参数时默认为remote，local，即中央仓库archetype元数据，由于中央仓库的archetype太多了，所以导致很慢，指定internal来表示仅使用内部元数据。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Jenkins配置+Maven的自动化构建]]></title>
    <url>%2F2018%2F05%2F04%2Fuse-jenkins-and-maven-automake-project%2F</url>
    <content type="text"><![CDATA[jenkins的搭建参考前一篇文章：Linux下安装和配置jenkins.本篇文章介绍如何通过jenkins+maven自动化构建Web应用。 git插件安装与配置如果git没有安装或配置不当，在新建任务时，会产生下面的问题。问题：1.jenkins Error performing command: git ls-remote -h解决：查看jenkins已经安装了git插件，但仍然提示这个错误。在Jenkins所在的服务器上发现git没有安装。使用git --version参考地址：https://blog.csdn.net/wangfei0904306/article/details/56011877 从另外一篇文章说需要使用源码的方式安装，地址：https://blog.csdn.net/u013256816/article/details/54743470好吧，那就来安装吧。1.从https://mirrors.edge.kernel.org/pub/software/scm/git/下载git最新版；2.参考上面链接的源码安装方式进行安装。这里贴一下：1234567891011121314151617181920安装依赖的包 yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker下载git源码并解压 目前最新版本下载地址：https://github.com/git/git/releases/tag/v2.11.0 解压 tar zxvf git-2.11.0.tar.gz cd git-2.11.0编译安装 make prefix=/usr/local/git all make prefix=/usr/local/git install配置环境变量 vim /etc/profile 加入export PATH=$PATH:/usr/local/git/bin 生效配置文件 source /etc/profile查看git whereis git git –version 最后使用git --version看到下面的图说明已经安装成功。 然后在jenkins的系统设置-&gt;全局工具配置界面，配置git的路径。Path to git executable填入： “whereis git”的地址 + “/bin/git” （如上面”whereis git”的地址为”/usr/local/git”，则应该填入 “/usr/local/git/bin/git”） 并保存参考这篇文章：https://blog.csdn.net/wangfei0904306/article/details/56011877 maven安装与配置参考：linux下maven安装参考https://www.cnblogs.com/jimisun/p/8054819.htmlmaven安装后记得在jenkins的系统配置-&gt;全局工具配置中配置maven的MAVEN_HOME。 JAVA_HOME的配置前一篇文章已经讲了，因为jenkins启动依赖Java，所以已经安装和配置了Java环境。还需要在jenkins的系统设置-&gt;全局工具配置-&gt;JDK配置JAVA_HOME。 新建一个任务配置git仓库地址配置Maven执行目标配置发布到容器这里我们将应用部署到tomcat，需要安装一个插件.在jenkins系统设置-&gt;插件管理-&gt;可选插件汇总搜索Deploy to container，找到插件并安装。 配置tomcat用户 tomcat配置找到tomcat–&gt;config–&gt;tomcat-users.xml打开后在&lt;tomcat-users&gt;&lt;/tomcat-users&gt;之间增加如下用户信息：123&lt;role rolename="manager-gui"&gt;&lt;/role&gt;&lt;role rolename="manager-script"&gt;&lt;/role&gt;&lt;user username="tomcat" password="admin" roles="manager-gui,manager-script"/&gt; 最后保存设置，执行构建即可。 jenkins每次构建时，都会自动从git上更新，然后打包，最后发布到tomcat中。这样开发环境提交的修改，执行一次构建测试环境就可以看到最新的内容，十分方便。 注意这里要部署的tomcat必须是启动的。因为Deploy to container插件实际是使用的tomcat的管理控制台来部署应用的。地址：http://vm1.com:8080/manager/html，输入我们上面配置tomcat用户的地方的用户名和密码进入。然后选择war包即可。 所以说，这里应用的tomcat必须是启动的。否则，构建时，会出现拒绝连接的错误。 参考：使用Jenkins配置+Maven的自动化构建]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下安装和配置jenkins]]></title>
    <url>%2F2018%2F05%2F04%2Flinux-jenkins-install-and-configuration%2F</url>
    <content type="text"><![CDATA[下载&amp;安装Jenkins 安装JDK 略。 添加Jenkins的源到yum，使用Jenkins的源下载安装包 12sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key 参考：https://pkg.jenkins.io/redhat-stable/ 安装Jenkins 1yum install jenkins 配置Jenkins端口 Jenkins默认端口是8080，可以在vi /etc/sysconfig/jenkins中修改。找到JENKINS_PORT=&quot;8080&quot;进行修改。 启动Jenkins 1service jenkins start ​ 停止：service jenkins stop ​ 重启：service jenkins restart ​ 6.Jenkins配置 在浏览器输入ip:8080，接口访问Jenkins。第一次需要输入初始密码。 初始密码在 /var/lib/jenkins/secrets/initialAdminPassword 。 然后选择安装推荐的 插件 然后就等待插件安装完毕。 ​ 然后就是创建管理员 问题 启动Jenkins报错：Starting Jenkins bash: /usr/bin/java: 没有那个文件或目录 解决办法有2种： a. 修改配置jenkins文件 ，指定本机JDK的位置。vim /etc/init.d/jenkins 然后执行systemctl daemon-reload使配置生效。 b. 建立软连接 1ln -s /data/soft/jdk1.8.0_144/bin/java /usr/bin/java]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下JDK的安装和配置]]></title>
    <url>%2F2018%2F05%2F04%2Flinux-jdk-install-and-configuration%2F</url>
    <content type="text"><![CDATA[1.从官网下载jdk安装包，下载完成后放入Linux指定的目录。 这里使用的rz命令上传，如果没有安装rz，可以使用yum install lrzsz进行安装。 这里安装的jdk版本是jdk-7u55 2.解压到指定的目录这里将jdk解压在/usr/java。1tar zxvf /data/jdk-7u55-linux-x64.gz -C /usr/java 3.配置java环境变量vi /etc/profile打开文件，shift+g进入文件尾部。添加如下java环境变量配置1234export JAVA_HOME=/usr/java/jdk1.7.0_55export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport classpath=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;PATH&#125; 然后:wq保存，最后使用source /etc/profile使配置生效。 4.测试输入java -verison，出现如下文字即说明配置成功。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java IDE的实现原理]]></title>
    <url>%2F2018%2F05%2F02%2Fjava-ide-impletation-principle%2F</url>
    <content type="text"><![CDATA[像Eclipse等java IDE是怎么编译和查找java源代码的呢？ 源代码保存这个无需多说，在编译器写入代码，并保存到文件。这个利用流来实现。 编译为class文件java提供了JavaCompiler，我们可以通过它来编译java源文件为class文件。 查找class可以通过Class.forName(fullClassPath)或自定义类加载器来实现。 生成对象，并调用对象方法通过上面一个查找class，得到Class对象后，可以通过newInstance()或构造器的newInstance()得到对象。然后得到Method，最后调用方法，传入相关参数即可。 示例代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class MyIDE &#123; public static void main(String[] args) throws IOException, ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123; // 定义java代码，并保存到文件（Test.java） StringBuilder sb = new StringBuilder(); sb.append("package com.tommy.core.test.reflect;\n"); sb.append("public class Test &#123;\n"); sb.append(" private String name;\n"); sb.append(" public Test(String name)&#123;\n"); sb.append(" this.name = name;\n"); sb.append(" System.out.println(\"hello,my name is \" + name);\n"); sb.append(" &#125;\n"); sb.append(" public String sayHello(String name) &#123;\n"); sb.append(" return \"hello,\" + name;\n"); sb.append(" &#125;\n"); sb.append("&#125;\n"); System.out.println(sb.toString()); String baseOutputDir = "F:\\output\\classes\\"; String baseDir = baseOutputDir + "com\\tommy\\core\\test\\reflect\\"; String targetJavaOutputPath = baseDir + "Test.java"; // 保存为java文件 FileWriter fileWriter = new FileWriter(targetJavaOutputPath); fileWriter.write(sb.toString()); fileWriter.flush(); fileWriter.close(); // 编译为class文件 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager manager = compiler.getStandardFileManager(null,null,null); List&lt;File&gt; files = new ArrayList&lt;&gt;(); files.add(new File(targetJavaOutputPath)); Iterable compilationUnits = manager.getJavaFileObjectsFromFiles(files); // 编译 // 设置编译选项，配置class文件输出路径 Iterable&lt;String&gt; options = Arrays.asList("-d",baseOutputDir); JavaCompiler.CompilationTask task = compiler.getTask(null, manager, null, options, null, compilationUnits); // 执行编译任务 task.call(); // 通过反射得到对象// Class clazz = Class.forName("com.tommy.core.test.reflect.Test"); // 使用自定义的类加载器加载class Class clazz = new MyClassLoader(baseOutputDir).loadClass("com.tommy.core.test.reflect.Test"); // 得到构造器 Constructor constructor = clazz.getConstructor(String.class); // 通过构造器new一个对象 Object test = constructor.newInstance("jack.tsing"); // 得到sayHello方法 Method method = clazz.getMethod("sayHello", String.class); // 调用sayHello方法 String result = (String) method.invoke(test, "jack.ma"); System.out.println(result); &#125;&#125; 自定义类加载器代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class MyClassLoader extends ClassLoader &#123; private String baseDir; public MyClassLoader(String baseDir) &#123; this.baseDir = baseDir; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; String fullClassFilePath = this.baseDir + name.replace("\\.","/") + ".class"; File classFilePath = new File(fullClassFilePath); if (classFilePath.exists()) &#123; FileInputStream fileInputStream = null; ByteArrayOutputStream byteArrayOutputStream = null; try &#123; fileInputStream = new FileInputStream(classFilePath); byte[] data = new byte[1024]; int len = -1; byteArrayOutputStream = new ByteArrayOutputStream(); while ((len = fileInputStream.read(data)) != -1) &#123; byteArrayOutputStream.write(data,0,len); &#125; return defineClass(name,byteArrayOutputStream.toByteArray(),0,byteArrayOutputStream.size()); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != fileInputStream) &#123; try &#123; fileInputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (null != byteArrayOutputStream) &#123; try &#123; byteArrayOutputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; return super.findClass(name); &#125;&#125; java源文件和编译后的class文件如下： 关于类的加载器可以参考：http://tommy88.top/2018/04/11/java-classloader/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springmvc集成velocity]]></title>
    <url>%2F2018%2F04%2F28%2Fspringmvc-and-velocity-integration%2F</url>
    <content type="text"><![CDATA[velocity是一个基于java的模板引擎，通过特定的语法，可以获取到在java中定义的对象，从而实现页面与java代码的分离。由于JSP需要先转换为Servlet，然后编译为class执行，导致效率较低。在访问量较大时表现较差，velocity则可以作为JSP的替代。 velocity的介绍、语法等可以参考：https://www.jianshu.com/p/5913903324ff。这里是一个springmvc集成velocity的显示用户列表和修改用户信息的例子，备忘。 maven依赖添加velocity的相关依赖。（注：spring相关的依赖未给出）12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity&lt;/artifactId&gt; &lt;version&gt;1.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-tools&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt;&lt;/dependency&gt; 注意：必须引入spring-context-support依赖，否则velocityConfig配置中configLocation和resourceLoaderPath属性找不到。 springmvc配置123456789101112131415161718192021222324252627&lt;!-- 自动扫描controller包下的所有类，如果@Controller注入为bean --&gt;&lt;context:component-scan base-package="com.tommy.velocity.controller"/&gt;&lt;!-- 注解驱动 --&gt;&lt;mvc:annotation-driven /&gt;&lt;!-- velocity环境配置 --&gt;&lt;bean id="velocityConfig" class="org.springframework.web.servlet.view.velocity.VelocityConfigurer"&gt; &lt;!-- velocity配置文件路径 或者直接用velocityProperties属性 --&gt; &lt;property name="configLocation" value="classpath:velocity.properties"/&gt; &lt;!-- velocity模板路径 --&gt; &lt;property name="resourceLoaderPath" value="/WEB-INF/view/"/&gt;&lt;/bean&gt;&lt;!-- velocity视图解析器 --&gt;&lt;bean id="velocityViewResolver" class="org.springframework.web.servlet.view.velocity.VelocityLayoutViewResolver"&gt; &lt;property name="order" value="0"/&gt; &lt;property name="contentType" value="text/html;charset=UTF-8"/&gt; &lt;property name="cache" value="true"/&gt; &lt;property name="suffix" value=".vm"/&gt; &lt;property name="layoutUrl" value="layout/layout.vm"/&gt; &lt;property name="exposeSpringMacroHelpers" value="true"/&gt; &lt;!--是否使用spring对宏定义的支持--&gt; &lt;property name="exposeSessionAttributes" value="true"/&gt; &lt;!--是否开放request属性--&gt; &lt;property name="requestContextAttribute" value="request"/&gt; &lt;!--request属性引用名称--&gt; &lt;property name="dateToolAttribute" value="dateTool"/&gt; &lt;property name="numberToolAttribute" value="numberTool"/&gt;&lt;/bean&gt; velocity.properties：12345678910#设置字符集#encodinginput.encoding=UTF-8output.encoding=UTF-8contentType=text/html;charset=UTF-8#autoreload when vm changedfile.resource.loader.cache=falsefile.resource.loader.modificationCheckInterval =1velocimacro.library.autoreload=false web.xml配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!-- 防止spring内存溢出监听器 --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.IntrospectorCleanupListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt; org.springframework.web.filter.CharacterEncodingFilter &lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;servlet&gt; &lt;servlet-name&gt;rest&lt;/servlet-name&gt; &lt;description&gt;spring mvc servlet&lt;/description&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; /WEB-INF/spring-mvc.xml &lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;rest&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 注意配置Spring的字符集过滤器，否则向后台提交数据时中文乱码。 模板文件布局模板：12345678910111213&lt;html&gt;&lt;head&gt; &lt;title&gt;$!page_title&lt;/title&gt; #parse("default/header.vm")&lt;/head&gt;&lt;body&gt;&lt;div&gt; $screen_content&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; header.vm:123456&lt;meta http-equiv="Content-Type" content="text/html;charset=UTF-8"&gt;&lt;meta http-equiv="Cache-Control" content="no-store"/&gt;&lt;meta http-equiv="Pragma" content="no-cache"/&gt;&lt;meta http-equiv="Expires" content="3600"/&gt;&lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt;&lt;meta content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" name="viewport"&gt; 展示用户列表的模板：12345678910111213141516171819202122232425&lt;html&gt;&lt;head&gt; &lt;title&gt;Spring MVC and Velocity&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Spring MVC and Velocity&lt;/h1&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;id&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;age&lt;/td&gt; &lt;td&gt;操作&lt;/td&gt; &lt;/tr&gt; #foreach($user in $users) &lt;tr&gt; &lt;td&gt;$!&#123;user.id&#125;&lt;/td&gt; &lt;td&gt;$!&#123;user.name&#125;&lt;/td&gt; &lt;td&gt;$!&#123;user.age&#125;&lt;/td&gt; &lt;td&gt;&lt;a href="/preEdit?userId=$&#123;user.id&#125;"&gt;修改&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; #end &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 修改的模板：123456789101112131415&lt;html&gt;&lt;head&gt; &lt;title&gt;Spring MVC and Velocity&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Spring MVC and Velocity&lt;/h1&gt;&lt;form action="/edit" method="post"&gt; &lt;input type="hidden" name="id" value="$&#123;user.id&#125;" /&gt; 姓名：&lt;input type="text" name="name" value="$!&#123;user.name&#125;" /&gt;&lt;br&gt; 年龄：&lt;input type="text" name="age" value="$!&#123;user.age&#125;" /&gt; &lt;input type="submit" value="提交" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; controller12345678910111213141516171819202122232425262728293031323334353637@Controllerpublic class HelloController &#123; private final static Map&lt;Integer,User&gt; users = new HashMap&lt;&gt;(8); static &#123; initData(); &#125; @RequestMapping(value = "/list") public String showList(ModelMap map) &#123; map.put("users",users); return "/list"; &#125; @RequestMapping(value = "/preEdit") public String preEdit(ModelMap map, Integer userId) &#123; User user = users.get(userId); map.put("user",user); return "/edit"; &#125; @RequestMapping(value = "/edit") public String edit(ModelMap map, User user) &#123; users.put(user.getId(),user); return showList(map); &#125; private static void initData() &#123; for (int i=0;i&lt;8;i++) &#123; User user = new User(); user.setId(i); user.setName("测试用户" + i); user.setAge((int) (Math.random()*100+10)); users.put(i, user); &#125; &#125;&#125; User:1234567891011121314151617181920212223242526272829public class User &#123; private int id; private String name; private int age; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 演示：列表页面修改一个用户名称再次回到列表页面 本文示例代码：https://gitee.com/qincd/my-test-projects下的spring-velocity模块。 本文参考：springmvc集成 velocity,实现多视图整合(jsp,velocity)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java关键字volatile解析]]></title>
    <url>%2F2018%2F04%2F26%2Fjava%E5%85%B3%E9%94%AE%E5%AD%97volatile%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[volatile是一个轻量级的锁（synchronized），如果一个变量使用volatile，则它比使用synchronized的成本更低，因为它不会引起线上上下文的切换和调度。 一个变量如果用volatile修饰了，则Java可以确保所有线程看到这个变量的值是一致的，如果某个线程对volatile修饰的共享变量进行更新，那么其他线程可以立马看到这个更新，这就是所谓的线程可见性。 注意：volatile不保证操作的原子性，但synchronized则可以保证。 volatile相对于synchronized稍微轻量些，在某些场合它可以替代synchronized，但是又不能完全取代synchronized，只有在某些场合才能够使用volatile。使用它必须满足如下两个条件：1.对变量的写操作不依赖当前值；2.该变量没有包含在具有其他变量的不变式中。volatile经常用于两个两个场景：状态量标记、double check double check示例：1234567891011121314151617public class Singleton &#123; private static volatile Singleton singleton = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 当然单例模式延迟初始化还可使用其他的方式，比如枚举、静态内部类。可以参考这篇文章：https://blog.csdn.net/goodlixueyong/article/details/51935526。 注意：使用volatile做双重检查只有在jdk1.5或之后的版本正常，之前的版本由于JMM（java内存模型）仍然是有问题的。 参考：死磕Java并发：深入分析volatile的实现原理、Java volatile关键字解惑]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决hexo代码多行空白的问题]]></title>
    <url>%2F2018%2F04%2F25%2Fhexo-resolve-multiline-blank%2F</url>
    <content type="text"><![CDATA[最近更换了hexo主题后，生成的文章代码最后面显示了多个空白行，而前面代码中原本的空白行则被移除了，看起来比较别扭。 解决办法：1.找到hexo-util/lib/highlight.js文件一般的路径为${blog_path}/node_modules/hexo-util/lib/highlight.js2.修改highlight.js文件中的代码大概在35~38行修改前：1234numbers += '&lt;div class="line"&gt;' + (firstLine + i) + '&lt;/div&gt;';content += '&lt;div class="line';content += (mark.indexOf(firstLine + i) !== -1) ? ' marked' : '';content += '"&gt;' + line + '&lt;/div&gt;'; 修改后：1234numbers += '&lt;span class="line"&gt;' + (firstLine + i) + '&lt;/span&gt;\n';content += '&lt;span class="line';content += (mark.indexOf(firstLine + i) !== -1) ? ' marked' : '';content += '"&gt;' + line + '&lt;/span&gt;\n'; 参考文章：https://blog.csdn.net/u014717036/article/details/79372461 另外一个问题，就是生成的代码前面的部分空白，如图：解决办法：这个跟具体使用的主题有关，比如BlueLake主题。在highlight.styl文件中找到padding: 0.3em 15px 0.3em 1em，去掉即可。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web安全通信之JWT简介]]></title>
    <url>%2F2018%2F04%2F25%2Fweb-security-commnication-with-jwt%2F</url>
    <content type="text"><![CDATA[jwt简介JWT是JSON Web Token的简称，它是一个非常轻巧的规范。这个规范允许我们使用JWT在用户和服务器之间传递安全可靠的信息。和Cookie-Session的模式不同，JWT使用Token替换了SessionID的资源访问和状态保持。 jwt的组成1.Header: 标题包含了令牌的元数据，并且在最小包含签名和/或加密算法的类型2.Claims: Claims包含您想要签署的任何信息3.JSON Web Signature (JWS): 在header中指定的使用该算法的数字签名和声明 jwt的认证过程1.用户登录系统；2.服务端验证，将认证信息通过指定的算法（例如HS256）进行加密，例如对用户名和用户所属角色进行加密，加密私钥是保存在服务器端的，将加密后的结果发送给客户端，加密的字符串格式为三个”.” 分隔的字符串 Token，分别对应头部、载荷与签名，头部和载荷都可以通过 base64 解码出来，签名部分不可以；3.客户端拿到返回的 Token，存储到 local storage 或本地数据库；4.下次客户端再次发起请求，将 Token 附加到 header 中；5.服务端获取header中的Token，通过相同的算法对Token中的用户名和所属角色进行相同的加密验证，如果验证结果相同，则说明这个请求是正常的，没有被篡改。这个过程可以完全不涉及到查询 Redis 或其他存储； jjwtJJWT是一个提供端到端的JWT创建和验证的Java库。JJWT的目标是最容易使用和理解用于在JVM上创建和验证JSON Web令牌(JWTs)的库。JJWT是基于JWT、JWS、JWE、JWK和JWA RFC规范的Java实现。 jjwt安装在pom.xml中配置jjwt的依赖即可：12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt;&lt;/dependency&gt; 创建签名秘钥12Key key = MacProvider.generateKey(); String compactJws = Jwts.builder().setSubject("Joe").signWith(SignatureAlgorithm.HS512, key).compact(); 验证JWT1assert Jwts.parser().setSigningKey(key).parseClaimsJws(compactJws).getBody().getSubject().equals("Joe"); 示例下面通过一个示例代码来说明如何使用。示例程序基于springboot。本例代码在：https://gitee.com/qincd/my-test-projects下的jwt-demo模块。 jwt的操作工具类：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class TokenMgr &#123; public static SecretKey generalKey() throws Base64DecodingException &#123; byte[] encodedKey = Base64.decode(Constant.JWT_SECERT); SecretKey key = new SecretKeySpec(encodedKey, 0, encodedKey.length, "AES"); return key; &#125; /** * 签发JWT * @param id * @param subject * @param ttlMillis * @return * @throws Exception */ public static String createJWT(String id, String subject, long ttlMillis) throws Base64DecodingException &#123; SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256; long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); SecretKey secretKey = generalKey(); JwtBuilder builder = Jwts.builder() .setId(id) .setSubject(subject) .setIssuedAt(now) .signWith(signatureAlgorithm, secretKey); if (ttlMillis &gt;= 0) &#123; long expMillis = nowMillis + ttlMillis; Date expDate = new Date(expMillis); builder.setExpiration(expDate); &#125; return builder.compact(); &#125; /** * 验证JWT * @param jwtStr * @return */ public static CheckResult validateJWT(String jwtStr) &#123; CheckResult checkResult = new CheckResult(); Claims claims = null; try &#123; claims = parseJWT(jwtStr); checkResult.setSuccess(true); checkResult.setClaims(claims); &#125; catch (ExpiredJwtException e) &#123; checkResult.setErrCode(Constant.JWT_ERRCODE_EXPIRE); checkResult.setSuccess(false); &#125; catch (SignatureException e) &#123; checkResult.setErrCode(Constant.JWT_ERRCODE_FAIL); checkResult.setSuccess(false); &#125; catch (Exception e) &#123; checkResult.setErrCode(Constant.JWT_ERRCODE_FAIL); checkResult.setSuccess(false); &#125; return checkResult; &#125; /** * * 解析JWT字符串 * @param jwt * @return * @throws Exception */ public static Claims parseJWT(String jwt) throws Exception &#123; SecretKey secretKey = generalKey(); return Jwts.parser() .setSigningKey(secretKey) .parseClaimsJws(jwt) .getBody(); &#125;&#125; jwt校验实体类：1234567891011121314151617181920212223242526272829public class CheckResult &#123; private boolean success; private Claims claims; private String errCode; public boolean isSuccess() &#123; return success; &#125; public void setSuccess(boolean success) &#123; this.success = success; &#125; public Claims getClaims() &#123; return claims; &#125; public void setClaims(Claims claims) &#123; this.claims = claims; &#125; public String getErrCode() &#123; return errCode; &#125; public void setErrCode(String errCode) &#123; this.errCode = errCode; &#125;&#125; 常量类：12345public class Constant &#123; public static final String JWT_SECERT = "security"; public static final String JWT_ERRCODE_EXPIRE = "expire"; public static final String JWT_ERRCODE_FAIL = "fail";&#125; JwtFilter：用于拦截/api/*请求123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class JwtFilter extends GenericFilter &#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; // jwt验证 HttpServletRequest request = (HttpServletRequest) servletRequest; // 1.从Cookie获取jwt String token = getTokenFromCookie(request); if (StringUtils.isEmpty(token)) &#123; // 2.从headers中获取 token = request.getHeader("Authorization"); &#125; if (StringUtils.isEmpty(token)) &#123; // 3.从请求参数获取 token = request.getParameter("token"); &#125; if (StringUtils.isEmpty(token)) &#123; throw new ServletException("Missing or invalid token."); &#125; CheckResult checkResult = TokenMgr.validateJWT(token); if (checkResult.isSuccess()) &#123; request.setAttribute("claims",checkResult.getClaims()); filterChain.doFilter(servletRequest,servletResponse); &#125; else &#123; if (checkResult.getErrCode().equals(Constant.JWT_ERRCODE_EXPIRE)) &#123; servletResponse.setCharacterEncoding("utf-8"); PrintWriter printWriter = servletResponse.getWriter(); printWriter.write("token过期，请重新登录"); printWriter.flush(); printWriter.close(); &#125; else if (checkResult.getErrCode().equals(Constant.JWT_ERRCODE_FAIL)) &#123; PrintWriter printWriter = servletResponse.getWriter(); servletResponse.setCharacterEncoding("utf-8"); printWriter.write("token验证失败！"); printWriter.flush(); printWriter.close(); &#125; &#125; &#125; private String getTokenFromCookie(HttpServletRequest request) &#123; String token = null; Cookie[] cookies = request.getCookies(); int len = null == cookies ? 0:cookies.length; if (len &gt; 0) &#123; for (int i=0;i&lt;cookies.length;i++) &#123; Cookie cookie = cookies[i]; if (cookie.getName().equals("token")) &#123; token = cookie.getValue(); break; &#125; &#125; &#125; return token; &#125; @Override public void destroy() &#123; &#125;&#125; LoginController:1234567891011121314151617181920212223242526272829303132@Controllerpublic class LoginController &#123; @RequestMapping(value = "/login",method = RequestMethod.GET) public String toLogin() &#123; return "/login"; &#125; @RequestMapping(value = "/login",method = RequestMethod.POST) @ResponseBody public Map&lt;String,String&gt; login(String username,String password,HttpServletResponse response) &#123; Map&lt;String,String&gt; result = new HashMap&lt;String, String&gt;(2); if (username.equals("admin") &amp;&amp; password.equals("123456")) &#123; String id= UUID.randomUUID().toString(); String subject = "&#123;role:1,permission:[1,2,3]&#125;"; try &#123; String token = TokenMgr.createJWT(id,subject,5*60*1000L); result.put("token",token); result.put("code","0"); &#125; catch (Base64DecodingException e) &#123; result.put("code","1"); result.put("msg", "内部错误！"); &#125; &#125; else &#123; result.put("code","1"); result.put("msg","用户名或密码错误！"); &#125; return result; &#125;&#125; ApiController:1234567891011121314@Controller@RequestMapping("/api")public class ApiController &#123; @RequestMapping(value = "/test",method = RequestMethod.GET) @ResponseBody public Map&lt;String,Object&gt; test() &#123; Map&lt;String,Object&gt; map = new HashMap&lt;String, Object&gt;(4); map.put("id",10000L); map.put("name","张三"); map.put("age",99); return map; &#125;&#125; SpringBoot应用启动类：1234567891011121314151617181920212223@SpringBootApplicationpublic class WebApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(WebApplication.class); &#125; //过滤器 @Bean public FilterRegistrationBean jwtFilter() &#123; final FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new JwtFilter()); registrationBean.addUrlPatterns("/api/*"); return registrationBean; &#125; public static void main( String[] args ) &#123; SpringApplication.run(WebApplication.class, args); &#125;&#125; 增加对jwtFilter的配置。 login.jsp:123456789101112131415161718192021222324252627282930313233343536373839&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;c:set var="ctx" value="$&#123;pageContext.request.contextPath&#125;"/&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;用户登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="loginDiv"&gt; 用户名：&lt;input type="text" name="username"&gt;&lt;br&gt; 密码：&lt;input type="password" name="password"&gt;&lt;br&gt; &lt;input type="button" value="登录" onclick="login();"&gt; &lt;/div&gt;&lt;script type="text/javascript" src="$&#123;ctx&#125;/js/jquery.js"&gt;&lt;/script&gt;&lt;script&gt; function login() &#123; var t = &#123; username:$('input[name=username]').val(), password:$('input[name=password]').val() &#125;; if (t.username == '' || t.password== '') &#123; alert('参数不全'); return; &#125; $.post('$&#123;ctx&#125;/login',t, function(r) &#123; if (r.code == 0) &#123; location.replace('$&#123;ctx&#125;/api/test?token='+ r.token); &#125; else &#123; alert(r.msg); &#125; &#125;); &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 测试：进入登录页面登录这里用户名和秘密为admin和123456 输入后，点登录按钮，会进入到/api/test页面。上面示例代码中token的有效期为5分钟，在5分钟内，可以在任何其他机器或浏览器输入登录后的地址，可以拿到返回结果。 如果超过5分钟再访问则会提示token过期。 示例工程参考：Web安全通讯之JWT的Java实现、JWT 进阶 – JJWT、JWT的Java使用 (JJWT)、你的JWTs存储在哪里、JWT（JSON WEB TOKEN）框架 JJWT 教程、jjwt的github地址]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java是值传递还是引用传递？]]></title>
    <url>%2F2018%2F04%2F21%2Fjava-pass-by-value-or-reference%2F</url>
    <content type="text"><![CDATA[在Java中一切皆对象，无论是int a;还是String a;，这两个变量a都是对象。在传递的时候究竟是按什么方式传递的呢？其答案就是：即是按值传递也是按引用传递，但通常基本数据类型（如int,double等）我们认为其是“值传递”，而自定义数据类型（class）我们认为其是“引用传递”。 简单类型1234567891011public static void swap(int a,int b) &#123; int c = a; a = b; b = c;&#125;// 调用int a=10;int b=20;swap(a, b);System.out.println(a);System.out.println(b); 输出结果：121020 可以看到，swap()方法并没有改变传入的参数的值。即说明参数是简单类型时是按值传递的。 用Integer测试一下1234567891011public static void swap2(Integer a,Integer b) &#123; Integer c = a; a = b; b = c;&#125;// 调用Integer a=10;Integer b=20;swap2(a, b);System.out.println(a);System.out.println(b); 输出：121020 可以看到参数是简单类型或是它的包装类型，都不会改变参数的值。 包括String。 1234567public static void change(String str) &#123; str = "world";&#125;// 调用String string = "hello";change(string);System.out.println(string); // hello 输出：1hello 通过上面的例子可以知道，在java中，简单类型（包括String）可以认为是按值传递的。 引用类型1234567891011static class T &#123; private int id;&#125;public static void change(T t) &#123; t.id = 20;&#125;//调用T t = new T();t.id=10;change(t);System.out.println(t.id); // 20 输出：120 可以看到t.id的值被改变了，说明是按引用传递的。 详细内容可以参考：深入理解Java引用类型]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java的4种引用类型——强引用、软引用、弱引用、虚引用]]></title>
    <url>%2F2018%2F04%2F21%2Fjava-four-kind-of-reference%2F</url>
    <content type="text"><![CDATA[在java中提供了4个级别的引用：强引用、软引用、弱引用、虚引用。只有强引用（FinalReference）类是包类可见，其他都是public，可以在应用程序中直接使用。 软引用适用于实现内存敏感的缓存，弱引用适用于实现无法防止其键（或值）被回收的规范化映射，而虚引用则适用于以某种比 Java 终结机制更灵活的方式调度 pre-mortem 清除操作。 参考：Java中的四种引用类型 Strong, Soft, Weak And Phantom]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用NIO提升性能]]></title>
    <url>%2F2018%2F04%2F19%2Fuse-nio-to-improve-performance%2F</url>
    <content type="text"><![CDATA[Buffer简介在JDK1.4之前，我们进行文件/流的读写都是通过java.io包的相关类来进行操作，虽然操作简便，但是性能较差。在JDK1.4引入了java.nio包，提供了相关的通道（Channel）和缓冲（Buffer）来操作，极大的提升了读写性能。 通道是双向的，既可用于读也可用于写数据。它从缓冲读取或写入数据到缓冲区。 基本每个java的基本类型都有一个对应的Buffer，比如byte的ByteBuffer；int的IntBuffer等等，但ByteBuffer是最常用的，是大多数标准I/O操作的接口。 Buffer有3个重要的参数：位置(position)、容量(capacity)、上限(limit)。 位置(position)a.在写模式下，标识当前缓冲区的位置，将从position的下个位置开始写数据；b.在读模式下，标识当前缓冲区读取的位置，将从此位置之后读取数据。 容量(capacity)缓冲区的容量上限 上限(limit)a.在写模式下，标识缓冲区的实际上限，它小于或等于容量(capacity)。通常情况下和容量(capacity)相等。b.在读模式下，代表可以读取的总容量，和上次写入的数据量相等。 Buffer的创建Buffer的创建有2种方式：1.从堆中创建1ByteBuffer buffer = ByteBuffer.allocate(1024); 2.从已有的数组创建12byte[] data = new byte[1024];ByteBuffer buffer = ByteBuffer.wrap(data); 重置和清空缓冲区 rewind()position置为0，mark清除，limit无修改。作用：为读取Buffer中有效数据做准备。 clear()position置为0，mark清除，limit设置为capacity。作用：为重新写入Buffer做准备。 flip()position置为0，mark清除，limit设置为position。作用：读写切换时使用 读写缓冲区常用的操作有： public byte get()返回当前position上的数据，并将position向下移动一位。 public ByteBuffer get(byte[] dst)从缓冲区读取数据到dst数组，并恰当的移动position到合适的位置。 public byte get(int index)读取指定Index上的数据，不会改变position的位置。 public ByteBuffer put(byte b)在当前位置写入给定的数据，并将position向后移动一位。 public ByteBuffer put(int index,byte b)将数据写入缓冲区的index位置。position没有改变。 public ByteBuffer put(byte[] src)将给定的数组写入当前Buffer。并恰当的移动position到合适的位置。 ByteBuffer提供了非常多的方法，这里只是列举了几个常用的方法。 标志缓冲区标志(mark)有点像书签，在需要标记的地方mark一下，后续任何时候都可以回到mark的地方。 Buffer提供了了下面2个方法： mark()用于记录当前的位置。 1234public final Buffer mark() &#123; mark = position; return this;&#125; reset()用于恢复到mark的位置，即将position设置为mark。 1234567public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; 示例：123456789101112131415161718ByteBuffer buffer = ByteBuffer.allocate(1024);for (int i=0;i&lt;10;i++) &#123; buffer.put((byte)i);&#125;buffer.flip(); // 重置position,为读取数据做准备for (int i=0;i&lt;buffer.limit();i++) &#123; System.out.print(buffer.get()); if (i == 4) &#123; // 在第5个字节的位置做标记 buffer.mark(); System.out.print("(mark at " + i + ")"); &#125;&#125;buffer.reset(); // 回到标记的地方System.out.println();System.out.println("reset to mark.");for (int i=buffer.position();i&lt;buffer.limit();i++) &#123; System.out.print(buffer.get());&#125; 输出结果：12301234(mark at 4)56789reset to mark.56789 上面的代码中，我们先向下缓冲区写入了10个数字（0到9）。然后循环从缓冲区读取并输出，并在第5个位置做了标记。最后重新回到标记的地方，获取缓冲区剩余的数据输出。 复制缓冲区复制缓冲区是以原缓冲区为基础，生成一个新的缓冲区。新生成的缓冲区与原缓冲区共享内存，对任意一方的数据改动都是相互可见的，但是2者又各自维护自己的position、limit、mark。这大大增加了程序的灵活性，为同时处理数据提供了可能。 复制缓冲区的方法如下：1public ByteBuffer duplicate(); 示例代码：123456789101112131415161718ByteBuffer buffer = ByteBuffer.allocate(1024);for (int i=0;i&lt;10;i++) &#123; buffer.put((byte)i);&#125;ByteBuffer buf = buffer.duplicate();System.out.println("After buffer.duplicate");System.out.println(buffer);System.out.println(buf);buf.flip();System.out.println("After buf.flip()");System.out.println(buffer);System.out.println(buf);buf.put((byte)100);System.out.println("After buf.put((byte)100)");System.out.println(buffer);System.out.println(buf);System.out.println("buffer.get(0)=" + buffer.get(0));System.out.println("buf.get(0)=" + buf.get(0)); 输出如下：1234567891011After buffer.duplicatejava.nio.HeapByteBuffer[pos=10 lim=1024 cap=1024]java.nio.HeapByteBuffer[pos=10 lim=1024 cap=1024]After buf.flip()java.nio.HeapByteBuffer[pos=10 lim=1024 cap=1024]java.nio.HeapByteBuffer[pos=0 lim=10 cap=1024]After buf.put((byte)100)java.nio.HeapByteBuffer[pos=10 lim=1024 cap=1024]java.nio.HeapByteBuffer[pos=1 lim=10 cap=1024]buffer.get(0)=100buf.get(0)=100 最开始创建了一个有1024个字节的缓冲区buffer，然后写入了10个数。随后通过duplicate()方法复制了一个缓冲区buf。可以看到复制后的缓冲区的pos,limit,cap都与原缓冲区一致。然后使用buf.flip()重置新的缓冲区buf然后写入了一个数字100，这时2个缓冲区的position和limit都不一样。说明原缓冲区和复制的缓冲区维护了各自的position和limit。最后打印原来的缓冲区和新的缓冲区的第1个位置的数据，都是100.说明原缓冲区和复制的缓冲区共享内存。 缓冲区分片利用缓冲区分片，可以将一个大的缓冲区分割成若干个子缓冲区，子缓冲区和父缓冲区共享数据。当需要处理一个缓冲区的一个分片时，使用slice()方法得到一个子缓冲区，然后可以像处理普通缓冲区的方法一样处理子缓冲区。示例：12345678910111213141516171819ByteBuffer buffer = ByteBuffer.allocate(10);for (int i=0;i&lt;10;i++) &#123; buffer.put((byte)i);&#125;buffer.position(2);buffer.limit(6);// 得到一个从第3个位置开始到第6个位置结束的子缓冲区ByteBuffer newBuffer = buffer.slice();// 输出子缓冲区的内容while (newBuffer.hasRemaining()) &#123; System.out.print(newBuffer.get());&#125;System.out.println();// 修改子缓冲区newBuffer.flip();newBuffer.put((byte)100);System.out.println(newBuffer.get(0));// 这里为什么去第3个位置？因为子缓冲区的第1个位置=父缓冲区的第3个位置System.out.println(buffer.get(2)); 输出结果：1232345100100 从结果可以看到，newBuffer是buffer的一部分（子缓冲区），而且数据是共享的（最后获取的第3个位置的数字都是100）。 只读缓冲区可以通过asReadOnlyBuffer()方法得到一个只读缓冲区，该缓冲区与原缓冲区共享内存数据。将缓冲区作为参数传递给某个方法时，无法确认该方法会不会破坏缓冲区的数据，此时可以使用只读缓冲区保证缓冲区数据不会被修改。同时，因为只读缓冲区和原缓冲区共享内存，因此原缓冲区的数据修改，对只读缓冲区也是可见的。 示例代码：123456789101112131415161718192021ByteBuffer buffer = ByteBuffer.allocate(10);for (int i=0;i&lt;10;i++) &#123; buffer.put((byte)i);&#125;// 得到一个只读缓冲区ByteBuffer bb = buffer.asReadOnlyBuffer();// 重置position，准备读取数据bb.flip();while (bb.hasRemaining()) &#123; System.out.print(bb.get()+",");&#125;System.out.println();// 重置原缓冲区的position，准备开始写入数据buffer.flip();// 在原缓冲区写入一个数字100buffer.put((byte)100);// 由于上面读取只读缓冲区的数据时，position移动了，所以这里重置position，准备从头开始读取数据bb.flip();while (bb.hasRemaining()) &#123; System.out.print(bb.get()+",");&#125; 输出结果如下：120,1,2,3,4,5,6,7,8,9,100,1,2,3,4,5,6,7,8,9, 在原缓冲区写入了一个数字100，然后在只读缓冲区也是可以拿到的，说明原缓冲区与只读缓冲区是共享内存数据的。 文件映射到内存NIO提供了一个将文件映射到内存的方法进行I/O操作，它比常规的基于流的I/O操作快很多。这个操作由FileChannel.map()方法实现。 示例代码：12345678910111213RandomAccessFile raf = new RandomAccessFile("d:/urls.txt","rw");// 得到FileChannelFileChannel channel = raf.getChannel();// 得到MappedByteBuffer，映射文件的第1到第1024个位置的内容到BufferMappedByteBuffer mbb = channel.map(FileChannel.MapMode.READ_WRITE, 0, 1024);// 循环输出缓冲的数据while(mbb.hasRemaining()) &#123; System.out.print((char)mbb.get()); // 这里文本的内容长度小于1024，mbb.get()到文件末尾后是空&#125;// 重置position，在文件开始位置写入hello,worldmbb.flip();mbb.put("hello,world".getBytes());raf.close(); MappedByteBuffer是ByteBuffer的子类，所以可以像操作ByteBuffer操作它。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java数据结构之Set]]></title>
    <url>%2F2018%2F04%2F18%2Fjava-datastructure-Set%2F</url>
    <content type="text"><![CDATA[先来一张UML图： 如上，Set最重要的是HashSet、LinkedHashSet、TreeSet和CopyOnWriteArraySet几个实现类。Set中的元素是不能重复的。关于Set的实现细节可以参考Map，因为这些Set的实现都是对应的Map的一种封装。比如HashSet是对HashMap的封装，LinkedHashSet对应LinkedHashMap，TreeSet对应TreeMap。 以HashSet为例，其内部维护了一个HashMap对象。在初始化HashSet时new了一个HashMap对象，后面的Set相关的操作方法都委托HashMap来完成。 比如，add方法和remove方法：123456public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 相关的Set及其特性： HashSet对应的Map是HashMap，是基于Hash的快速元素插入，元素无顺序。 LinkedHashSet对应的Map是LinkedHashMap，是基于Hash的快速元素插入，同时维护了元素插入时集合的顺序。遍历集合时，按照先进先出的顺序排序。 TreeSet基于红黑树的实现，有着高效的基于元素Key的排序算法。 参考：《java程序性能优化——让你java程序更快、更稳定》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java数据结构之Map]]></title>
    <url>%2F2018%2F04%2F17%2Fjava-datastructure-Map%2F</url>
    <content type="text"><![CDATA[Java中的List和Map是使用频率非常高的数据结构。这里介绍下常用的Map实现。先来看下类图： HashMap的实现原理HashMap的实现原理参考：HashMap的实现原理 HashMap与HashTable的异同HashTable与HashMap的存储机制基本相同，都是采用数组+链表。不同点：1.HashMap是非线程安全的，HashTable是线程安全的。它的大多数方法都加了synchronized。2.HashMap允许key和value的值为null，HashTable不允许null值的存在。在HashTable的put方法中，如果V为null，直接抛出NullPointerException。3.因为HashTable加了同步处理，所以HashMap效率高于HashTable。 HashTable与ConcurrentHashMap有何不同？HashTable与ConcurrentHashMap都是线程安全的Map，有何不同？HashTable使用的synchronized对方法加锁，实际锁住的是整个对象；而ConcurrentHashMap使用的是lock，这样在操作的时候锁住的不是这个对象。而且ConcurrentHashMap采用了分段锁的设计，只有在同一个分段内才存在竞态关系，不同的分段锁之间没有锁竞争。相比于对整个Map加锁的设计，分段锁大大的提高了高并发环境下的处理能力。 ConcurrentHashMap使用多个子Hash表，即Segment。每个Segment是一个子Hash表。 ConcurrentHashMap要避免调用size()和containsValue()方法，会对整个Map进行扫描。 参考：ConcurrentHashMap总结、Java集合—ConcurrentHashMap原理分析 LinkedHashMap——有序的HashMapLinkedHashMap继承自HashMap，在HashMap的基础上增加了一个链表，用以存放元素的顺序。 LinkedHashMap提供2种类型的顺序：一是元素插入时的顺序；二是最近访问的顺序。可以通过下面的构造函数指定排序行为：1234public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123;&#125; accessOrder为true时表示按照元素访问时间排序；为false时表示按照元素插入的顺序排序。默认是false。示例代码：12345678Map&lt;String,String&gt; map = new LinkedHashMap&lt;&gt;(16,0.75f,false);map.put("hello","hello");map.put("world","world");map.put("!","!");for (Iterator&lt;String&gt; iterator = map.keySet().iterator();iterator.hasNext();) &#123; String key = iterator.next(); System.out.println(key + "-&gt;" + map.get(key));&#125; 输出如下：123hello-&gt;helloworld-&gt;world!-&gt;! 按照元素插入的顺序输出。如果把上面的构造函数的最后一个参数accessOrder改为true，则在迭代器遍历时会报错。1Map&lt;String,String&gt; map = new LinkedHashMap&lt;&gt;(16,0.75f,true); 错误信息：123456789Exception in thread &quot;main&quot; java.util.ConcurrentModificationException at java.util.LinkedHashMap$LinkedHashIterator.nextEntry(LinkedHashMap.java:390) at java.util.LinkedHashMap$KeyIterator.next(LinkedHashMap.java:401) at com.tommy.core.test.Test.main(Test.java:54) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) ConcurrentModificationException异常一般是在对集合迭代的过程中被修改时抛出。不仅仅是LinkedHashMap，所有的集合都不允许在迭代器中修改集合的结构。 因为我们将accessOrder改为true，表示按照最后访问的时间排序。在迭代器中遍历时会将访问的元素移动链表到尾部，发生了修改操作。 我们看下LinkedHashMap的get方法：123456789101112131415public V get(Object key) &#123; Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; e.recordAccess(this); return e.value;&#125;void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) &#123; lm.modCount++; remove(); addBefore(lm.header); &#125;&#125; 可以看到，在get方法中调用了e.recordAccess()方法，recordAccess方法中如果accessOrder=true会有修改操作。所以在迭代器中循环get时出错了。 但是，如果把遍历的代码改一下，运行就正常了。1234for (Iterator&lt;Map.Entry&lt;String,String&gt;&gt; iterator = map.entrySet().iterator();iterator.hasNext();) &#123; Map.Entry&lt;String,String&gt; entry = iterator.next(); System.out.println(entry.getKey() + "-&gt;" + entry.getValue());&#125; 没报错是因为没有对数据结构修改，因为直接调用的getKey和getValue方法。 TreeMap——另一种排序的MapTreeMap实现了SortedMap接口，这意味着它可以对元素进行排序。 但TreeMap与LinkedHashMap的排序不同，它是通过指定的Comparator或Comparable确定。 为了确定Key的排序算法，可以通过2种方式制定：1.在TreeMap的构造函数中注入一个Comparator123public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; this.comparator = comparator;&#125; 2.使用实现了Comparable接口的Key。 如果不指定Comparable或Compartor，则在put时会报ClassCastException。123456789Exception in thread &quot;main&quot; java.lang.ClassCastException: com.tommy.core.test.Test$Student cannot be cast to java.lang.Comparable at java.util.TreeMap.compare(TreeMap.java:1188) at java.util.TreeMap.put(TreeMap.java:531) at com.tommy.core.test.Test.main(Test.java:62) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) 因为构造函数没有传入Comparator，TreeMap认为你的Key（即这里的Student）应该实现了Comparable接口，所以会做一个转换，就出错了。 示例代码：12345678910111213141516171819202122232425262728293031class Student implements Comparable&lt;Student&gt;&#123; private int id; private String name; public Student(int id, String name) &#123; this.id = id; this.name = name; &#125; @Override public int compareTo(Student o) &#123; if (o == null || this.id &gt; o.id ) &#123; return 1; &#125; if (this.id == o.id) &#123; return 0; &#125; return -1; &#125;&#125;TreeMap&lt;Student,Student&gt; map = new TreeMap&lt;&gt;();Student s1 = new Student(1003,"张三");Student s2 = new Student(1002,"李四");Student s3 = new Student(1001,"王五");map.put(s1,s1);map.put(s2,s2);map.put(s3,s3);for(Iterator&lt;Student&gt; iterator = map.keySet().iterator();iterator.hasNext();) &#123; Student student = iterator.next(); System.out.println(student.id+":"+student.name);&#125; 或者TreeMap的初始化指定Comparator：123456789TreeMap&lt;Student, Student&gt; map = new TreeMap&lt;&gt;(new Comparator() &#123; @Override public int compare(Object o1, Object o2) &#123; Student s1 = (Student) o1; Student s2 = (Student) o2; boolean f1 = s1 == null &amp;&amp; s2 == null; return (f1 || s1.id == s2.id) ? 0 : (s1.id &gt; s2.id ? 1 : -1); &#125;&#125;); 输出：1231001:王五1002:李四1003:张三 此外，TreeMap还提供了一系列有用的方法，用于获取大于，小于，以及2个Key直接的子Map的功能。 如果需要使用Map，并且需要实现排序的功能，建议使用TreeMap。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java数据结构之List]]></title>
    <url>%2F2018%2F04%2F13%2Fjava-datastructure-List%2F</url>
    <content type="text"><![CDATA[List是java中重要的数据结构之一，这里介绍常用的3种实现方式：ArrayList、Vector、LinkedList。类图如下： 可以看到，ArrayList、Vector、LinkedList都是AbstractList的实现。而AbstractList实现了List接口，并扩展自AbstractCollection。 其中，ArrayList和Vector底层使用了数组，LinkedList使用的是循环双向链表。这是2种完全不同的实现，所有这也决定了它们的适应的工作场景不同。 ArrayList和Vector的区别是对多线程的支持，ArrayList没有对任何一个方法做同步，因此不是线程安全的。而Vector中绝大多数方法都做了线程同步。所以在多线程环境中，建议使用Vector，反之则使用ArrayList。 ArrayList和Vector实现除了同步几乎一样，所以下面以ArrayList进行说明。 添加元素123456789101112131415161718192021222324252627282930313233public boolean add(E e) &#123; // 确保内部数组有足够的空间 ensureCapacityInternal(size + 1); // Increments modCount!! // 将元素添加到数组的末尾 elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 新的数组容量是原来数组的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果新的容量小于需要的最小容量，则使用最小需要的容量 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 在添加元素前，ArrayList先确保数组空间够用，否则会对数组进行扩容。新数组的长度是原数组的1.5倍。 通过代码可以知道，如果ArrayList内部数组的空间足够大，那么添加元素是很快的。在数组的容量不够时，会进行扩容，在扩容的过程中，会进行大量的数组的复制操作。 LinkedList的add操作123456789101112131415public boolean add(E e) &#123; linkLast(e); return true;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; 将新的元素放到最后。并设置添加前的最后一个元素的下一个元素是要添加的元素。可以看到，LinkedList不用担心容量的问题，添加的效率也是很高的，只是每次添加时会生成一个新的Node对象，会有一定的性能损耗。在ArrayList容量足够的情况下，ArrayList的速度是非常快的，是直接操作的数组。 添加操作性能测试1.ArrayList的添加操作12345long s = System.currentTimeMillis();for (int i=0;i&lt;5000000;i++) &#123; list.add(i);&#125;System.out.println(System.currentTimeMillis() - s); 耗时：161ms. 2.LinkedList的添加操作12345long s = System.currentTimeMillis();for (int i=0;i&lt;5000000;i++) &#123; linkedList.add(i);&#125;System.out.println(System.currentTimeMillis() - s); 耗时：3476ms. 如果列表容量足够（不用扩容），添加元素到尾部，推荐使用ArrayList，效率高于LinkedList。 添加元素到任意位置1.ArrayList12345678public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; 可以看到，ArrayList添加元素到指定位置时，会导致index之后的所有元素向后移动，如果数据量大而index比较小的话，产生的数组拷贝是非常多的。这样必然导致效率降低。所以，尽量将元素插入到列表的尾部，可以提高该方法的性能。 2.LinkedList123456789101112131415161718192021222324252627282930313233public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125;Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 如果index=size，就跟add(E e)是一样的，添加在最后；否则调用linkBefore方法。在linkBefore方法中，注意第2个参数node(index)，该方法中，如果index在LinkedList的前半部分就在前半部分查找；否则在后半部分查找。所以，可以看到，如果index在靠近中间的位置，效率比较低。 添加元素到任意位置测试1.ArrayList12345long s = System.currentTimeMillis();for (int i=0;i&lt;50000;i++) &#123; list.add(0,i);&#125;System.out.println(System.currentTimeMillis() - s); 耗时：236ms。 2.LinkedList12345long s = System.currentTimeMillis();for (int i=0;i&lt;50000;i++) &#123; linkedList.add(i);&#125;System.out.println(System.currentTimeMillis() - s); 耗时：5ms。 除了一些极端的情况（首尾），添加元素到列表任意位置，LinkedList效率高于ArrayList。所以如果有在任意位置插入元素的需求，可以考虑LinkedList。 删除任意位置的元素ArrayList1234567891011public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // Let gc do its work return oldValue;&#125; 可以看到，跟add(index,E e)方法比较类似，在任意位置删除元素后，都需要进行数组的重组。而且，要删除的元素越靠前，开销越小；要删除的元素越靠后，开销越大。 LinkedList1234567891011121314151617181920212223242526public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125; E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; 注意remove方法中，最后调用了unlink方法，该方法中也查找了index位置的元素。代码同add(index,E)。如果元素在前半段，则在链表的前半段循环查找；否则在链表的后半段循环查找。所以如果要删除的元素在前半段或后半段还好，如果在中间位置效率就比较低了（需要循环一半的链表）。 容量参数在前面添加元素的地方说了，ArrayList和Vector在容量不够的情况下会进行扩容，新的容量是原来的1.5倍，扩容后会对之前的数据重组，所以性能损耗是比较大的。在ArrayList和Vector的构造器中，有一个初始容量参数可指定列表的容量，如果在构造列表时预估数据量，将会避免进行列表扩容，从而可以提升效率。 列表遍历分别使用ArrayList和LinkedList进行for循环、forEach循环、迭代器进行100万条数据的遍历测试。测试代码：12345678910111213141516171819for (int i=0;i&lt;1000000;i++) &#123; list.add(i);&#125;long s = System.currentTimeMillis();for (int i=0;i&lt;list.size();i++) &#123; list.get(i);&#125;System.out.println("for循环耗时：" + (System.currentTimeMillis() - s) + "ms.");s = System.currentTimeMillis();Integer tmp = null;for (Integer i:list) &#123; tmp = i;&#125;System.out.println("forEach耗时："+(System.currentTimeMillis() - s) + "ms.");s = System.currentTimeMillis();for (Iterator&lt;Integer&gt; iterator = list.iterator();iterator.hasNext();) &#123; tmp = iterator.next();&#125;System.out.println("迭代器耗时：" + (System.currentTimeMillis() - s) + "ms."); ArrayList测试结果：for循环耗时：4ms.forEach耗时：17ms.迭代器耗时：10ms. LinkedList测试结果：forEach耗时：11ms.迭代器耗时：15ms.for循环耗时：无穷大，没法等到执行结束。 注意：上面代码在测试时将for循环放到最后，否则测试LinkedList时，看不到forEach和迭代器的执行结果。 可以看到，对于ArrayList来说，for循环的效率是最高的，forEach反而最低。LinkedList使用for循环完全没法忍受，原因可以看之前的LinkedList查找元素的部分，每次循环都会遍历一次列表。编译后的代码如下：123456789101112131415161718long var8 = System.currentTimeMillis();Integer tmp = null;Iterator i;Integer i1;for(i = list.iterator(); i.hasNext(); i1 = (Integer)i.next()) &#123; ;&#125;System.out.println("forEach耗时：" + (System.currentTimeMillis() - var8) + "ms.");var8 = System.currentTimeMillis();for(i = list.iterator(); i.hasNext(); tmp = (Integer)i.next()) &#123; ;&#125;System.out.println("迭代器耗时：" + (System.currentTimeMillis() - var8) + "ms.");var8 = System.currentTimeMillis();for(int var9 = 0; var9 &lt; list.size(); ++var9) &#123; list.get(var9);&#125;System.out.println("for循环耗时：" + (System.currentTimeMillis() - var8) + "ms."); forEach在编译时被优化为使用迭代器，但是多了一个赋值操作，所以比使用迭代器慢一点。 总结要根据应用场景选择合适的List，否则会导致性能问题。同时也要注意ArrayList和Vector的容量，使用前如果能评估大小，最好初始化List时就指定，这样可以避免数组扩容，导致大量的数据拷贝，导致性能下降。 参考：《java程序性能优化——让你的java程序更快、更稳定》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享一个对象复制的工具类]]></title>
    <url>%2F2018%2F04%2F13%2Fshare-one-object-copy-utility%2F</url>
    <content type="text"><![CDATA[使用cglib的BeanCopier复制对象的工具类。 性能比spring的BeanUtils，Apache common的BeanUtils快很多倍。 注意： 1）BeanCopier只拷贝名称和类型都相同的属性 2）当目标类的setter数目比getter少时，创建BeanCopier会失败而导致拷贝不成功 3）引用类型不会拷贝，直接引用，所以操作源对象的引用类型属性会导致copy的对象的引用类型属性一起变化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class BeanCopyUtils &#123; // 使用WeakHashMap缓存,在内存不足时会自动释放 private final static Map&lt;String,BeanCopier&gt; BEAN_COPIER_MAP = new WeakHashMap&lt;&gt;(); private final static Map&lt;String,Converter&gt; CONVERTER_MAP = new WeakHashMap&lt;&gt;(); private static Object lock1 = new Object(); private static Object lock2 = new Object(); private BeanCopyUtils()&#123;&#125; /** * 创建BeanCopier，并缓存 * @param src * @param target * @param useConverter * @return */ private static BeanCopier getBeanCopier(Object src,Object target,boolean useConverter) &#123; String key = generateKey(src,target,useConverter); BeanCopier bc = BEAN_COPIER_MAP.get(key); if (null == bc) &#123; synchronized (lock1) &#123; bc = BEAN_COPIER_MAP.get(key); if (null == bc) &#123; bc = BeanCopier.create(src.getClass(),target.getClass(),useConverter); BEAN_COPIER_MAP.put(key,bc); System.out.println("Create BeanCopier with key:" + key); &#125; &#125; &#125; return bc; &#125; /** * 复制对象属性 * @param src * @param target */ public static void copy(Object src,Object target) &#123; BeanCopier bc = getBeanCopier(src, target, false); bc.copy(src,target,null); &#125; /** * 使用自定义的属性转换器复制对象属性 * @param src * @param target * @param converter */ public static void copy(Object src,Object target,Converter converter) &#123; BeanCopier bc = getBeanCopier(src,target,true); bc.copy(src,target,converter); &#125; /** * 对象属性复制，只复制fields中指定的属性，每个属性用逗号分隔 * @param src * @param target * @param fields */ public static void copyWithFields(Object src,Object target,final String fields) &#123; BeanCopier bc = getBeanCopier(src,target,true); bc.copy(src, target, newConverter(src,target,fields,true)); &#125; /** * 对象属性复制，排除指定属性 * @param src * @param target * @param fields */ public static void copyWithoutFields(Object src,Object target,final String fields) &#123; BeanCopier bc = getBeanCopier(src,target,true); bc.copy(src, target, newConverter(src,target,fields,false)); &#125; /** * new属性转换器， * @param fields 需要复制或排除的属性 * @param fieldCopyFlag 属性复制标识 true:表明fields为需要复制的属性；false:表明fields是需要排除复制的属性 * @return */ private static Converter newConverter(Object src,Object target,final String fields,final boolean fieldCopyFlag) &#123; String key = buildConverterkey(src,target,fields,fieldCopyFlag); Converter converter = CONVERTER_MAP.get(key); if (null == converter) &#123; synchronized (lock2) &#123; converter = CONVERTER_MAP.get(key); if (null == converter) &#123; converter = new Converter() &#123; @Override public Object convert(Object fieldValue, Class fieldType, Object methodName) &#123; String field = methodName.toString().substring(3); // 得到属性名，如Name field = field.substring(0,1).toLowerCase() + field.substring(1); // 将首字母小写 if ((fieldCopyFlag &amp;&amp; fields.contains(field)) || (!fieldCopyFlag &amp;&amp; !fields.contains(field))) &#123; return fieldValue; &#125; return null; &#125; &#125;; CONVERTER_MAP.put(key,converter); System.out.println("Created Converter with key:" + key); &#125; &#125; &#125; return converter; &#125; private static String generateKey(Object src,Object target,boolean useConverter) &#123; return src.getClass().getName() + target.getClass().getName() + String.valueOf(useConverter); &#125; private static String buildConverterkey(Object src,Object target,String fields,boolean copyFlag) &#123; String baseKey = generateKey(src,target,true); String key = baseKey + fields + String.valueOf(copyFlag); return key; &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java字符串连接]]></title>
    <url>%2F2018%2F04%2F12%2Fjava-string-join%2F</url>
    <content type="text"><![CDATA[由于String是不可变对象（final），所以，对字符串进行连接、替换操作时，String对象总是会生成新的对象。所以连接和替换时性能很差。 String常量字符串的累加比如我们使用如下代码进行字符串连接：1String str = "hello"+"world"+"!"; 先有hello和world2个字符串生成helloworld，然后再生成helloworld!。将上面的代码做5万次循环。但上面的代码执行效率竟然比使用StringBuilder快，为什么呢？1234StringBuilder sb = new StringBuilder();sb.append("hello");sb.append("world");sb.append("!"); 对第一段代码进行反编译，可以看到对于常量字符串的累加，java在编译时就做了优化。1String str = "helloworld!"; String变量字符串的累加123456789101112131415161718192021public class Test &#123; public static void main(String[] args) &#123; String a = "hello"; String b = "world"; String c = "!"; int loopCount = 50000000; long s = System.currentTimeMillis(); for (int i=0;i&lt;loopCount;i++) &#123;// test(a,b,c); test2(a,b,c); &#125; System.out.println("cost " + (System.currentTimeMillis() - s) + "ms."); &#125; private static void test(String a,String b,String c) &#123; StringBuilder stringBuilder = new StringBuilder(); String s = stringBuilder.append(a).append(b).append(c).toString(); &#125; private static void test2(String a,String b,String c) &#123; String s = a + b + c; &#125;&#125; 同样做5万次循环，发现与使用StringBuilder性能差不多。反编译，发现java在编译时做了优化。12345678910111213141516171819202122public class Test &#123; public Test() &#123; &#125; public static void main(String[] args) &#123; String a = "hello"; String b = "world"; String c = "!"; int loopCount = 50000000; long s = System.currentTimeMillis(); for(int i = 0; i &lt; loopCount; ++i) &#123; test2(a, b, c); &#125; System.out.println("cost " + (System.currentTimeMillis() - s) + "ms."); &#125; private static void test(String a, String b, String c) &#123; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(a).append(b).append(c).toString(); &#125; private static void test2(String a, String b, String c) &#123; (new StringBuilder()).append(a).append(b).append(c).toString(); &#125;&#125; 可以看到，java在编译的时候将字符串的+操作转换成了使用StringBuilder的append方式。 构建超大的字符串对下面的代码ABC分别执行10000次。代码A：1234String s = "";for (int i = 0; i &lt; 1000; i++) &#123; s = s + i;&#125; 执行耗时：4542ms。 代码B：1234String s = "";for (int i = 0; i &lt; 1000; i++) &#123; s = s.concat(String.valueOf(i));&#125; 执行耗时：4079ms。 代码C：12345StringBuilder stringBuilder = new StringBuilder();for (int i = 0; i &lt; 1000; i++) &#123; stringBuilder.append(i);&#125;String s = stringBuilder.toString(); 执行耗时：259ms。 可以看到，从快到慢依次是StringBuilder &gt; String.concat() &gt; String+。并且StringBuilder要快很多。 观察编译后的代码发现代码Ajava编译器并没有做任何优化。 选择StringBuilder还是StringBuffer？StringBuffer与StringBuilder最大的不同在于，StringBuffer对几乎所有的方法都做了同步，StringBuilder没有做任何同步。由于方法同步需要消耗一定的系统资源，因此，StringBuffer效率要低于StringBuilder。但是，在多线程环境中，StringBuilder无法保证线程安全，不能使用。 所以，如果是不需要考虑线程安全的情况下，使用StringBuilder；相反则使用StringBuffer。 容量参数无论是StringBuffer还是StringBuilder都可以在初始化时设置一个容量参数。12public StringBuffer(int capacity);public StringBuilder(int capacity); 在不指定容量参数时，默认是16个字符。代码如下：123public StringBuilder() &#123; super(16);&#125; StringBuffer和StringBuilder都继承自AbstractStringBuilder，AbstractStringBuilder的构造器代码：123AbstractStringBuilder(int capacity) &#123; value = new char[capacity];&#125; 不带容量参数测试12345//StringBuilder sb = new StringBuilder();StringBuffer sb = new StringBuffer();for (int i=0;i&lt;10000000;i++) &#123; sb.append(i);&#125; StringBuilder耗时405ms，StringBuffer耗时557ms。 带容量参数测试123456//StringBuilder sb = new StringBuilder(68888890);StringBuffer sb = new StringBuffer(68888890);for (int i=0;i&lt;10000000;i++) &#123; sb.append(i);&#125;//System.out.println(sb.length()); StringBuilder耗时330ms，StringBuffer耗时464ms。 通过对比，可以看到增加容量参数可以增加StringBuffer和StringBuilder的性能。 StringBuffer和StringBuilder在执行append方法时，实际是调用父类AbstractStringBuilder的append方法。父类append方法定义如下：12345678public AbstractStringBuilder append(String str) &#123; if (str == null) str = "null"; int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this;&#125; 可以看到一个ensureCapacityInternal方法，定义如下：12345678910111213141516171819202122232425/** * This method has the same contract as ensureCapacity, but is * never synchronized. */private void ensureCapacityInternal(int minimumCapacity) &#123; // overflow-conscious code if (minimumCapacity - value.length &gt; 0) expandCapacity(minimumCapacity);&#125;/** * This implements the expansion semantics of ensureCapacity with no * size check or synchronization. */void expandCapacity(int minimumCapacity) &#123; int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity; if (newCapacity &lt; 0) &#123; if (minimumCapacity &lt; 0) // overflow throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; &#125; value = Arrays.copyOf(value, newCapacity);&#125; minimumCapacity就是现在存储的数据的长度+本次append字符串的长度。如果该长度比定义的保存数据的char[]的长度大，说明char[]存储空间不够，需要进行扩容了。 扩容的逻辑：新的容量为目前数据的容量的2倍+2；如果扩容后的长度仍然小于目前数据的长度+本次append字符串的长度，则新的容量为目前数据的长度+本次append字符串的长度。然后执行了一次数组的复制，将旧的数据复制到新的数组中。 所以，如果指定合适的容量，可以避免SringBuilder和StringBuffer的内存复制，这样可以提升append的性能。这个跟HashMap比较像，HashMap在put数据时，也会在容量不够是进行扩容。 参考：《Java程序性能优化——让你的java程序更快、更稳定》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java的类加载器]]></title>
    <url>%2F2018%2F04%2F11%2Fjava-classloader%2F</url>
    <content type="text"><![CDATA[1.为什么要有类加载器java文件编译后产生的，class文件不是可执行文件，需要通过类加载器将.class加载到虚拟机中。 2.java类加载器有多少Bootstrap–&gt;ExtClassLoader-&gt;AppClassLoader-&gt;自定义的ClassLoader。 BootStrap ClassLoader：称为启动类加载器，C++实现的，是Java类加载层次中最顶层的类加载器(JVM启动后初始化的)，负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等； ExtensionClassLoader：称为扩展类加载器，负责加载Java的扩展类库，默认加载JAVA_HOME/jre/lib/ext/目下的所有jar。该加载器是有java实现的，由Bootstrploader加载ExtClassLoader,并且将ExtClassLoader的父加载器设置为Bootstrp loader； AppClassLoader：称为系统类加载器，负责加载应用程序classpath目录下的所有jar和class文件。 3.类加载器的委托机制先委托给父加载器去加载，一直委托到最顶层Bootstrap，Bootstrap去查找对应的类，没找到则委托ExtClassLoader去查找，一直到最底层的ClassLoader。 4.自定义类加载器继承ClassLoader,重写findClass方法即可。 5.应用场景热部署、tomcat为每个应用创建了不同的类加载器隔离应用（tomcat的类加载器破坏了双亲委派机制，tomcat是从自定义的类加载器往Bootstrap查找）、class文件解密（假定传输方对class为了安全进行了加密，接收方需要自定义加载器进行解密，然后创建响应的对象使用）、java Applet（从远程下载class文件）、应用中需要用到不同版本的jar。 可以参考下面的这些链接，有详细的说明和例子。参考：自定义类加载器：从网上加载class到内存、实例化调用其中的方法、JVM高级特性与实践（九）：类加载器 与 双亲委派模式（自定义类加载器源码探究ClassLoader）、深入探讨 Java 类加载器、java类加载器和双亲委派模型]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git中本地与远程库的关联与取消]]></title>
    <url>%2F2018%2F04%2F10%2Fgit-local-remote-relation%2F</url>
    <content type="text"><![CDATA[1.在本地目录下关联远程repository ：1git remote add origin git@github.com:git_username/repository_name.git 2.取消本地目录下关联的远程库：1git remote remove origin 参考：https://blog.csdn.net/wsycsdn19930512/article/details/50574217]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo主题推荐]]></title>
    <url>%2F2018%2F04%2F10%2Fhexo-recommended-themes%2F</url>
    <content type="text"><![CDATA[hexo主题：hexo官网所有主题：https://hexo.io/themes/ 个人觉得比较ok的主题：https://shuoit.net/http://www.91h5.cc/https://itimetraveler.github.io/hexo-theme-hiero/archives/http://chaoo.oschina.io/http://haojen.github.io/https://www.haomwei.com/https://blog.minhow.com/http://notes.iissnan.com/http://raytaylorlin.com/http://sabrinaluo.github.io/tech/http://blog.minfive.com/https://vevlins.github.io/https://geekplux.com/https://yanm1ng.github.io/http://moxfive.xyz/http://bubuzou.com/https://www.buhuoblog.com/https://www.imys.net/https://luuman.github.io/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Session跨域共享问题解决]]></title>
    <url>%2F2018%2F04%2F09%2Fsession-crossdomain-share%2F</url>
    <content type="text"><![CDATA[1.Session跨域存在的问题不同的域名下，Session无法共享。即设定用户在www.a.com登录，后端在Session中放入了用户的username和age，用户从www.a.com跳转到www.b.com，无法获取到Session中的用户信息。 演示：这里使用一个nginx+2个tomcat来演示。nginx在本机，1台tomcat在本机，另外一台IP为192.168.74.135。 项目结构如下： 添加JSP和servlet的依赖：12345678910111213&lt;!--配置servlet--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--配置jsp jstl的支持--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; 页面如下：session.jsp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;%@include file="head.jsp"%&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Session跨域共享测试&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form method="POST"&gt; 用户名：&lt;input type="text" name="username" /&gt; 年龄：&lt;input type="text" name="age" /&gt; &lt;input type="button" value="创建Session" id="addBtn"&gt; &lt;/form&gt; &lt;hr/&gt; &lt;input type="button"value="获取Session" id="getSessionBtn"&gt; &lt;textarea rows="10" cols="80"&gt;&lt;/textarea&gt; &lt;script src="$&#123;ctx&#125;/js/jquery.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; var flag = true; $('#addBtn').click(function()&#123; if (!flag) &#123; alert('操作正在进行中...'); return; &#125; flag = false; var name = $('[name=username]').val(); var age = $('[name=age]').val(); if (name != '' &amp;&amp; age != '') &#123; $.post('$&#123;ctx&#125;/session/add',&#123;username:name, age:age&#125;,function(r) &#123; var code = $.parseJSON(r).code; console.log('code-&gt;' + code); if (code == 0) &#123; alert('创建session成功！'); &#125; flag = true; &#125;); &#125; else &#123; alert('缺少参数！'); &#125; &#125;); $('#getSessionBtn').click(function() &#123; if (!flag) &#123; alert('操作正在进行中...'); return; &#125; flag = false; $.get('$&#123;ctx&#125;/session/get',function(r) &#123; $('textarea').html(r); flag = true; &#125;); &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; head.jsp:123&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; isELIgnored=&quot;false&quot; %&gt;&lt;%@taglib prefix=&quot;c&quot; uri=&quot;http://java.sun.com/jsp/jstl/core&quot; %&gt;&lt;c:set var=&quot;ctx&quot; value=&quot;$&#123;pageContext.request.contextPath&#125;&quot; /&gt; 创建Session的Servlet：12345678910111213141516@WebServlet(name = "sessionAddServlet",urlPatterns = "/session/add")public class SessionAddServlet extends HttpServlet &#123; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String username = req.getParameter("username"); String age = req.getParameter("age"); System.out.println(String.format("username-&gt;%s,age-&gt;%s",username,age)); HttpSession session = req.getSession(); session.setAttribute("username",username); session.setAttribute("age",age); PrintWriter printWriter = resp.getWriter(); printWriter.write("&#123;\"code\":0&#125;"); printWriter.flush(); printWriter.close(); &#125;&#125; 获取Session的Servlet：12345678910111213141516@WebServlet(name = "getSessionServlet",urlPatterns = "/session/get")public class GetSessionServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; HttpSession session = req.getSession(); String username = (String) session.getAttribute("username"); String age = (String) session.getAttribute("age"); String ip = req.getRemoteHost(); String userInfo = String.format("&#123;ip:%s,username:%s,age:%s&#125;",ip,username,age); System.out.println(userInfo); PrintWriter pw = resp.getWriter(); pw.write(userInfo); pw.flush(); pw.close(); &#125;&#125; 将应用达成WAR包分别部署到本机和192.168.74.135的tomcat，并启动它们。端口信息如下：192.168.74.135的端口为8080，本机的端口为8081。 nginx配置如下：12345678910111213141516171819202122upstream server_list &#123; server 192.168.74.135:8080; server localhost:8081;&#125;server &#123; listen 8088; server_name localhost_nginx; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; #root html; proxy_pass http://server_list; #index index.html index.htm; &#125; ...后面省略&#125; 这里指定nginx监听端口为8088，默认是80。 测试：1.在浏览器输入http://localhost:8088/crossdomain-session/session.jsp，这样通过nginx转发请求。a.输入用户名，年龄，然后点击“创建Session”创建Session保存用户名和年龄。b.点击“获取Session”，可以看到用户名和年龄有值。c.再次点击”获取Session”可以看到，这次请求的IP是192.168.74.135，用户名和年龄都是空。 因为Session是本机IP创建的，所以本机IP可以获取到，而192.168.74.135则无法获取到。 2.使用IP_HASH在upstream中增加ip_hash;12345upstream server_list &#123; server 192.168.74.135:8080; server localhost:8081; ip_hash;&#125; 重新启动nginx，再多次点击“获取Session”，发现都是本机的请求。nginx根据IP将请求分配给了本机的tomcat，由于Session是本机的tomcat创建的，所以可以获取到。 其实可以看到，多个tomcat并没有共享Session，只是nginx根据IP分发到了固定的tomcat。 弊端：1.nginx不是最前端的服务器。ip_hash要求nginx一定是最前端的服务器，否则nginx得不到正确ip，就不能根据ip作hash。譬如使用的是squid为最前端，那么nginx取ip时只能得到squid的服务器ip地址，用这个地址来作分流是肯定错乱的。 2.nginx的后端还有其它方式的负载均衡。假如nginx后端又有其它负载均衡，将请求又通过另外的方式分流了，那么某个客户端的请求肯定不能定位到同一台session应用服务器上。这么算起来，nginx后端只能直接指向应用服务器，或者再搭一个squid，然后指向应用服务器。最好的办法是用location作一次分流，将需要session的部分请求通过ip_hash分流，剩下的走其它后端去。可以参考：http://www.cnblogs.com/xiaogangqq123/archive/2011/03/04/1971002.html 3.使用jvm-route参考：https://blog.csdn.net/honghailiang888/article/details/51066411跟ip hash类似，也并没有真正解决session共享问题。而且将特定会话附属到特定的tomcat上，当该tomcat宕机时，用户的Session也会丢失。 4.使用Redis等NoSQL这里以Redis为例。 在用户登录成功后，将用户相关信息放入Redis，并设置过期时间；在用户退出登录时从Redis删除；如果会话超时则重新将用户数据放入Redis。 操作Redis的工具类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168public final class RedisUtil &#123; //Redis服务器IP private static String ADDR = "192.168.74.135"; //Redis的端口号 private static int PORT = 6379; //访问密码 private static String AUTH = "system"; //可用连接实例的最大数目，默认值为8； //如果赋值为-1，则表示不限制；如果pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted(耗尽)。 private static int MAX_ACTIVE = 1024; //控制一个pool最多有多少个状态为idle(空闲的)的jedis实例，默认值也是8。 private static int MAX_IDLE = 200; //等待可用连接的最大时间，单位毫秒，默认值为-1，表示永不超时。如果超过等待时间，则直接抛出JedisConnectionException； private static int MAX_WAIT = 10000; private static int TIMEOUT = 10000; //在borrow一个jedis实例时，是否提前进行validate操作；如果为true，则得到的jedis实例均是可用的； private static boolean TEST_ON_BORROW = true; private static JedisPool jedisPool = null; /** * 初始化Redis连接池 */ static &#123; try &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(MAX_ACTIVE); config.setMaxIdle(MAX_IDLE); config.setMaxWaitMillis(MAX_WAIT); config.setTestOnBorrow(TEST_ON_BORROW); jedisPool = new JedisPool(config, ADDR, PORT, TIMEOUT, AUTH); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 获取Jedis实例 * @return */ public synchronized static Jedis getJedis() &#123; try &#123; if (jedisPool != null) &#123; Jedis resource = jedisPool.getResource(); return resource; &#125; else &#123; return null; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 释放jedis资源 * @param jedis */ public static void returnResource(final Jedis jedis) &#123; if (jedis != null) &#123; jedisPool.returnResource(jedis); &#125; &#125; /** * 获取redis键值-object * * @param key * @return */ public static String get(String key) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); String value = jedis.get(key); return value; &#125; catch (Exception e) &#123; System.err.println("getObject获取redis键值异常:key=" + key + " cause:" + e.getMessage()); &#125; finally &#123; jedis.close(); &#125; return null; &#125; /** * 设置redis键值-object * @param key * @param value * @return */ public static String set(String key, String value) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); return jedis.set(key,value); &#125; catch (Exception e) &#123; System.err.println("setObject设置redis键值异常:key=" + key + " value=" + value + " cause:" + e.getMessage()); return null; &#125; finally &#123; if(jedis != null) &#123; jedis.close(); &#125; &#125; &#125; public static String set(String key, String value,int expiretime) &#123; String result = ""; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); result = jedis.set(key,value); if(result.equals("OK")) &#123; jedis.expire(key.getBytes(), expiretime); &#125; return result; &#125; catch (Exception e) &#123; System.err.println("setObject设置redis键值异常:key=" + key + " value=" + value + " cause:" + e.getMessage()); &#125; finally &#123; if(jedis != null) &#123; jedis.close(); &#125; &#125; return result; &#125; /** * 删除key */ public static Long delkey(String key) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); return jedis.del(key.getBytes()); &#125;catch(Exception e) &#123; e.printStackTrace(); return null; &#125;finally&#123; if(jedis != null) &#123; jedis.close(); &#125; &#125; &#125; public static Boolean existsKey(String key) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); return jedis.exists(key.getBytes()); &#125;catch(Exception e) &#123; e.printStackTrace(); return null; &#125;finally&#123; if(jedis != null) &#123; jedis.close(); &#125; &#125; &#125; public static Set&lt;String&gt; keys(String keyPattern) &#123; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); return jedis.keys(keyPattern); &#125;catch(Exception e) &#123; e.printStackTrace(); return null; &#125;finally&#123; if(jedis != null) &#123; jedis.close(); &#125; &#125; &#125;&#125; 操作Cookie的工具类：123456789101112131415public final class CookieUtil &#123; public final static String getCookie(HttpServletRequest request,String cookieName) &#123; Cookie[] cookies = request.getCookies(); String key = null; if (null != cookies &amp;&amp; cookies.length &gt; 0) &#123; for (Cookie cookie: cookies) &#123; if (cookie.getName().equals("sid")) &#123; key = cookie.getValue(); break; &#125; &#125; &#125; return key; &#125;&#125; 创建Session的Servlet：12345678910111213141516171819202122232425262728293031@WebServlet(name = "sessionAddServlet",urlPatterns = "/session/add")public class SessionAddServlet extends HttpServlet &#123; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String username = req.getParameter("username"); String age = req.getParameter("age"); System.out.println(String.format("username-&gt;%s,age-&gt;%s",username,age)); String key = CookieUtil.getCookie(req, "sid"); boolean addFlag = null == key || "".equals(key); if (null != key &amp;&amp; !"".equals(key)) &#123; String sid = RedisUtil.get(key); addFlag = null == sid || "".equals(sid); &#125; if (addFlag) &#123; key = UUID.randomUUID().toString(); String ip = req.getRemoteHost(); System.out.println("创建Session的IP：" + ip); String userInfo = String.format("&#123;username:%s,age:%s&#125;",username,age); // 将要保存到session中的数据写入Redis，有效期30分钟 RedisUtil.set(key,userInfo,30*60*1000); // 将Session的Key写入到用户浏览器cookie Cookie cookie = new Cookie("sid",key); resp.addCookie(cookie); System.out.println("sid-&gt;" + key); &#125; PrintWriter printWriter = resp.getWriter(); printWriter.write(String.format("&#123;\"code\":0,\"msg\":\"%s\"&#125;",addFlag ? "Session创建成功！":"Session已存在！")); printWriter.flush(); printWriter.close(); &#125;&#125; 获取Session的Servlet：123456789101112131415161718@WebServlet(name = "getSessionServlet",urlPatterns = "/session/get")public class GetSessionServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String key = CookieUtil.getCookie(req,"sid"); String userInfo = null; if (null != key) &#123; userInfo = RedisUtil.get(key); System.out.println(userInfo); &#125; userInfo = userInfo == null ? "No Session info.":userInfo; userInfo += "\nIP:"+req.getRemoteHost(); PrintWriter pw = resp.getWriter(); pw.write(userInfo); pw.flush(); pw.close(); &#125;&#125; 注意：1.在创建Session（放入用户数据到Redis）的地方，如果已经有了Session，不能再重复创建。这个上面已经实现；2.写入用户数据到Redis需要有过期时间（跟Session过期时间一致）；3.用户退出登录时，需要将Redis的数据清空； 5.进阶版上面使用Redis可以实现Session共享的功能，但是需要程序员去写这些相关代码。其实这些代码对所有需要使用Session共享的应用都是一样的，完全可以抽出来。比如作为一个单独的依赖，其他应用使用只需要引入该依赖，并进行少量设置即可，相关Session操作跟操作HttpSession没有不同。 重写HttpSession，涉及到Session相关的操作全部改为操作Redis； 重写HttpServletRequest，因为HttpServletRequest中有创建HttpSession的方法，我们需要改为我们自定义的HttpSession的实现类； 定义一个Filter，过滤需要登录的受保护的资源。在doFilter方法中，我们根据ServletRequest和ServletResponse重新构造我们自定义的HttpServletRequest。并调用filterChain.doFilter方法，将ServletRequest包装为我们自己的ServletRequest； 代码参考：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public class HttpSessionImpl implements HttpSession &#123; private HttpServletRequest request; private HttpServletResponse response; private String id; private long createTime; private long lastAccessTime; // session有效期30分钟 private int maxInactiveInterval = 30*60; private Vector&lt;String&gt; names = new Vector&lt;&gt;(); private final String SESSION_KEY_PREFIX = "session"; public HttpSessionImpl(HttpServletRequest request,HttpServletResponse response) &#123; this.request = request; this.response = response; boolean isExist = false; // 如果已经有Session就不再创建了，否则会导致每次请求产生新的Session // 从请求头获取sid String sid = CookieUtil.getCookie(request,"sid"); if (null != sid &amp;&amp; !"".equals(sid)) &#123; // 检查Redis是否存在该Key Set&lt;String&gt; keys = RedisUtil.keys(SESSION_KEY_PREFIX+":"+sid+":*"); if (null != keys &amp;&amp; !keys.isEmpty()) &#123; isExist = true; this.id = sid; &#125; &#125; if (!isExist) &#123; this.id = sid != null &amp;&amp;!"".equals(sid) ? sid : UUID.randomUUID().toString(); this.createTime = System.currentTimeMillis(); if (null == sid || "".equals(sid)) &#123; Cookie cookie = new Cookie("sid",this.id); response.addCookie(cookie); &#125; &#125; &#125; @Override public long getCreationTime() &#123; return createTime; &#125; @Override public String getId() &#123; return id; &#125; @Override public long getLastAccessedTime() &#123; return lastAccessTime; &#125; @Override public ServletContext getServletContext() &#123; return request.getServletContext(); &#125; @Override public void setMaxInactiveInterval(int i) &#123; this.maxInactiveInterval = i; &#125; @Override public int getMaxInactiveInterval() &#123; return maxInactiveInterval; &#125; @Override public HttpSessionContext getSessionContext() &#123; return null; &#125; @Override public Object getAttribute(String s) &#123; this.lastAccessTime = System.currentTimeMillis(); String key = SESSION_KEY_PREFIX + ":" + id + ":" + s; return RedisUtil.get(key); &#125; @Override public Object getValue(String s) &#123; return this.getAttribute(s); &#125; @Override public Enumeration&lt;String&gt; getAttributeNames() &#123; return names.elements(); &#125; @Override public String[] getValueNames() &#123; return new String[0]; &#125; @Override public void setAttribute(String s, Object o) &#123; String key = SESSION_KEY_PREFIX + ":" + id + ":" + s; // 这里RedisUtil要实现保存对象，即byte[]的功能。 //RedisUtil.set(s,o,maxInactiaveInterval); // 这里测试，假定保存的value是String类型 RedisUtil.set(key, (String) o, maxInactiveInterval); this.lastAccessTime = System.currentTimeMillis(); this.names.add(s); &#125; @Override public void putValue(String s, Object o) &#123; &#125; @Override public void removeAttribute(String s) &#123; String key = SESSION_KEY_PREFIX + ":" + id + ":" + s; RedisUtil.delkey(key); this.names.remove(s); &#125; @Override public void removeValue(String s) &#123; &#125; @Override public void invalidate() &#123; // session过期时，从Redis删除相关数据 String key; for (String name : names) &#123; key = SESSION_KEY_PREFIX + ":" + id + ":" + name; RedisUtil.delkey(key); &#125; &#125; @Override public boolean isNew() &#123; return false; &#125;&#125; 123456789101112131415161718192021public class TommyHttpServletRequest extends HttpServletRequestWrapper &#123; private HttpServletRequest request; private HttpServletResponse response; private HttpSessionImpl session; public TommyHttpServletRequest(HttpServletRequest request,HttpServletResponse response) &#123; super(request); this.request = request; this.response = response; &#125; @Override public HttpSession getSession() &#123; return this.getSession(true); &#125; @Override public HttpSession getSession(boolean create) &#123; if (create &amp;&amp; this.session == null) &#123; this.session = new HttpSessionImpl(request,response); &#125; return session; &#125;&#125; 1234567891011121314@WebFilter(filterName = "sessionFilter",urlPatterns = "/*")public class SessionFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; TommyHttpServletRequest request = new TommyHttpServletRequest((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); filterChain.doFilter(request,servletResponse); &#125; @Override public void destroy() &#123; &#125;&#125; 可以将上面的当初抽取出来作为一个依赖，其他应用引入该依赖，并配置Redis和Filter即可。 6.使用Spring Session参考：分布式系统session共享方案 代码参考：crossdomain-session]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列13——实现分布式配置管理]]></title>
    <url>%2F2018%2F04%2F08%2Fspringcloud-series-13-distributed-configuration-management%2F</url>
    <content type="text"><![CDATA[在软件开发中，少不了系统参数配置信息。通常我们会将信息写入配置文件中。但是如果有很多个服务或应用需要配置，并且每个服务还分为开发、测试、生产等不同维度的配置，那配置量还是很大的。当然，我们也可以将配置信息放入Redis、db、zookeeper等，然后开发一个管理界面进行管理。但是这无疑增加了额外的工作成本。 在spring cloud中，为我们提供了分布式配置管理功能，我们只需稍加配置即可使用。使用spring cloud来实现分布式配置管理功能大致需要如下几步：1、创建配置文件仓库Spring cloud使用git或svn存放配置文件，默认情况下使用git，因此你需要安装git私服或者直接使用互联网上的github或者git.oschina，这里使用的git.oschina。创建一个空的module，取名cloud-config-repo，另外创建2个配置文件，名字分别为cloud-config-dev.properties和cloud-config-test.properteis。这两个文件分别对应开发环境和测试环境所需要的配置信息，配置信息如下：123456mysqldb.datasource.url=jdbc\:mysql\://192.168.74.135\:3306/test?useUnicode\=true&amp;characterEncoding\=utf-8mysqldb.datasource.username=rootmysqldb.datasource.password=123456logging.level.org.springframework.web:DEBUGmy.custom.message=Hello,This message is from cloud-config-repo! 如上，配置文件包含了mysql的数据库连接信息和一条自定义的message。 然后提交到git.oschina。 2、创建spring cloud配置服务器配置服务器的作用是从远程git或svn仓库中提取配置信息，并提供rest接口给外部调用。这个功能是spring cloud提供的，我们只需引入相关的jar包，并稍微设置一下即可。 创建一个module，并取名为cloud-config-server。在pom文件中增加配置服务器的相关依赖：1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; application.properteis文件配置如下：123server.port=8888spring.cloud.config.server.git.uri=https://gitee.com/qincd/springcloud-demos.gitspring.cloud.config.server.git.searchPaths=cloud-config-repo 其中server.port是配置当前web应用绑定8888端口，git.uri指定配置文件所在的git工程路径，searchPaths表示将搜索该文件夹下的配置文件（我们的配置文件放在springcloud-demos这个工程的cloud-config-repo文件夹下） 在spring boot应用启动类中增加@EnableConfigServer，激活该应用为配置文件服务器。123456789@SpringBootApplication@EnableConfigServerpublic class App&#123; public static void main( String[] args ) &#123; SpringApplication.run(App.class, args); &#125;&#125; 然后启动cloud-config-server，浏览器输入http://127.0.0.1:8888/cloud-config-dev.properties，可以看到已经获取到配置信息，如图： 3、创建一个服务使用该远程配置创建一个module，取名为cloud-config-client，来从cloud-config-server获取配置信息使用。 这里我们使用mysql的配置信息来获取用户的信息，以及显示自定义的1条消息。 相关依赖如下：12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.45&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt;&lt;/dependency&gt; 在resources下新增bootstrap.properteis文件，123spring.cloud.config.uri=http://127.0.0.1:$&#123;config.port:8888&#125;spring.cloud.config.name=cloud-configspring.cloud.config.profile=$&#123;config.profile:dev&#125; 其中config.uri指定远程加载配置信息的地址，就是前面我们刚建立的配置管理服务器的地址，绑定端口8888，其中config.port:8888，表示如果在命令行提供了config.port参数，我们就用这个端口，否则就用8888端口。config.name表示配置文件名称，查看我们前面创建配置文件，是这个名称：cloud-config-dev.properties可以分成两部分: {application}- {profile}.properties 所以我们配置config.name为cloud-config，config.profile为dev，其中dev表示开发配置文件，配置文件仓库里还有一个测试环境的配置文件，切换该配置文件只需要将dev改为test即可，当然这个参数也可以由启动时命令行传入，如：java -jar cloud-simple-service-1.0.0.jar –config.profile =test此时应用就会加载测试环境下的配置信息。 application.properties:1234567891011121314151617server.port=8080#DB Configuration:spring.datasource.driverClassName = com.mysql.jdbc.Driverspring.datasource.url = $&#123;mysqldb.datasource.url&#125;spring.datasource.username = $&#123;mysqldb.datasource.username&#125;spring.datasource.password = $&#123;mysqldb.datasource.password&#125;#JPA Configuration:spring.jpa.database=MySQLspring.jpa.show-sql=truespring.jpa.generate-ddl=truespring.jpa.hibernate.ddl-auto=update#spring.jpa.database-platform=org.hibernate.dialect.MySQL5Dialectspring.jpa.hibernate.naming_strategy=org.hibernate.cfg.ImprovedNamingStrategy#spring.jpa.database=org.hibernate.dialect.MySQL5InnoDBDialect#spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MYSQL5Dialect 数据库的一张user表数据如下： 定义一个实体类User1234567891011121314151617181920212223@Entity@Table(name = "user")public class User &#123; @Column @Id private String id; @Column(name = "user_id") private String userId; @Column private String username; @Column private String password; @Column(name = "user_image") private String userImage; @Column private String name; @Column private String summary; @Column private String email; @Column private Long createdAt;&#125; 增加一个根据username获取用户想信息的方法：1234@Repositorypublic interface UserDao extends CrudRepository&lt;User,String&gt; &#123; User findByUsername(String username);&#125; 12345678@Servicepublic class UserService &#123; @Autowired private UserDao userDao; public User findByUsername(String username) &#123; return userDao.findByUsername(username); &#125;&#125; 1234567891011121314@Controller@RequestMapping("/user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping("/&#123;username&#125;") @ResponseBody public User findUserByUsername(@PathVariable String username) throws Exception &#123; if (StringUtils.isEmpty(username)) &#123; throw new Exception("参数不能为空！"); &#125; return userService.findByUsername(username); &#125;&#125; 再增加一个获取自定义配置信息的Service12345678@Servicepublic class ConfigService &#123; @Value("$&#123;my.custom.message&#125;") private String msg; public String getCustomMsg() &#123; return this.msg; &#125;&#125; OK，准备工作完毕！下面进行测试。 启动cloud-config-server和cloud-config-client应用。1.数据库配置测试浏览器输入http://127.0.0.1:8080/user/admin，结果如下：可以看到获取到了用户信息，即说明已经使用了远程参考的数据库配置信息。 2.自定义消息测试我们新建一个测试类来进行测试1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class AppTest &#123; @Autowired private ConfigService configService; @Test public void testGetCustomMsg() &#123; String msg = configService.getCustomMsg(); assertNotNull(msg); System.out.println(msg); &#125;&#125; 运行该测试类，执行结果如下：说明已经获取到了远程参考中定义的自定义配置。 代码：https://gitee.com/qincd/springcloud-demos/ 说明：本文参照使用spring cloud实现分布式配置管理进行测试。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BlueLake主题增加gitment评论]]></title>
    <url>%2F2018%2F04%2F03%2Fhexo-bluelake-theme-use-gitment%2F</url>
    <content type="text"><![CDATA[1.注册 OAuth Application点击此处 来注册一个新的 OAuth Application。其他内容可以随意填写，但要确保填入正确的 callback URL（一般是评论页面对应的域名，如 https://imsun.net）。如果使用的github地址跳转到http://tommy88.top，则填写http://tommy88.top。 你会得到一个 client ID 和一个 client secret，这个将被用于之后的用户登录。 2.在BlueLake主题的_config.yml中增加gitment的配置12345678910111213gitment: enable: true # 是否开启gitment评论系统 mint: true # count: true # 是否显示评论数 lazy: true # 懒加载，设置为ture时需手动展开评论 cleanly: true # 是否隐藏&apos;Powered by ...&apos; language: en # 语言，置空则随主题的语言 github_user: luckystar88 # Github用户名 github_repo: comments # 在Github新建一个仓库用于存放评论，这是仓库名 client_id: beecde0acb47cc10965c # 注册OAuth Application时生成 client_secret: 2a7655badd4d1e416000a3abc4b0676e5c70577f # 注册OAuth Application时生成 proxy_gateway: # Address of api proxy, See: https://github.com/aimingoo/intersect redirect_protocol: # Protocol of redirect_uri with force_redirect_protocol when mint enabled 3.在comments_js.jade中增加gitment配置1234567891011121314if theme.gitment.enable link(rel=&apos;stylesheet&apos;,href=&apos;https://imsun.github.io/gitment/style/default.css&apos;) script(src=&apos;https://imsun.github.io/gitment/dist/gitment.browser.js&apos;) script. var gitment = new Gitment(&#123; id: &apos;#&#123;page.path&#125;&apos;, // 可选。默认为 location.href owner: &apos;#&#123;theme.gitment.github_user&#125;&apos;, repo: &apos;#&#123;theme.gitment.github_repo&#125;&apos;, oauth: &#123; client_id: &apos;#&#123;theme.gitment.client_id&#125;&apos;, client_secret: &apos;#&#123;theme.gitment.client_secret&#125;&apos;, &#125;, &#125;); gitment.render(&apos;comments&apos;) 注意：BlueLake主题使用的容器是base.jade中的id=comments的div，所以这里gitment.render的id不是自己创建的容器。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用socket模拟tomcat实现静态资源处理]]></title>
    <url>%2F2018%2F03%2F30%2Fuse-socket-mock-tomcat-handle-static-resources%2F</url>
    <content type="text"><![CDATA[步骤：1.服务端使用ServerSocket，监听指定的端口。2.调用ServerSocket的accept方法接收客户端连接，得到Socket对象。3.根据Socket对象的getInputStream()方法得到输入流，从而拿到浏览器发送的http请求的基本信息。12345678910GET /htmlfiles/test2.jsp HTTP/1.1Host: localhost:9191Connection: keep-aliveUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8DNT: 1Accept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.9Cookie: Hm_lvt_9bd56a6d0766b887592ee921aa94763f=1500436957; __atuvc=47%7C35; _ga=GA1.1.2016651800.1504071340; Hm_lvt_4e003ba2028a4a83d95714c602ee7df5=1507970222; Hm_lvt_47acec2d282c3986f1b600abdc11c7ab=1520665960,1521097911,1521252255,1521540649 4.解析http请求，提取要访问的资源文件的位置，使用Socket的getOutputStream拿到输出流，将文件的内容写到输出流。5.资源请求完毕，关闭相关的流和Socket。 代码1234567891011121314151617181920212223242526272829public class Server &#123; public static void main(String[] args) &#123; ServerSocket serverSocket = null; Socket socket = null; try &#123; serverSocket = new ServerSocket(9191); System.out.println("Server已在端口9191启动！"); while (true) &#123; socket = serverSocket.accept(); InputStream inputStream = socket.getInputStream(); Request request = new Request(inputStream); OutputStream outputStream = socket.getOutputStream(); Response response = new Response(outputStream, request); response.response(); outputStream.close(); inputStream.close(); socket.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; serverSocket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425public class Request &#123; private String uri; public Request(InputStream in) &#123; try &#123; String content = IOUtils.getRequestContent(in); if (null == content || "".equals(content)) &#123; System.out.println("Bad request."); return; &#125; System.out.println("客户端请求：\n" + content); parseUri(content); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void parseUri(String content) &#123; this.uri = content.substring(content.indexOf("/"),content.indexOf("HTTP/")-1); &#125; public String getUri() &#123; return uri; &#125; public void setUri(String uri) &#123; this.uri = uri; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Response &#123; private Request request; private OutputStream os; public Response(OutputStream os, Request request) &#123; this.os = os; this.request = request; &#125; public void response() &#123; String uri = request.getUri(); if (null != uri &amp;&amp; !"".equals(uri)) &#123; if (isResource()) &#123; String path = Http_Server.WEB_ROOT + uri.substring(1); if (IOUtils.isFileExist(path)) &#123; IOUtils.writeFile(os, path); &#125; else &#123; String errorMessage = buildResponse("File Not Found","404",""); IOUtils.write(os, errorMessage.getBytes()); &#125; &#125; else &#123; String errorMessage = buildResponse("动态请求暂不支持","200","OK"); IOUtils.write(os, errorMessage.getBytes()); &#125; &#125; &#125; private String buildResponse(String content, String statusCode, String statusMsg) &#123; String html = buildHTML(content); int chineseCount = StringUtils.getChineseCharCount(html); StringBuffer buffer = new StringBuffer(); buffer.append("HTTP/1.1 ") .append(statusCode).append(" ") .append(statusMsg).append("\r\n") .append("Content-Type: text/html\r\n")// .append("Content-Length: ")// .append(html.length()+2*chineseCount) // 1个中文字符占3个字节 .append("\r\n\r\n") .append(html); return buffer.toString(); &#125; private String buildHTML(String content) &#123; StringBuffer html = new StringBuffer(); html.append("&lt;html&gt;\n"); html.append("&lt;head&gt;\n"); html.append("&lt;meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"&gt;\n"); html.append("&lt;/head&gt;\n"); html.append("&lt;body&gt;\n"); html.append("&lt;h1&gt;").append(content).append("&lt;/h1&gt;\n"); html.append("&lt;/body&gt;\n"); html.append("&lt;/html&gt;"); return html.toString(); &#125; private boolean isResource() &#123; String[] suffixs = &#123;"html", "js", "css", "jpg", "jpeg", "gif", "bmp"&#125;; for (String suf : suffixs) &#123; if (request.getUri().endsWith("." + suf)) &#123; return true; &#125; &#125; return false; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class IOUtils &#123; public static String getRequestContent(InputStream inputStream) throws IOException &#123; byte[] data = new byte[2048]; int len = inputStream.read(data); if (len &gt; 0) &#123; return new String(data,0,len); &#125; return null; &#125; public static boolean isFileExist(String path) &#123; File file = new File(path); return file.exists(); &#125; public static byte[] getFileContent(String path) &#123; try &#123; File file = new File(path); if (file.exists()) &#123; byte[] data = new byte[(int) file.length()]; FileInputStream fis = new FileInputStream(file); fis.read(data); return data; &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; public static void write(OutputStream os,byte[] data) &#123; try &#123; os.write(data); os.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void writeFile(OutputStream os,String path) &#123; FileInputStream fis = null; try &#123; int BUFFER_SIZE = 1024; fis = new FileInputStream(path); byte[] data = new byte[BUFFER_SIZE]; int len = fis.read(data,0,BUFFER_SIZE); boolean isFirst = true; while (len != -1) &#123; if (isFirst) &#123; os.write("HTTP/1.0 200 OK\r\n".getBytes()); os.write("\r\n".getBytes());;// 根据 HTTP 协议, 空行将结束头信息 isFirst = false; &#125; os.write(data,0,len); len = fis.read(data,0,BUFFER_SIZE); os.flush(); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (fis != null) &#123; try &#123; fis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 123public class Http_Server &#123; public final static String WEB_ROOT = Http_Server.class.getResource("/").getPath();&#125; 测试HTML123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;测试页面&lt;/title&gt; &lt;link href="/htmlfiles/css/test.css" rel="stylesheet"&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;这是测试页面。&lt;br&gt;&lt;/h1&gt; &lt;a href="http://localhost:9191/htmlfiles/images/1.jpg"&gt;点击打开图片&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 资源文件放在src目录下。如图： 测试1.动态请求测试 2.不存在的静态文件 3.存在的静态文件 4.图片等二进制文件测试 注意1.你得通过响应头告诉浏览器请求的状态码和资源类型，否则浏览器会告诉你这是无效的http响应。12os.write("HTTP/1.0 200 OK\r\n".getBytes());os.write("\r\n".getBytes());;// 根据 HTTP 协议, 空行将结束头信息 2.如果指定了Content-Length，需要注意中文1个字符占用3个字节，否则会导致浏览器显示不全。12buffer.append("Content-Length: ")buffer.append(html.length()+2*chineseCount) // 1个中文字符占3个字节]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql分库分区分表]]></title>
    <url>%2F2018%2F03%2F28%2Fmysql-pool-partiion-table%2F</url>
    <content type="text"><![CDATA[分库分表、分区、读写分离 这些都是用在什么场景下 ，会带来哪些效率或者其他方面的好处https://segmentfault.com/q/1010000009044121 mysql 分表，分区，分库相关及merge引擎https://blog.csdn.net/mengfanzhong/article/details/55107106]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HttpClient进行https请求]]></title>
    <url>%2F2018%2F03%2F22%2FHttpClient-https%2F</url>
    <content type="text"><![CDATA[并不是所有的https请求都需要按照下面的代码进行设置，如果遇到下面的问题，则需要这么做。 javax.net.ssl.SSLException: hostname in certificate didn’t match: 采用绕过验证的方式处理https请求需要指定信任所有证书，并指定不校验域名。 DefaultHttpClient代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public static DefaultHttpClient getHttpClient(String url, Proxy proxy) throws Exception &#123; SSLSocketFactory sf = new SSLSocketFactory(new TrustStrategy() &#123; // 信任所有 @Override public boolean isTrusted(java.security.cert.X509Certificate[] x509Certificates, String s) throws java.security.cert.CertificateException &#123; return true; &#125; &#125;); sf.setHostnameVerifier(SSLSocketFactory.ALLOW_ALL_HOSTNAME_VERIFIER); // 连接池设置 SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", 80, PlainSocketFactory.getSocketFactory())); schemeRegistry.register(new Scheme("https", 443, sf)); PoolingClientConnectionManager cm = new PoolingClientConnectionManager(schemeRegistry); cm.setMaxTotal(200); // 连接池里的最大连接数 cm.setDefaultMaxPerRoute(20); // 每个路由的默认最大连接数 // 其它设置 DefaultHttpClient httpClient = new DefaultHttpClient(cm); CookieStore cookieStore = httpClient.getCookieStore(); // 添加语言cookie BasicClientCookie2 langCookie = new BasicClientCookie2("LangKey", "cs"); langCookie.setVersion(0); langCookie.setDomain(Utility.getPurceHost(url)); langCookie.setPath("/"); cookieStore.addCookie(langCookie); HttpRequestRetryHandler myRetryHandler = new HttpRequestRetryHandler() &#123; public boolean retryRequest(IOException exception, int executionCount, HttpContext context) &#123; if (executionCount &gt;= 3) &#123; // 如果超过最大重试次数，那么就不要继续了 return false; &#125; if (exception instanceof NoHttpResponseException) &#123; // 如果服务器丢掉了连接，那么就重试 return true; &#125; if (exception instanceof SSLHandshakeException) &#123; // 不要重试SSL握手异常 return false; &#125; HttpRequest request = (HttpRequest) context .getAttribute(ExecutionContext.HTTP_REQUEST); boolean idempotent = !(request instanceof HttpEntityEnclosingRequest); if (idempotent) &#123; // 如果请求被认为是幂等的，那么就重试 return true; &#125; return false; &#125; &#125;; httpClient.setHttpRequestRetryHandler(myRetryHandler); // 设置读取超时时间 httpClient.getParams().setIntParameter("http.socket.timeout", SnatchConstant.TIMEOUT); // 设置连接超时超时 httpClient.getParams() .setIntParameter(HttpConnectionParams.CONNECTION_TIMEOUT, SnatchConstant.TIMEOUT); // 添加代理 if (null != proxy) &#123; if (proxy.getUsed() == 1) &#123; String ip = proxy.getIp();// 代理ip int port = proxy.getPort();// 代理端口 String proxyUserName = proxy.getUsername();// 代理账号用户名 String proxyPassword = proxy.getPassword();// 代理账号密码 if (!(Utility.isNull(ip) || port &lt;= 0)) &#123; // 访问的目标站点，端口和协议 httpClient.getCredentialsProvider().setCredentials( new AuthScope(ip, port), new UsernamePasswordCredentials(proxyUserName, proxyPassword)); // 代理的设置 HttpHost proxyHost = new HttpHost(ip, port); httpClient.getParams().setParameter( ConnRoutePNames.DEFAULT_PROXY, proxyHost); &#125; &#125; &#125; return httpClient;&#125; CloseableHttpClient如果是CloseableHttpClient，可以使用下面的代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public static CloseableHttpClient createSSLClientDefault(String url, Proxy proxy)&#123; try &#123; CookieStore cookieStore = new BasicCookieStore(); // 添加语言cookie BasicClientCookie2 langCookie = new BasicClientCookie2("LangKey", "cs"); langCookie.setVersion(0); langCookie.setDomain(Utility.getPurceHost(url)); langCookie.setPath("/"); cookieStore.addCookie(langCookie); RequestConfig config = null; if (config == null) &#123; config = RequestConfig.custom().setConnectTimeout(SnatchConstant.TIMEOUT).setSocketTimeout(SnatchConstant.TIMEOUT).build(); &#125; SSLContext sslContext = new SSLContextBuilder().loadTrustMaterial(null, new TrustStrategy() &#123; //信任所有 @Override public boolean isTrusted(java.security.cert.X509Certificate[] x509Certificates, String s) throws java.security.cert.CertificateException &#123; return true; &#125; &#125;).build(); SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(sslContext); return HttpClients.custom().setSSLSocketFactory(sslsf).setDefaultCookieStore(cookieStore).setDefaultRequestConfig(config).setRetryHandler((new HttpRequestRetryHandler() &#123; @Override public boolean retryRequest(IOException exception, int executionCount, HttpContext context) &#123; if (executionCount &gt;= 3) &#123; // 如果超过最大重试次数，那么就不要继续了 return false; &#125; if (exception instanceof NoHttpResponseException) &#123; // 如果服务器丢掉了连接，那么就重试 return true; &#125; if (exception instanceof SSLHandshakeException) &#123; // 不要重试SSL握手异常 return false; &#125; HttpRequest request = (HttpRequest) context.getAttribute(ExecutionContext.HTTP_REQUEST); boolean idempotent = !(request instanceof HttpEntityEnclosingRequest); if (idempotent) &#123; // 如果请求被认为是幂等的，那么就重试 return true; &#125; return false; &#125; &#125;)).build(); &#125; catch (KeyManagementException e) &#123; e.printStackTrace(); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (KeyStoreException e) &#123; e.printStackTrace(); &#125; return HttpClients.createDefault();&#125; 参考：轻松把玩HttpClient之配置ssl，采用绕过证书验证实现https 加载证书来访问HTTPS网站DefaultHttpClient1234567891011DefaultHttpClient hc = new DefaultHttpClient();//加载证书 java.security.KeyStore trustStore = java.security.KeyStore.getInstance(java.security.KeyStore.getDefaultType()); //"123456"为制作证书时的密码 trustStore.load(new FileInputStream(new File("你的证书位置")), "123456".toCharArray()); org.apache.http.conn.ssl.SSLSocketFactory socketFactory = new org.apache.http.conn.ssl.SSLSocketFactory(trustStore); //不校验域名 socketFactory.setHostnameVerifier(org.apache.http.conn.ssl.SSLSocketFactory.ALLOW_ALL_HOSTNAME_VERIFIER); //这个8446是和被访问端约定的端口，一般为443 org.apache.http.conn.scheme.Scheme sch = new org.apache.http.conn.scheme.Scheme("https", socketFactory, 8446); hc.getConnectionManager().getSchemeRegistry().register(sch); 参考：http://blog.csdn.net/wangshfa/article/details/9059089 CloseableHttpClient1234567891011121314KeyStore trustStore = KeyStore.getInstance(KeyStore.getDefaultType()); //加载证书文件 FileInputStream instream = new FileInputStream(new File("/home/victor/my.store")); try &#123; trustStore.load(instream, "mypassword".toCharArray()); &#125; finally &#123; instream.close(); &#125; SSLContext sslcontext = SSLContexts.custom().loadTrustMaterial(trustStore).build(); SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(sslcontext, SSLConnectionSocketFactory.BROWSER_COMPATIBLE_HOSTNAME_VERIFIER); CloseableHttpClient httpclient = HttpClients.custom() .setSSLSocketFactory(sslsf) .build(); 参考：http://blog.csdn.net/wanglha/article/details/51140846]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows查看某个端口被谁占用]]></title>
    <url>%2F2018%2F03%2F22%2Fwindows-find-who-bind-a-port%2F</url>
    <content type="text"><![CDATA[参考：https://jingyan.baidu.com/article/3c48dd34491d47e10be358b8.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一位10年Java工作经验的架构师聊Java和工作经验]]></title>
    <url>%2F2018%2F03%2F22%2Fan-architect-with-10years-experience-talk-about-java-and-experience%2F</url>
    <content type="text"><![CDATA[参考：http://blog.csdn.net/lifuxiangcaohui/article/details/48342315]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[抓取WebSocket推送的消息]]></title>
    <url>%2F2018%2F03%2F21%2Fgrab-websocket-push-messages%2F</url>
    <content type="text"><![CDATA[介绍很多直播或对数据及时性要求比较高的网站，使用了WebSocket。这种数据要怎么抓呢？ 我们这里以socket.io为例，我们可以查看网站网页源代码看使用的H5的WebSocket还是socket.io等JS库。 这里以java语言为例说明。假定网站使用的是socket.io库来实现消息推送。我们如何通过java来获取服务端推送的信息呢？ socket.io提供了java的客户端实现socket.io-client。所以获取服务端推送的数据，本质是作为一个客户端连接上WebSocket server。 连接websocket server接收推送的数据首先添加依赖12345&lt;dependency&gt; &lt;groupId&gt;io.socket&lt;/groupId&gt; &lt;artifactId&gt;socket.io-client&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; ws地址的java代码12345678910111213141516171819202122232425262728293031323334final Socket socket = IO.socket("http://localhost:9098/");socket.on(Socket.EVENT_CONNECTING, new Emitter.Listener() &#123; @Override public void call(Object... objects) &#123; System.out.println("WebSocket连接中"); &#125; &#125;).on(Socket.EVENT_CONNECT, new Emitter.Listener() &#123; @Override public void call(Object... objects) &#123; System.out.println("WebSocket连接成功！"); &#125; &#125;).on("OnMSG", new Emitter.Listener() &#123; // 这里指定要接收的事件名称 @Override public void call(Object... objects) &#123; JSONObject object = (JSONObject) objects[0]; System.out.println("OnMSG:\n"+object.toString()); &#125; &#125;).on(Socket.EVENT_DISCONNECT, new Emitter.Listener() &#123; @Override public void call(Object... objects) &#123; System.out.println("WebSocket连接关闭！"); &#125; &#125;);// 连接websocket serversocket.connect();// 休眠3S后发送一条信息给websocket serverThread.sleep(3000L);if (socket.connected()) &#123; JSONObject msg = new JSONObject(); msg.put("from","jack"); msg.put("to","admin"); msg.put("content","Hello,I am jack!"); socket.emit("OnMSG", msg);&#125; 如果websocket地址是ws://localhost:9098，则在socket.io-java中地址写http://localhost:9098；如果是wss://localhost:9098，则写为https://localhost:9098. 服务端的例子参考：socketio推送技术。 wss地址的java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public HostnameVerifier getMyHostnameVerifier() &#123; return new HostnameVerifier() &#123; @Override public boolean verify(String s, SSLSession sslSession) &#123; return true; &#125; &#125;;&#125;public X509TrustManager getTrustManager() &#123; return new X509TrustManager() &#123; @Override public java.security.cert.X509Certificate[] getAcceptedIssuers() &#123; return new java.security.cert.X509Certificate[] &#123;&#125;; &#125; @Override public void checkClientTrusted(X509Certificate[] certs, String authType) &#123; &#125; @Override public void checkServerTrusted(X509Certificate[] certs, String authType) &#123; &#125; &#125;;&#125;public SSLContext createSSLContext(X509TrustManager trustManager) throws GeneralSecurityException, IOException &#123;// Security.insertProviderAt(new BouncyCastleProvider(), 1); try &#123; TrustManager[] trustAllCerts = new TrustManager[]&#123;trustManager&#125;; // Install the all-trusting trust manager SSLContext sc = SSLContext.getInstance("SSL"); sc.init(null, trustAllCerts, new java.security.SecureRandom()); return sc; &#125; catch (Exception exception) &#123; exception.printStackTrace(); &#125; return null;&#125;X509TrustManager trustManager = getTrustManager();SSLContext sslContext = createSSLContext(trustManager);HostnameVerifier myHostnameVerifier = getMyHostnameVerifier();OkHttpClient okHttpClient = new OkHttpClient.Builder() .hostnameVerifier(myHostnameVerifier) .sslSocketFactory(sslContext.getSocketFactory(), trustManager) .build();// default settings for all socketsIO.setDefaultOkHttpWebSocketFactory(okHttpClient);IO.setDefaultOkHttpCallFactory(okHttpClient);// set as an optionIO.Options opts = new IO.Options();opts.callFactory = okHttpClient;opts.webSocketFactory = okHttpClient;opts.port = 443;opts.secure = true;final Socket socket = IO.socket("http://localhost:9098/", opts);...其他部分的代码参考ws部分 在浏览器中，在websocket请求的Frames部分是发送和接收到消息。如图：向上箭头（绿色）表示向websocket server发送的消息，向下箭头（红色）表示接收的消息。 注意有些网站可能对url上加了token或其他参数验证，防止不可靠的连接，一般比如会员登录后，生成token并发起websocket连接。这就需要自己处理token。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>推送技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap的实现原理]]></title>
    <url>%2F2018%2F03%2F20%2FHashMap-realization-principle%2F</url>
    <content type="text"><![CDATA[在java中，HashMap是一种重要的数据结构，它的底层实际上是一个数组，数组的每个元素是一个链表。 在添加元素的时候，会根据hash函数计算出在数组中的下标。如果数组中该下标有元素存在，则将当前元素覆盖之前的元素；之前的元素则放到当前元素的下一个元素。如果数组中该位置没有元素，则直接放到该位置。 元素个数默认是16，加载因子是0.75，当元素的个数达到数组容量*加载因子时，会进行扩容（容量增加一倍）。 在构造HashMap时，会进行容量的计算，以及数组的初始化。123456// 默认数组容量static final int DEFAULT_INITIAL_CAPACITY = 16;// 默认加载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;// 保存数据的数组transient Entry[] table; HashMap的构造方法：1234567891011121314151617181920212223242526272829303132public HashMap(int initialCapacity, float loadFactor) &#123; // 参数检查 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); // Find a power of 2 &gt;= initialCapacity // 找出一个&gt;=指定容量的数，该数必须是2的N次方。比如指定的容量是10，则最终capacity=16 int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; this.loadFactor = loadFactor; // 数组进行扩容的阀值 threshold = (int)(capacity * loadFactor); table = new Entry[capacity]; init();&#125;public HashMap(int initialCapacity) &#123; // 使用指定的容量和默认加载因子构造HashMap this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap() &#123; // 不指定参数，则使用默认的容量和加载因子构造HashMap this.loadFactor = DEFAULT_LOAD_FACTOR; threshold = (int)(DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR); table = new Entry[DEFAULT_INITIAL_CAPACITY]; init();&#125; HashMap的hash函数：1234567static int hash(int h) &#123; // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 一个好的hash函数，应该最大限度的保证key与value一一对应，即保证数组的每个位置上都只有一个元素，不用再去遍历链表，这样查找和添加的速度都是最快的。 计算元素在数组中的索引：123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 注意：h是上面经过对key经过hash之后的值。 看下HashMap的put方法：123456789101112131415161718public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null;&#125; 可以看到，HashMap支持null作为key。看下putForNullKey的处理。12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; key=null的元素放在数组的首位，替换key=null的元素的value，返回原来的value。 如果key不是null，首先通过hash函数计算key的hash值，然后通过indexFor计算在数组中的下标。然后遍历计算的数组下标的元素的链表，如果存在key=传入的key的元素，则覆盖原来的value，并返回原来的value。 如果在计算的数组索引位置的链表结构上没有找到key为传入key的元素，则执行addEntry方法。 123456void addEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); if (size++ &gt;= threshold) resize(2 * table.length);&#125; 在addEntry中，首先拿到通过hash函数计算到的数组相应index的元素，然后构造一个新的Entry对象，放到数组的index位置。如果数组元素的个数达到阀值（即数组容量*负载因子），则将数组容量扩容2倍。 1234567891011121314151617181920212223242526272829void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);&#125;void transfer(Entry[] newTable) &#123; Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; src[j] = null; do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; while (e != null); &#125; &#125;&#125; 主要看transfer方法，遍历原数组的每个元素，如果某个位置有元素，则遍历该链表结构上的所有元素，重新计算在数组的下标，并放到新数组中。 get方法更put类似，先通过hash函数对key进行hash，然后通过indexFor得到在数组的位置。然后遍历数组中该位置的链表上的所有元素，找出key为传入的key的元素，返回。 HashMap其中有些设计很精妙，比如数组的容量为何是2的N次方？hash函数和indexFor函数。详细可以参考：HashMap的实现原理 下来来一个简易版的HashMap实现。 1234public interface MyMap&lt;K, V&gt; &#123; V put(K k, V v); V get(K k);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155public class MyHashMap&lt;K, V&gt; implements MyMap&lt;K, V&gt; &#123; // 计算当前数组元素的个数，hash计算后index相同的元素只作为一个计算。 private int size; // 默认负载因子 private static double defaultLoader = 0.75; // 默认容量 private static int defaultCapacity = 16; // 实际使用的加载因子 private double loader; // 实际的数组容量 private int capacity = 1; // 保存Map元素的数组 private Entry&lt;K, V&gt;[] table = null; public MyHashMap(int capacity, double loader) &#123; this.loader = loader; // 找出一个刚好大于给定元素个数的数作为数组的容量 // 比如指定capactiy为10，则实际容量是16. while (this.capacity &lt; capacity) &#123; this.capacity = this.capacity &lt;&lt; 1; &#125; System.out.println("capacity is :" + this.capacity); table = new Entry[this.capacity]; &#125; public MyHashMap(int capacity) &#123; this(capacity,defaultLoader); &#125; public MyHashMap() &#123; // 不指定容量和加载因子，则使用默认的 this(defaultCapacity, defaultLoader); &#125; @Override public V put(K k, V v) &#123; // 当元素的个数达到数组的容量*负载因子时，进行扩容。 if (size &gt; this.capacity * this.loader) &#123; expand(); &#125; // 根据hash函数计算K在数组中的下标 int index = getIndex(k); // 计算出的数组下标的元素 Entry&lt;K, V&gt; entry = table[index]; // entry为null，说明当前数组index位置还没有元素 if (entry == null) &#123; entry = new Entry(k, v, null); table[index] = entry; // 添加元素后，size计数器加1 size++; &#125; else &#123; // 说明，数组index位置已经有元素 // 将原来index位置的元素作为新元素的next，即新元素覆盖老元素，老元素作为新元素的下一个元素。 Entry&lt;K,V&gt; newEntry = new Entry(k, v, entry); // 新元素覆盖老元素的位置。 table[index] = newEntry; // 注意这里，size并不会增加，因为该位置原来有元素，新的元素只是增加到链表上而已。 &#125; // 这里返回的是新元素的value，即返回的是要put的元素 return table[index].getValue(); &#125; @Override public V get(K k) &#123; // 根据hash函数计算K在数组中的下标 int index = getIndex(k); // 如果下标超出当前记录的数组的index，或者数组该位置没有元素，直接返回null。 if (table[index] == null) &#123; return null; &#125; // 计算的数组index位置的元素 Entry&lt;K, V&gt; entry = table[index]; // 上面已经处理了entry为null的情况，这里next为null，说明数组index位置只有一个元素，直接返回 if (entry.next == null) &#123; return entry.getValue(); &#125; else &#123; // 链表上所有元素在数组的下标一样，但key不一样。这里需要遍历所有链表上的元素确定是哪个元素 while (entry != null) &#123; Entry&lt;K, V&gt; oldEntry = entry; entry = entry.next; if (oldEntry.getKey() == k || k.equals(oldEntry.getKey())) &#123; return oldEntry.getValue(); &#125; &#125; &#125; return null; &#125; /** * 计算Key在数组的下标 * @param k * @return */ private int getIndex(K k) &#123; int index = k.hashCode() % this.capacity; return index &gt;= 0 ? index : -index; &#125; /** * 扩容方法。将数组容量扩大一倍。原来的数据重新计算在数组的位置。 */ private void expand() &#123; this.size = 0; this.capacity = this.capacity * 2; Entry&lt;K, V&gt;[] newTable = new Entry[this.capacity]; List&lt;Entry&lt;K, V&gt;&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; this.table.length; i++) &#123; // 数组的某个位置元素为空不处理。 if (table[i] == null) &#123; continue; &#125; Entry&lt;K, V&gt; entry = table[i]; // 当前数组位置只有一个元素，链表上没有其他数据 if (entry.next == null) &#123; list.add(entry); &#125; else &#123; // 添加链表上所有的元素 while (entry != null) &#123; Entry&lt;K, V&gt; oldEntry = entry; entry = entry.next; // 这里将当前元素的下一个元素设置为null，重新计算next。 oldEntry.next = null; list.add(oldEntry); &#125; &#125; &#125; // 重新计算元素在数组的index for (int i = 0; i &lt; list.size(); i++) &#123; Entry&lt;K, V&gt; entry = list.get(i); this.put(entry.getKey(), entry.getValue()); &#125; this.table = newTable; &#125; /** * 链表结构，存储数组的元素key,value和下一个元素 * * @author Administrator * * @param &lt;K&gt; * @param &lt;V&gt; */ class Entry&lt;K, V&gt; &#123; // key K k; // value V v; // 下一个元素，即通过hash函数计算出index相同的元素 Entry&lt;K, V&gt; next; public Entry(K k, V v, Entry&lt;K, V&gt; next) &#123; this.k = k; this.v = v; this.next = next; &#125; public V getValue() &#123; return v; &#125; public K getKey() &#123; return k; &#125; &#125;&#125; 测试类：12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) &#123; Long t1 = System.currentTimeMillis(); MyMap&lt;String, String&gt; myMap = new MyHashMap&lt;&gt;(1000); for (int i = 0; i &lt; 1000; i++) &#123; myMap.put("key" + i, "value" + i); &#125; for (int i = 0; i &lt; 1000; i++) &#123; System.out.println("key" + i + " value:" + myMap.get("key" + i)); &#125; Long t2 = System.currentTimeMillis(); System.out.println("自己写的HashMap耗时：" + (t2-t1)); System.out.println("======================HashMap=========================="); Long t3 = System.currentTimeMillis(); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(1000); for (int i = 0; i &lt; 1000; i++) &#123; map.put("key" + i, "value" + i); &#125; for (int i = 0; i &lt; 1000; i++) &#123; System.out.println("key" + i + " value:" + map.get("key" + i)); &#125; Long t4 = System.currentTimeMillis(); System.out.println("JDK的HashMap耗时：" + (t4-t3)); &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程之wait、notify、notifyAll]]></title>
    <url>%2F2018%2F03%2F17%2Fjava-multi-thread-wait_notify_notifyAll%2F</url>
    <content type="text"><![CDATA[在java中，线程间通信可以使用wait、notify、notifyAll来进行控制。注意：这3个方法是Object的方法。 在调用一个对象的wait、notify、notifyAll方法时，必须持有该对象的锁。否则会报下面的错误：123Exception in thread &quot;Thread-1&quot; java.lang.IllegalMonitorStateException at java.lang.Object.notify(Native Method) at com.tommy.core.test.threadtest.SubThread.run(Test1.java:58) 多个线程都持有同一个对象的时候，如果都要进入synchronized(obj){……}的内部，就必须拿到这个对象的锁，synchronized的机制保证了同一时间最多只能有1个线程拿到了对象的锁.wait：线程自动释放其占有的对象锁，并等待notifynotify：唤醒一个正在wait当前对象锁的线程，并让它拿到对象锁notifyAll：唤醒所有正在wait前对象锁的线程 notify和notifyAll的最主要的区别是：notify只是唤醒一个正在wait当前对象锁的线程，而notifyAll唤醒所有。值得注意的是：notify是本地方法，具体唤醒哪一个线程由虚拟机控制；notifyAll后并不是所有的线程都能马上往下执行，它们只是跳出了wait状态，接下来它们还会是竞争对象锁。 永远在循环（loop）里调用 wait 和 notify，不是在 If 语句。原因参考：如何在 Java 中正确使用 wait, notify 和 notifyAll – 以生产者消费者模型为例 下面通过一个IBM的多线程面试题来说明。实现的功能是：主线程和子线程一次执行1次，共执行10次。 共享资源对象1234class R &#123; // true：主线程运行标志；false：子线程运行标志。 boolean masterRunFlag = true;&#125; 主线程：123456789101112131415161718192021222324252627282930class MasterThread extends Thread &#123; private R r; public MasterThread(R r) &#123; this.r = r; &#125; @Override public void run() &#123; int i = 0; while (true) &#123; synchronized (r) &#123; if (i == 10) &#123; break; &#125; while (!r.masterRunFlag) &#123; try &#123; System.out.println("主线程等待执行.flag="+r.masterRunFlag); r.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; r.masterRunFlag = false; System.out.println("主线程第" + (i + 1) + "次执行。flag="+r.masterRunFlag); i++; r.notify(); &#125; &#125; System.out.println("主线程执行完毕。。。。"); &#125;&#125; 子线程：123456789101112131415161718192021222324252627282930class SubThread extends Thread &#123; private R r; public SubThread(R r) &#123; this.r = r; &#125; @Override public void run() &#123; int i = 0; while (true) &#123; if (i == 10) &#123; break; &#125; synchronized (r) &#123; while (r.masterRunFlag) &#123; try &#123; System.out.println("子线程等待执行。flag="+r.masterRunFlag); r.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; r.masterRunFlag = true; System.out.println("子线程第" + (i + 1) + "次执行完毕。flag="+r.masterRunFlag); i++; r.notify(); &#125; &#125; System.out.println("子线程执行完毕。。。。"); &#125;&#125; 测试类：123456789public class Test1 &#123; public static void main(String[] args) &#123; R r = new R(); MasterThread mt = new MasterThread(r); SubThread st = new SubThread(r); mt.start(); st.start(); &#125;&#125; 执行结果：12345678910111213141516171819202122232425262728293031323334353637383940主线程第1次执行。flag=false主线程等待执行.flag=false子线程第1次执行完毕。flag=true子线程等待执行。flag=true主线程第2次执行。flag=false主线程等待执行.flag=false子线程第2次执行完毕。flag=true子线程等待执行。flag=true主线程第3次执行。flag=false主线程等待执行.flag=false子线程第3次执行完毕。flag=true子线程等待执行。flag=true主线程第4次执行。flag=false主线程等待执行.flag=false子线程第4次执行完毕。flag=true子线程等待执行。flag=true主线程第5次执行。flag=false主线程等待执行.flag=false子线程第5次执行完毕。flag=true子线程等待执行。flag=true主线程第6次执行。flag=false主线程等待执行.flag=false子线程第6次执行完毕。flag=true子线程等待执行。flag=true主线程第7次执行。flag=false主线程等待执行.flag=false子线程第7次执行完毕。flag=true子线程等待执行。flag=true主线程第8次执行。flag=false主线程等待执行.flag=false子线程第8次执行完毕。flag=true子线程等待执行。flag=true主线程第9次执行。flag=false主线程等待执行.flag=false子线程第9次执行完毕。flag=true子线程等待执行。flag=true主线程第10次执行。flag=false主线程执行完毕。。。。子线程第10次执行完毕。flag=true子线程执行完毕。。。。 注意：主线程（生产者）和子线程（消费者）的执行次数必须相同。因为主线程和子线程的执行都依赖对方改变masterRunFlag的状态。所以这里主线程执行10次，子线程也必须执行10次。 生产者、消费者模型，可以参考：https://www.jianshu.com/p/f7d4819b7b24]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware虚拟机安装]]></title>
    <url>%2F2018%2F03%2F15%2Fvmware-install%2F</url>
    <content type="text"><![CDATA[准备VMWare14和CentOS系统镜像文件。 安装VMWare一路next直到完成，可能花费时间较长。 安装虚拟机1.选择“文件”-&gt;”新建虚拟机“-&gt;“典型”-&gt;“稍后安装操作系统”-&gt;”Linux“-&gt;”CentOS 6 64位“（这里根据你准备的CentOS版本选择）-&gt;虚拟机的名字（随便填）-&gt;最大磁盘大小（就默认20G即可）-&gt;”完成“。 2,选择左侧的虚拟机，右键“设置”，设置内存为2G，CD/DVD选择你的镜像文件，最后点完成。 3.点击左侧的虚拟机，然后在右边点“开启此虚拟机”进行系统安装。在出现的操作选择的页面中，选择第一个Install or update…（用方向键选择），然后用TAB确定，最后按Enter。第一步Media Check,这个根据需要安装，我们这里就不管了，直接忽略。后面基本一路next，最后设置密码，然后安装完毕后，要重启才能生效。 为虚拟机分配静态IP参考：http://blog.csdn.net/xiaoyangsavvy/article/details/73718473 使用远程工具连接虚拟机参考：http://blog.csdn.net/xiaoyangsavvy/article/details/73718473 问题：xshell无法连接虚拟机昨天安装虚拟机后，可以使用xshell连接虚拟机，今天就不能访问了。在主机中ping虚拟机的IP提示“TTL 传输中过期”，如图： 百度了一通没用，但可以 参考一下：解决ping域名时出现“TTL传输中过期”的问题 最后增加了一个端口转发成功。将主机的2222映射到虚拟机的22端口。参考：远程连接win7上VMWare安装的linux虚拟机、windows下使用远程工具登录虚拟机上的Linux、访问虚拟机上的服务 、端口转发、win7 telnet登陆虚拟机 ===========================================解决：启动虚拟机前，确保网络适配器是NAT，如图： 确保下面的參数例如以下设置12ONBOOT=yesNM_CONTROLLED=yes 增加了下面的设置：123DNS1=192.168.84.2IPV6INIT=noARPCHECK=no 参考：https://www.cnblogs.com/gavanwanggw/p/6960996.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chrome浏览器必装插件]]></title>
    <url>%2F2018%2F03%2F15%2Fchrome-browser-plugins%2F</url>
    <content type="text"><![CDATA[crxMouse鼠标手势插件。 可以实现浏览器的后退、前进、向上滚动、向下滚动、关闭标签页、重新打开关闭的标签页、到底部、到顶部、刷新页面、强制刷新、到左侧标签页、到右侧标签页、新建窗口、关闭窗口、进入扩展设置页。 IDM Integration Module浏览器默认下载工具或迅雷的替代工具。IDM使用多线程下载，可以提升你的下载速度最多5倍。并且可以监视网页视频和音频。 下载IDM的绿色版，在“选项”中将chrome浏览器加入到监视，chrome浏览器打开提示集成IDM，集成后即可替换浏览器的默认下载。后续用浏览器下载文件时会自动使用IDM下载。 Proxy SwitchySharp浏览器代理切换插件 Tampermonkey油猴，是一款免费的浏览器扩展和最为流行的用户脚本管理器。我们可以用它做很多事情，比如百度云下载大文件会要求启动百度云客户端，使用百度云直接下载助手脚本即可直接下载。 参考：http://tampermonkey.net/油猴脚本：https://greasyfork.org/zh-CN 有道词典Chrome划词插件不多说，提供了划词翻译、句子翻译功能。 谷歌访问助手访问谷歌、Gmail、youtobe的插件。不是很稳定，如果有条件，自己搭建vpn。 Advanced REST clienthttp请求测试插件。 插件安装方法如果没法通过Google的在线商店安装，可以先从http://chromecj.com/下载，然后进入扩展页，将下载的*.crx拖拽进去安装即可。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx安装与配置]]></title>
    <url>%2F2018%2F03%2F15%2Fnginx-install-and-configuration%2F</url>
    <content type="text"><![CDATA[windows上安装Linux虚拟机参考：VMware虚拟机安装 nginx安装参考：http://www.runoob.com/linux/nginx-install-setup.html 启动nginx在上面我们将nginx安装在/usr/local/nginx。通过下面的命令启动：1./sbin/nginx 启动后，在主机浏览器输入虚拟机的IP测试，如图：说明测试Ok了。 nginx负载均衡、多域名配置参考：nginx反向代理配置 nginx缓存静态文件参考：https://linux.cn/article-7726-1.html nginx session共享参考：https://cloud.tencent.com/developer/article/1041678 隐藏nginx版本号参考：https://www.cnblogs.com/toughlife/p/5475180.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说说web数据推送技术]]></title>
    <url>%2F2018%2F03%2F10%2Fweb-datapush-tecnology%2F</url>
    <content type="text"><![CDATA[页面使用定时器，定时向后端请求数据页面使用定时器，定时检查资源是否有更新在检查到资源有更新时，触发一次Ajax请求，从后端获取数据。 后端将变化的数据写入文件，页面定时请求comet利用Ajax与服务器建立http长连接查询是否有数据更新，服务器收到一个连接如果没有数据更新就阻塞这个连接不要返回给客户端，直到有新数据再返回给客户端。Web客户端，发起的连接一旦被返回，或者超时就再次建立http长连接。这样就能保证数据的即时更新，以及尽量减少服务器的计算工作。 websocketWebSocketAPI是下一代客户端-服务器的异步通信方法。该通信取代了单个的TCP套接字，使用ws或wss协议，可用于任意的客户端和服务器程序。 socket.ioSocket.IO使用检测功能来判断是否建立WebSocket连接，或者是AJAXlong-polling连接，或Flash等。可快速创建实时的应用程序。 参考：基于web的服务器push技术：comet vs websocket]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>推送技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot jsp支持]]></title>
    <url>%2F2018%2F03%2F09%2Fspringboot-jsp-support%2F</url>
    <content type="text"><![CDATA[springboot不推荐使用jsp,默认使用的是Thymeleaf模板。不过，如果你一定要使用jsp，需要做一些配置。 依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tommy.springboot.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-demo&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;jsp-demo Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;springboot.version&gt;1.5.9.RELEASE&lt;/springboot.version&gt; &lt;/properties&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!--配置servlet--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--配置jsp jstl的支持--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--对jsp的支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.properties指定jsp文件的位置在/WEB-INF/jsp/12spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jsp 应用启动类1234567891011@SpringBootApplicationpublic class Application extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(Application.class); &#125; public static void main( String[] args ) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 测试controller123456789@Controllerpublic class TestController &#123; @RequestMapping(value = &#123;"","/test"&#125;) public ModelAndView index(ModelAndView mv) &#123; mv.setViewName("/test"); mv.addObject("msg","你好，世界！"); return mv; &#125;&#125; 测试页面123456789&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt; $&#123;msg&#125;&lt;/body&gt;&lt;/html&gt; 部署测试在idea的tomcat中添加该web项目，启动tomcat。可以看到，测试成功。 注意事项由于jsp的性能比较低，而且对JSP的支持比较麻烦，spring推荐使用Thymeleaf模板，spring的官网即是使用的该模板。所以如无必要尽量还是不要使用JSP了。如果是打jar包运行，把spring-boot-start-tomcat的依赖去掉。 springboot打jar包运行相关问题1.idea多模块项目启动访问JSP404；需要指定工作目录为当前模块Run-&gt;Edit Configurations，将spring-boot启动类的Working Directory指定为$MODULE-WORKING-DIR$。 2.jar包无法读取配置文件（classpath路径）；可以使用spring的ResourcesLoader1234567@Beanpublic ResourceLoader resourceLoader() &#123; return new DefaultResourceLoader();&#125;// 使用流，不要使用FileInputStream cc = resourceLoader.getResource(classPathLocation).getInputStream(); 3.向资源文件写入数据1File file = new File(getClass().getClassLoader().getResource(URLCONFIGFILE).getFile()); 4.打成jar包后运行访问页面404a.spring-boot-maven-plugin使用1.4.2版本，并指定启动类123456789&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.2.RELEASE&lt;/version&gt; &lt;configuration&gt; &lt;mainClass&gt;com.hhly.rbnode.Application&lt;/mainClass&gt; &lt;layout&gt;JAR&lt;/layout&gt; &lt;/configuration&gt; &lt;/plugin&gt; b.将webapp下的文件拷贝到/META-INF12345678910111213141516&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/webapp&lt;/directory&gt; &lt;targetPath&gt;META-INF/resources&lt;/targetPath&gt; &lt;includes&gt; &lt;include&gt;**/**&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/**&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt;&lt;/resources&gt; 参考：https://blog.csdn.net/u013189824/article/details/80389419]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea springboot项目热更新]]></title>
    <url>%2F2018%2F03%2F09%2Fspringboot-hot-deploy%2F</url>
    <content type="text"><![CDATA[前言在项目开发过程中，常常会改动页面数据或者修改数据结构，为了显示改动效果，往往需要重启应用查看改变效果。这种开发体验无疑是很差的，Springboot为我们提供了devtools来帮助我们实现热更新。 使用springboot提供的spring-boot-devtools添加devtools依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; springboot maven插件配置1234567&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;!-- 如果没有该配置，devtools不会生效 --&gt; &lt;/configuration&gt;&lt;/plugin&gt; application.properties配置123456789#热部署生效spring.devtools.restart.enabled=true#设置重启的目录spring.devtools.restart.additional-paths=src/main/java#classpath目录下的resources文件夹内容修改不重启spring.devtools.restart.exclude=src/main/resources# 禁用缓存（开发阶段）spring.thymeleaf.cache=false 打开idea的自动make功能 查找Registry –&gt; 找到并勾选compiler.automake.allow.when.app.running 网上都是快捷键CTRL + SHIFT + A，如果不生效，在keymap中搜索registry，然后设置快捷键即可。 页面修改自动加载在application.properties中禁用了缓存后，在浏览器禁用缓存。 页面有修改就会自动加载。 启动直接运行springboot主类即可。 class只要有变动就会重启，springboot实现了自己的类加载器，该加载器加载自己写的类，另外一个加载器加载第三方的依赖。重启的时候只重启自己写的类，所以速度很快。 通过.trigger文件来触发更新上面的配置，只要文件有修改就会触发更新。有2个问题： 如果电脑配置较差，那么就会比较卡顿； 由于idea是自动保存的，可能你文件还没有修改好，这个时候重启其实是不必要的。 所以，基于上面的原因，可以通过trigger来触发。 在application.properties中增加如下配置：1234spring: devtools: restart: trigger-file: .trigger 在resources目录下新建META-INF目录，在该目录下创建.trigger文件，文件内容为空。如果要触发更新，就随便修改.trigger文件即可。 在idea集成的tomcat中运行Springbootpom.xml中打包类型修改为war1&lt;packaging&gt;war&lt;/packaging&gt; maven添加spring-boot-starter-tomcat依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 应用启动类修改12345678910111213@SpringBootApplicationpublic class App extends SpringBootServletInitializer&#123; @Override protected SpringApplicationBuilder configure( SpringApplicationBuilder application) &#123; return application.sources(App.class); &#125; public static void main( String[] args ) &#123; SpringApplication.run(App.class,args); &#125;&#125; 继承SpringBootServletInitializer，重写configure方法。 部署跟常规的idea的web项目一样即可。如图： 后续页面、资源文件、class等修改都跟常规的idea的web项目一样操作即可。这样class只要没有增加类、方法、修改签名等就不用重启tomcat了。 注意：我发现有时候没法触发自动重启，手动触发一下编译即可（idea中快捷键ctrl+F9）。 参考常用热部署方式 参考：https://www.cnblogs.com/winner-0715/p/6666579.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[socket.io数据推送]]></title>
    <url>%2F2018%2F03%2F08%2Fsocketio-push-tecnology%2F</url>
    <content type="text"><![CDATA[参考：基于netty-socketio的web推送服务、Spring Boot实战之netty-socketio实现简单聊天室(给指定用户推送消息)、socket.io 中文文档 socketio简介Socket.io是一个WebSocket库，包括了客户端的js和服务器端的nodejs，它的目标是构建可以在不同浏览器和移动设备上使用的实时应用。它会自动根据浏览器从WebSocket、AJAX长轮询、Iframe流等等各种方式中选择最佳的方式来实现网络实时应用，非常方便和人性化，而且支持的浏览器最低达IE5.5. socket.io特点实时分析：将数据推送到客户端，这些客户端会被表示为实时计数器，图表或日志客户。实时通信和聊天：只需几行代码便可写成一个Socket.IO的”Hello,World”聊天应用。二进制流传输：从1.0版本开始，Socket.IO支持任何形式的二进制文件传输，例如：图片，视频，音频等。文档合并：允许多个用户同时编辑一个文档，并且能够看到每个用户做出的修改。 Demo简介服务端使用netty-socketio，客户端使用socket.io.js。本例完全来自上面的链接，这里只是测试效果以及做备忘。本例实现的功能是一个用户向另外一个用法发小消息。 maven中添加依赖12345&lt;dependency&gt; &lt;groupId&gt;com.corundumstudio.socketio&lt;/groupId&gt; &lt;artifactId&gt;netty-socketio&lt;/artifactId&gt; &lt;version&gt;1.7.3&lt;/version&gt;&lt;/dependency&gt; 服务端SocketServer1234567891011121314151617181920@Componentpublic class ChatServer implements InitializingBean &#123; @Autowired private EventListenner eventListenner; @Override public void afterPropertiesSet() throws Exception &#123; Configuration config = new Configuration(); config.setPort(9098); SocketConfig socketConfig = new SocketConfig(); socketConfig.setReuseAddress(true); socketConfig.setTcpNoDelay(true); socketConfig.setSoLinger(0); config.setSocketConfig(socketConfig); config.setHostname("localhost"); SocketIOServer server = new SocketIOServer(config); server.addListeners(eventListenner); server.start(); System.out.println("启动正常"); &#125;&#125; 缓存类，缓存客户端连接1234567891011121314151617@Component("clientCache")public class SocketIOClientCache &#123; //String：EventType类型 private Map&lt;String,SocketIOClient&gt; clients=new ConcurrentHashMap&lt;String,SocketIOClient&gt;(); //用户发送消息添加 public void addClient(SocketIOClient client,MsgBean msgBean)&#123; clients.put(msgBean.getFrom(),client); &#125; //用户退出时移除 public void remove(MsgBean msgBean) &#123; clients.remove(msgBean.getFrom()); &#125; //获取所有 public SocketIOClient getClient(String to) &#123; return clients.get(to); &#125;&#125; 消息发送的类1234567@Service("socketIOResponse")public class SocketIOResponse &#123; public void sendEvent(SocketIOClient client, MsgBean bean) &#123; System.out.println("推送消息"); client.sendEvent("OnMSG", bean); &#125;&#125; 事件监听器123456789101112131415161718192021222324252627@Service("eventListenner")public class EventListenner &#123; @Resource(name = "clientCache") private SocketIOClientCache clientCache; @Resource(name = "socketIOResponse") private SocketIOResponse socketIOResponse; @OnConnect public void onConnect(SocketIOClient client) &#123; System.out.println("建立连接"); &#125; @OnEvent("OnMSG") public void onSync(SocketIOClient client, MsgBean bean) &#123; System.out.printf("收到消息-from: %s to:%s\n", bean.getFrom(), bean.getTo()); clientCache.addClient(client, bean); SocketIOClient ioClients = clientCache.getClient(bean.getTo()); System.out.println("clientCache"); if (ioClients == null) &#123; System.out.println("你发送消息的用户不在线"); return; &#125; socketIOResponse.sendEvent(ioClients,bean); &#125; @OnDisconnect public void onDisconnect(SocketIOClient client) &#123; System.out.println("关闭连接"); &#125;&#125; 消息bean123456789101112131415161718192021222324252627public class MsgBean &#123; private String from; private String to; private String content; public String getFrom() &#123; return from; &#125; public void setFrom(String from) &#123; this.from = from; &#125; public String getTo() &#123; return to; &#125; public void setTo(String to) &#123; this.to = to; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; @Override public String toString() &#123; return "MsgBean [from=" + from + ", to=" + to + ", content=" + content + "]"; &#125;&#125; 页面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;title&gt;socket.io demo&lt;/title&gt; &lt;meta http-equiv="content-type" content="text/html; charset=UTF-8" /&gt; &lt;script type="text/javascript" th:src="@&#123;/js/jquery.js&#125;"&gt;&lt;/script&gt; &lt;script type="text/javascript" th:src="@&#123;/js/socket.io.min.js&#125;"&gt;&lt;/script&gt; &lt;style&gt; body &#123; padding: 20px; &#125; #console &#123; height: 400px; overflow: auto; &#125; .username-msg &#123; color: orange; &#125; .connect-msg &#123; color: green; &#125; .disconnect-msg &#123; color: red; &#125; .send-msg &#123; color: #888 &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Netty-socketio chat demo&lt;/h1&gt;&lt;br /&gt;&lt;div id="console" class="well"&gt;&lt;/div&gt;&lt;form class="well form-inline" onsubmit="return false;"&gt; &lt;input id="from" class="input-xlarge" type="text" placeholder="from. . . " /&gt; &lt;input id="to" class="input-xlarge" type="text" placeholder="to. . . " /&gt; &lt;input id="content" class="input-xlarge" type="text" placeholder="content. . . " /&gt; &lt;button type="button" onClick="sendMessage()" class="btn"&gt;Send&lt;/button&gt; &lt;button type="button" onClick="sendDisconnect()" class="btn"&gt;Disconnect&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;&lt;script type="text/javascript"&gt; var socket = io.connect('http://localhost:9098'); socket.on('connect',function() &#123; output('&lt;span class="connect-msg"&gt;Client has connected to the server!&lt;/span&gt;'); &#125;); socket.on('OnMSG', function(data) &#123; output('&lt;span class="username-msg"&gt;' + data.content + ' : &lt;/span&gt;'); &#125;); socket.on('disconnect',function() &#123; output('&lt;span class="disconnect-msg"&gt;The client has disconnected! &lt;/span&gt;'); &#125;); function sendDisconnect() &#123; socket.disconnect(); &#125; function sendMessage() &#123; var from = $("#from").val(); var to = $("#to").val(); var content = $('#content').val(); socket.emit('OnMSG', &#123; from : from, to : to, content : content &#125;); &#125; function output(message) &#123; console.log(message) var currentTime = "&lt;span&gt;" + new Date() + "&lt;/span&gt;"; var element = $("&lt;div&gt;" + currentTime + " " + message + "&lt;/div&gt;&lt;br/&gt;"); $('#console').prepend(element); &#125;&lt;/script&gt;&lt;/html&gt; 说明:工程基于springboot，关于springboot相关的内容并未给出。 测试浏览器2个标签页分页输入地址，进入到聊天页面。标签页1 我们假定标签页1用户为admin，标签页2用户为test。标签页1：admin向test发送1条消息，点击发送，切换到标签页2，发现并没有消息。因为这个时候缓存中没有test，所以没有发送成功。标签页2：test向admin发送1条消息。切换到标签页1，可以发现已经接受到test发送的消息 我们F12打开开发人员工具，可以看到多次发送消息并没有产生新的请求。 问题1.中文乱码尚未找到解决方案。 netty-socketio:https://github.com/mrniko/netty-socketionetty-socketio-demo:https://github.com/mrniko/netty-socketio-demo]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>推送技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot thymeleaf模板使用]]></title>
    <url>%2F2018%2F03%2F08%2FSpringboot%2BThymeleaf%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[application.properties添加对thymeleaf的支持12345678spring.thymeleaf.prefix=classpath:/templates/spring.thymeleaf.suffix=.htmlspring.thymeleaf.mode=HTML5spring.thymeleaf.encoding=UTF-8spring.thymeleaf.content-type=text/htmlspring.thymeleaf.cache=falsespring.resources.chain.strategy.content.enabled=truespring.resources.chain.strategy.content.paths=/** 加入相关依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 注意：thymeleaf模板使用的资源文件位于/resources/static，html文件一般则位于/resources/templates/。 测试controller12345678910@Controllerpublic class TestController &#123; @GetMapping("/test") public ModelAndView test() &#123; ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName("test"); modelAndView.addObject("your_name","World"); return modelAndView; &#125;&#125; test.html:1234567891011121314&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;title&gt;socket.io demo&lt;/title&gt; &lt;script type="text/javascript" th:src="@&#123;/js/jquery.js&#125;"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; $(function() &#123; alert('page load.'); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; Hello,&lt;span th:text="$&#123;your_name&#125;"&gt;!&lt;/span&gt;&lt;/body&gt;&lt;/html&gt; thymeleaf使用HTML5，对文件格式要求严格，比如：&lt;input type=text&gt;会报出下面的错误：org.xml.sax.SAXParseException: 元素类型 “input” 必须由匹配的结束标记 ““ 终止。 解决方法参考：spring-boot-starter-thymeleaf 避坑指南 thymeleaf用法参考：https://www.cnblogs.com/ityouknow/p/5833560.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot thymeleaf模板使用]]></title>
    <url>%2F2018%2F03%2F08%2Fspringboot_thymeleaf%2F</url>
    <content type="text"><![CDATA[application.properties添加对thymeleaf的支持12345678spring.thymeleaf.prefix=classpath:/templates/spring.thymeleaf.suffix=.htmlspring.thymeleaf.mode=HTML5spring.thymeleaf.encoding=UTF-8spring.thymeleaf.content-type=text/htmlspring.thymeleaf.cache=falsespring.resources.chain.strategy.content.enabled=truespring.resources.chain.strategy.content.paths=/** 加入相关依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 注意：thymeleaf模板使用的资源文件位于/resources/static，html文件一般则位于/resources/templates/。 测试controller12345678910@Controllerpublic class TestController &#123; @GetMapping("/test") public ModelAndView test() &#123; ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName("test"); modelAndView.addObject("your_name","World"); return modelAndView; &#125;&#125; test.html:1234567891011121314&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;title&gt;socket.io demo&lt;/title&gt; &lt;script type="text/javascript" th:src="@&#123;/js/jquery.js&#125;"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; $(function() &#123; alert('page load.'); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; Hello,&lt;span th:text="$&#123;your_name&#125;"&gt;!&lt;/span&gt;&lt;/body&gt;&lt;/html&gt; thymeleaf使用HTML5，对文件格式要求严格，比如：&lt;input type=text&gt;会报出下面的错误：org.xml.sax.SAXParseException: 元素类型 “input” 必须由匹配的结束标记 ““ 终止。 解决方法参考：spring-boot-starter-thymeleaf 避坑指南 thymeleaf用法参考：https://www.cnblogs.com/ityouknow/p/5833560.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java日志管理]]></title>
    <url>%2F2018%2F03%2F02%2Fjava-log-manage%2F</url>
    <content type="text"><![CDATA[java常用日志框架简介log4j和logback都是java项目中经常使用的日志框架，通常会结合slf4j一起使用。log4j和logback都是具体的日志实现框架，slf4j是一个接口层框架，slf4j-log4j，slf4j-logback则是针对log4j和logback的桥接框架。使用slf4j，就可以随意切换日志框架，而不用修改代码。 高并发系统日志记录多线程环境会由于多个线程同时会向一个日志文件记录日志，所以会导致日志混乱，查找某个线程的日志变的不方便。比如跟踪某个订单号、某个用户的相关日志。我们可以使用slf4j的MDC来解决这个问题。 MDC ( Mapped Diagnostic Contexts )，顾名思义，其目的是为了便于我们诊断线上问题而出现的方法工具类。虽然，Slf4j 是用来适配其他的日志具体实现包的，但是针对 MDC功能，目前只有logback以及log4j支持。MDC对外提供的接口：1234567891011public class MDC &#123; //Put a context value as identified by key //into the current thread's context map. public static void put(String key, String val); //Get the context identified by the key parameter. public static String get(String key); //Remove the context identified by the key parameter. public static void remove(String key); //Clear all entries in the MDC. public static void clear();&#125; 接口定义非常简单，此外，其使用也非常简单。 一般，我们在代码中，只需要将指定的值put到线程上下文的Map中，然后，在对应的地方使用 get方法获取对应的值。此外，对于一些线程池使用的应用场景，可能我们在最后使用结束时，需要调用clear方法来清洗将要丢弃的数据。 看看一个MDC使用的简单示例123456MDC.put("traceNo","jd.com");logger.info("method testFindByName in UserServiceTest");User user = userService.findByName("test");logger.info("user:&#123;&#125;",user);Assert.assertNotNull(user);MDC.clear(); logback.xml配置：12345678&lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- 对日志进行格式化。 --&gt; &lt;encoder&gt; &lt;pattern&gt; %d&#123;yyyy-MM-dd HH:mm:ss&#125; %level %logger.%M\(%F:%L\)] [%X&#123;traceNo&#125;] %msg%n &lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 如上，在logback.xml中的pattern中我们加入了[%X{traceNo}]，在MDC中放入traceNo的值，就可以记录日志了。 12018-03-03 10:11:27 INFO com.tommy.myapp.dao.UserServiceTest.testFindByName(UserServiceTest.java:52)] [jd.com] user:User&#123;id=1, name=&apos;test&apos;, birthday=Sat Mar 03 10:11:27 CST 2018&#125; 注意日志中的[jd.com]，这就是我们日志中加入的自定义的字段，在Linux系统中，我们可以通过grep traceNo xx.log --color查询某个跟踪号相关的日志，并高亮显示。 在WEB系统中，则可以新建一个自定义的请求过滤器，对业务请求进行过滤，在过滤器内处理请求前加入traceNo，请求处理完毕后，从MDC删除traceNo。 logback MDC的使用和分析可以参考：Slf4j MDC 使用和 基于 Logback 的实现分析 logback使用参考：Java 日志组件slf4j+logback使用实例、logback.xml常用配置 参考：Java日志终极指南]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring单元测试]]></title>
    <url>%2F2018%2F03%2F01%2Fspring-unittests%2F</url>
    <content type="text"><![CDATA[环境搭建参考《SpringDataJpa基本使用》。 DAO测试新建一个测试基类，后续所有的测试类继承该类123456@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = "classpath:spring.xml")@TransactionConfiguration(transactionManager = "transactionManager",defaultRollback = true)@Transactionalpublic class BaseSpringTest &#123;&#125; 123456789101112131415public class UserDaoTest extends BaseSpringTest &#123; private final Logger logger = LoggerFactory.getLogger(UserDaoTest.class); @Autowired private UserDao userDao; @Test public void testSave() &#123; logger.info("testSave method in UserDaoTest"); User user = new User(); user.setName("test"); user.setBirthday(new Date()); user = this.userDao.save(user); assert user.getId() &gt; 0; dbUserId = user.getId(); &#125;&#125; 注意：dao的测试一定不能污染数据库，这里配置了TransactionConfiguration，在测试方法执行完毕后回滚事务。 Service测试service层的测试通常依赖dao层，对于dao的依赖，使用mock框架mock出相应的bean，重心放在service方法的逻辑处理是否正确。参考：《springockito-annotations做spring的单元测试》 Controller测试参考Spring Controller单元测试 外部接口测试1.mock外部依赖；2.新建被测试外部依赖接口service的实现（在test/java/src），使用单元测试的spring配置文件。 多线程测试12345678910111213141516171819202122232425262728293031323334353637383940414243444546@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = "classpath:spring.xml")public class MultiThreadServiceTest &#123; private final Logger logger = LoggerFactory.getLogger(MultiThreadServiceTest.class); @Autowired private UserService userService; @Test public void multithreadSaveTest() throws InterruptedException &#123; for (int i=0;i&lt;10;i++) &#123; Thread thread = new Thread(new WorkerTask()); thread.start(); latch.countDown(); // 线程启动后将latch数量减一，在WorkTask中会等待latch数量为0时执行数据库插入和查询操作。即保证所有线程同时执行数据库插入和查询操作。 &#125; // 这里要休眠一定时间，否则会导致所有WorkTask都没有执行。 // 因为Junit将测试方法执行完毕就退出了，这时候子线程其实还没开始执行。 Thread.sleep(3000L); &#125; @After public void teadDown() &#123; // 执行数据库清理工作。在多线程环境，在单元测试类上加入@Transactional并没有用，只对被测试方法本身所在的线程（主线程）有用，其他线程无效。 // 所以这里在单元测试执行完毕后，对数据库做清理工作。 userService.deleteAll(dbIds); &#125; private CountDownLatch latch = new CountDownLatch(10); private Collection&lt;Long&gt; dbIds = new ArrayList&lt;&gt;(); class WorkerTask implements Runnable &#123; @Override public void run() &#123; try &#123; latch.await(); // 等待所有线程准备就绪同时执行数据库插入操作。 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; User user = new User(); user.setName("test"); user.setBirthday(new Date()); user = userService.save(user); assert user.getId() &gt; 0; dbIds.add(user.getId()); user = userService.findById(user.getId()); logger.info("user:&#123;&#125;",user); Assert.assertNotNull(user); Assert.assertEquals("test",user.getName()); &#125; &#125;&#125; 注意：多线程环境单元测试，就算在测试类上加入@Transactional注解，数据库操作也是不会回滚的。原因可以查看代码注释，所以需要手动执行清理操作。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springockito-annotations做spring的单元测试]]></title>
    <url>%2F2018%2F03%2F01%2Fspringockito-annotations-to-test-spring%2F</url>
    <content type="text"><![CDATA[Service层通常依赖DAO的Bean，在做Service层的单元测试时应该将DAO层的Bean Mock出来，只关注于Service层的业务逻辑处理是否正确。这里介绍的是使用springockito-annotations来模拟spring bean。 引入springockito-annotations依赖123456&lt;dependency&gt; &lt;groupId&gt;org.kubek2k&lt;/groupId&gt; &lt;artifactId&gt;springockito-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;springockito.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 单元测试1234567891011121314151617181920212223242526@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(loader = SpringockitoContextLoader.class,locations = "classpath:spring.xml")public class UserServiceTest &#123; private Logger logger = LoggerFactory.getLogger(UserServiceTest.class); @Autowired @ReplaceWithMock private UserDao userDao; // UserService中依赖UserDao，这里mock出UserDao @Autowired private UserService userService; @Before public void setUp() &#123; User user = new User(); user.setId(1L); user.setName("test"); user.setBirthday(new Date()); // 对UserDao的findByName方法进行模拟，如果传入的参数是test则返回uesr对象。 Mockito.when(userDao.findByName("test")).thenReturn(user); &#125; @Test public void testFindByName() &#123; logger.info("method testFindByName in UserServiceTest"); User user = userService.findByName("test"); logger.info("user:&#123;&#125;",user); Assert.assertNotNull(user); &#125;&#125; 注意：涉及到的spring的配置文件以及其他依赖、代码等没有给出。 具体使用可以参考：Spring 测试：其实很简单、ockito-annotations 做spring的单元测试]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Data Jpa使用]]></title>
    <url>%2F2018%2F02%2F28%2FSpringDataJpa-basic-usage%2F</url>
    <content type="text"><![CDATA[Spring Data Jpa简介 Spring Data JPA是Spring Data框架的一个模块。 Spring Data JPA依赖于Spring的核心jar,JPA只有接口和注解，Spring Data JPA的功能实现默是使用的Hibernate，因此还必须引入Hibernate对JPA的支持（整合）项目hibernate-entitymanager。 JPA编程是通过EntityManagerFactory（类似SessionFactory），获得EntityManager （类似Session）进行增删改查，CRUD的方法分别为： 增加 persist()、修改 merge()、删除 remove()、查询 find() Spring Data JPA配置和基本使用1.引入spring data jpa和hibernate-entitymanager的依赖；2.配置DataSource，配置EntityManagerFactory，配置事务，配置JPA扫描。3.编写接口继承Repository系列接口，按照JPA规范编写相关方法。 具体实例依赖：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;properties&gt; &lt;spring.version&gt;4.0.3.RELEASE&lt;/spring.version&gt; &lt;spring.groupId&gt;org.springframework&lt;/spring.groupId&gt; &lt;druid.version&gt;1.0.28&lt;/druid.version&gt; &lt;mysql.version&gt;5.1.45&lt;/mysql.version&gt; &lt;spring.data.jpa.version&gt;1.7.0.RELEASE&lt;/spring.data.jpa.version&gt; &lt;hibernate.entitymanager.version&gt;4.3.6.Final&lt;/hibernate.entitymanager.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;aspectjweaver.version&gt;1.8.1&lt;/aspectjweaver.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.data.jpa.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.entitymanager.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;$&#123;aspectjweaver.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.springframework.org/schema/beans" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:cache="http://www.springframework.org/schema/cache" xmlns:p="http://www.springframework.org/schema/p" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/cache http://www.springframework.org/schema/cache/spring-cache-4.0.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa.xsd"&gt; &lt;context:component-scan base-package="com.tommy.myapp"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; &lt;context:property-placeholder location="classpath:db.properties"/&gt; &lt;!--alibaba druid数据库连接池配置--&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name="url" value="$&#123;db.url&#125;"/&gt; &lt;property name="username" value="$&#123;db.username&#125;"/&gt; &lt;property name="password" value="$&#123;db.password&#125;"/&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="10"/&gt; &lt;property name="minIdle" value="10"/&gt; &lt;property name="maxActive" value="100"/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000"/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000"/&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000"/&gt; &lt;property name="validationQuery" value="$&#123;db.test_sql&#125;"/&gt; &lt;!-- 指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除.注意: 设置为true后如果要生效,validationQuery参数必须设置为非空字符串 --&gt; &lt;property name="testWhileIdle" value="true"/&gt; &lt;!-- 默认值是 true ，当从连接池取连接时，验证这个连接是否有效 --&gt; &lt;property name="testOnBorrow" value="false"/&gt; &lt;!-- 默认值是 flase, 当从把该连接放回到连接池的时，验证这个连接是否有效 --&gt; &lt;property name="testOnReturn" value="false"/&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20"/&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name="filters" value="stat"/&gt; &lt;/bean&gt; &lt;!-- 实体管理工厂 --&gt; &lt;bean id="entityManagerFactory" class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- 扫描实体类 --&gt; &lt;property name="packagesToScan" value="com.tommy.myapp.entity"/&gt; &lt;!--JPA供应商适配：数据库和方言 --&gt; &lt;property name="jpaVendorAdapter"&gt; &lt;bean class="org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter"&gt; &lt;!-- 数据库类型配置 --&gt; &lt;property name="database" value="$&#123;db.type&#125;"/&gt; &lt;!-- 是否自动生成DDL建表 --&gt; &lt;property name="generateDdl" value="true"/&gt; &lt;!-- 配置dialect方言 --&gt; &lt;property name="databasePlatform" value="$&#123;db.dialect&#125;"/&gt; &lt;!-- 打印sql --&gt; &lt;property name="showSql" value="true"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;!-- 配置hibernate的其他属性 --&gt; &lt;property name="jpaProperties"&gt; &lt;props&gt; &lt;prop key="hibernate.format_sql"&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.jpa.JpaTransactionManager"&gt; &lt;property name="entityManagerFactory" ref="entityManagerFactory"/&gt; &lt;/bean&gt; &lt;!-- 注册驱动 --&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; &lt;tx:advice id="transactionAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="add*" propagation="REQUIRED"/&gt; &lt;tx:method name="append*" propagation="REQUIRED"/&gt; &lt;tx:method name="insert*" propagation="REQUIRED"/&gt; &lt;tx:method name="save*" propagation="REQUIRED"/&gt; &lt;tx:method name="update*" propagation="REQUIRED"/&gt; &lt;tx:method name="modify*" propagation="REQUIRED"/&gt; &lt;tx:method name="edit*" propagation="REQUIRED"/&gt; &lt;tx:method name="delete*" propagation="REQUIRED"/&gt; &lt;tx:method name="remove*" propagation="REQUIRED"/&gt; &lt;tx:method name="repair" propagation="REQUIRED"/&gt; &lt;tx:method name="get*" propagation="SUPPORTS"/&gt; &lt;tx:method name="select*" propagation="SUPPORTS"/&gt; &lt;tx:method name="find*" propagation="SUPPORTS"/&gt; &lt;tx:method name="load*" propagation="SUPPORTS"/&gt; &lt;tx:method name="search*" propagation="SUPPORTS"/&gt; &lt;tx:method name="*" propagation="SUPPORTS"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- AOP配置--&gt; &lt;aop:config proxy-target-class="true"&gt; &lt;aop:pointcut id="myPointcut" expression="execution(* com.tommy.myapp.service.impl.*.*(..))"/&gt; &lt;aop:advisor advice-ref="transactionAdvice" pointcut-ref="myPointcut"/&gt; &lt;/aop:config&gt; &lt;jpa:repositories base-package="com.tommy.myapp.dao" entity-manager-factory-ref="entityManagerFactory" transaction-manager-ref="transactionManager"&gt; &lt;/jpa:repositories&gt;&lt;/beans&gt; db.properties:123456db.type=MYSQLdb.dialect=org.hibernate.dialect.MySQL5InnoDBDialectdb.url=jdbc:mysql://192.168.74.135:3306/test?useUnicode=true&amp;characterEncoding=utf8db.username=rootdb.password=123456db.test_sql=select 1 User.java123456789101112131415161718192021222324252627@Entity@Table(name = "t_user")public class User &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; private String name; private Date birthday; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125;&#125; UserDao.java123public interface UserDao extends JpaRepository&lt;User,Long&gt; &#123; User findByName(String name);&#125; 单元测试1234567891011121314151617181920212223242526272829@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = "classpath:spring.xml")@TransactionConfiguration(transactionManager = "transactionManager",defaultRollback = true) // 单元测试完毕回滚事务@Transactionalpublic class UserDaoTest &#123; @Autowired private UserDao userDao; private Long dbUserId = 0L; @Test public void testSave() &#123; User user = new User(); user.setName("test"); user.setBirthday(new Date()); user = this.userDao.save(user); assert user.getId() &gt; 0; dbUserId = user.getId(); &#125; @Test public void testFindUserById() &#123; User user = this.userDao.findOne(dbUserId); assert user != null; &#125; @Test public void testFindUserByName() &#123; String name = "test"; User user = this.userDao.findByName(name); assert user != null; &#125;&#125; 相关问题：1.org.hibernate.id.IdentifierGenerationException: ids for this class must be manually assigned before解决：在实体类的id字段上加入@GeneratedValue(strategy = GenerationType.AUTO)注解123@Id@GeneratedValue(strategy = GenerationType.AUTO)private Long id; 参考：Spring Data JPA框架、使用Spring Data JPA简化JPA开发、Spring Data系列入门]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web工程非Spring管理的Bean使用Spring管理的Bean]]></title>
    <url>%2F2018%2F02%2F26%2Fweb-not-spring-managed-app-use-spring-managed-beans%2F</url>
    <content type="text"><![CDATA[某个类的属性在每次构建对象时传入，且属性不是固定的，就没法使用spring管理它。但这个类有可能应用其他被spring管理的类。 那么既然是web工程，我们可以创建一个ServletContextListener，然后在web.xml中配置该监听器即可。12345678910111213public class InitDataListener implements ServletContextListener &#123; @Override public void contextDestroyed(ServletContextEvent event) &#123; &#125; @Override public void contextInitialized(ServletContextEvent event) &#123; ApplicationContext context = WebApplicationContextUtils.getRequiredWebApplicationContext(this.getServletContext()); SpringUtil.setContext(context); &#125; &#125; SpringUtil：12345678910111213141516171819public class SpringUtil &#123; private static ApplicationContext context; public static void setContext(ApplicationContext _context) &#123; context = _context; &#125; public static Object getBean(String beanName) &#123; if (context != null) &#123; return context.getBean(beanName); &#125; else &#123; return null; &#125; &#125; public static &lt;T&gt; T getBean(Class&lt;T&gt; tClass) &#123; if (context != null) &#123; return context.getBean(tClass); &#125; return null; &#125;&#125; web.xml:123&lt;listener&gt; &lt;listener-class&gt;com.tommy.myapp.listener.InitDataListener&lt;/listener-class&gt;&lt;/listener&gt; 然后其他工程中可以通过SpringUtil.getBean()来获取spring管理的bean。 当然了，你用一个Servlet也是可以的，继承HttpServlet，在init()中获取ApplicationContext，注意在web.xml中配置该servlet。 这里可能的应用场景包括：1.在系统启动时查询一些数据放入内存等等；–也可以使用@PostConstruct注解，在对象初始化后执行。2.在非Spring管理的类中应用Spring管理的类。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis逆向工程生成代码]]></title>
    <url>%2F2018%2F02%2F26%2FMyBatis-code-generation%2F</url>
    <content type="text"><![CDATA[mybatis官方提供了一个逆向工程，可以针对单表自动生成mybatis执行所需要的代码（包括mapper.xml、mapper.java、po..）。一般在开发中，常用的逆向工程方式是通过数据库的表生成代码。 mybatis-generator有三种用法：命令行、eclipse插件、maven插件。个人觉得maven插件最方便，可以在eclipse/intellij idea等ide上可以通用。 在pom.xml中添加plugin1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;test&lt;/artifactId&gt; &lt;groupId&gt;com.tommy&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;mybatis-generator&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;mybatis-generator&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.35&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 其中generatorConfig.xml的位置，大家根据实际情况自行调整 generatorConfig.xml配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;context id="testTables" targetRuntime="MyBatis3"&gt; &lt;commentGenerator&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name="suppressAllComments" value="true"/&gt; &lt;/commentGenerator&gt; &lt;!--mysql数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://192.168.74.135:3306/test" userId="root" password="123456"&gt; &lt;/jdbcConnection&gt; &lt;!--oracle配置--&gt; &lt;!-- &lt;jdbcConnection driverClass="oracle.jdbc.OracleDriver" connectionURL="jdbc:oracle:thin:@127.0.0.1:1521:yycg" userId="yycg" password="yycg"&gt; &lt;/jdbcConnection&gt; --&gt; &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer， 为 true时把JDBC DECIMAL和NUMERIC类型解析为java.math.BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name="forceBigDecimals" value="false"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- targetProject:生成model类的位置，重要！！ --&gt; &lt;javaModelGenerator targetPackage="com.tommy.myapp.model" targetProject="./src/main/java"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name="enableSubPackages" value="false"/&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name="trimStrings" value="true"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- targetProject:mapper映射xml文件生成的位置，重要！！ --&gt; &lt;sqlMapGenerator targetPackage="com.tommy.myapp.mapper" targetProject="./src/main/java"&gt; &lt;property name="enableSubPackages" value="false"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- targetPackage：mapper接口生成的位置，重要！！ --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="com.tommy.myapp.dao" targetProject="./src/main/java"&gt; &lt;property name="enableSubPackages" value="false"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定数据库表，要生成哪些表，就写哪些表，要和数据库中对应，不能写错！ --&gt; &lt;table tableName="articles"&gt;&lt;/table&gt; &lt;table tableName="blog"&gt;&lt;/table&gt; &lt;table tableName="user"&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 使用方式1mvn mybatis-generator:generate 如果是在intellij 环境，直接鼠标点击即可 刷新工程目录，即可看到生成的文件。 注意： 建表时，表字段名称建议用”_”分隔多个单词，比如:order_detail,这样生成的model，属性名称就会变成漂亮的驼峰命名，即：orderDetail。 另外，每次最好不要在实际的工程中生成，如果有同名的会覆盖。所以建议以一个单独的工程来生成，然后拷贝过去。 参考：MyBatis的逆向工程生成代码、Mybatis逆向工程_使用maven]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[取消Notepad++红色下划线（错误提示）]]></title>
    <url>%2F2018%2F02%2F26%2Fnotepad%2B%2B-remove-red-underline-show%2F</url>
    <content type="text"><![CDATA[notepad++新升级了之后就有自动判断的红线，单词拼错了就给提示，看着这红线实在难受。 把【插件】-【DSpellCheck】-【Spell Check Document Automatically】前面的打钩去掉即可。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列12——Eureka的高可用]]></title>
    <url>%2F2018%2F02%2F04%2Fspringcloud-series-12-eureka-high-avaiable%2F</url>
    <content type="text"><![CDATA[Eureka Server的高可用是通过各个Eureka Server作为服务向其他Eureka Server注册，来实现服务列表的同步，达到高可用的效果。 默认情况下，每个Eureka服务器也是Eureka客户端，并且需要（至少一个）服务URL来定位对等端。 我们对以前的Eureka Server工程做修改，在application.yml配置如下：123456789101112131415161718192021222324252627282930313233---server: port: 8761spring: profiles: peer1eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2:8762/eureka/,http://peer3:8763/eureka/---server: port: 8762spring: profiles: peer2eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1:8761/eureka/,http://peer3:8763/eureka/---server: port: 8763spring: profiles: peer3eureka: instance: hostname: peer3 client: serviceUrl: defaultZone: http://peer1:8761/eureka/,http://peer2:8762/eureka/ 这里是本地测试，所以3个Eureka Server的配置都写在一个配置文件。修改hosts文件：127.0.0.1 peer1 peer2 peer3，peer1,peer2,peer3都映射到127.0.0.1。在启动时指定profile，idea的配置如下： 依次启动peer1，peer2，peer3。观察peer1，peer2的日志都有报错。peer1报错是因为peer2和peer3服务没有启动，导致没法将自己注册到peer2和peer3。peer2报错是因为peer3没有启动，peer3启动正常，无错误。查看peer1 查看peer2 查看peer3可以看到： 1.每个Eureka Server都是其他Eureka Server的一个服务； 2.每个Eureka Server都是相互同步的。 其他服务提供者的application.yml修改：1234eureka: client: serviceUrl: defaultZone: http://peer1:8761/eureka,http://peer1:8762/eureka,http://peer1:8763/eureka 建议把每个Eureka Server地址都写上。只写其中一个启动也是没问题的。但是，如果只写peer1的地址，那么该服务挂掉，且peer1也挂掉，将导致服务不能注册。 Eureka Server的高可用参考Spring Cloud官方文档]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列11——覆盖Feign的默认配置]]></title>
    <url>%2F2018%2F02%2F03%2Fspringcloud-series-11-covering-Feign-default-configuration%2F</url>
    <content type="text"><![CDATA[Spring Cloud Feign简介Spring Cloud官方原文： A central concept in Spring Cloud’s Feign support is that of the named client. Each feign client is part of an ensemble of components that work together to contact a remote server on demand, and the ensemble has a name that you give it as an application developer using the@FeignClient annotation. Spring Cloud creates a new ensemble as anApplicationContext on demand for each named client usingFeignClientsConfiguration. This contains (amongst other things) anfeign.Decoder, afeign.Encoder, and afeign.Contract. Spring Cloud lets you take full control of the feign client by declaring additional configuration (on top of the FeignClientsConfiguration) using @FeignClient. 翻译：Spring Cloud的Feign支持中的一个中心概念是命名的客户端。 每个feign客户端都是组件的一部分，这些组件是按需联系远程服务器的组件的一部分，并且集合有一个名称，您可以使用@FeignClient注释将其作为应用程序开发人员提供。 Spring Cloud使用FeignClientsConfiguration创建一个新的集合，作为每个指定客户端的ApplicationContext。 这包含（其中包括）feign.Decoder，feign.Encoder和feign.Contract。 通过使用@FeignClient声明额外的配置（在FeignClientsConfiguration之上），Spring Cloud可让您完全控制Feign客户端。 覆盖Feign的默认配置定义Feign客户端接口12345@FeignClient(name = "microservice-springcloud-user",configuration = MyConfiguration.class)public interface UserFeignClient &#123; @RequestLine("GET /sample/&#123;userId&#125;") User findUserById(@Param("userId") Long userId);&#125; 自定义FeignClientsConfiguration1234567@Configurationpublic class MyConfiguration &#123; @Bean public Contract feignContract() &#123; return new feign.Contract.Default(); &#125;&#125; 使用的Controller123456789@RestControllerpublic class MovieController &#123; @Autowired private UserFeignClient userFeignClient; @GetMapping("/findUser/&#123;userId&#125;") public User findUserById(@PathVariable Long userId) &#123; return this.userFeignClient.findUserById(userId); &#125;&#125; 注意：FeignClientsConfiguration类不在Spring Boot启动类的扫描路径下，否则会覆盖该项目所有的Feign接口的默认配置。 测试 1.启动Eureka Server； 2.启动microservice-springcloud-user服务； 3.启动microservice-springcloud-movie-feign-customization（本例中的测试项目）；浏览器输入http://10.41.12.63:7901/findUser/1请求成功。 1.@FeignClient注解的serviceId参数不建议被使用。 2.以前使用@FeignClient注解的时候使用了url参数，name参数不是必须的；但现在name必须，只是作为一个标识。* 3.Feign默认使用的spring MVC的注解，参考《springcloud系列10——Feign的简介及基础使用》。如果覆盖了Feign的默认配置，则需要使用Feign的注解。 @FeignClient使用name和url的示例这里使用的Feign的默认配置。12345@FeignClient(name = "test", url = "http://localhost:8761")public interface FeignClient2 &#123; @RequestMapping(value = "/eureka/apps/&#123;serviceName&#125;", method = RequestMethod.GET) String findServiceInfo(@PathVariable("serviceName") String serviceName);&#125; 123456789101112131415@RestControllerpublic class MovieController &#123; @Autowired private UserFeignClient userFeignClient; @Autowired private FeignClient2 feignClient2; @GetMapping("/findUser/&#123;userId&#125;") public User findUserById(@PathVariable Long userId) &#123; return this.userFeignClient.findUserById(userId); &#125; @GetMapping("/service/&#123;serviceName&#125;") public String findServiceInfoFromEureka(@PathVariable String serviceName) &#123; return this.feignClient2.findServiceInfo(serviceName); &#125;&#125; 注意目录结构：FeignConfiguration类如果加了@Configuration注解，则不能被@ComponetScan扫描到，可以不加这个注解。Spring Cloud官方文档有说： 参考：Spring Cloud官方文档——spring-cloud-feign-overriding-defaults Feign日志配置为每个创建的Feign客户端创建一个记录器。 默认情况下，记录器的名称是用于创建Feign客户端的接口的完整类名称。 Feign日志记录只响应DEBUG级别。 配置日志级别在application.yml中增加FeignClient的日志级别（注意：每个FeignClient是单独配置的）123logging: level: com.tommy.springcloud.config.feign.UserFeignClient: DEBUG 设置记录哪些日志12345678910public class MyConfiguration &#123; @Bean public Contract feignContract() &#123; return new feign.Contract.Default(); &#125; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; 这里配置日志记录所有请求和响应信息，包括请求头、请求体、元数据 测试 日志记录的选择您可以为每个客户端配置的Logger.Level对象告诉Feign需要记录多少。 选择是： NONE：不记录（默认）。 BASIC：只记录请求方法和URL以及响应状态码和执行时间。 HEADERS：记录基本信息以及请求和响应标题。 FULL：记录请求和响应的标题，正文和元数据。 参考：Spring Cloud官方文档——Feign logging]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列10——Feign的简介及基础使用]]></title>
    <url>%2F2018%2F02%2F02%2Fspringcloud-series-10-Feign-install-and-basic-useage%2F</url>
    <content type="text"><![CDATA[Feign简介Feign 是一个声明web服务客户端，这使得编写web服务客户端更容易，使用Feign 创建一个接口并对它进行注解，它具有可插拔的注解支持包括Feign注解与JAX-RS注解，Feign还支持可插拔的编码器与解码器，Spring Cloud 增加了对 Spring MVC的注解，Spring Web 默认使用了HttpMessageConverters, Spring Cloud集成了Ribbon 和 Eureka使Feign支持http client负载均衡。 上面其实是对Spring Cloud官方文档Declarative REST Client: Feign一节的翻译。 Feign基本使用添加spring-cloud-starter-openfeign依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 应用启动类上加入@EnableFeignClients123456789101112131415@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class App &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main( String[] args ) &#123; SpringApplication.run(App.class,args); &#125;&#125; 定义一个接口类并加入@FeignClient1234567@FeignClient("microservice-springcloud-user")public interface UserFeignClient &#123; @RequestMapping(value = "/sample/&#123;userId&#125;", method = RequestMethod.GET) User findUserById(@PathVariable("userId") Long userId); @RequestMapping(value = "/user/&#123;userId&#125;", method = RequestMethod.POST) User updateUser(@PathVariable("userId") Long userId, @RequestParam("name") String name,@RequestParam("balance") BigDecimal balance);&#125; 上面的例子代码中提供了2个get请求和一个post请求。@FeignClient中value为服务id。 在Controller中注入上面创建的接口12345678910111213@RestControllerpublic class MovieController &#123; @Autowired private UserFeignClient userFeignClient; @GetMapping("/findUser/&#123;userId&#125;") public User findUserById(@PathVariable Long userId) &#123; return this.userFeignClient.findUserById(userId); &#125; @PostMapping("/user/&#123;userId&#125;") public User updateUserById(@PathVariable Long userId, User user) &#123; return this.userFeignClient.updateUser(userId,user.getName(),user.getBalance()); &#125;&#125; 测试 1.启动Eureka Server； 2.启动microservice-springcloud-user服务； 3.启动microservice-springcloud-movie（本例）； 1.GET请求测试浏览器输入http://localhost:7901/findUser/1可以看到，请求成功。 2.POST请求测试使用ARC（一个Chrome浏览器的http插件）测试POST请求，请求也是成功的 问题 1.在UserFeignClient中不能使用GetMapping，要使用RequestMapping注解； 2.url路径中的参数，在@PathVariable注解中必须指定value，如@PathVariable(&quot;userId&quot;) Long userId，使用@RequestParam也需要指定value； 3.不支持复杂对象，需要结合@RequestParam实现复杂对象。如果使用复杂对象，比如：12@RequestMapping(value = "/user/&#123;userId&#125;", method = RequestMethod.POST)User updateUser(@PathVariable("userId") Long userId, User user); 比如上面方法中的User为复杂对象，在使用ARC（一个Chrome浏览器的http插件）测试时，后台Controller接收是正常的，但UserFeignClient调用microservice-springcloud-user时User里面属性都是null，如下图。后台Controller UserFeignClient 参考：Spring Cloud官方文档]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列9——Ribbon脱离Eureka使用]]></title>
    <url>%2F2018%2F02%2F02%2Fspringcloud-series-9-use%20Ribbon-without-Eureka%2F</url>
    <content type="text"><![CDATA[前言Eureka对远程服务发现提供了抽象，你不需要在客户端硬编码URL。但是，如果你不想在Ribbon中使用Eureka，也是非常简单的。这里仍然以前面章节中的microservice-springcloud-movie进行测试。 在Ribbon中禁用Eureka在application.yml中增加下面的配置：123ribbon: eureka: enabled: false 声明Ribbon客户端提供的服务列表在application.yml中增加：1234567microservice-springcloud-user: ribbon: listOfServers: localhost:7902,localhost:7903 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRulemicroservice-springcloud-user2: ribbon: listOfServers: localhost:7904,localhost:7905 在上面Ribbon客户端中定义的服务列表包括了microservice-springcloud-user和microservice-springcloud-user2两个服务，其中microservice-springcloud-user服务随机访问，microservice-springcloud-user2不配置则使用默认的轮询策略。 测试 1.启动Eureka Server； 2.启动microservice-springcloud-user的2个服务； 3.启动microservice-springcloud-user2的2个服务； 4.启动microservice-springcloud-movie。 测试1浏览器中输入http://localhost:7901/test并刷新多次，查看控制台可以看到microservice-springcloud-user随机访问的，microservice-springcloud-user2则是轮询。 测试2如果在application.yml中不配置microservice-springcloud-user2，则访问http://localhost:7901/test会报错，但使用了eureka则不会。 直接使用Ribbon API123456789public class MyClass &#123; @Autowired private LoadBalancerClient loadBalancer; public void doStuff() &#123; ServiceInstance instance = loadBalancer.choose("stores"); URI storesUri = URI.create(String.format("http://%s:%s", instance.getHost(), instance.getPort())); // ... do something with the URI &#125;&#125; 参考Spring Cloud官方文档第16.6到16.8章节。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列8——使用配置文件自定义Ribbon Client]]></title>
    <url>%2F2018%2F02%2F02%2Fspringcloud-series-8-use-config-file-custom-RibbonClient%2F</url>
    <content type="text"><![CDATA[参考《springcloud系列7——通过代码自定义配置ribbon》，将microservice-springcloud-movie中应用启动类中的@RibbonClient注释。这里是继续《springcloud系列7——通过代码自定义配置ribbon》测试的。 配置文件修改在application.yml中增加下面的配置：1234# 定义访问microservice-springcloud-user服务随机访问microservice-springcloud-user: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 测试 1.启动Eureka Server； 2.microservice-springcloud-user中分别修改端口为7902,7904，然后分别启动； 3.microservice-springcloud-user中分别修改端口为7903,7905，spring.application.name修改为microservice-springcloud-user2，然后分别启动； 4.启动microservice-springcloud-movie；浏览器输入http://localhost:8761/，可以看到：提供microservice-springcloud-user和microservice-springcloud-user2服务的分别有2个。 microservice-springcloud-user服务随机访问测试在浏览器输入http://localhost:7901/user/1多次，查看控制台：可以看到一个控制台打印了2条SQL，一个控制台打印了4条SQL。说明是随机的。 microservice-springcloud-user默认负载均衡规则测试Ribbon默认使用的负载均衡策略是轮询，在上面的配置文件中，只对microservice-springcloud-user配置了随机访问，那么microservice-springcloud-user2应该是轮询的。下面测试一下。在浏览器输入http://localhost:7901/test，查看microservice-springcloud-movie控制台：可以看到microservice-springcloud-user是随机访问，microservice-springcloud-user2是轮询的。 参考Spring Cloud官方文档Customizing the Ribbon Client using properties中Customizing the Ribbon Client using properties部分。 注意：Spring Cloud官方文档提到的使用负载均衡规则的优先级：配置文件 &gt; 代码自定义 &gt; 系统默认。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列7——通过代码自定义配置ribbon]]></title>
    <url>%2F2018%2F02%2F01%2Fspringcloud-series-7-use-code-custom-ribbon%2F</url>
    <content type="text"><![CDATA[前言我们这里准备了2组服务： 2个microservice-springcloud-user服务，端口分别为7902和7904； 2个microservice-springcloud-user2服务，端口分别为7903和7905；我们想实现的效果是：microservice-springcloud-user服务随机访问，microservice-springcloud-user2服务顺序访问。下面我们通过代码的方式来实现。 创建Ribbon规则123456789package com.tommy.config;@Configurationpublic class RibbonChooseConfiguration &#123; @Bean public IRule ribbonRule(IClientConfig config) &#123; return new RandomRule(); &#125;&#125; 这里指定的规则是随机。 The FooConfiguration has to be @Configuration but take care that it is not in a @ComponentScan for the main application context, otherwise it will be shared by all the @RibbonClients. If you use @ComponentScan (or @SpringBootApplication) you need to take steps to avoid it being included (for instance put it in a separate, non-overlapping package, or specify the packages to scan explicitly in the @ComponentScan). 上面是Spring Cloud官方文档的原文，这里的config类所在的包有一定讲究，就是你的包不能被@ComponentScan或者@SpringBootApplication扫描到。官方文档Ribbon部分：http://cloud.spring.io/spring-cloud-static/Edgware.SR1/single/spring-cloud.html#spring-cloud-ribbon 在应用启动类上配置访问规则12345678910111213141516package com.tommy.springcloud;@SpringBootApplication@EnableEurekaClient@RibbonClient(name = "microservice-springcloud-user",configuration = RibbonChooseConfiguration.class)public class App &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main( String[] args ) &#123; SpringApplication.run(App.class,args); &#125;&#125; 这里指定microservice-springcloud-user使用的规则是RibbonChooseConfiguration定义的规则，也就是随机的。 测试Controller修改12345678910111213141516171819@RestControllerpublic class MovieController &#123; @Autowired private RestTemplate restTemplate; @Autowired private LoadBalancerClient loadBalancerClient; @GetMapping("/user/&#123;userId&#125;") public User getUser(@PathVariable Long userId) &#123; return restTemplate.getForObject("http://microservice-springcloud-user/sample/" + userId,User.class); &#125; @GetMapping(value = "/test") public String test() &#123; ServiceInstance serviceInstance = loadBalancerClient.choose("microservice-springcloud-user"); System.out.println(serviceInstance.getServiceId()+"--&gt;"+serviceInstance.getHost()+":"+serviceInstance.getPort()); ServiceInstance serviceInstance2 = loadBalancerClient.choose("microservice-springcloud-user2"); System.out.println(serviceInstance2.getServiceId()+"--&gt;"+serviceInstance2.getHost()+":"+serviceInstance2.getPort()); return "hello,world"; &#125;&#125; getUser()方法仍然访问microservice-springcloud-user服务，test()方法则2个服务都访问，打印服务的id、ip和端口。 测试 1.开启2个microservice-springcloud-user服务，端口分别为7902和7904； 2.开启2个microservice-springcloud-user2服务，端口分别为7903和7905； 3.开启microservice-springcloud-movie，进行测试； 4.浏览器输入http://localhost:7901/user/1，查看控制台：可以看到，microservice-springcloud-user一个控制台打印了3条SQL，一个1条SQL，说明访问是随机的。而我们在代码中指定了Ribbon访问microservice-springcloud-user的规则是随机的，所以说明规则生效了。 5.浏览器输入http://localhost:7901/test，访问6次可以看到，microservice-springcloud-user是随机访问的，microservice-springcloud-user2是轮询。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列6——通过注册中心调用服务]]></title>
    <url>%2F2018%2F02%2F01%2Fspringcloud-series-6-use-regisster-center-call-servies%2F</url>
    <content type="text"><![CDATA[前言前面在注册中心已经注册了一个服务microservice-springcloud-user，这里我们在microservice-springcloud-movie中通过注册中心调用microservice-springcloud-user用户查询服务，并且实现负载均衡能力。 注意：这里不是直接通过microservice-springcloud-movie调用，是通过Eureka Server。 microservice-springcloud-movie增加eureka client的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; application.yml增加eureka配置123456789101112server: port: 7901spring: application: name: microservice-springcloud-movieeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instanceId: $&#123;spring.application.name&#125;:$&#123;vcap.application.instance_id:$&#123;spring.application.instance_id:$&#123;random.value&#125;&#125;&#125; MovieController修改1234@GetMapping("/user/&#123;userId&#125;")public User getUser(@PathVariable Long userId) &#123; return restTemplate.getForObject("http://microservice-springcloud-user/sample/" + userId,User.class);&#125; 这里是通过注册到注册中心的服务名称来调用（microservice-springcloud-user中spring.application.name）。 启动类修改1234567891011121314@SpringBootApplication@EnableEurekaClientpublic class App &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main( String[] args ) &#123; SpringApplication.run(App.class,args); &#125;&#125; 启动类2处修改： 增加@EnableEurekaClient； RestTemplate增加@LoadBalanced，表示开启客户端负载均衡。 负载均衡测试 1.启动microservice-discovery-eureka； 2.启动microservice-springcloud-user； 3.修改microservice-springcloud-user的application.yml中server.port为其他值（比如7903），再启动microservice-springcloud-user； 4.启动microservice-springcloud-movie浏览器输入http://localhost:8761/，可以看到2个user的service。如图： 浏览器输入http://localhost:7901/user/1，看控制台日志microservice-springcloud-user其中一个打印了查询的SQL，刷新浏览器，可以看到microservice-springcloud-user另外一个打印了查询的SQL。多次执行，都是按顺序依次调用，实现了负载均衡。 Ribbonspringcloud的负载均衡是通过Ribbon实现的，是一个客户端的负载均衡组件，Ribbon实现了客户端的一些负载均衡算法，包括轮询（Round-Robin）、随机选择、最大可用策略等多种策略。Ribbon负载均衡策略 RoundRobinRule: 轮询策略，Ribbon以轮询的方式选择服务器，这个是默认值。所以示例中所启动的两个服务会被循环访问; RandomRule: 随机选择，也就是说Ribbon会随机从服务器列表中选择一个进行访问; BestAvailableRule: 最大可用策略，即先过滤出故障服务器后，选择一个当前并发请求数最小的; WeightedResponseTimeRule: 带有加权的轮询策略，对各个服务器响应时间进行加权处理，然后在采用轮询的方式来获取相应的服务器; AvailabilityFilteringRule: 可用过滤策略，先过滤出故障的或并发请求大于阈值一部分服务实例，然后再以线性轮询的方式从过滤后的实例清单中选出一个; ZoneAvoidanceRule: 区域感知策略，先使用主过滤条件（区域负载器，选择最优区域）对所有实例过滤并返回过滤后的实例清单，依次使用次过滤条件列表中的过滤条件对主过滤条件的结果进行过滤，判断最小过滤数（默认1）和最小过滤百分比（默认0），最后对满足条件的服务器则使用RoundRobinRule(轮询方式)选择一个服务器实例。参考：https://www.jianshu.com/p/df9393755a05 Spring Cloud官方文档Ribbon的介绍：http://cloud.spring.io/spring-cloud-static/Edgware.SR1/single/spring-cloud.html#spring-cloud-ribbon 注意：Spring Cloud官方文档中在How to Include Ribbon一节中说，要加入Ribbon的starter依赖。实际上是不需要的，在spring-cloud-dependencies依赖中已经包含了Ribbon的starter。或者idea模块依赖中也可以看到已经有Ribbon的依赖了。如图：]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列5——创建服务并注册到Eureka]]></title>
    <url>%2F2018%2F02%2F01%2Fspringcloud-series-5-create-and-register-services-to-Eureka%2F</url>
    <content type="text"><![CDATA[添加eureka客户端的依赖在microservice-springcloud-user模块加入eureka客户端的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 在application.yml添加eureka的配置1234567eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true instanceId: $&#123;spring.application.name&#125;:$&#123;vcap.application.instance_id:$&#123;spring.application.instance_id:$&#123;random.value&#125;&#125;&#125; spring.application.name属性我们可以指定微服务的名称后续在调用的时候只需要使用该名称就可以进行服务的访问。 eureka.client.serviceUrl.defaultZone属性指定服务注册中心的位置。为了在本机上测试区分服务提供方和服务注册中心，使用server.port属性设置不同的端口。 启动类增加@EnableEurekaClient注解1234567@SpringBootApplication@EnableEurekaClientpublic class MicroserviceUserProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MicroserviceUserProviderApplication.class, args); &#125;&#125; @EnableEurekaClient : 声明这是一个Eureka Client 启动MicroserviceUserProviderApplication，访问http://localhost:8761，可以看到有一个服务microservice-springcloud-user。 注意：启动《springcloud系列4——创建一个Eureka Server》中的Eureka Server。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列4——创建一个Eureka Server]]></title>
    <url>%2F2018%2F02%2F01%2Fspringcloud-series-4-create-Eureka%20Server%2F</url>
    <content type="text"><![CDATA[创建一个Eureka Server创建一个子模块microserver-discovery-eureka，该模块属于microserver-spring-cloud（看第一篇）。 pom.xml123456789101112131415161718192021&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;microserver-spring-cloud&lt;/artifactId&gt; &lt;groupId&gt;com.tommy.springcloud&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tommy.springcloud&lt;/groupId&gt; &lt;artifactId&gt;microservice-discovery-eureka&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;microservice-discovery-eureka&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 注意：microserver-spring-cloud的pom.xml中增加springcloud依赖：1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 应用启动类1234567891011121314151617181920212223package com.tommy.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * Hello world! * */@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication&#123; /** * 注意： * 1.启动之后访问的地址是：http://localhost:8761/，不是http://localhost:8761/eureka。 * 2.注意父pom.xml中spring-cloud-dependencies的版本，可能导致子工程中找不到对应版本。这里使用的版本Edgware.SR1是Ok的。 * @param args */ public static void main( String[] args ) &#123; SpringApplication.run(EurekaApplication.class,args); &#125;&#125; 通过@EnableEurekaServer注解启动一个服务注册中心 application.yml1234567891011server: port: 8761eureka: client: # 表示是否将自己注册到Eureka Server,默认为true.由于当前应用就是Eureka Server,故而设置为false. register-with-eureka: false # 表示是否从Eureka Server获取注册信息,默认为true.因为这是一个单点的Eureka Server,不需要同步其他的Eureka Server节点的数据,这里设置为false fetch-registry: false service-url: # 设置Eureka Server的地址,查询服务和注册服务都需要依赖这个地址.默认是http://localhost:8761/eureka/;多个地址可使用','风格. defaultZone: http://localhost:8761/eureka 运行EurekaApplication，在浏览器输入http://localhost:8761/，可以看到下面的页面，还没有任何服务。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列3——Eureka简介和原理]]></title>
    <url>%2F2018%2F02%2F01%2Fspringcloud-series-3-Eureka-introduction-and-principle%2F</url>
    <content type="text"><![CDATA[Eureka简介及原理Eureka是Netflix开发的服务发现组件，本身是一个基于REST的服务。Spring Cloud将它集成在其子项目spring-cloud-netflix中，以实现Spring Cloud的服务发现功能。目前Eureka 项目相当活跃，代码更新相当频繁，目前最新的版本是1.5.5。Eureka 2.0也在紧锣密鼓地开发中，2.0将会带来更强的功能和更好的扩展性，但是由于还没有Release，故而不作讨论。 本文讲解的Spring Cloud Camden SR1所使用的Eureka版本是1.4.11，还是比较新的。同时有了Eureka 1.x的基础，未来上手Eureka 2.x也会比较容易。 Eureka的Github：https://github.com/Netflix/Eureka Region、Zone解析Eureka的官方文档对regin、zone几乎没有提及，由于概念抽象，新手很难理解。因此，在分析Eureka原理之前，我们先来了解一下region、zone、Eureka集群三者的关系，如图4-2。图4-2 region、zone、Eureka集群之间的关系 region和zone（或者Availability Zone）均是AWS的概念。在非AWS环境下，我们可以简单地将region理解为Eureka集群，zone理解成机房。这样图4-2就很好理解了——一个Eureka集群被部署在了zone1机房和zone2机房中。 对region和zone感兴趣的读者可前往http://blog.csdn.net/awschina/article/details/17639191 扩展阅读。Spring Cloud中默认的region是us-east-1 。 Eureka架构图4-3 Eureka架构图 图4-3是来自Eureka官方的架构图，大致描述了Eureka集群的工作过程。图中包含的组件非常多，可能比较难以理解，我们用通俗易懂的语言解释一下： Application Service 相当于本书中的服务提供者，Application Client相当于本书中的服务消费者； ke Remote Call，可以简单理解为调用RESTful API； us-east-1c、us-east-1d等都是zone，它们都属于us-east-1这个region；由图可知，Eureka包含两个组件：Eureka Server 和 Eureka Client，它们的作用如下： Eureka Client是一个Java客户端，用于简化与Eureka Server的交互； Eureka Server提供服务发现的能力，各个微服务启动时，会通过Eureka Client向Eureka Server进行注册自己的信息（例如网络信息），Eureka Server会存储该服务的信息； 微服务启动后，会周期性地向Eureka Server发送心跳（默认周期为30秒）以续约自己的信息。如果Eureka Server在一定时间内没有接收到某个微服务节点的心跳，Eureka Server将会注销该微服务节点（默认90秒）；每个Eureka Server同时也是Eureka Client，多个Eureka Server之间通过复制的方式完成服务注册表的同步； Eureka Client会缓存Eureka Server中的信息。即使所有的Eureka Server节点都宕掉，服务消费者依然可以使用缓存中的信息找到服务提供者。 综上，Eureka通过心跳检测、健康检查和客户端缓存等机制，提高了系统的灵活性、可伸缩性和可用性。 转载于Spring Cloud第一篇 Eureka简介及原理]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列2——SpringCloud简介]]></title>
    <url>%2F2018%2F02%2F01%2Fspringcloud-series-2-SpringCloud-introduction%2F</url>
    <content type="text"><![CDATA[Spring Cloud简介Spring Cloud是一系列框架的有序集合。利用Spring Boot的开发模式简化了分布式系统基础设施的开发，如服务发现、注册、配置中心、消息总线、负载均衡、断路器、数据监控等（这里只简单的列了一部分），都可以用Spring Boot的开发风格做到一键启动和部署。Spring Cloud将目前比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装，屏蔽掉了复杂的配置和实现原理，最终整合出一套简单易懂、易部署和易维护的分布式系统架构平台。 Spring Cloud组成Spring Cloud的子项目，大致可分成两类： 一类是对现有成熟框架Spring Boot的封装和抽象，也是数量最多的项目； 第二类是开发了一部分分布式系统的基础设施的实现，如Spring Cloud Stream就是kafka, ActiveMQ这样的角色。开发人员进行微服务的实践，第一类子项目就已经足够使用，如： Spring Cloud Netflix 是对Netflix开发的一套分布式服务框架的封装，包括服务的发现和注册，负载均衡、断路器、REST客户端、请求路由等。 Spring Cloud Config 将配置信息中央化保存, 配置Spring Cloud Bus可以实现动态修改配置文件。 Spring Cloud Bus 分布式消息队列，是对Kafka, MQ的封装。 Spring Cloud Security 对Spring Security的封装，并能配合Netflix使用。 Spring Cloud Zookeeper 对Zookeeper的封装，使之能配置其它Spring Cloud的子项目使用。 Spring Cloud Eureka Spring Cloud Eureka 是 Spring Cloud Netflix 微服务套件中的一部分，它基于Netflix Eureka 做了二次分装，主要负责完成微服务架构中的服务治理功能。 Spring Cloud未来Spring Cloud为未来互联网企业提供分布式基础设施解决方案。同时，随着近几年微服务架构和Docker容器概念的火爆，也会让Spring Cloud在未来越来越“云”化的软件开发风格中立有一席之地，尤其是在目前五花八门的分布式解决方案中提供了标准化的、全站式的技术方案，有效推进服务端软件系统技术水平提升。 转载于http://www.jcodecraeer.com/a/chengxusheji/java/2017/1031/8663.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springcloud系列1——使用Springboot对外提供rest服务]]></title>
    <url>%2F2018%2F02%2F01%2Fspringcloud-series-1-use-Springboot-to-support-outer-services%2F</url>
    <content type="text"><![CDATA[说明由于springclound基于Springboot，因此第一篇熟悉一下Springboot。这里为了后面的演示，创建一个project，名为microservice-spring-cloud。创建2个子模块： microservice-springcloud-user 该模块提供用户查询功能 microservice-springcloud-movie 该模块是电影模块，从microservice-springcloud-user模块查询用户信息。 microservice-spring-cloudpom.xml123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tommy.springcloud&lt;/groupId&gt; &lt;artifactId&gt;microserver-spring-cloud&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;microservice-springcloud-user&lt;/module&gt; &lt;module&gt;microservice-springcloud-movie&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; microservice-springcloud-user模块该模块使用Springboot，数据库使用h2内存数据库，数据库框架使用jpa。 application.yml:12345678910111213141516171819202122232425262728server: port: 7902spring: application: name: microservice-springcloud-user jpa: generate-ddl: false # 显示SQL show-sql: true format_sql: true hibernate: ddl-auto: none datasource: platform: h2 # 指定DDL脚本 schema: classpath:schema.sql # 指定数据初始化脚本 data: classpath:data.sqlloggin: level: root: INFO org.hibernate: INFO org.hibernate.type.descriptor.sql.BasicBinder: TRACE org.hibernate.type.descriptor.sql.BasicExtractor: TRACE com.tommy: DEBUG schema.sql:12DROP TABLE USER IF EXISTS ;create table USER(id bigint generated BY DEFAULT AS IDENTITY ,username VARCHAR(32),NAME VARCHAR (20),balance DECIMAL(10,2),PRIMARY KEY (id)); data.sql:1234INSERT INTO USER(ID,username,NAME ,balance) VALUES (1,'user1','张三',100.00);INSERT INTO USER(ID,username,NAME ,balance) VALUES (2,'user2','李四',100.00);INSERT INTO USER(ID,username,NAME ,balance) VALUES (3,'user3','王五',100.00);INSERT INTO USER(ID,username,NAME ,balance) VALUES (4,'user4','马六',100.00); pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tommy.cloud&lt;/groupId&gt; &lt;artifactId&gt;microservice-sample-provider&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;microservice-sample-provider&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 用户实体类：12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.tommy.springcloud.entity;import javax.persistence.*;import java.math.BigDecimal;/** * @author j.tommy * @version 1.0 * @date 2018/1/24 */@Entitypublic class User &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; @Column private String username; @Column private String name; @Column private BigDecimal balance; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public BigDecimal getBalance() &#123; return balance; &#125; public void setBalance(BigDecimal balance) &#123; this.balance = balance; &#125;&#125; 数据库操作类：1234567891011121314package com.tommy.springcloud.repository;import com.tommy.springcloud.entity.User;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.stereotype.Repository;/** * @author j.tommy * @version 1.0 * @date 2018/1/24 */@Repositorypublic interface UserRepository extends JpaRepository&lt;User,Long&gt; &#123;&#125; 对外提供服务的Controller：123456789101112131415161718192021package com.tommy.springcloud.controller;import com.tommy.springcloud.entity.User;import com.tommy.springcloud.repository.UserRepository;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;/** * @author j.tommy * @version 1.0 * @date 2018/1/24 */@RestControllerpublic class UserController &#123; @Autowired private UserRepository userRepository; @GetMapping("/sample/&#123;id&#125;") public User findById(@PathVariable Long id) &#123; return this.userRepository.findOne(id); &#125;&#125; 应用启动类：12345678910111213package com.tommy.springcloud;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;/** * @author Administrator */@SpringBootApplicationpublic class MicroserviceUserProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MicroserviceUserProviderApplication.class, args); &#125;&#125; 启动后，通过http://localhost:7902/sample/1，即可查询用户id为1的用户信息。 microservice-springcloud-movie模块电影模块，从microservice-springcloud-user模块查询用户信息。 pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tommy.cloud&lt;/groupId&gt; &lt;artifactId&gt;microservice-springcloud-movie&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;microservice-springcloud-movie&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml:12server: port: 7901 用户实体类：12345678910111213141516171819202122232425262728293031323334353637package com.tommy.cloud.microservicemovie.entity;import java.math.BigDecimal;/** * @author j.tommy * @version 1.0 * @date 2018/1/24 */public class User &#123; private Long id; private String username; private String name; private BigDecimal balance; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public BigDecimal getBalance() &#123; return balance; &#125; public void setBalance(BigDecimal balance) &#123; this.balance = balance; &#125;&#125; MovieController123456789101112131415161718192021package com.tommy.cloud.microservicemovie.controller;import com.tommy.cloud.microservicemovie.entity.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;/** * @author j.tommy * @version 1.0 * @date 2018/1/24 */@RestControllerpublic class MovieController &#123; @Autowired private RestTemplate restTemplate; @GetMapping("/movie/&#123;id&#125;") public User findUserById(@PathVariable Long id) &#123; return this.restTemplate.getForObject("http://localhost:7902/sample/" + id, User.class); &#125;&#125; 应用启动类：12345678910111213141516package com.tommy.cloud.microservicemovie;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;@SpringBootApplicationpublic class MicroserviceSampleConsumerApplication &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(MicroserviceSampleConsumerApplication.class, args); &#125;&#125; 启动后，通过http://localhost:7901/movie/1，即可查询用户id为1的用户信息。至此，使用Springboot搭建的一个服务提供者和服务消费者模块就完成了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis常见问题]]></title>
    <url>%2F2018%2F01%2F31%2Fshow-redis-client-list-ip%2F</url>
    <content type="text"><![CDATA[查看Redis连接数在Redis命令行执行info clients得到类似下面的结果：1234connected_clients:357 client_longest_output_list:0 client_biggest_input_buf:0 blocked_clients:0 redis连接数过多的问题可以参考：处理redis连接数过多 查询Redis客户端列表Redis操作很慢，网络正常，Redis连接数也还好。使用client list查看Redis客户端分布，发现大量的Redis连接（同一个IP），且执行的都是keys命令，导致Redis命令执行缓慢。 Redis命令行常用命令参考：Redis详解与常见问题解决方案、一行shell查看redis 连接数分布]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用jstack排查系统问题]]></title>
    <url>%2F2018%2F01%2F31%2Fuse_stack_to_find_system_bugs%2F</url>
    <content type="text"><![CDATA[jstack介绍jstack是java虚拟机自带的一种堆栈跟踪工具,用于生成java虚拟机当前时刻的线程快照。 生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。 使用jstack的一般步骤查找java进程id这里得到的进程ID是10226. 找出最耗费CPU的线程可以使用：1231.ps -Lfp pid2.ps -mp pid -o THREAD, tid, time3.top -Hp pid 上面3者之一。这里使用第3种：1top -Hp 10226 TIME列就是各个Java线程耗费的CPU时间，CPU时间最长的是线程ID为11149的线程，用printf &quot;%x\n&quot; 11149得到11149的十六进制值为2b8d，下面会用到。 使用jstack输出进程10226的堆栈信息，然后根据线程ID的十六进制grep。1jstack 10226 | grep 2b8d 接下来就可以根据结果分析代码了。 或者直接在找出进程id后，使用jstack -l 10226 &gt; 10226.txt将进程的所有堆栈想信息输出到10226.txt文件。然后分析10226.txt，找出有问题的代码修改。比如：可以看到有问题的代码和行数。 参考：线程的状态信息、Java命令学习系列（二）——Jstack、执行jstack报Unable to open socket file错误]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[secureCRT安装、破解]]></title>
    <url>%2F2018%2F01%2F28%2FsecureCRT-unpack-and-use%2F</url>
    <content type="text"><![CDATA[SecureCRT是最常用的终端仿真程序，简单的说就是Windows下登录UNIX或Liunx服务器主机的软件。本文讲解SecureCRT的安装、破解与使用。 下载&amp;安装1.从https://pan.baidu.com/s/1dGMKJF7下载2.解压缩下载的文件，双击scrt736-x64.exe执行安装。 破解1.打开SecureCRT.7.3.keygen.exe，点击Patch按钮，依次选择SecureCRT.exe和LicenseHelper.exe2.双击打开安装后的secureCRT，在License Wizard选择下一步，然后点击Enter License Manually按钮，然后依次填入注册机上的Name,Company，Serial，License key，Issue date，然后点击下一步，完成。如果输入完毕，点击下一步提示你的License不适用于该版本，在注册机上点Generate，重新生成License key，再次输入。 PublicKey认证的设置Authentication只选择PublicKey，点击Properties选择key文件，点击OK即可。 这里以JumpServer堡垒机为例说明。在JumpServer的WEB页面输入用户名，密码和手机动态口令，登入后，可以下载key文件。这里的Key文件即为上面PublicKey认证用到的文件。点击key后面的下载，下载PublicKey文件。 中文乱码问题]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java代理设置]]></title>
    <url>%2F2018%2F01%2F27%2Fhttpclient-proxy%2F</url>
    <content type="text"><![CDATA[本文主要讲述使用HttpClient时的代理设置。 常见的设置代理的方法使用系统代理配置可以通过下面的方式来分别设置HTTP代理，HTTPS代理和SOCKS代理：123456789101112// HTTP 代理，只能代理 HTTP 请求System.setProperty("http.proxyHost", "127.0.0.1");System.setProperty("http.proxyPort", "9876"); // HTTPS 代理，只能代理 HTTPS 请求System.setProperty("https.proxyHost", "127.0.0.1");System.setProperty("https.proxyPort", "9876"); // SOCKS 代理，支持 HTTP 和 HTTPS 请求// 注意：如果设置了 SOCKS 代理就不要设 HTTP/HTTPS 代理System.setProperty("socksProxyHost", "127.0.0.1");System.setProperty("socksProxyPort", "1080"); 这里有三点要说明：1.系统默认先使用 HTTP/HTTPS 代理，如果既设置了 HTTP/HTTPS 代理，又设置了 SOCKS 代理，SOCKS 代理会起不到作用2.由于历史原因，注意 socksProxyHost 和 socksProxyPort 中间没有小数点3.HTTP 和 HTTPS 代理可以合起来缩写，如下：123// 同时支持代理 HTTP/HTTPS 请求System.setProperty("proxyHost", "127.0.0.1");System.setProperty("proxyPort", "9876"); JVM 命令行参数在VM arguments中填写参数：-DproxyHost=127.0.0.1 -DproxyPort=9876 HttpURLConnection 使用代理HttpURLConnection 的 openConnection() 方法可以传入一个 Proxy 参数，如下：123Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress("127.0.0.1", 9876));URL obj = new URL(url);HttpURLConnection con = (HttpURLConnection) obj.openConnection(proxy); OK 了，就这么简单！ 不仅如此，我们注意到 Proxy 构造函数的第一个参数为枚举类型 Proxy.Type.HTTP ，那么很显然，如果将其修改为 Proxy.Type.SOCKS 即可以使用 SOCKS 代理。 HttpClient 使用代理由于 HttpClient 非常灵活，使用 HttpClient 来连接代理有很多不同的方法。最简单的方法莫过于下面这样：1234HttpHost proxy = new HttpHost("127.0.0.1", 9876, "HTTP");CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet request = new HttpGet(url);CloseableHttpResponse response = httpclient.execute(proxy, request); 使用RequestConfig类12345678910CloseableHttpClient httpclient = HttpClients.createDefault(); HttpGet request = new HttpGet(url); request.setConfig( RequestConfig.custom() .setProxy(new HttpHost("45.32.21.237", 8888, "HTTP")) .build()); CloseableHttpResponse response = httpclient.execute(request); 使用RoutePlanner类1234567HttpHost proxy = new HttpHost("127.0.0.1", 9876, "HTTP");DefaultProxyRoutePlanner routePlanner = new DefaultProxyRoutePlanner(proxy); CloseableHttpClient httpclient = HttpClients.custom() .setRoutePlanner(routePlanner) .build();HttpGet request = new HttpGet(url);CloseableHttpResponse response = httpclient.execute(request); 使用系统代理怎么在程序中自动使用系统代理呢？ 对于 HttpURLConnection 类来说，程序不用做任何变动，它会默认使用系统代理。但是 HttpClient 默认是不使用系统代理的，如果想让它默认使用系统代理，可以通过 SystemDefaultRoutePlanner 和 ProxySelector 来设置。示例代码如下：123456SystemDefaultRoutePlanner routePlanner = new SystemDefaultRoutePlanner(ProxySelector.getDefault());CloseableHttpClient httpclient = HttpClients.custom() .setRoutePlanner(routePlanner) .build();HttpGet request = new HttpGet(url); CloseableHttpResponse response = httpclient.execute(request); 以上内容来自：Java 和 HTTP 的那些事（二） 使用代理 使用shadowsocks的代理说明我有一台香港的windows服务器，在上面搭建了Shadowsocks服务，本地浏览器测试正常，但程序中使用System.setProperty和RequestConfig的方式都无效。最后使用RoutePlanner类成功。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Windows Server 上搭建Shadowsocks服务器]]></title>
    <url>%2F2018%2F01%2F27%2Fcreate-shadowsocks-server-on-windows%2F</url>
    <content type="text"><![CDATA[这里是在windows上搭建Shadowsocks服务器，使用的是github上的libQtShadowsocks项目。项目地址：https://github.com/shadowsocks/libQtShadowsocks 准备一台可以翻墙的windows。 下载libQtShadowsocks从https://github.com/shadowsocks/libQtShadowsocks/releases下载一个已经编译好的版本，这里是shadowsocks-libqss-v1.10.0-win64.7z，原来下载的是最新的2.0版本，结果用不了。下载后解压到任意位置，里面就一个shadowsocks-libqss.exe文件。 配置文件在解压目录下创建2个文件，一个config.json，一个shadowsocks-server.bat。config.json放置配置信息。内容如下：1234567891011&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8023, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;wyvbboy&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;http_proxy&quot;: false, &quot;auth&quot;: false &#125; 配置说明：serverthe address your server listens（服务器IP）local_addressthe address your local listens（本地代理地址）local_portlocal port（本地代理端口）（写之前创建的ss的端口）port_passwordpassword used for encryption(自己设定的服务器端口和密码)（自己可以随便设定）timeoutin seconds（超时断开，以秒为单位）methoddefault: “aes-256-cfb”, see Encryption（加密方式）fast_openuse TCP_FASTOPEN, true / false（是否使用TCP）workersnumber of workers, available on Unix/Linux（这个只在Unix和Linux下有用，可不设置）。 shadowsocks-server.bat内容如下：12@echo offshadowsocks-libqss.exe -c config.json -S 运行Shadowsocks服务直接运行shadowsocks-server.bat即可运行Shadowsocks服务，你也可以在命令提示符进入软件目录，运行shadowsocks-libqss.exe -c config.json -S这行命令。 客户端配置这里使用的客户端为Shadowsocks，github地址：https://github.com/shadowsocks/shadowsocks-windows。 注意：要以PAC模式运行，如果选择全局模式，所有的访问都会使用shadowsocks；如果选择了PaC模式，则只有pac.txt中的网址才会使用shadowsocks。注意防火墙开通相应的端口。 自定义规则参考：http://honglu.me/2015/06/26/ShadowSocks%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A7%84%E5%88%99/从网上查阅的资料编辑FGWList的用户规则但我本地最后从FGWList更新本地pac时报错了 所以我是直接修改的pac.txt文件，在其中加入你想使用shadowsocks访问的网址，最后选择使用PAC模式即可。 多用户如果希望多个用户使用shadowsocks服务，使用下面的配置替换password:xxx部分。123456&quot;port_password&quot;: &#123; &quot;8381&quot;: &quot;foobar1&quot;, &quot;8382&quot;: &quot;foobar2&quot;, &quot;8383&quot;: &quot;foobar3&quot;, &quot;8384&quot;: &quot;foobar4&quot; &#125;, 问题更新于2018-05-31.某天shadowsocks服务不能使用了。server端日志：1234567891011122018-05-31 16:15:41.382 INFO: Connecting clients1.google.com:443 from 183.62.174.53:489772018-05-31 16:15:44.649 INFO: Connecting clients1.google.com:443 from 183.62.174.53:490212018-05-31 16:15:44.665 INFO: Connecting clients1.google.com:443 from 183.62.174.53:490322018-05-31 16:15:50.803 INFO: Connecting clients1.google.com:443 from 183.62.174.53:491032018-05-31 16:15:56.177 INFO: Connecting www.google.com:443 from 183.62.174.53:491992018-05-31 16:15:56.185 INFO: Connecting www.google.com:443 from 183.62.174.53:492002018-05-31 16:16:11.364 DEBUG: Local socket: The remote host closed the connection2018-05-31 16:16:14.637 DEBUG: Local socket: The remote host closed the connection2018-05-31 16:16:14.654 DEBUG: Local socket: The remote host closed the connection2018-05-31 16:16:20.794 DEBUG: Local socket: The remote host closed the connection2018-05-31 16:16:26.164 DEBUG: Local socket: The remote host closed the connection2018-05-31 16:16:26.172 DEBUG: Local socket: The remote host closed the connection 更换了算法、端口还是不行，客户端更新版本也不行，最后更新服务端版本后ok了。这里使用的版本是：shadowsocks-libqss-v2.0.2-win64.7z。 PS：有问题先看看github上相关的Issues。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tesseract-ocr-demo]]></title>
    <url>%2F2018%2F01%2F19%2Ftesseract-ocr-demo%2F</url>
    <content type="text"><![CDATA[Tesseract-OCR验证码识别1.下载tesseract，目前最新版本tesseract-ocr-setup-3.05.01.exe；2.安装，安装的时候勾选中文（如果要识别中文）；3.配置环境变量。将安装目录配置到path中； 将tessdata目录配置到TESSDATA_PREFIX环境变量；4.重启电脑。（idea要重启电脑才能读取环境变量）5.命令行测试。识别结果：发现有些无关的东西。 6.测试代码（JAVA）：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** 验证码识别 * @author j.tommy * @version 1.0 * @date 2018/1/11 */public class LJValideCode &#123; protected final static Logger log = Logger.getLogger(LJValideCode.class); private final static String LANG_OPTION = "-l"; private final static String EOL = "/"; public static void main(String[] args) throws Exception &#123; for (int i=0;i&lt;10;i++) &#123; String code = recognizeText(new File("D:/Work/helloworld/resources/validate/download/"+i+".jpg")); System.out.println(code); &#125; &#125; /** * @param imageFile * 传入的图像文件 * @return 识别后的字符串 */ public static String recognizeText(File imageFile) throws Exception &#123; /** * 设置输出文件的保存的文件目录 */ File outputFile = new File(imageFile.getParentFile(), "output"); StringBuffer strB = new StringBuffer(); List&lt;String&gt; cmd = new ArrayList&lt;String&gt;(); cmd.add("tesseract"); cmd.add(imageFile.getName()); cmd.add(outputFile.getName()); cmd.add(LANG_OPTION);// cmd.add("chi_sim"); cmd.add("eng"); ProcessBuilder pb = new ProcessBuilder(); /** *Sets this process builder's working directory. */ pb.directory(imageFile.getParentFile()); pb.command(cmd); for (String string :cmd) &#123; System.out.print(string + " "); &#125; System.out.println(); pb.redirectErrorStream(true); Process process = pb.start(); // tesseract.exe 1.jpg 1 -l chi_sim // Runtime.getRuntime().exec("tesseract.exe 1.jpg 1 -l chi_sim"); /** * the exit value of the process. By convention, 0 indicates normal * termination. */// System.out.println(cmd.toString()); int w = process.waitFor(); if (w == 0)// 0代表正常退出 &#123; BufferedReader in = new BufferedReader(new InputStreamReader( new FileInputStream(outputFile.getAbsolutePath() + ".txt"), "UTF-8")); String str; while ((str = in.readLine()) != null) &#123; strB.append(str).append(EOL); &#125; in.close(); &#125; else &#123; String msg = ""; BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(process.getInputStream())); String line = null; while ((line = bufferedReader.readLine()) != null) &#123; msg += line; &#125; bufferedReader.close(); throw new RuntimeException(msg); &#125; new File(outputFile.getAbsolutePath() + ".txt").delete(); String result = ""; String string = strB.toString(); for (int i=0;i&lt;string.length();i++) &#123; // 这里识别的验证码是数字，实际识别后发现有一些无关的东西，所以这里过滤掉。 if (StringUtils.isNumeric(string.charAt(i)+"")) &#123; result += string.charAt(i); &#125; &#125; return result; &#125;&#125; OCR识别训练http://blog.csdn.net/why200981317/article/details/48265621 相关资源Tesseract-OCR识别中文与训练字库实例https://www.cnblogs.com/mafeng/p/8124159.htmlhttps://www.cnblogs.com/wzben/p/5930538.html Android Studio里面配置Tesseracthttp://www.cnblogs.com/wzben/p/5932331.html 基于Tesseract的身份证识别Android端应用http://www.cnblogs.com/wzben/p/5945071.html tess4j识别图片中的文字http://blog.csdn.net/u012386311/article/details/60135355 JAVA识别身份证号码，H5识别身份证号码，tesseract-ocr识别（一）http://blog.csdn.net/hiredme/article/details/50894814 ocr智能图文识别 tess4j 图文，验证码识别https://www.cnblogs.com/cmyxn/p/6993422.html 商业：http://leadtools.gcpowertools.com.cn/products/ocr/ 机器学习之验证码识别http://blog.csdn.net/Alis_xt/article/details/65627303 tesseract-ocr:wiki:https://github.com/tesseract-ocr/tesseract/wiki/Data-Files 相关问题：https://github.com/tesseract-ocr/tesseract/wiki/FAQ 提升识别的质量：https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality上面提到Tesseract works best on images which have a DPI of at least 300 dpi, so it may be beneficial to resize images. 使用java修改图片DPI：http://blog.csdn.net/shakalin2008/article/details/78799671http://blog.csdn.net/chenweionline/article/details/2026855 OCR学习及tesseract的一些测试http://blog.csdn.net/viewcode/article/details/7784600]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>验证码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP推送技术]]></title>
    <url>%2F2018%2F01%2F17%2Fhttp_push%2F</url>
    <content type="text"><![CDATA[在一般的Web应用中，浏览器和服务器之间使用的是请求/响应的交互模式。浏览器发出请求，服务器根据收到的请求来生成相应的响应。浏览器再对收到的响应进行处理，展现给用户。响应的格式可能是 HTML、XML 或 JSON 等。为了防止页面整个刷新，引入了Ajax来实现页面的局部刷新。不过对于需要及时获取服务器数据的应用场景来说，使用Ajax轮询就不行了，服务器并不能在有新数据时主动推送给浏览器，只能等待浏览器的下一次请求到来后响应。 对于数据及时性要求比较高的应用来说，可以考虑的实现方式是：基于HTML5的WebSocket、基于HTML5的服务器推送事件（EventSource）、comet技术。 关于服务器数据推送的相关技术可以参考：HTML5 服务器推送事件（Server-sent Events）实战开发、html5利用websocket完成的推送功能（tomcat）、Web推送技术之comet4j使用]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>推送技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tess4j验证码识别]]></title>
    <url>%2F2018%2F01%2F11%2Ftess4j_demo%2F</url>
    <content type="text"><![CDATA[tess4j验证码识别 tess4j的安装和使用参考：https://www.cnblogs.com/cmyxn/p/6993422.html tess4j提高识别率1.对称近邻均值滤波参考：http://blog.csdn.net/fangbinwei93/article/details/50562449 2.指定config为digits，并修改tessdata\configs\digits文件，将白名单中设置需要识别的内容。如只需要识别数字，则指定whitelist为0123456789即可。也可在程序中指定：参考http://blog.csdn.net/hellousb2010/article/details/39477859 3.尽量指定图像的一块区域识别。比如验证码起始位置和结束位置很多空白的，可以去掉，只对验证码区域做识别。 4.训练字库，提升识别率http://blog.csdn.net/white0blue/article/details/47972405http://blog.csdn.net/tuling_research/article/details/41091163 其他参考tesseract-ocr参数http://www.sk-spell.sk.cx/tesseract-ocr-parameters-in-302-version 使用百度的OCR识别http://console.bce.baidu.com/ai/#/ai/ocr/overview/index1天500次的免费调用，一般也足够使用了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>验证码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python博客搭建]]></title>
    <url>%2F2018%2F01%2F10%2FPython_blog%2F</url>
    <content type="text"><![CDATA[python搭建博客问题汇总 环境python版本：2.7web框架：Flaskorm框架：flask_sqlalchemy前端框架：Bootstrap 问题问题1：如何限制访问受保护的资源（需登录）flask中拦截用户登录修饰符decorator的使用https://segmentfault.com/a/1190000006658289http://blog.csdn.net/kongxx/article/details/51654751http://blog.csdn.net/kuangshp128/article/details/65629533 问题2：如何书写Markdown格式的文章。flask markdown用法：http://blog.csdn.net/jhgjdfhre/article/details/52253630说明一下：如果要代码语法高亮，参考：http://pythonhosted.org/Markdown/extensions/code_hilite.html1.安装Pygments2.使用pygmentize -S default -f html -a .codehilite &gt; styles.css生成styles.css3.复制styles.css到你的工程中。 问题3：flask框架数据库和页面分页flask数据分页：http://baagee.vip/index/article/id/63.htmlhttps://www.jianshu.com/p/d5224b90afebhttp://www.jb51.net/article/118715.htm 问题4：Flask框架使用的模板引擎Jinja2用法。Jinja2文档：http://docs.jinkan.org/docs/jinja2/templates.html 问题5：Flask框架Jinja2日期格式化新建一个日期处理函数12345678910111213141516171819# file:jinja_filter.py# coding: utf-8__author__ = 'j.tommy'import datetimedef datetimeformat(value, format='%Y-%m-%d'): """ 将float类型的日期格式化为字符串格式。 :param value: 日期（float类型） :param format: 日期格式 :return: """ d = datetime.datetime.fromtimestamp(value) print d,type(d) return d.strftime(format)``` 在app中指定过滤器```python# 用于页面模板进行日期格式化app.jinja_env.filters['datetimeformat'] = jinja_filters.datetimeformat 页面使用1&#123;&#123;blog.created_at|datetimeformat('%Y-%m-%d %H:%M')&#125;&#125; python博客代码：https://gitee.com/qincd/awesome-python-blog]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[notepad++之python环境搭建]]></title>
    <url>%2F2018%2F01%2F03%2Fnotepad-python%2F</url>
    <content type="text"><![CDATA[参考在Notepad++中搭配Python开发环境(修改版）比如设置运行的快捷键为CTRL+SHIFT+F10.python的插件式通过pip或easy_install安装的。安装插件前确保安装了pip或easy_install。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git配置多个SSH-Key]]></title>
    <url>%2F2018%2F01%2F02%2FGit-config-multi-SSH-Key%2F</url>
    <content type="text"><![CDATA[默认情况下，我们通过ssh-keygen -t rsa -C “XXXXXX@XXX.com”命令生成的ssh keys是在用户目录的.ssh目录（~/.ssh）中，一个id_rsa，一个id_rsa.pub。然后一路回车，最后再.ssh目录即可看到id_rsa和id_rsa.pub。将id_rsa.pub文件内容复制并添加到github或gitlab的ssh key。如果使用了github，同时使用了gitlab，就需要配置多个ssh key，并通过配置config文件用以区分多个ssh key。 参考：http://blog.csdn.net/birdben/article/details/51824788]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将项目迁移到gitlab]]></title>
    <url>%2F2017%2F12%2F14%2Fsvn-to-git%2F</url>
    <content type="text"><![CDATA[1.在gitlab上建立project，得到一个git地址，如：http://192.168.74.90/xxx_sportSnatch/bt_receive.git。在gitlib上可以看到2种，一种是ssh，一种是http的。我们后面使用git bash操作，使用http方式。 2.忽略不需要提交的文件这里以idea为例，忽略target目录和.iml文件。在bt_receive项目根目录创建.gitignore文件，文件内容：123.idea*.imltarget 3.在项目所在目录（比如bt_receive）右键，git bash here。会弹出一个git bash窗口依次执行123456cd bt_receivegit initgit add .git commit -m &apos;Initial commit&apos;git remote add origin http://192.168.74.90/hhly_sportSnatch/bt_receive.gitgit push origin master（这一步执行后提示输入用户名和密码，输入gitlab的用户名和密码即可） 这样代码就会提交到git的master分支上。 4.删除gitlab上的文件比如idea的打包目录target。这些是不需要上传到gitlab上的。1234git rm -r --cached -n &quot;target/&quot; #这一步不会删除，只会显示要删除的文件git rm -r --cached &quot;target/&quot; #这一步删除target目录git commit -m &apos;remove target folder&apos; #提交修改到本地仓库git push origin master # 推送到远程仓库 注意：要安装git for windows]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA中git操作]]></title>
    <url>%2F2017%2F12%2F13%2Fidea-git-operate%2F</url>
    <content type="text"><![CDATA[&lt;在IDEA中实战Git&gt;参考：http://blog.csdn.net/autfish/article/details/52513465包括了： 创建项目并提交到远程Git仓库 从远程Git仓库上获取项目源码 提交修改到Git仓库 从Git仓库获取更新 创建分支，在分支上开发 分支合并到主干 &lt;IDEA中切换到某个分支&gt;1.执行fetch/pull操作；2.在右下角选择你要切换的分支 &lt;IDEA中checkout某个Tag&gt;切换到某个Tag，复制SHA在图1中粘贴 也可参考：http://blog.csdn.net/zhang_guyuan/article/details/77160387]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java日期多线程处理]]></title>
    <url>%2F2017%2F12%2F13%2Fjava-date-multithread%2F</url>
    <content type="text"><![CDATA[java的DateFormat不是线程安全的，在多线程环境可能导致出现问题。 线程不安全的处理方式1private static final DateFormat DATE_FORMAT = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");//线程不安全 问题参考：http://blog.csdn.net/zdp072/article/details/41044059 网上提到的几种替代方案：1.每次new一个对象123public static Date parse(String date) throws ParseException &#123; return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(date);&#125; 2.通过ThreadLocal进行处理123456private static final ThreadLocal&lt;DateFormat&gt; LOCAL_DATE_FORMAT = new ThreadLocal&lt;DateFormat&gt;()&#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); &#125;&#125;; 3.java8 通过 DateTimeFormatter 进行处理123private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");LocalDateTime dateTime = LocalDateTime.parse(date, DATE_TIME_FORMATTER);LOCAL_DATE_FORMAT.get().parse(date); 如果是JDK8的应用，可以使用instant代替Date，Localdatetime代替Calendar，Datetimeformatter代替Simpledateformatter，官方给出的解释：simple beautiful strong immutable thread-safe。 4.使用Joda-TimeJoda-Time 是一个很棒的开源的 JDK 的日期和日历 API 的替代品，其 DateTimeFormat 是线程安全而且不变的12345private final DateTimeFormatter fmt = DateTimeFormat.forPattern("yyyyMMdd"); public Date convert(String source)&#123; DateTime d = fmt.parseDateTime(source); returnd.toDate(); &#125; 5.使用Apache commons-lang包下的DateUtils和DateFormatUtils处理。参考：http://blog.csdn.net/marila4720/article/details/8468394]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows开启FTP服务]]></title>
    <url>%2F2017%2F12%2F10%2FWindows-FTP%2F</url>
    <content type="text"><![CDATA[1.开启FTP服务“控制面板”-》“程序和功能”-》“打开或关闭Windows功能”，在弹出的窗口中选择“Internet信息服务”，然后“确定”，如图： “计算机”-》右键-》“管理” 2.FTP共享文件夹然后点“完成”。 ftp://你的IP即可访问。如图：]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty使用Protobuf编解码]]></title>
    <url>%2F2017%2F12%2F10%2FNetty-Protobuf%2F</url>
    <content type="text"><![CDATA[Protobuf是一个灵活、高效、结构化的数据序列化框架，相比于XML等传统的序列化工具，它更小、更快、更简单。Protobuf支持数据结构化一次可以到处使用，甚至跨语言使用，通过代码生成工具可以自动生成不同语言版本的源代码，甚至可以在使用不同版本的数据结构进程间进行数据传递，实现数据结构的前向兼容。 下面结合一个例子看看在Netty如何使用Protobuf对POJO对象进行编解码。 1.Protobuf环境搭建从https://developers.google.com/protocol-buffers/docs/downloads下载Protobuf，本例中是3.0.0版本。 下载后对压缩包进行解压，在/bin目录可以看到protoc.exe。protoc.exe根据.proto文件生成代码。下面根据图书订购程序定义SubcribeReq.proto和SubcribeResp.proto文件。SubcribeReq.proto文件内容：1234567891011syntax = &quot;proto3&quot;;package netty;option java_package = &quot;com.tommy.netty.protobuf&quot;;option java_outer_classname = &quot;SubcribeReqProto&quot;;message SubcribeReq &#123; int32 subReqID = 1; string userName = 2; string productName = 3; repeated string address = 4;&#125; SubcribeResp.proto文件内容：12345678910syntax = &quot;proto3&quot;;package netty;option java_package = &quot;com.tommy.netty.protobuf&quot;;option java_outer_classname = &quot;SubcribeRespProto&quot;;message SubcribeResp &#123; int32 subReqID = 1; int32 respCode = 2; string desc = 3;&#125; 通过protoc.exe生成代码。进入到protoc.exe目录，分别执行：protoc.exe --java_out=.\src .\netty\SubcribeReq.proto和protoc.exe --java_out=.\src .\netty\SubcribeResp.proto在/bin目录的src目录中可以看到生成的文件。（注意：要提前创建好src目录） 将生成的SubcribeReqProto.java和SubcribeRespProto.java复制到工程中。 在工程中导入protobuf3.0.0的包：123456&lt;!-- https://mvnrepository.com/artifact/com.google.protobuf/protobuf-java --&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt; 2.Protobuf编解码开发123456789101112131415161718192021222324252627282930313233/** * @author j.tommy * @version 1.0 * @date 2017/12/10 */public class TestSubcribeReqProto &#123; private static byte[] encode(SubcribeReqProto.SubcribeReq subcribeReq) &#123; return subcribeReq.toByteArray(); &#125; private static SubcribeReqProto.SubcribeReq decode(byte[] body) throws InvalidProtocolBufferException &#123; return SubcribeReqProto.SubcribeReq.parseFrom(body); &#125; private static SubcribeReqProto.SubcribeReq createSubcribeReq() &#123; SubcribeReqProto.SubcribeReq.Builder builder = SubcribeReqProto.SubcribeReq.newBuilder(); builder.setSubReqID(1); builder.setUserName("j.tommy"); builder.setProductName("Netty权威指南"); List&lt;String&gt; addressList = new ArrayList&lt;String&gt;(); addressList.add("北京市"); addressList.add("上海市"); addressList.add("西安市"); addressList.add("深圳市"); builder.addAllAddress(addressList); return builder.build(); &#125; public static void main(String[] args) throws InvalidProtocolBufferException &#123; SubcribeReqProto.SubcribeReq req = createSubcribeReq(); System.out.println("Before encode:" + req); SubcribeReqProto.SubcribeReq req2 = decode(encode(req)); System.out.println("After decode:" + req2); System.out.println("Assert equals:" + req.equals(req2)); &#125;&#125; 通过SubcribeReq的.newBuilder()创建Builder，通过Builder设置SubscribeReq的属性，最后通过builder.builder()方法生成对象。 编码时通过SubscribeReq的toByteArray()即可将SubcribeReq编码为直接数组。解码时通过SubscribeReq的parseForm将二进制数组编码为SubscribeReq对象。 运行结果： 3.Netty的Protobuf订购程序开发服务端代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * @author j.tommy * @version 1.0 * @date 2017/12/10 */public class SubcribeServer &#123; public static void main(String[] args) &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap s = new ServerBootstrap(); s.group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .option(ChannelOption.SO_BACKLOG, 100) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(new ProtobufVarint32FrameDecoder()); sc.pipeline().addLast(new ProtobufDecoder(SubcribeReqProto.SubcribeReq.getDefaultInstance())); sc.pipeline().addLast(new ProtobufVarint32LengthFieldPrepender()); sc.pipeline().addLast(new ProtobufEncoder()); sc.pipeline().addLast(new SubcribeServerHandler()); &#125; &#125;); try &#123; ChannelFuture cf = s.bind(9989).sync(); cf.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;class SubcribeServerHandler extends ChannelHandlerAdapter &#123; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; private SubcribeRespProto.SubcribeResp createSubcribeResp(int subReqID) &#123; SubcribeRespProto.SubcribeResp.Builder builder = SubcribeRespProto.SubcribeResp.newBuilder(); builder.setSubReqID(subReqID); builder.setRespCode(0); builder.setDesc("Order success."); return builder.build(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; SubcribeReqProto.SubcribeReq req = (SubcribeReqProto.SubcribeReq) msg; System.out.println("接收到客户端请求：" + req.getSubReqID() + ",userName:" + req.getUserName() + ",productName:" + req.getProductName()); SubcribeRespProto.SubcribeResp resp = createSubcribeResp(req.getSubReqID()); ctx.writeAndFlush(resp); &#125;&#125; 客户端代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/** * @author j.tommy * @version 1.0 * @date 2017/12/10 */public class SubcribleClient &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(new ProtobufVarint32FrameDecoder()); sc.pipeline().addLast(new ProtobufDecoder(SubcribeRespProto.SubcribeResp.getDefaultInstance())); sc.pipeline().addLast(new ProtobufVarint32LengthFieldPrepender()); sc.pipeline().addLast(new ProtobufEncoder()); sc.pipeline().addLast(new SubcribleClientHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.connect("127.0.0.1", 9989).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125;class SubcribleClientHandler extends ChannelHandlerAdapter &#123; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; SubcribeReqProto.SubcribeReq req = null; for (int i=0;i&lt;10;i++) &#123; req = createSubcribeReq(i); ctx.write(req); &#125; ctx.flush(); &#125; private SubcribeReqProto.SubcribeReq createSubcribeReq(int subSeqID) &#123; SubcribeReqProto.SubcribeReq.Builder builder = SubcribeReqProto.SubcribeReq.newBuilder(); builder.setSubReqID(subSeqID); builder.setUserName("j.tommy"); builder.setProductName("netty权威指南"); List&lt;String&gt; addressList = new ArrayList&lt;String&gt;(); addressList.add("北京市"); addressList.add("西安市"); addressList.add("深圳市"); return builder.build(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; SubcribeRespProto.SubcribeResp resp = (SubcribeRespProto.SubcribeResp) msg; System.out.println("接收到服务端响应：" + resp.getSubReqID() + ",responseCode:" + resp.getRespCode() + ",desc:" + resp.getDesc()); &#125;&#125; ProtobufVarint32FrameDecoder，它主要用来处理半包； ProtobufDecoder解压器，它的参数是com.google.protobuf.MessageLite，实际上是告诉ProtobufDecoder需要解码的目标类是什么，否则仅仅从字节数组是无法知道要解码的目标类型信息的。 服务端中ProtobufEncoder用于对响应的SubcribeResp进行编码。 运行结果：服务端：客户端： 4.Protobuf的使用注意事项ProtobufDecoder仅仅负责解码，它不支持读半包。因此在ProtobufDecoder的前面，一定要有能够处理半包消息的解码器。有3种方式可以选择：1.使用Netty提供的ProtobufVarint32FrameDecoder，它可以处理半包消息；2.继承Netty提供的通用半包解码器LengthFieldBasedFrameDecoder;3.继承ByteToMessageDecoder类，自己处理半包消息。 如果只使用ProtobufDecoder解码器，而忽略对半包消息的处理，程序没法正常工作。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>Protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java时区转换]]></title>
    <url>%2F2017%2F12%2F10%2Fjava-timezone%2F</url>
    <content type="text"><![CDATA[包括将世界标准时间转换为本地时间和将世界标准时间转换为目标时区的本地时间，以及将本地时间转换为世界标准时间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * @author j.tommy * @version 1.0 * @date 2017/12/10 */public final class DateUtil &#123; /** * 将世界标准时间转换为本地时间 * @param gmtDate * @return */ public static Date convertGMT2Local(Date gmtDate) &#123; Calendar c = Calendar.getInstance(); c.setTime(gmtDate); int zoneOffset = c.get(Calendar.ZONE_OFFSET); int dstOffset = c.get(Calendar.DST_OFFSET); c.add(Calendar.MILLISECOND,zoneOffset+dstOffset); return c.getTime(); &#125; /** * 将世界标准时间转换为目标时区的本地时间 * @param gmtDate * @param id * @return */ public static Date convertGMTToLocal(Date gmtDate, String id) &#123; Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone("UTC")); calendar.setTime(gmtDate); calendar.setTimeZone(TimeZone.getTimeZone(id)); int zoneOffset = calendar.get(Calendar.ZONE_OFFSET); int dstOffset = calendar.get(Calendar.DST_OFFSET); calendar.add(Calendar.MILLISECOND, dstOffset+zoneOffset); return calendar.getTime(); &#125; /** * 将本地时间转换为世界标准时间 * @param date * @return */ public static Date convertToGMT(Date date) &#123; //Local Time Zone Calendar Instance Calendar calendar = Calendar.getInstance(); calendar.setTime(date); int zoneOffset = calendar.get(Calendar.ZONE_OFFSET); int dstOffset = calendar.get(Calendar.DST_OFFSET); calendar.add(Calendar.MILLISECOND, -(dstOffset+zoneOffset)); return calendar.getTime(); &#125; public static void main(String[] args) &#123; String gmtDateString = "2017-12-10T04:10:01.794Z"; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"); SimpleDateFormat sdf2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS"); try &#123; Date gmtDate = sdf.parse(gmtDateString); Date localDate = convertGMT2Local(gmtDate); System.out.println(sdf2.format(localDate));// for (String id : TimeZone.getAvailableIDs()) &#123;// System.out.println(id);// &#125; localDate = convertGMTToLocal(gmtDate,"Asia/Hong_Kong"); System.out.println(sdf2.format(localDate)); gmtDate = convertToGMT(localDate); System.out.println(sdf.format(gmtDate)); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 参考：http://blog.csdn.net/calkee/article/details/50879383http://blog.csdn.net/tjgykhulj/article/details/68953636]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[log4j动态创建日志文件]]></title>
    <url>%2F2017%2F12%2F10%2Flog4j-create-dynamic-log-files%2F</url>
    <content type="text"><![CDATA[比如现在系统会给多个公司发送数据，现希望给每个公司的数据有单独的日志文件记录。由于公司名字是动态的没法在log4j配置文件中写死，这时就只能通过动态创建了。 12345678910111213141516171819202122232425262728293031323334/** * Created by Administrator on 2017/12/10. */public final class Log4jUtil &#123; private final static ConcurrentHashMap&lt;String,Logger&gt; loggerMap = new ConcurrentHashMap&lt;String, Logger&gt;(); public static Logger getLogger(String name) &#123; Logger logger = loggerMap.get(name); if (null != logger) &#123; return logger; &#125; return createNewLogger(name); &#125; private static Logger createNewLogger(String name) &#123; Logger logger = Logger.getLogger(name); logger.removeAllAppenders(); logger.setLevel(Level.DEBUG); logger.setAdditivity(false); RollingFileAppender appender = new RollingFileAppender(); PatternLayout layout = new PatternLayout(); String conversionPatten = "[%d] %p %t %c - %m%n"; layout.setConversionPattern(conversionPatten); appender.setLayout(layout); String basePath = "/usr/logs/rb/"; appender.setFile(basePath + name + ".log"); appender.setEncoding("utf-8"); appender.setMaxBackupIndex(10); appender.setMaxFileSize("50MB"); appender.setAppend(true); appender.activateOptions(); logger.addAppender(appender); loggerMap.put(name,logger); return logger; &#125;&#125; 测试代码：1234567891011121314151617181920212223242526272829/** * 动态生成日志文件名。 * Created by Administrator on 2017/12/10. */public class DynamicLogFileName &#123; public static void main(String[] args) &#123; LogTestThread ltt1 = new LogTestThread("test1"); LogTestThread ltt2 = new LogTestThread("test2"); ltt1.start(); ltt2.start(); &#125;&#125;class LogTestThread extends Thread &#123; private String name; public LogTestThread(String name) &#123; this.name = name; &#125; public void run() &#123; Logger logger = Log4jUtil.getLogger(this.name); for (int i=0;i&lt;10;i++) &#123; try &#123; Thread.sleep((long) (Math.random()*1500L+1000L)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; logger.info(this.getName() + " msg." + i); &#125; &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery图表插件之plot]]></title>
    <url>%2F2017%2F12%2F03%2FjQuery-plot%2F</url>
    <content type="text"><![CDATA[使用参考：https://www.cnblogs.com/lwme/archive/2012/08/18/jquery-flot-plugin.html 下面是一个显示内存和存储空间使用率的折线统计图123456789101112131415161718192021&lt;!-- statistics chart built with jQuery Flot --&gt;&lt;div class="row chart"&gt; &lt;div class="col-md-12"&gt; &lt;h4 class="clearfix"&gt; MQ内存和空间使用 &lt;div class="btn-group pull-right"&gt; &lt;!--&lt;button class="glow left"&gt;日&lt;/button&gt; &lt;button class="glow middle active"&gt;月&lt;/button&gt; &lt;button class="glow right"&gt;年&lt;/button&gt;--&gt; &lt;select id="chartOpts" class="form-control"&gt; &lt;option value=""&gt;请选择&lt;/option&gt; &lt;option th:each="t:$&#123;mqConfigs&#125;" th:value="$&#123;t.serverIp&#125;" th:text="$&#123;t.serverIp&#125;"&gt;&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;/h4&gt; &lt;/div&gt; &lt;div class="col-md-12"&gt; &lt;div id="statsChart" style="height: 500px;"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;!-- end statistics chart --&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899// 切换服务器时，自动定时获取数据重绘$('#chartOpts').on('change',function() &#123; var server = $(this).val(); if (server != '') &#123; if (timerId) &#123; clearInterval(timerId); &#125; darwMqStatistics(); timerId = setInterval('darwMqStatistics()',60000); &#125;&#125;);var timerId;// 鼠标移动到图表的点上时显示提示function showTooltip(x, y, contents) &#123; $('&lt;div id="tooltip"&gt;' + contents + '&lt;/div&gt;').css( &#123; position: 'absolute', display: 'none', top: y - 30, left: x - 50, color: "#fff", padding: '2px 5px', 'border-radius': '6px', 'background-color': '#000', opacity: 0.80 &#125;).appendTo("body").fadeIn(200); &#125; var previousPoint = null; $("#statsChart").bind("plothover", function (event, pos, item) &#123; if (item) &#123; if (previousPoint != item.dataIndex) &#123; previousPoint = item.dataIndex; $("#tooltip").remove(); var x = item.datapoint[0].toFixed(0), y = item.datapoint[1].toFixed(0); var xLabel = item.series.xaxis.ticks[item.dataIndex].label; showTooltip(item.pageX, item.pageY, item.series.label + ": " + y + "%"); &#125; &#125; else &#123; $("#tooltip").remove(); previousPoint = null; &#125; &#125;);function darwMqStatistics() &#123; var serverIp = $('#chartOpts').val(); $.get(CTX+'/mqMonitor/getStatisticsData',&#123;serverIp:serverIp&#125;,function(r) &#123; var storeUsed = r.data.storeUsed; var memoryUsed = r.data.memoryUsed; var xLabel = r.data.xLabel; console.log(storeUsed); console.log(memoryUsed); console.log(xLabel); // jQuery Flot Chart var plot = $.plot($("#statsChart"), [ &#123; data: storeUsed, label: "存储空间使用百分比"&#125;, &#123; data: memoryUsed, label: "内存使用百分比" &#125;], &#123; series: &#123; lines: &#123; show: true, lineWidth: 1, fill: true, fillColor: &#123; colors: [ &#123; opacity: 0.1 &#125;, &#123; opacity: 0.13 &#125; ] &#125; &#125;, points: &#123; show: true, lineWidth: 2, radius: 3 &#125;, shadowSize: 0, stack: false /*如果有多条线要设置成false，否则最上面显示的那条线是下面所有线的value的和*/ &#125;, grid: &#123; hoverable: true, clickable: true, tickColor: "#f9f9f9", borderWidth: 0 &#125;, legend: &#123; show: true, labelBoxBorderColor: "#fff" &#125;, colors: ["#a7b5c5", "#30a0eb"], xaxis: &#123; ticks: xLabel, font: &#123; size: 12, family: "Open Sans, Arial", variant: "small-caps", color: "#697695" &#125; &#125;, yaxis: &#123; ticks:[[0,'0'],[10,'10%'],[20,'20%'],[30,'30%'],[40,'40%'],[50,'50%'],[60,'60%'],[70,'70%'],[80,'80%'],[90,'90%'],[100,'100%']], font: &#123;size:12, color: "#9da3a9"&#125;, tickOptions: &#123; formatString: "'%.2f", showMark: false &#125; &#125; &#125;); &#125;); 效果：]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpclient之basic认证]]></title>
    <url>%2F2017%2F12%2F02%2Fhttpclient-baisc-auth%2F</url>
    <content type="text"><![CDATA[本文主要说明如何使用httpclient进行basic认证。 我们常用的登录是form形式，但也有的登录采用的basic认证，比如activeMq默认就是basic认证。 1234567891011121314151617private final static CloseableHttpClient getBasicHttpClient(String username,String password) &#123; // 创建HttpClientBuilder HttpClientBuilder httpClientBuilder = HttpClientBuilder.create(); // 设置BasicAuth CredentialsProvider provider = new BasicCredentialsProvider(); // Create the authentication scope AuthScope scope = new AuthScope(AuthScope.ANY_HOST, AuthScope.ANY_PORT, AuthScope.ANY_REALM); // Create credential pair，在此处填写用户名和密码 UsernamePasswordCredentials credentials = new UsernamePasswordCredentials(username,password); // Inject the credentials provider.setCredentials(scope, credentials); // Set the default credentials provider httpClientBuilder.setDefaultCredentialsProvider(provider); // HttpClient CloseableHttpClient closeableHttpClient = httpClientBuilder.build(); return closeableHttpClient;&#125; Ok，获取到CloseableHttpClient后，其他的操作就简单了。比如想通过httpclient访问ActiveMQ的首页的内容，http://192.168.74.135:8161/admin。123HttpGet get = new HttpGet("http://192.168.74.135:8161/admin");CloseableHttpResponse response = getBasicHttpClient("admin","admin").execute(get);System.out.println(EntityUtils.toString(response.getEntity));]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>httpclient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[art-template日期格式化]]></title>
    <url>%2F2017%2F11%2F30%2Fart-template-dateformat%2F</url>
    <content type="text"><![CDATA[使用art-template我们避免了N多的字符串拼接，但遇到日期格式化该如何处理呢？ 我们定义一个处理日期格式化的JS函数，放到一个单独的文件dateformate.js。1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 对日期进行格式化， * @param date 要格式化的日期 * @param format 进行格式化的模式字符串 * 支持的模式字母有： * y:年, * M:年中的月份(1-12), * d:月份中的天(1-31), * h:小时(0-23), * m:分(0-59), * s:秒(0-59), * S:毫秒(0-999), * q:季度(1-4) * @return String * @author yanis.wang * @see http://yaniswang.com/frontend/2013/02/16/dateformat-performance/ */function dateFormat(date, format) &#123; date = new Date(date); var map = &#123; "M": date.getMonth() + 1, //月份 "d": date.getDate(), //日 "h": date.getHours(), //小时 "m": date.getMinutes(), //分 "s": date.getSeconds(), //秒 "q": Math.floor((date.getMonth() + 3) / 3), //季度 "S": date.getMilliseconds() //毫秒 &#125;; format = format.replace(/([yMdhmsqS])+/g, function(all, t)&#123; var v = map[t]; if(v !== undefined)&#123; if(all.length &gt; 1)&#123; v = '0' + v; v = v.substr(v.length-2); &#125; return v; &#125; else if(t === 'y')&#123; return (date.getFullYear() + '').substr(4 - all.length); &#125; return all; &#125;); return format;&#125;; 使用：12// art-template日期格式化template.defaults.imports.dateFormat = dateFormat; 在页面先定义模板html1234567891011&lt;script id="mqMonitorRecordTemplate" type="text/html"&gt; &#123;&#123;each list item index&#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123;index+1&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;item['serverIp']&#125;&#125;&lt;/td&gt; &lt;td&gt;&lt;%=#dateFormat(item['createTime'],'yyyy/MM/dd hh:mm')%&gt;&lt;/td&gt; &lt;td&gt;&#123;&#123;item['type']&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;item['reason']&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123;/each&#125;&#125;&lt;/script&gt; 在&lt;script&gt;中先编译上面的模板1var render = template.compile($('#mqMonitorRecordTemplate').html()); 使用（一个分页的例子）：12345678910111213141516function mqMonitorRecordSearch() &#123; var pageNo = $('[name=pageNo]').val(); var data = &#123; serverIp: $('[name=serverIp]').val(), type: $('[name=type]').val() &#125;; $.get('[[$&#123;ctx&#125;]]/mqMonitor/search/' + pageNo,data,function(r) &#123; if (r.returnCode == 0) &#123; $('#mqMonitorRecordTbl tbody').html(render(r.data.pager)); // 这行代码是使用模板渲染，获取渲染后的html，设置到tbody。 $('#DataTables_Table_1_paginate').html(r.data.pageHtml); &#125; else &#123; layer.alert(r.errMsg); &#125; &#125;);&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot单元测试]]></title>
    <url>%2F2017%2F11%2F30%2FSpringBoot-unittest%2F</url>
    <content type="text"><![CDATA[常规的Service和DAO的测试在SpringBoot里添加单元测试是非常简单的一件事，我们只需要添加SpringBoot单元测试的依赖jar，然后再添加两个注解就可搞定了。 首先我们来添加单元测试所需要的jar1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; 接着我们写了一个单元测试的demo1234567891011@RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = FirstExample.class) public class TestService extends BaseTestService&#123; @Autowired private PersonService personService; @Test public void testSys() &#123; System.out.println(personService.getPersonDomain().toString()); &#125; &#125; 然后我们run一下，一个单元测试就搞定了。 另外：@RunWith和@SprintBootTest这两个注解上都有@Inherited这个注解，所以我们可以定义一个单元测的父类，然后所有的单元测试类继承这个父类就行了。如下所示：123456789101112131415@RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = FirstExample.class) public class BaseTestService &#123; &#125;public class TestService extends BaseTestService&#123; @Autowired private PersonService personService; @Test public void testSys() &#123; System.out.println(personService.getPersonDomain().toString()); &#125; &#125; 如果你用的SpringBoot是1.4.0之前的话，所用的注解稍有不同。你需要把@SpringBootTest注解换成@SpringApplicationConfiguration和@WebAppConfiguration。出处：https://www.2cto.com/kf/201611/569221.html controller测试1234567891011121314151617181920212223242526@RunWith(SpringJUnit4ClassRunner.class)//@SpringApplicationConfiguration(classes = MockServletContext.class)//这个测试单个controller，不建议使用@SpringApplicationConfiguration(classes = Application.class)//这里的Application是springboot的启动类名。@WebAppConfigurationpublic class ApplicationTests &#123; @Autowired private WebApplicationContext context; private MockMvc mvc; @Before public void setUp() throws Exception &#123; // mvc = MockMvcBuilders.standaloneSetup(new TestController()).build(); mvc = MockMvcBuilders.webAppContextSetup(context).build();//建议使用这种 &#125; @Test public void test1() throws Exception &#123; mvc.perform(MockMvcRequestBuilders.get("/data/getMarkers") .contentType(MediaType.APPLICATION_JSON_UTF8) .param("lat", "123.123").param("lon", "456.456") .accept(MediaType.APPLICATION_JSON)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andExpect(MockMvcResultMatchers.content().string(Matchers.containsString("SUCCESS"))); &#125;&#125; 问题1.springboot单元测试保存和修改数据，发现数据库并没有更改。原因：Springboot单元测试默认设置的事务自动回滚，需要通过注解@Rollback(false)设置不回滚。http://blog.csdn.net/qq_32002237/article/details/78044172]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring结合activemq消息过期配置]]></title>
    <url>%2F2017%2F11%2F23%2Fspring-activemq-overtime-msg%2F</url>
    <content type="text"><![CDATA[包括queue和topic的消息过期配置。发送消息使用的spring-jms提供的JmsTemplate。 queue的配置设置pubSubDomain为false，默认即为false。需要将explicitQosEnabled设置为true，过期时间要生效依赖它。timeToLive即为过期时间，本例中设置的是10秒过期。 topic的配置设置pubSubDomain为true，表示是发布订阅模式。explicitQosEnabled设置为true，timeToLive设置过期时间。 spring结合ActiveMQ过期消息完整的spring配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms.xsd" &gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="fileEncoding" value="UTF-8" /&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath:mq.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.CachingConnectionFactory"&gt; &lt;description&gt;JMS连接工厂&lt;/description&gt; &lt;property name="targetConnectionFactory"&gt; &lt;bean class="org.apache.activemq.spring.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="$&#123;mq.brokerURL&#125;"/&gt; &lt;property name="userName" value="$&#123;mq.userName&#125;"/&gt; &lt;property name="password" value="$&#123;mq.password&#125;"/&gt; &lt;!--&lt;property name="trustAllPackages" value="true"/&gt;--&gt; &lt;property name="useAsyncSend" value="true"/&gt; &lt;property name="useDedicatedTaskRunner" value="false"/&gt; &lt;property name="optimizeAcknowledge" value="true"&gt;&lt;/property&gt; &lt;property name="producerWindowSize" value="1024000"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="sessionCacheSize" value="$&#123;mq.sessionCacheSize&#125;"/&gt; &lt;/bean&gt; &lt;bean id="jmsQueueTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;description&gt;PTP模式模型&lt;/description&gt; &lt;constructor-arg ref="connectionFactory"/&gt; &lt;property name="defaultDestination" ref="destinationQueue" /&gt; &lt;property name="pubSubDomain" value="false"/&gt; &lt;property name="deliveryPersistent" value="true" /&gt; &lt;!-- 发送模式 DeliveryMode.NON_PERSISTENT=1:非持久 ; DeliveryMode.PERSISTENT=2:持久，可以不配置，默认就是持久--&gt; &lt;property name="deliveryMode" value="2" /&gt; &lt;property name="explicitQosEnabled" value="true" /&gt; &lt;property name="timeToLive" value="10000" /&gt; &lt;/bean&gt; &lt;bean id="jmsTopicTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;description&gt;发布/订阅模式模型&lt;/description&gt; &lt;constructor-arg ref="connectionFactory"/&gt; &lt;property name="defaultDestination" ref="destinationTopic" /&gt; &lt;property name="pubSubDomain" value="true"/&gt; &lt;property name="deliveryPersistent" value="true" /&gt; &lt;!-- 发送模式 DeliveryMode.NON_PERSISTENT=1:非持久 ; DeliveryMode.PERSISTENT=2:持久--&gt; &lt;property name="deliveryMode" value="2" /&gt; &lt;property name="explicitQosEnabled" value="true" /&gt; &lt;property name="timeToLive" value="10000" /&gt; &lt;/bean&gt; &lt;bean id="destinationTopic" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg index="0" value="test.topic" /&gt; &lt;/bean&gt; &lt;bean id="destinationQueue" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg index="0" value="test.queue" /&gt; &lt;/bean&gt;&lt;/beans&gt; 发送代码示例：123456789101112public static void main(String[] args) &#123; ApplicationContext ac = new ClassPathXmlApplicationContext("spring-jms-producer.xml"); JmsTemplate j = (JmsTemplate) ac.getBean("jmsTopicTemplate"); j.send(new MessageCreator() &#123; @Override public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage("hello,world"); &#125; &#125;); System.out.println("消息发送完毕"); System.exit(0);&#125; queue和topic的发送一样，不再赘述。 发送消息后对于queue，在Activemq Console的queues中可以看到Messages Enqueued数量加110秒后，Messages Dequeued中加1，同时ActiveMQ.DLQ（即死信队列）中加1. 对于topic，可以看到Pending Queue Size加1.10秒后，Pending Queue Size减1.,，同时ActiveMQ.DLQ中加1. 死信队列消息的处理死信队列的消息来源包括2部分：1.过期的消息，如上面的例子；2.客户端消息处理异常，导致MQ反复重新发送，最终达到阀值（默认为6次），放入死信队列。 对于第1点如果有大量的消息，或消费者消费的太慢，或订阅者offline，会导致死信队列存在大量的过期消息。最终可能会导致磁盘爆满。解决方法：1.监听死信队列这样我们可以知道哪些数据处理失败，同时因为消费了消息，死信队列中的消息减少，这样避免了磁盘爆满。 2.过期的消息不放到死信队列。在activemq.xml中的增加一个策略：12345&lt;policyEntry topic="&gt;" expireMessagesPeriod="30000"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processExpired="false" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; expireMessagesPeriod=30000表示每隔30秒检查是否过期processExpired为false表示不保存过期消息到死信队列，为true则是保留。参考http://ask.csdn.net/questions/376817ActiveMQ消息策略：http://blog.csdn.net/wangtaomtk/article/details/51531354 对于第2点可以将重新投递的次数设置小一些，因为1次处理异常，多次也是一样。 更多ActiveMQ使用和优化Spring+ActiveMQ消息持久化，Topic持久化订阅http://blog.csdn.net/u014756827/article/details/77896930 activemq性能优化：http://blog.csdn.net/yinwenjie/article/details/50991443 ActiveMQ讯息传送机制以及ACK机制http://www.oschina.net/question/2854673_2190316?sort=time 消息预取限制：activeMQ 消息量限制 与 性能http://www.360doc.com/content/11/1027/19/1542811_159668819.shtml ActiveMQ消息策略http://blog.csdn.net/wangtaomtk/article/details/51531354 折腾ActiveMQ时遇到的问题和解决方法http://blog.163.com/_kid/blog/static/3040547620161634230453/]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ处理积压的消息]]></title>
    <url>%2F2017%2F11%2F22%2FActiveMQ-delete-overtime-queue-topic%2F</url>
    <content type="text"><![CDATA[为持久化消息设置过期时间ActiveMQ提供了一个timeStampingBrokerPlugin插件，通过此插件，我们可以为持久化消息设置过期时间。参考：http://activemq.apache.org/timestampplugin.html1234&lt;plugins&gt; &lt;!-- 86,400,000 ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling="86400000" zeroExpirationOverride="86400000"/&gt;&lt;/plugins&gt; zeroExpirationOverride会为没有设置过期时间的消息设置过期时间。ttlCeiling表示过期时间上限，如果程序中设置的过期时间超过此值，以此值为准。 配置消息过期丢弃策略12345678910111213141516&lt;borker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;!--expireMessagesPeriod=60000表示每隔60s检查消息是否过期--&gt; &lt;!--topic=&gt;表示对所有topic都生效--&gt; &lt;policyEntry topic="&gt;" expireMessagesPeriod="60000"&gt; &lt;deadLetterStrategy&gt; &lt;!--processExpired为false表示过期消息不进入死信队列，即执行删除操作--&gt; &lt;sharedDeadLetterStrategy processExpired="false" /&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt;&lt;/borker&gt; 删除空的Queue和Topic1234567891011&lt;broker xmlns="http://activemq.apache.org/schema/core" schedulePeriodForDestinationPurge="10000"&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry queue="&gt;" gcInactiveDestinations="true" inactiveTimoutBeforeGC="30000"/&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; schedulePeriodForDestinationPurge：执行清理任务的周期；gcInactiveDestinations=true：表示启用清理功能；inactiveTimoutBeforeGC：queue或topic的超时时间，在规定的时间内，无有效订阅，没有入队记录，超时后就会被清理。参考：http://activemq.apache.org/delete-inactive-destinations.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis对CLOB类型的处理]]></title>
    <url>%2F2017%2F11%2F19%2Fmybatis-clob%2F</url>
    <content type="text"><![CDATA[mybatis插入时，当插入clob类型时报错，ORA-01461:仅能绑定要插入LONG列的LONG值。mapper文件SQL如下12345&lt;insert id="addDutyPost" parameterType="dp"&gt; insert into sds_duty_post(id,title,content,creator,create_date) select SEQ_SDS_DUTY_POST.NEXTVAL,#&#123;title,jdbcType=VARCHAR&#125;,#&#123;content,jdbcType=CLOB&#125;,#&#123;creator,jdbcType=VARCHAR&#125;,sysdate from dual where not exists(select 'x' from sds_duty_post where title=#&#123;title&#125;)&lt;/insert&gt; 这个SQL在长度&lt;4000时，工作正常；大于4000，会提示ORA-01461.在插入时指定了jdbcType=CLOB，但仍然不奏效。 在网上查了很久，有可能问题是出现在当从dual中取数据时，会将clob对象的字段转为Long型。所以改写一下SQL1234567&lt;select id="selPostByTitle" parameterType="string" resultType="dp"&gt; select id as postid,title,content,creator,create_date,updator,update_date from sds_duty_post where title=#&#123;value&#125;&lt;/select&gt;&lt;insert id="addDutyPost" parameterType="dp"&gt; insert into sds_duty_post(id,title,content,creator,create_date) values (SEQ_SDS_DUTY_POST.NEXTVAL,#&#123;title,jdbcType=VARCHAR&#125;,#&#123;content,jdbcType=CLOB&#125;,#&#123;creator,jdbcType=VARCHAR&#125;,sysdate)&lt;/insert&gt; 我这里分成了2个SQL，selPostByTitle用来实现根据title查询记录，addDutyPost用来添加记录。只是最开始的SQL是合二为一。拆分后问题即解决，查询不需要指定jdbcType=CLOB。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Netty对POJO对象进行序列化]]></title>
    <url>%2F2017%2F11%2F18%2Fnetty-pojo-serialiazation%2F</url>
    <content type="text"><![CDATA[使用JDK的ObjectInputStream和ObjectOutputStream可以实现java对象的序列化和反序列化（只要被序列化的POJO对象实现Serializable接口）。 在不需要考虑跨语言，并且对序列化的性能要去不苛刻时，JDK默认的序列化机制是最明智的选择之一。 下面的例子中，我们使用Netty的ObjectDecoder和ObjectEncoder对请求和应答对象进行序列化。请求对象：12345678910111213141516171819202122232425262728293031323334353637383940414243/** * @author j.tommy * @version 1.0 * @date 2017/11/18 */public class SubscribeReq implements Serializable &#123; private int subReqId; private String userName; private String productName; public SubscribeReq() &#123; &#125; public SubscribeReq(int subReqId, String userName, String productName) &#123; this.subReqId = subReqId; this.userName = userName; this.productName = productName; &#125; public int getSubReqId() &#123; return subReqId; &#125; public void setSubReqId(int subReqId) &#123; this.subReqId = subReqId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getProductName() &#123; return productName; &#125; public void setProductName(String productName) &#123; this.productName = productName; &#125; @Override public String toString() &#123; return "SubscribeReq&#123;" + "subReqId=" + subReqId + ", userName='" + userName + '\'' + ", productName='" + productName + '\'' + '&#125;'; &#125;&#125; 应答对象：1234567891011121314151617181920212223242526272829/** * @author j.tommy * @version 1.0 * @date 2017/11/18 */public class SubscribeResp implements Serializable &#123; private int subReqId; private int respCode; private String desc; public SubscribeResp() &#123; &#125; public SubscribeResp(int subReqId, int respCode) &#123; this.subReqId = subReqId; this.respCode = respCode; &#125; public SubscribeResp(int subReqId, int respCode, String desc) &#123; this.subReqId = subReqId; this.respCode = respCode; this.desc = desc; &#125; @Override public String toString() &#123; return "SubscribeResp&#123;" + "subReqId=" + subReqId + ", respCode=" + respCode + ", desc='" + desc + '\'' + '&#125;'; &#125;&#125; 服务端在ChannelPipeline中增加ObjectDecoder解码器和ObjectEncoder编码器，并对要进行java序列化的对象实现Serialzable接口。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * @author j.tommy * @version 1.0 * @date 2017/11/18 */public class SubReqServer &#123; public static void main(String[] args) &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup,workerGroup).channel(NioServerSocketChannel.class).option(ChannelOption.SO_BACKLOG,1024).childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new ObjectDecoder(1024*1024, ClassResolvers.weakCachingConcurrentResolver(this.getClass().getClassLoader()))); socketChannel.pipeline().addLast(new ObjectEncoder()); socketChannel.pipeline().addLast(new SubReqServerHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.bind(9988).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;class SubReqServerHandler extends ChannelHandlerAdapter &#123; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; SubscribeReq subscribeReq = (SubscribeReq) msg; System.out.println("接收到客户端请求：" + subscribeReq); ctx.writeAndFlush(resp(subscribeReq.getSubReqId())); &#125; private SubscribeResp resp(int subReqId) &#123; SubscribeResp subscribeResp = new SubscribeResp(subReqId,0); return subscribeResp; &#125;&#125; 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @author j.tommy * @version 1.0 * @date 2017/11/18 */public class SubReqClient &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class).option(ChannelOption.TCP_NODELAY,true).handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new ObjectDecoder(1024*1024, ClassResolvers.cacheDisabled(this.getClass().getClassLoader()))); socketChannel.pipeline().addLast(new ObjectEncoder()); socketChannel.pipeline().addLast(new SubReqClientHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.connect("127.0.0.1",9988).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125;class SubReqClientHandler extends ChannelHandlerAdapter &#123; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // 链路激活后，向服务端发送10条订购信息 for (int i=0;i&lt;10;i++) &#123; SubscribeReq subscribeReq = new SubscribeReq(i,"tommy","Netty权威指南"); ctx.write(subscribeReq); &#125; ctx.flush(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; SubscribeResp subscribeResp = (SubscribeResp) msg; System.out.println("接收到服务端响应：" + subscribeResp); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125;&#125; 运行结果：服务端客户端 ObjectDecoder负责对实现了Serialzable接口的POJO对象进行解码，它有多个构造函数，支持不同的ClassResolver。服务端使用的是weakCachingConcurrentResolver，创建线程安全的WeakReferenceMap对类加载器进行缓存，它支持多线程并发访问。当虚拟机内存不足时，会释放缓存中的内存。客户端使用的是cacheDisabled，禁止对类加载器进行缓存，它在基于OSGi的动态模块化编程中经常使用。由于OSGi的bundle可以进行热部署和热升级，当某个bundle升级后，它对应的类加载器也将一起升级，因此在动态模块化编程中，很少对类加载器进行缓存，因为它随时可能发生变化。为了防止异常码流和解码错位导致的内存溢出，这里将单个对象的最大序列化后的字节数设置为1M。 ObjectEncoder负责将实现了Serialzable接口的POJO对象进行编码，用户对对象手动进行序列化，关注于自己的业务即可。对象的序列化和反序列化都由Netty的ObjectDecoder和ObjectEncoder来搞定。 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty固定长度解码器]]></title>
    <url>%2F2017%2F11%2F18%2FNetty-fix-length-decoder%2F</url>
    <content type="text"><![CDATA[FixedLengthFrameDecoder是固定长度解码器，它根据指定的长度自动对消息进行解码，开发者不需要考虑TCP拆包/粘包问题。下面通过一个例子进行说明。 服务端：在服务端的ChannelPipleline中增加FixedLengthFrameDecoder，长度设置为20，然后依次增加字符串解码器和自定义的EchoServerHandler。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 使用FixedLengthFrameDecoder解码器解决TCP粘包/拆包问题。 * * @author j.tommy * @version 1.0 * @date 2017/11/18 */public class EchoServer &#123; public static void main(String[] args) &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new FixedLengthFrameDecoder(20)); // 固定长度解码器，长度设置为20 socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new EchoServerHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.bind(8899).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;class EchoServerHandler extends ChannelHandlerAdapter &#123; private int counter; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String body = (String) msg; System.out.println("接收到客户端请求：" + body + ",counter=" + ++counter); // 响应客户端 ByteBuf resp = Unpooled.copiedBuffer(body.getBytes()); ctx.write(resp); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125;&#125; 客户端：在客户端的ChannelPipleline中增加FixedLengthFrameDecoder，长度设置为20，然后依次增加字符串解码器和自定义的EchoClientHandler。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * @author j.tommy * @version 1.0 * @date 2017/11/18 */public class EchoClient &#123; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class).option(ChannelOption.TCP_NODELAY,true).handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new FixedLengthFrameDecoder(20)); socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new EchoClientHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.connect("127.0.0.1",8899).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125;class EchoClientHandler extends ChannelHandlerAdapter &#123; private int counter = 0; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; String req = "hello,this message is from client."; ByteBuf sendBuf = null; for (int i=0;i&lt;100;i++) &#123; sendBuf = Unpooled.copiedBuffer(req.getBytes()); ctx.writeAndFlush(sendBuf); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String resp = (String) msg; System.out.println("接收到服务端响应：" + resp + ",counter=" + ++counter); &#125;&#125; 示例中，客户端发送的消息是hello,this message is from client.因为按照固定长度截取，所以服务端接收到的是这样的： 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DelimiterBasedFrameDecoder解决TCP粘包拆包问题]]></title>
    <url>%2F2017%2F11%2F17%2Fnetty-DelimiterBasedFrameDecoder-use%2F</url>
    <content type="text"><![CDATA[通过对DelimiterBasedFrameDecoder的使用，我们可以自动完成分隔符为结束标识的消息的解码。 下面的例子中，将$_作为分隔符。 服务端代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 使用DelimiterBasedFrameDecoder解码器解决TCP粘包/拆包问题。 * * @author j.tommy * @version 1.0 * @date 2017/11/17 */public class EchoServer &#123; protected final static String DELIMITER = "$_"; public static void main(String[] args) &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ByteBuf delimiter = Unpooled.copiedBuffer(DELIMITER.getBytes()); socketChannel.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter)); // 这里的1024标识单条消息的最大长度，如果达到长度后仍然没有读取到分隔符，就抛出TooLongFrameException，防止由于异常码流缺失导致的内存溢出，这是Netty解码器的可靠性保护；第二个参数是分隔符 socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new EchoServerHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.bind(8899).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;class EchoServerHandler extends ChannelHandlerAdapter &#123; private int counter; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String body = (String) msg; System.out.println("接收到客户端请求：" + body + ",counter=" + ++counter); // 响应客户端 body += EchoServer.DELIMITER; ByteBuf resp = Unpooled.copiedBuffer(body.getBytes()); ctx.write(resp); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125;&#125; 客户端代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @author j.tommy * @version 1.0 * @date 2017/11/17 */public class EchoClient &#123; protected final static String DELIMITER = "$_"; public static void main(String[] args) &#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class).option(ChannelOption.TCP_NODELAY,true).handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ByteBuf delimiter = Unpooled.copiedBuffer(DELIMITER.getBytes()); socketChannel.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter)); socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new EchoClientHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.connect("127.0.0.1",8899).sync(); f.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125;class EchoClientHandler extends ChannelHandlerAdapter &#123; private int counter = 0; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; String req = "hello,this message is from client."+EchoClient.DELIMITER; ByteBuf sendBuf = null; for (int i=0;i&lt;100;i++) &#123; sendBuf = Unpooled.copiedBuffer(req.getBytes()); ctx.writeAndFlush(sendBuf); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String resp = (String) msg; System.out.println("接收到服务端响应：" + resp + ",counter=" + ++counter); &#125;&#125; 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Netty解决TCP粘包-拆包问题]]></title>
    <url>%2F2017%2F11%2F17%2Fnetty-tcp%2F</url>
    <content type="text"><![CDATA[TCP粘包和拆包TCP底层并不知道上层业务数据的具体含义，它会根据缓冲区的实际情况进行包的拆分，所以在业务上认为，一个完整的包可能会被TCP拆分成多个包进行发送，也有可能将多个小的数据包封装成一个大的数据包发送，这就是所谓的TCP粘包/拆包问题。 TCP粘包/拆包的原因1.应用程序写入的字节大小大于套接字发送缓冲区大小；2.进行MSS大小的TCP分段；3.以太网帧的payload大于MTU进行IP分片。 解决策略由于底层的TCP协议无法理解上层业务数据，所以在底层是无法保证数据包不被拆分和重组的。只能通过上层的业务协议栈设计来解决，根据业务的主流 协议的解决方案，归纳为如下：（1）消息定长，例如每个报文的大小定位200字节，如果不够，空位补空格；（2）包结尾增加回车换行符进行分割，例如FTP协议；（3）将消息分为消息头和消息体，消息头中包含标识消息的总长度（或者消息体长度）的字段，通常涉及思路是消息头的第一个字段使用int32来表示消息的总长度；（4）更复杂的应用层协议。 未考虑TCP粘包导致的功能异常案例服务端代码片段：123456789101112131415161718192021222324252627class TimeServerHandler extends ChannelHandlerAdapter &#123; private int counter = 0; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // ByteBuf类似于JDK中的ByteBuffer，但提供更强大跟灵活的功能 ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; // 根据缓冲区可读字节数构建字节数组 buf.readBytes(req); // 将缓冲区的直接数组复制到req String body = new String(req, "UTF-8"); System.out.println("接收到客户端请求：" + body + ",counter:" + ++counter); // 如果接受到的消息时Server Time，则异步将服务端当前时间发送给客户端。 if ("Server Time".equalsIgnoreCase(body)) &#123; ByteBuf resp = Unpooled.copiedBuffer((new Date()).toString().getBytes()); // 这里write方法只是将数据写入缓冲区，并没有真正发送 ctx.write(resp); &#125; &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; // 将缓冲区的数据写入SocketChannel ctx.flush(); &#125;&#125; 这里增加了counter来统计接收到报文的数量。 客户端代码片段：1234567891011121314151617181920212223242526272829class TimeClientHandler extends ChannelHandlerAdapter &#123; private ByteBuf msgSendBuf; private int counter = 0; public TimeClientHandler() &#123; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // 链路建立成功后，将Server Time请求发送给服务端 for (int i=0;i&lt;100;i++) &#123; // 这里循环发送100次请求 // 待发送数据 String req = "Server Time"; msgSendBuf = Unpooled.copiedBuffer(req.getBytes()); ctx.writeAndFlush(msgSendBuf); &#125; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // 接收服务端响应 ByteBuf buf = (ByteBuf) msg; byte[] resp = new byte[buf.readableBytes()]; buf.readBytes(resp); String response = new String(resp, "UTF-8"); System.out.println("接收到服务端响应：" + response + ",counter:" + ++counter); &#125;&#125; 客户端在连接上服务端后，循环发送100条报文。在Handler类中增加了counter来统计接收到的服务器响应的次数。 运行结果如下：服务端 客户端：可以看到服务端只接收到2次，客户端并没有接收到服务端的响应。服务端只接收到2次的原因是发生了TCP粘包，第1次接收的报文长度是1024。客户端没有接收到服务器响应是因为由于发送了粘包，导致不符合服务端响应的条件。 使用LineBasedFrameDecoder和StringDecoder解决粘包服务端：12345protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new LineBasedFrameDecoder(1024)); socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new TimeServerHandler());&#125; 增加了LineBasedFrameDecoder和StringDecoder解码器。 TimeServerHandler的channelRead方法修改：12345678910111213@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String body = (String) msg; System.out.println("接收到客户端请求：" + body + ",counter:" + ++counter); // 如果接受到的消息时Server Time，则异步将服务端当前时间发送给客户端。 if ("Server Time".equalsIgnoreCase(body)) &#123; byte[] data = ((new Date()).toString() + System.getProperty("line.separator")).getBytes(); ByteBuf resp = Unpooled.copiedBuffer(data); // 这里write方法只是将数据写入缓冲区，并没有真正发送 ctx.write(resp); &#125;&#125; 1.直接将msg转换为String；2.响应的消息最后增加了换行符。 客户端：12345678910b.group(group) .channel(NioSocketChannel.class) // 设置线程的Channel .option(ChannelOption.TCP_NODELAY, true) // 设置NIOSocketChannel的参数 .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; // 绑定I/O事件处理类 protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new LineBasedFrameDecoder(1024)); socketChannel.pipeline().addLast(new StringDecoder()); socketChannel.pipeline().addLast(new TimeClientHandler()); &#125; &#125;); 增加了LineBasedFrameDecoder和StringDecoder解码器。 TimeClientHandler的channelActive和channelRead方法修改：1234567891011121314151617@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // 链路建立成功后，将Server Time请求发送给服务端 String req = "Server Time" + System.getProperty("line.separator"); for (int i=0;i&lt;100;i++) &#123; // 这里循环发送100次请求 // 待发送数据 msgSendBuf = Unpooled.copiedBuffer(req.getBytes()); ctx.writeAndFlush(msgSendBuf); &#125;&#125;@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // 接收服务端响应 String response = (String) msg; System.out.println("接收到服务端响应：" + response + ",counter:" + ++counter);&#125; 1.发送的报文最后增加换行符；2.接收的消息msg直接转为String。 运行结果：服务端客户端 LineBasedFrameDecoder和StringDecoder的原理分析LineBasedFrameDecoder的工作原理是依次遍历ByteBuf中的可读直接，看是否有\r\n或\n，如果有，就以此位置为结束为止，从可读索引到结束位置区间的字节就组成了一行。它是以换行符为标志的解码器。支持携带结束符或不携带结束符两种解码方式，同时支持配置单行的最大长度。如果在连续读取到最大长度后仍然没有发现换行符，就会抛出异常，同时忽略之前读到的异常码流。 StringDecoder的功能非常简单，就是将接受到的对象转换层字符串，然后继续调用后面的Handler。LineBasedFrameDecoder和StringDecoder组合起来就是支持换行的文本解码器，被设计用来支持TCP粘包和拆包。 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty版本时间服务器]]></title>
    <url>%2F2017%2F11%2F17%2FNetty-timeserver%2F</url>
    <content type="text"><![CDATA[本篇文章与前几篇文章BIO编程、AIO编程、伪异步IO编程、NIO编程一起，作为对比的Netty实现，并未考虑TCP粘包/拆包的问题。由阻塞I/O，伪异步I/O，非阻塞I/O，异步非阻塞I/O到Netty实现相同功能的代价，以及使用其他方式的弊端。 下面仍以时间服务器为例进行说明。服务端代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @author j.tommy * @version 1.0 * @date 2017/11/17 */public class TimeServer &#123; public static void main(String[] args) &#123; // 创建NIO线程组，用于服务端接收客户端请求 EventLoopGroup bossGroup = new NioEventLoopGroup(); // 用户处理SocketChannel的网络读写 EventLoopGroup workerGroup = new NioEventLoopGroup(); // 启动NIO服务端的辅助启动类 ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) // 设置线程的Channel .option(ChannelOption.SO_BACKLOG, 1024) // 设置NioServerSocketChannel的参数 .childHandler(new ChildChannelHandler()); // 绑定I/O事件的处理类 try &#123; ChannelFuture f = b.bind(8808).sync(); // 绑定监听端口，并阻塞等待绑定操作完成 f.channel().closeFuture().sync(); // 阻塞，等待服务端链路关闭 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; bossGroup.shutdownGracefully(); // 进行优雅退出，会释放跟shutdownGracefully相关联的资源 workerGroup.shutdownGracefully(); &#125; &#125;&#125;class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; &#123; protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new TimeServerHandler()); &#125;&#125;class TimeServerHandler extends ChannelHandlerAdapter &#123; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // ByteBuf类似于JDK中的ByteBuffer，但提供更强大跟灵活的功能 ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; // 根据缓冲区可读字节数构建字节数组 buf.readBytes(req); // 将缓冲区的直接数组复制到req String body = new String(req, "UTF-8"); System.out.println("接收到客户端请求：" + body); // 如果接受到的消息时Server Time，则异步将服务端当前时间发送给客户端。 if ("Server Time".equalsIgnoreCase(body)) &#123; ByteBuf resp = Unpooled.copiedBuffer((new Date()).toString().getBytes()); // 这里write方法只是将数据写入缓冲区，并没有真正发送 ctx.write(resp); &#125; &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; // 将缓冲区的数据写入SocketChannel ctx.flush(); &#125;&#125; 客户端代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * @author j.tommy * @version 1.0 * @date 2017/11/17 */public class TimeClient &#123; public static void main(String[] args) &#123; // 构造NIO线程组 NioEventLoopGroup group = new NioEventLoopGroup(); // 辅助启动类 Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) // 设置线程的Channel .option(ChannelOption.TCP_NODELAY, true) // 设置NIOSocketChannel的参数 .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; // 绑定I/O事件处理类 protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new TimeClientHandler()); &#125; &#125;); try &#123; ChannelFuture f = b.connect("127.0.0.1", 8808).sync(); // 连接并等待连接成功 f.channel().closeFuture().sync(); // 阻塞，等待客户端连接关闭 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; group.shutdownGracefully(); // 优雅退出 &#125; &#125;&#125;class TimeClientHandler extends ChannelHandlerAdapter &#123; private ByteBuf msgSendBuf; public TimeClientHandler() &#123; // 待发送数据 String req = "Server Time"; msgSendBuf = Unpooled.copiedBuffer(req.getBytes()); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // 链路建立成功后，将Server Time请求发送给服务端 ctx.writeAndFlush(msgSendBuf); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // 接收服务端响应 ByteBuf buf = (ByteBuf) msg; byte[] resp = new byte[buf.readableBytes()]; buf.readBytes(resp); String response = new String(resp, "UTF-8"); System.out.println("接收到服务端响应：" + response); &#125;&#125; 相比使用NIO开发简单了很多。 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AIO编程]]></title>
    <url>%2F2017%2F11%2F16%2FAIO-programing%2F</url>
    <content type="text"><![CDATA[NIO2.0引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。异步通道提供2种方式获取操作结果。 1.通过java.util.concurrent.Future来获取异步操作的结果；2.在异步操作的时候传入一个java.nio.channels。CompletionHandler作为异步完成的回调。 NIO2.0的异步套接字通道是真正的异步非阻塞I/O，它对应UNIX网络编程中的事件驱动I/O（AIO），它不需要通过多路复用器轮询注册的通道即可实现异步读写，从而简化了NIO的编程模型。 AIO版本的时间服务器代码服务端：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class TimeServer &#123; public static void main(String[] args) &#123; TimeServer ts = new TimeServer(); AsyncTimeServerHandler atsh = ts.new AsyncTimeServerHandler(9999); // 可以不使用线程 new Thread(atsh,"AsyncTimeServerHandler").start(); &#125; class AsyncTimeServerHandler implements Runnable &#123; private AsynchronousServerSocketChannel asynchronousServerSocketChannel; private CountDownLatch latch = null; public AsyncTimeServerHandler(int port) &#123; try &#123; // 创建一个异步的服务端通道 asynchronousServerSocketChannel = AsynchronousServerSocketChannel.open(); // 绑定监听端口 asynchronousServerSocketChannel.bind(new InetSocketAddress(port)); System.out.println("TimeServer is start at:" + port); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; // 使用CountDownLatch来让服务端在操作完成才退出。 latch = new CountDownLatch(1); doAccept(); try &#123; latch.await(); // 阻塞 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void doAccept() &#123; // 接收客户端的连接，使用CompletionHandler来接收accept操作成功的通知消息 asynchronousServerSocketChannel.accept(this,new AccpetCompleteHandler()); &#125; &#125; class AccpetCompleteHandler implements CompletionHandler&lt;AsynchronousSocketChannel,AsyncTimeServerHandler&gt; &#123; @Override public void completed(AsynchronousSocketChannel result, AsyncTimeServerHandler attachment) &#123; // 继续接收其他的客户端连接 attachment.asynchronousServerSocketChannel.accept(attachment,this); // 客户端连接成功后，使用ReadCompletionHandler读取客户端发送的信息，将信息读取到byteBuffer。 ByteBuffer byteBuffer = ByteBuffer.allocate(1024); result.read(byteBuffer,byteBuffer,new ReadCompleteHandler(result)); &#125; @Override public void failed(Throwable exc, AsyncTimeServerHandler attachment) &#123; exc.printStackTrace(); attachment.latch.countDown(); &#125; &#125; class ReadCompleteHandler implements CompletionHandler&lt;Integer,ByteBuffer&gt; &#123; private AsynchronousSocketChannel channel; public ReadCompleteHandler(AsynchronousSocketChannel channel) &#123; if (this.channel == null) &#123; this.channel = channel; &#125; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; // 为后续的从缓冲区读取数据做准备 attachment.flip(); // 根据缓冲区的可读字节数创建数组 byte[] bytes = new byte[attachment.remaining()]; // 将缓冲区的可读数据读取到bytes数组 attachment.get(bytes); try &#123; String body = new String(bytes,"UTF-8"); System.out.println("接收到客户端请求：" + body); // 如果客户端发送的是Server Time，则将服务器当前时间发送给客户端。 if ("Server Time".equalsIgnoreCase(body)) &#123; doWrite((new Date()).toString()); &#125; &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; exc.printStackTrace(); try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void doWrite(String response) &#123; byte[] bytes = response.getBytes(); // 根据响应内容的大小构建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(bytes.length); // 将相应内容复制到缓冲区 buffer.put(bytes); // 为后续从缓冲区读取数据准备 buffer.flip(); // 异步write方法将缓冲区数据写出 channel.write(buffer, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; // 如果缓冲区还有数据，继续发送 if (attachment.hasRemaining()) &#123; channel.write(attachment,attachment,this); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125;&#125; 客户端：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public class TimeClient &#123; public static void main(String[] args) &#123; TimeClient tc = new TimeClient(); AsyncTimeClientHandler tch = tc.new AsyncTimeClientHandler("127.0.0.1",9999); new Thread(tch,"TimeClientHandler").start(); &#125; class AsyncTimeClientHandler implements CompletionHandler&lt;Void,AsyncTimeClientHandler&gt;,Runnable &#123; private String host; private int port; private CountDownLatch latch ; private AsynchronousSocketChannel client; public AsyncTimeClientHandler(String host,int port) &#123; this.host = host; this.port = port; try &#123; client = AsynchronousSocketChannel.open(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; // 使用CountDownLatch，防止异步操作还未完成就退出了。 latch = new CountDownLatch(1); // 异步连接服务端 client.connect(new InetSocketAddress(host,port),this,this); try &#123; latch.await(); // 阻塞 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; client.close(); // 操作完成后，关闭通道 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void completed(Void result, AsyncTimeClientHandler attachment) &#123; // 要向服务器发送的数据 byte[] data = "Server Time".getBytes(); final ByteBuffer buffer = ByteBuffer.allocate(data.length); buffer.put(data); buffer.flip(); // 异步写消息给服务端 client.write(buffer, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; // 如果有消息还没有发送完毕，则继续发送 if (buffer.hasRemaining()) &#123; client.write(attachment,attachment,this); &#125; else &#123; // 消息发送完成后，异步读取服务器响应 // 预分配空间为1K ByteBuffer readBuffer = ByteBuffer.allocate(1024); client.read(readBuffer, readBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; // 为后续从缓冲区读取数据做准备 attachment.flip(); // 根据缓冲区可读字节的长度构建字节数组 byte[] data = new byte[attachment.remaining()]; // 将缓冲区数据复制到data数组 attachment.get(data); try &#123; String body = new String(data,"UTF-8"); System.out.println("接收到服务端消息：" + body); // 这里模拟只请求服务器1次，完成后退出。 latch.countDown(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;); &#125; @Override public void failed(Throwable exc, AsyncTimeClientHandler attachment) &#123; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;&#125; JDK底层通过线程池ThreadPoolExecutor来执行回调通知。AsynchronousServerSocketChannel和AsynchronousSocketChannel，他们都由JDK底层的线程池回调并驱动读写操作。 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NIO编程]]></title>
    <url>%2F2017%2F11%2F15%2FNIO-programing%2F</url>
    <content type="text"><![CDATA[NIO是JDK1.4进入的非阻塞IO。NIO弥补了原来BIO的不足。 与NIO相关的几个概念 1.缓冲区BufferBuffer是一个对象，包含一些要 写入或读出的数据。在NIO库中，所有数据都是经过缓冲区处理的。在读取数据时，它是直接读取到缓冲区的；在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。 缓冲区本质上是一个数组，通常是一个字节数组（ByteBuffer），也可以使用其他种类的数组。但是缓冲区不仅是一个数组，它提供了对数据的结构化访问以及维护读写位置等信息。 最常用的是ByteBuffer，它提供了一组功能用于操作byte数组。 2.通道ChannelChannel是一个通道，可以通过它来读取和写入数据。通道是双向的，流只在一个方向移动，而且通道可以同时用于读取和写入。因为Channel是全双工的，所以可以更好的映射底层操作系统的api。3.多路复用器SelectorSelector会不断轮询注册在它上面的Channel，如果某个Channel上有新的TCP连接、读和写事件，这个Channel就处于就绪状态。会被Selector轮询出来，然后通过SelectionKey可以获取就绪的Channel的集合，进行后续的I/O操作。一个多路复用器可以同时轮询多个Channel，由于JDK使用epool替代了传统的select实现，所以它并没有最大连接句柄1024/2048的限制。这也就意味着只需要一个线程负责Selector的轮询，就可以接入成千上万的客户端。 服务端代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135/** * @author j.tommy * @date 2017/11/11 */public class NioTimeServer &#123; public static void main(String[] args) &#123; NioTimeServer nts = new NioTimeServer(); // 创建Reactor线程，并启动 TimeServerHandler tsh = nts.new TimeServerHandler(8080); new Thread(tsh,"Nio-Time-Server").start(); &#125; class TimeServerHandler implements Runnable &#123; private volatile boolean stop = false; Selector selector = null; ServerSocketChannel serverSocketChannel = null; /** * 初始化多路复用器，绑定监听端口 * @param port */ public TimeServerHandler(int port) &#123; try &#123; // 创建多路复用器 selector = Selector.open(); // 打开ServerSocketChannel，监听客户端连接 serverSocketChannel = ServerSocketChannel.open(); // 设置连接为非阻塞模式 serverSocketChannel.configureBlocking(false); // 绑定监听端口 serverSocketChannel.socket().bind(new InetSocketAddress(port),1024); // 将ServerSocketChannel注册到Reactor线程的多路复用器上，并监听OP_ACCET事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println("The time server is start at port:" + port); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; @Override public void run() &#123; // 循环遍历selector，休眠时间为1S，无论是否有读写事件发生，selector每隔1S被唤醒1次。 while (!stop) &#123; try &#123; // 选择一组准备就绪的Key selector.select(1000); // 遍历准备就绪的Key Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; itKeys = keys.iterator(); while (itKeys.hasNext()) &#123; SelectionKey k = itKeys.next(); itKeys.remove(); try &#123; handleKey(k); &#125; catch (Exception e) &#123; if (k != null) &#123; k.cancel(); if (k.channel() != null) &#123; k.channel().close(); &#125; &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; // 关闭多路复用器，所有注册在上面的Channel和Pipe等资源会自动去注册并关闭，不需要重复释放资源 if (selector != null) &#123; try &#123; selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void handleKey(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; if (key.isAcceptable()) &#123; // 多路复用器监听到新的客户端接入，处理新的接入请求 ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); // 设置客户端链路为非阻塞模式 sc.configureBlocking(false); // 将新接入的客户端注册到Reactor线程的多路复用器上，并监听读操作，用来读取客户端发送的消息 sc.register(selector,SelectionKey.OP_READ); &#125; if (key.isReadable()) &#123; SocketChannel socketChannel = (SocketChannel) key.channel(); ByteBuffer readBuffer = ByteBuffer.allocate(1024); // 异步读取客户端消息到缓冲区 int readBytes = socketChannel.read(readBuffer); if (readBytes &gt; 0) &#123; // 重置缓冲区的position，将limit设置为postion，position设置为0.用于后续的读取操作 readBuffer.flip(); // 创建一个容量为缓冲区可读字节个数的字节数组。=limit - postion。本例中position=0，所以实际上=limit byte[] bytes = new byte[readBuffer.remaining()]; // 将缓冲区的可读的数据复制到字节数组中 readBuffer.get(bytes); // 根据字节数组，构造一个字符串 String body = new String(bytes,"UTF-8"); System.out.println("服务器接收到客户端请求：" + body); // 如果客户端发送的是Server Time的请求，则应答 if (body.equalsIgnoreCase("Server Time")) &#123; doWrite(socketChannel,(new Date()).toString()); &#125; &#125; else if (readBytes &lt; 0) &#123; // 客户端链路关闭 key.cancel(); socketChannel.close(); &#125; else &#123; // 没有读取到数据，不处理 &#125; &#125; &#125; &#125; /** * 向客户端写入当前时间 * @param sc * @param response * @throws IOException */ private void doWrite(SocketChannel sc , String response) throws IOException &#123; if (response != null &amp;&amp; response.trim().length() &gt; 0) &#123; byte[] bytes = response.getBytes(); // 构造一个缓冲区，缓冲区的大小=要发送给客户端的数据的字节长度 ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); // 将数据复制到缓冲区 writeBuffer.put(bytes); // 重置缓冲区postion writeBuffer.flip(); // 将消息异步发送到客户端 sc.write(writeBuffer); &#125; &#125; &#125;&#125; 客户端代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/** * @author j.tommy * @date 2017/11/11 */public class NioTimeClient &#123; public static void main(String[] args) &#123; NioTimeClient ntc = new NioTimeClient(); TimeClientHandler tch = ntc.new TimeClientHandler("127.0.0.1",8080); // 创建Reactor线程并启动 new Thread(tch,"Nio Time Client").start(); &#125; class TimeClientHandler implements Runnable &#123; private String host; private int port; private volatile boolean stop = false; private Selector selector = null; private SocketChannel socketChannel = null; public TimeClientHandler(String host,int port) &#123; this.host = host; this.port = port; try &#123; selector = Selector.open(); socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); &#125; catch (IOException e) &#123; System.exit(1); &#125; &#125; @Override public void run() &#123; try &#123; doConnect(); &#125; catch (Exception e) &#123; e.printStackTrace(); System.exit(1); &#125; System.out.println("开始轮休多路复用器已准备就绪的key"); while (!stop) &#123; try &#123; selector.select(1000); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; itKeys = keys.iterator(); while (itKeys.hasNext()) &#123; SelectionKey sk = itKeys.next(); itKeys.remove(); try &#123; handleInput(sk); &#125; catch (IOException e) &#123; if (sk != null) &#123; sk.cancel(); &#125; if (sk.channel() != null) &#123; sk.channel().close(); &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; if (selector != null) &#123; try &#123; selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void handleInput(SelectionKey sk) throws IOException &#123; if (sk.isValid()) &#123; SocketChannel sc = (SocketChannel) sk.channel(); if (sk.isConnectable()) &#123; if (sc.finishConnect()) &#123; sc.register(selector,SelectionKey.OP_READ); doWrite(sc); &#125; else &#123; System.exit(1); &#125; &#125; if (sk.isReadable()) &#123; ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(byteBuffer); if (readBytes &gt; 0) &#123; byteBuffer.flip(); byte[] bytes = new byte[byteBuffer.remaining()]; byteBuffer.get(bytes); String response = new String(bytes,"UTF-8"); System.out.println("Server response:" + response); this.stop = true; &#125; else if (readBytes &lt; 0) &#123; sk.cancel(); sc.close(); &#125; else &#123; &#125; &#125; &#125; &#125; private void doConnect() throws IOException &#123; boolean connected = socketChannel.connect(new InetSocketAddress(host,port)); if (connected) &#123; socketChannel.register(selector,SelectionKey.OP_READ); doWrite(socketChannel); &#125; else &#123; socketChannel.register(selector,SelectionKey.OP_CONNECT); &#125; &#125; private void doWrite(SocketChannel sc) throws IOException &#123; byte[] data = "Server Time".getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(data.length); writeBuffer.put(data); writeBuffer.flip(); sc.write(writeBuffer); if (!writeBuffer.hasRemaining()) &#123; System.out.println("Server Time请求发送成功！"); &#125; &#125; &#125;&#125; 这里的代码并没有考虑“半包读”和“半包写”，如果加上这些，相比BIO难度要大很多。 实用NIO编程的优点：1.客户端发起的连接操作时异步的，可以通过在多路复用器注册OP_CONNECT等待后续结果，不需要向BIO的客户端那样被同步阻塞。2.SocketChannel的读写操作都是异步的，如果没有可写数据，它不会同步等待，直接返回。这样I/O线程可以处理其他的链路。3.线程模型的优化：由于JDK的selector在Linux等主流的操作系统中通过epoll实现，它没有连接句柄数的限制，这样一个Selector线程就可以同时处理成千上万的客户端连接，而且性能不会随着客户端的增加而线性下降。因此，它非常适合做高性能、高负载的网络服务器。 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伪异步IO编程]]></title>
    <url>%2F2017%2F11%2F15%2Fnot-aio-programing%2F</url>
    <content type="text"><![CDATA[为了解决BIO（同步阻塞IO）带来的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化，后端通过一个线程池来处理多个客户端的接入，从而形成了一个客户端个数M：线程池最大数N的关系。M可以远大于N，通过线程池可以灵活的调整线程资源，设置线程的最大值，防止由于大量并发导致资源耗尽。服务端代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * @author j.tommy * Created by j.tommy on 2017/11/11. */public class TimeServer &#123; private ThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat("demo-pool-%d").build(); private ExecutorService es = new ThreadPoolExecutor(1,100,0L, TimeUnit.MICROSECONDS,new LinkedBlockingQueue&lt;Runnable&gt;(1024),namedThreadFactory,new ThreadPoolExecutor.AbortPolicy()); public static void main(String[] args) &#123; TimeServer timeServer = new TimeServer(); timeServer.start(8080); &#125; private void start(int port) &#123; ServerSocket ss = null; try &#123; ss = new ServerSocket(port); System.out.println("TimeServer is running..."); while (true) &#123; Socket socket = ss.accept(); es.submit(new TimeServerHandler(socket)); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (ss != null) &#123; try &#123; ss.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; es.shutdownNow(); &#125; &#125; &#125; class TimeServerHandler implements Runnable &#123; private Socket socket = null; public TimeServerHandler(Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; BufferedReader br = null; PrintWriter pw = null; try &#123; br = new BufferedReader(new InputStreamReader(socket.getInputStream())); pw = new PrintWriter(new OutputStreamWriter(socket.getOutputStream()),true); while (true) &#123; String input = br.readLine(); if (null == input) &#123; break; &#125; System.out.println("接收到客户端请求：" + input); if ("Server Time".equalsIgnoreCase(input)) &#123; pw.println((new Date()).toString()); &#125; &#125; &#125; catch (IOException e) &#123; System.out.println("ip:" + socket.getInetAddress().getHostAddress() + " I/O异常"); &#125; finally &#123; if (br != null) &#123; try &#123; br.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (pw != null) &#123; pw.close(); &#125; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; 客户端代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @author j.tommy * Created by j.tommy on 2017/11/11. */public class TimeClient &#123; public static void main(String[] args) &#123; TimeClient tc = new TimeClient(); tc.connect("127.0.0.1",8080); &#125; private void connect(String host,int port) &#123; Socket socket = null; InputStream in = null; OutputStream out = null; try &#123; socket = new Socket(host,port); in = socket.getInputStream(); out = socket.getOutputStream(); PrintWriter pw = new PrintWriter(new OutputStreamWriter(out),true); BufferedReader br = new BufferedReader(new InputStreamReader(in)); System.out.println("请求服务器时间"); pw.println("Server Time"); String response = br.readLine(); System.out.println("response:" + response); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (out != null) &#123; try &#123; out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 伪异步IO通过线程池+任务队列来实现，当有新的客户端接入时，将客户端封装成一个新的Task，交给线程池处理。由于线程池和任务队列的大小都是可控制的，所以不论有多少个客户端访问，都不会导致资源耗尽和宕机。 伪异步IO的弊端：当对Socket的输入流进行读取时，它会一直阻塞，直到发生下面3种事件之一：1.有数据可读；2.可用数据已经读取完毕；3.发生空指针或IO异常。 这就意味着，当对方发送请求或应答消息缓慢、或者网络传输较慢时，读取输入流一方的线程将被长时间阻塞。在此期间，其他接入消息只能在任务队列中排队。 参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[传统的BIO编程]]></title>
    <url>%2F2017%2F11%2F15%2Fbio-programing%2F</url>
    <content type="text"><![CDATA[在传统的同步阻塞模型开发中，ServerSocket绑定监听端口，Socket发起连接操作。连接成功后，双方通过输入输出流进行同步阻塞式通信。 下面以时间服务器为例说明。客户端向服务端发送“Server Time”，服务端向客户端返回服务端当前时间。服务端代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * @author j.tommy * Created by j.tommy on 2017/11/11. */public class TimeServer &#123; public static void main(String[] args) &#123; TimeServer timeServer = new TimeServer(); timeServer.start(8080); &#125; private void start(int port) &#123; ServerSocket ss = null; try &#123; ss = new ServerSocket(port); System.out.println("TimeServer is running..."); while (true) &#123; Socket socket = ss.accept(); new Thread(new TimeServerHandler(socket)).start(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (ss != null) &#123; try &#123; ss.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; es.shutdownNow(); &#125; &#125; &#125; class TimeServerHandler implements Runnable &#123; private Socket socket = null; public TimeServerHandler(Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; BufferedReader br = null; PrintWriter pw = null; try &#123; br = new BufferedReader(new InputStreamReader(socket.getInputStream())); pw = new PrintWriter(new OutputStreamWriter(socket.getOutputStream()),true); while (true) &#123; String input = br.readLine(); if (null == input) &#123; break; &#125; System.out.println("接收到客户端请求：" + input); if ("Server Time".equalsIgnoreCase(input)) &#123; pw.println((new Date()).toString()); &#125; &#125; &#125; catch (IOException e) &#123; System.out.println("ip:" + socket.getInetAddress().getHostAddress() + " I/O异常"); &#125; finally &#123; if (br != null) &#123; try &#123; br.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (pw != null) &#123; pw.close(); &#125; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; 客户端代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @author j.tommy * Created by j.tommy on 2017/11/11. */public class TimeClient &#123; public static void main(String[] args) &#123; TimeClient tc = new TimeClient(); tc.connect("127.0.0.1",8080); &#125; private void connect(String host,int port) &#123; Socket socket = null; InputStream in = null; OutputStream out = null; try &#123; socket = new Socket(host,port); in = socket.getInputStream(); out = socket.getOutputStream(); PrintWriter pw = new PrintWriter(new OutputStreamWriter(out),true); BufferedReader br = new BufferedReader(new InputStreamReader(in)); System.out.println("请求服务器时间"); pw.println("Server Time"); String response = br.readLine(); System.out.println("response:" + response); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (out != null) &#123; try &#123; out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 由一个Acceptor线程负责监听客户端连接请求，接收到客户端连接请求后，为每个客户端分配一个新的线程进行链路处理。处理完成后，通过输出流应答客户端。 BIO模型的最大问题在于缺乏弹性伸缩能力，因为服务端线程和客户端是呈现的1:1的关系。当线程数膨胀后，系统性能急剧下降，随着并发访问量的继续增大，系统会发生线程堆栈溢出、创建新线程失败等问题，最终导致进程宕机，不能对外提供服务。参考《Netty权威指南》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[notepad++7.5版本插件安装方法]]></title>
    <url>%2F2017%2F11%2F15%2Fnotepad7.5-version-plugins-install%2F</url>
    <content type="text"><![CDATA[notepad++7.5版本，插件安装方法与之前不同。是通过“设置-&gt;导入-&gt;导入插件”来完成的。需要先将插件下载到本地。 这里说一下2个格式化插件的安装方法。 1.JSON Viewer从https://sourceforge.net/projects/nppjsonviewer/下载到本地，然后解压缩导入.dll文件，然后重启notepad++即可。 2.XML Tools从https://sourceforge.net/projects/npp-plugins/files/XML%20Tools/下载，然后解压缩。导入XML Tools.dll文件，然后将ext_libs解压缩然后将里面的项目.dll复制到与notepad++同级目录，然后重启。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket编程使用IO流需要注意的地方]]></title>
    <url>%2F2017%2F11%2F11%2FSocket-OutputStream%2F</url>
    <content type="text"><![CDATA[在Socket编程中，我们经常会创建Socket连接后。获取InputStream和OutputStream，并进一步包装以便方便的进行数据的读取或写入操作。但是，如果流使用的不对，就可能会产生无法读取到数据的情况。 下面是使用BufferedWriter和PrintWriter需要注意的地方。 1.使用BufferedReader和BufferedWriter如果使用BufferedReader和BufferedWriter来一次读取或写入一行数据，必须要加\n，代表一行结束。否则BufferedReader读取不到数据。1234567891011121314151617181920BufferedReader br = null;BufferedWriter pw = null;try &#123; br = new BufferedReader(new InputStreamReader(socket.getInputStream())); pw = new BufferedWriter(new OutputStreamWriter(socket.getOutputStream())); while (true) &#123; String input = br.readLine(); if (null == input) &#123; break; &#125; System.out.println("接收到客户端请求：" + input); if ("Server Time".equalsIgnoreCase(input)) &#123; // 注意：这里使用了BufferedWriter，必须要加\n，否则对方的BufferedReader的readLine()获取不到数据。 pw.write((new Date()).toString()+"\n"); pw.flush(); &#125; &#125;&#125; catch (IOException e) &#123; System.out.println("ip:" + socket.getInetAddress().getHostAddress() + " I/O异常");&#125; 2.使用BufferedReader和PrintWriter仍然是使用BufferedReader一次读取一行数据，写数据用PrintWriter的println()方法。同时在构造PrintWriter时设置autoFlush=true。123456789socket = new Socket(host,port);in = socket.getInputStream();out = socket.getOutputStream();PrintWriter pw = new PrintWriter(new OutputStreamWriter(out),true); // 这里设置autoFlush=trueBufferedReader br = new BufferedReader(new InputStreamReader(in));System.out.println("请求服务器时间");pw.println("Server Time"); // 使用println写数据，不要使用write()String response = br.readLine();System.out.println("response:" + response);]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot集成ActiveMQ]]></title>
    <url>%2F2017%2F11%2F10%2Fspringboot%E9%9B%86%E6%88%90activeMQ%2F</url>
    <content type="text"><![CDATA[1.添加依赖：123456789&lt;!-- activemq --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt;&lt;/dependency&gt; 2.在application.properties中加入activemq的配置1234567spring.activemq.broker-url=tcp://192.168.74.135:61616spring.activemq.user=adminspring.activemq.password=adminspring.activemq.pool.enabled=truespring.activemq.pool.max-connections=50spring.activemq.pool.expiry-timeout=10000spring.activemq.pool.idle-timeout=30000 3.创建一个消息生产者12345678@Componentpublic class JMSProducer &#123; @Autowired private JmsTemplate jmsTemplate; public void sendMessage(Destination destination,String message) &#123; this.jmsTemplate.convertAndSend(destination,message); &#125;&#125; 4.创建一个消息消费者12345678@Componentpublic class JMSConsumer &#123; private final static Logger logger = LoggerFactory.getLogger(JMSConsumer.class); @JmsListener(destination = "springboot.queue.test") public void receiveQueue(String msg) &#123; logger.info("接收到消息：&#123;&#125;",msg); &#125;&#125; 5.测试类1234567891011public class JmsTest extends BaseTest&#123; @Autowired private JMSProducer jmsProducer; @Test public void testJms() &#123; Destination destination = new ActiveMQQueue("springboot.queue.test"); for (int i=0;i&lt;10;i++) &#123; jmsProducer.sendMessage(destination,"hello,world!" + i); &#125; &#125;&#125; BaseTest代码如下：1234@RunWith(SpringRunner.class)@SpringBootTest(classes = com.sample.activity.web.Application.class)public abstract class BaseTest &#123;&#125; 6.发送和接收TOPIC消息默认只能发送和接收queue消息，如果要发送和接收topic消息，需要在application.properties文件中加入：1spring.jms.pub-sub-domain=true 发送和接收的代码同queue一样。但是这样有另外一个问题：无法发送和接收queue消息。那么如何同时支持发送和接收queue/topic消息呢？ 7.支持同时发送和接收queue/topici. 新建一个JMS的配置类：12345678910111213141516171819202122232425262728@Configurationpublic class JmsConfig &#123; public final static String TOPIC = "springboot.topic.test"; public final static String QUEUE = "springboot.queue.test"; @Bean public Queue queue() &#123; return new ActiveMQQueue(QUEUE); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(TOPIC); &#125; // topic模式的ListenerContainer @Bean public JmsListenerContainerFactory&lt;?&gt; jmsListenerContainerTopic(ConnectionFactory activeMQConnectionFactory) &#123; DefaultJmsListenerContainerFactory bean = new DefaultJmsListenerContainerFactory(); bean.setPubSubDomain(true); bean.setConnectionFactory(activeMQConnectionFactory); return bean; &#125; // queue模式的ListenerContainer @Bean public JmsListenerContainerFactory&lt;?&gt; jmsListenerContainerQueue(ConnectionFactory activeMQConnectionFactory) &#123; DefaultJmsListenerContainerFactory bean = new DefaultJmsListenerContainerFactory(); bean.setConnectionFactory(activeMQConnectionFactory); return bean; &#125;&#125; ii. 消息消费者的代码改成如下：123456789101112@Componentpublic class JMSConsumer &#123; private final static Logger logger = LoggerFactory.getLogger(JMSConsumer.class); @JmsListener(destination = JmsConfig.TOPIC,containerFactory = "jmsListenerContainerTopic") public void onTopicMessage(String msg) &#123; logger.info("接收到topic消息：&#123;&#125;",msg); &#125; @JmsListener(destination = JmsConfig.QUEUE,containerFactory = "jmsListenerContainerQueue") public void onQueueMessage(String msg) &#123; logger.info("接收到queue消息：&#123;&#125;",msg); &#125;&#125; 可以看到，这里指定了ConnectionFactory。 iii. 测试类：123456789101112131415public class JmsTest extends BaseTest&#123; @Autowired private JMSProducer jmsProducer; @Autowired private Topic topic; @Autowired private Queue queue; @Test public void testJms() &#123; for (int i=0;i&lt;10;i++) &#123; jmsProducer.sendMessage(queue,"queue,world!" + i); jmsProducer.sendMessage(topic, "topic,world!" + i); &#125; &#125;&#125; springboot中activemq的一些配置属性参考：springboot activemq配置属性]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot集成ActiveMQ]]></title>
    <url>%2F2017%2F11%2F10%2Fspringboot-ActiveMQ%2F</url>
    <content type="text"><![CDATA[1.添加依赖：123456789&lt;!-- activemq --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt;&lt;/dependency&gt; 2.在application.properties中加入activemq的配置1234567spring.activemq.broker-url=tcp://192.168.74.135:61616spring.activemq.user=adminspring.activemq.password=adminspring.activemq.pool.enabled=truespring.activemq.pool.max-connections=50spring.activemq.pool.expiry-timeout=10000spring.activemq.pool.idle-timeout=30000 3.创建一个消息生产者12345678@Componentpublic class JMSProducer &#123; @Autowired private JmsTemplate jmsTemplate; public void sendMessage(Destination destination,String message) &#123; this.jmsTemplate.convertAndSend(destination,message); &#125;&#125; 4.创建一个消息消费者12345678@Componentpublic class JMSConsumer &#123; private final static Logger logger = LoggerFactory.getLogger(JMSConsumer.class); @JmsListener(destination = "springboot.queue.test") public void receiveQueue(String msg) &#123; logger.info("接收到消息：&#123;&#125;",msg); &#125;&#125; 5.测试类1234567891011public class JmsTest extends BaseTest&#123; @Autowired private JMSProducer jmsProducer; @Test public void testJms() &#123; Destination destination = new ActiveMQQueue("springboot.queue.test"); for (int i=0;i&lt;10;i++) &#123; jmsProducer.sendMessage(destination,"hello,world!" + i); &#125; &#125;&#125; BaseTest代码如下：1234@RunWith(SpringRunner.class)@SpringBootTest(classes = com.sample.activity.web.Application.class)public abstract class BaseTest &#123;&#125; 6.发送和接收TOPIC消息默认只能发送和接收queue消息，如果要发送和接收topic消息，需要在application.properties文件中加入：1spring.jms.pub-sub-domain=true 发送和接收的代码同queue一样。但是这样有另外一个问题：无法发送和接收queue消息。那么如何同时支持发送和接收queue/topic消息呢？ 7.支持同时发送和接收queue/topici. 新建一个JMS的配置类：12345678910111213141516171819202122232425262728@Configurationpublic class JmsConfig &#123; public final static String TOPIC = "springboot.topic.test"; public final static String QUEUE = "springboot.queue.test"; @Bean public Queue queue() &#123; return new ActiveMQQueue(QUEUE); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(TOPIC); &#125; // topic模式的ListenerContainer @Bean public JmsListenerContainerFactory&lt;?&gt; jmsListenerContainerTopic(ConnectionFactory activeMQConnectionFactory) &#123; DefaultJmsListenerContainerFactory bean = new DefaultJmsListenerContainerFactory(); bean.setPubSubDomain(true); bean.setConnectionFactory(activeMQConnectionFactory); return bean; &#125; // queue模式的ListenerContainer @Bean public JmsListenerContainerFactory&lt;?&gt; jmsListenerContainerQueue(ConnectionFactory activeMQConnectionFactory) &#123; DefaultJmsListenerContainerFactory bean = new DefaultJmsListenerContainerFactory(); bean.setConnectionFactory(activeMQConnectionFactory); return bean; &#125;&#125; ii. 消息消费者的代码改成如下：123456789101112@Componentpublic class JMSConsumer &#123; private final static Logger logger = LoggerFactory.getLogger(JMSConsumer.class); @JmsListener(destination = JmsConfig.TOPIC,containerFactory = "jmsListenerContainerTopic") public void onTopicMessage(String msg) &#123; logger.info("接收到topic消息：&#123;&#125;",msg); &#125; @JmsListener(destination = JmsConfig.QUEUE,containerFactory = "jmsListenerContainerQueue") public void onQueueMessage(String msg) &#123; logger.info("接收到queue消息：&#123;&#125;",msg); &#125;&#125; 可以看到，这里指定了ConnectionFactory。 iii. 测试类：123456789101112131415public class JmsTest extends BaseTest&#123; @Autowired private JMSProducer jmsProducer; @Autowired private Topic topic; @Autowired private Queue queue; @Test public void testJms() &#123; for (int i=0;i&lt;10;i++) &#123; jmsProducer.sendMessage(queue,"queue,world!" + i); jmsProducer.sendMessage(topic, "topic,world!" + i); &#125; &#125;&#125; springboot中activemq的一些配置属性参考：springboot activemq配置属性]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用TimerTask的坑]]></title>
    <url>%2F2017%2F11%2F10%2Fjava-timertask%2F</url>
    <content type="text"><![CDATA[使用TimerTask可以方便的实现定时任务的功能，但是如果使用不当，反而会带来隐患。 在使用TimerTask时，TimerTask中的代码必须要做异常处理，否则产生异常的时候，就挂掉了。特别像使用MQ发送数据的时候，不会显式的要求你捕获异常，如果你忘记了，那么在某个时刻MQ异常的时候（比如网络异常），在发送数据到MQ失败的时候，TimerTask就挂掉了。 比如如下代码：123456789101112ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext_*.xml");final JmsSender jmsSender = ac.getBean(JmsSender.class);Timer timer = new Timer();// 1.TimerTask中不处理异常timer.schedule(new TimerTask() &#123; @Override public void run() &#123; System.out.println("开始发送数据"); jmsSender.sendTopicMsg("test.topic","hello,world"); System.out.println("数据发送成功"); &#125;&#125;,10000,5000); 这段代码没有做异常处理，我们看下执行结果：最开始启动程序时，让MQ正常启动起来，这个时候TimerTask是正常工作的；在某个时刻关闭MQ，这个时候发现TimerTask中已经没有打印任何东西了，包括后面MQ恢复了也没有再打印，说明TimerTask已经挂掉了。所以在使用TimerTask的时候要尤其注意这点，搞不好就踩着坑了。 处理方法有这么几种：1.仍然使用TimerTask，但做异常处理；2.使用单一线程的线程池来做；3.使用线程，同样做异常处理。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为dubbo接口增加IP白名单]]></title>
    <url>%2F2017%2F11%2F04%2Fdubbo-interface-whiteip%2F</url>
    <content type="text"><![CDATA[在开发dubbo接口时，有时可能会限制接口的访问，ip白名单即是一种。在dubbo中，通过扩展Filter接口，可以实现IP白名单的功能。 先定义一个配置IP白名单的bean12345678910111213141516171819/** * Created by j.tommy on 2017/11/4. */public class IPWhiteList &#123; private boolean isEnabled; // 是否启用白名单 private List&lt;String&gt; allowIps; // 允许的白名单列表 public boolean isEnabled() &#123; return isEnabled; &#125; public void setEnabled(boolean isEnabled) &#123; this.isEnabled = isEnabled; &#125; public List&lt;String&gt; getAllowIps() &#123; return allowIps; &#125; public void setAllowIps(List&lt;String&gt; allowIps) &#123; this.allowIps = allowIps; &#125;&#125; 然后我们实现dubbo的Filter接口12345678910111213141516171819202122/** * Created by j.tommy on 2017/11/4. */public class IPWhiteListFilter implements Filter&#123; private IPWhiteList ipWhiteList; public void setIpWhiteList(IPWhiteList ipWhiteList) &#123; this.ipWhiteList = ipWhiteList; &#125; @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; if (!ipWhiteList.isEnabled()) &#123; System.out.println("dubbo IP白名单被禁用！"); return invoker.invoke(invocation); &#125; String clientIp = RpcContext.getContext().getRemoteHost(); if (ipWhiteList.getAllowIps().contains(clientIp)) &#123; return invoker.invoke(invocation); &#125; System.out.println("dubbo客户端IP[" + clientIp + "]不在白名单，禁止调用！"); return new RpcResult(); &#125;&#125; 在/resources目录下，新建META-INF/dubbo目录，并新建一个名为com.alibaba.dubbo.rpc.Filter的文本文件内容如下：1ipWhiteListFilter=com.tommy.service.provider.filter.IPWhiteListFilter dubbo的配置文件中增加filter的配置：123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="demo-provider"/&gt; &lt;dubbo:registry address="multicast://224.5.6.7:1234"/&gt; &lt;dubbo:protocol name="dubbo" port="20880" /&gt; &lt;dubbo:provider filter="ipWhiteListFilter"/&gt; &lt;dubbo:service interface="com.tommy.service.DemoService" ref="demoService"/&gt; &lt;bean id="demoService" class="com.tommy.service.provider.DemoServiceImpl"/&gt; &lt;bean id="ipWhiteList" class="com.tommy.service.provider.bean.IPWhiteList"&gt; &lt;property name="enabled" value="true"/&gt; &lt;property name="allowIps"&gt; &lt;list&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;value&gt;192.168.71.170&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 参考：http://blog.csdn.net/mj158518/article/details/47379799]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串分隔性能测试]]></title>
    <url>%2F2017%2F10%2F14%2Fstring-split-test%2F</url>
    <content type="text"><![CDATA[看《Java程序性能优化-让你的Java程序更快、更稳定》一书，在提到字符串分割的性能优化方面，提到了String自带的split方法，使用StringTokenizer，以及使用String.indexOf3种方式做测试，效率JDK&lt;StringTokenizer&lt;indexOf。 但我本机测试结果却不同，本机测试的结果是StringTokenizer&lt;StringUtils(apache commons-lang包)&lt;JDK&lt;indexOf。测试代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public static void spliteTest(String testType) &#123; StringBuffer stringBuffer = new StringBuffer(); String str = null; String SPLIT = ","; // 分隔符 int MAX = 10000; // 分割10000次 // 构造一个包含1000个分隔符的长字符串 for (int i=0;i&lt;1000;i++) &#123; stringBuffer.append(i+SPLIT); &#125; str = stringBuffer.toString(); long start = System.currentTimeMillis(); switch (testType) &#123; case "jdk": for (int i=0;i&lt;MAX;i++) &#123; str.split(SPLIT); &#125; System.out.println(testType + " cost " + (System.currentTimeMillis() - start)); break; case "stringTokenizer": StringTokenizer stringTokenizer = new StringTokenizer(str,SPLIT); for (int i=0;i&lt;MAX;i++) &#123; while (stringTokenizer.hasMoreTokens()) &#123; stringTokenizer.nextToken(); &#125; stringTokenizer = new StringTokenizer(str,SPLIT); &#125; System.out.println(testType +" cost " + (System.currentTimeMillis() - start)); break; case "stringUtils": for (int i=0;i&lt;MAX;i++) &#123; StringUtils.split(str,SPLIT); &#125; System.out.println(testType +" cost " + (System.currentTimeMillis() - start)); break; case "indexOf": String tmp = str; String splitStr = null; for (int i=0;i&lt;MAX;i++) &#123; while (true) &#123; int index = tmp.indexOf(SPLIT); // 找到分隔符 if (index &lt; 0) &#123; break; &#125; splitStr = tmp.substring(0,index); // 此次循环分隔的子串 tmp = tmp.substring(index+1); // 剩下需要处理的字符串 &#125; tmp = str; &#125; System.out.println(testType +" cost " + (System.currentTimeMillis() - start)); break; default: break; &#125;&#125; 测试结果：1234jdk cost 259stringTokenizer cost 374stringUtils cost 225indexOf cost 149 有时候jdk&gt;StringUtils，有时候反过来，差别很小。但StringTokenizer效率很低。indexOf始终是速度最快的。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决360浏览器不支持IDM下载的问题]]></title>
    <url>%2F2017%2F09%2F23%2Fresolve-360browser-not-support-idm%2F</url>
    <content type="text"><![CDATA[像360安全浏览器和360极速浏览器的设置中，下载工具都只能选择自己。不能选择IDM下载。如图： 如何让它们支持IDM下载呢？在IDM的文件夹中，可以看到一个扩展文件，将它拖动的浏览器中进行安装即可。如图：然后打开IDM，可以看到360安全/技术浏览器了。如果没有手动添加浏览器。然后就可以用IDM下载了。]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat监控助手-自动重启相关服务]]></title>
    <url>%2F2017%2F09%2F22%2FTomcat-monitor%2F</url>
    <content type="text"><![CDATA[功能说明该小工具使用swing实现，实现监控某个服务地址，在异常时（连续3次访问不通）自动重启tomcat，并启动配置好的抓取项。 先看下效果图： 代码说明下面是代码：配置文件TomcatMonitor.properties1234567891011121314151617181920#tomcat的启动脚本位置tomcat.home=D:/luckystar88/soft/apache-tomcat-8.5.6/bin/startup.bat#tomcat服务监控地址listen.url=http://localhost:8080/nodeManage/index.jsp#tomcat监控间隔（秒）listen.interval=10#抓取节点snatch.node=test-99-YY#抓取节点下的抓取项snatch.items=皇冠#足球.滚球#1,皇冠#足球.单式#1,皇冠#足球.早餐#0,皇冠#足球.单式.上半场波胆#0,皇冠#足球.单式.全场波胆#0,皇冠#足球.单式.总进球#0,皇冠#足球.单式.半场全场#0,利记#足球.滚球#0,利记#足球.单式#0,利记#足球.早餐#0,浩博#足球.早餐#0,浩博#足球.单式#0,浩博#足球.滚球#0,500w#500w必发指数#0,球探网#足球.赛果（API）#0,球探网#足球.比分.API#0,竞彩网#足球.受注赛程#0#开启抓取项的URLsnatch.url=http://localhost:8080/nodeManage/nodeSnatchManage/startOrStopSnatchItem#管理中心的登录地址snatch.login.url=http://localhost:8080/nodeManage/user/login#管理中心登录用户名snatch.login.username=admin#管理中心登录密码snatch.login.pwd=test123456 读写配置文件的工具类PropertiesUtils12345678910111213141516171819202122232425262728293031323334353637/** * Created by j.tommy on 2017/9/17. */public final class PropertiesUtils &#123; private final static Properties properties = new Properties(); private final static String CONF_FILE = "/TomcatMonitor.properties"; public final static String KEY_TOMCAT_HOME = "tomcat.home"; public final static String KEY_LISTEN_URL = "listen.url"; public final static String KEY_LISTEN_INTERVAL = "listen.interval"; public final static String KEY_SNATCH_NODE = "snatch.node"; public final static String KEY_SNATCH_ITEMS = "snatch.items"; public final static String KEY_SNATCH_URL = "snatch.url"; public final static String KEY_LOGIN_URL = "snatch.login.url"; public final static String KEY_LOGIN_USERNAME = "snatch.login.username"; public final static String KEY_LOGIN_PWD = "snatch.login.pwd"; static &#123; InputStream in = PropertiesUtils.class.getResourceAsStream(CONF_FILE); try &#123; properties.load(in); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static String getString(String key) &#123; return properties.getProperty(key); &#125; public static void setString(String key,String value) &#123; properties.setProperty(key,value); try &#123; properties.store(new FileOutputStream(PropertiesUtils.class.getResource(CONF_FILE).getPath()),"update " + key); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Http请求的工具类HttpClientUtils：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * Created by j.tommy on 2017/9/20. */public final class HttpClientUtils &#123; private final static String USER_AGENT = "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36"; private final static ThreadLocal&lt;CloseableHttpClient&gt; HTTP_CLIENT_THREAD_LOCAL = new ThreadLocal&lt;CloseableHttpClient&gt;()&#123; @Override protected CloseableHttpClient initialValue() &#123; return HttpClients.custom().setUserAgent(USER_AGENT).build(); &#125; &#125;; private static CloseableHttpClient getClosableHttpClient() &#123; return HTTP_CLIENT_THREAD_LOCAL.get(); &#125; public static String get(String url,Map&lt;String,Object&gt; params,String encoding) throws IOException &#123; url = makeUrlParams(url,params); HttpGet hg = new HttpGet(url); CloseableHttpClient chc = getClosableHttpClient(); try &#123; CloseableHttpResponse chr = chc.execute(hg); if (chr.getStatusLine().getStatusCode() == HttpStatus.SC_OK) &#123; return EntityUtils.toString(chr.getEntity(),StringUtils.isEmpty(encoding) ? "utf-8" : encoding); &#125; &#125; finally &#123; hg.releaseConnection(); &#125; return null; &#125; public static String post(String url,Map&lt;String,Object&gt; params,String encoding) throws IOException &#123; HttpPost hp = new HttpPost(url); if (null != params &amp;&amp; !params.isEmpty()) &#123; List&lt;NameValuePair&gt; urlParams = new ArrayList&lt;NameValuePair&gt;(); for (Iterator&lt;Map.Entry&lt;String,Object&gt;&gt; it = params.entrySet().iterator();it.hasNext();) &#123; Map.Entry&lt;String,Object&gt; entry = it.next(); urlParams.add(new BasicNameValuePair(entry.getKey(),entry.getValue()+"")); &#125; hp.setEntity(new UrlEncodedFormEntity(urlParams)); &#125; CloseableHttpClient chc = getClosableHttpClient(); try &#123; CloseableHttpResponse chr = chc.execute(hp); if (chr.getStatusLine().getStatusCode() == HttpStatus.SC_OK) &#123; return EntityUtils.toString(chr.getEntity(), StringUtils.isEmpty(encoding) ? "utf-8" : encoding); &#125; &#125; finally &#123; hp.releaseConnection(); &#125; return null; &#125; /** * 组装URL参数 * @param url * @param params * @return */ private static String makeUrlParams(String url,Map&lt;String,Object&gt; params) &#123; StringBuffer urlBuf = new StringBuffer(url); boolean isEmpty = true; if (null != params &amp;&amp; !params.isEmpty()) &#123; isEmpty = false; urlBuf.append("?"); &#125; if (!isEmpty) &#123; Iterator&lt;Map.Entry&lt;String,Object&gt;&gt; it = params.entrySet().iterator(); while (it.hasNext()) &#123; Map.Entry&lt;String,Object&gt; entry = it.next(); urlBuf.append(entry.getKey()).append("=").append(entry.getValue()).append("&amp;"); &#125; &#125; return isEmpty ? url : urlBuf.substring(0,urlBuf.length()-1); &#125;&#125; 表格用到的数据对象SnatchConfig：12345678910111213141516171819202122232425262728293031323334353637383940/** * Created by j.tommy on 2017/9/21. */public class SnatchConfig &#123; private int index; private String thirdSystem; private String snatchItem; private boolean startFlag; public SnatchConfig()&#123;&#125; public SnatchConfig(int index,String thirdSystem,String snatchItem,boolean startFlag) &#123; this.index = index; this.thirdSystem = thirdSystem; this.snatchItem = snatchItem; this.startFlag = startFlag; &#125; public String getSnatchItem() &#123; return snatchItem; &#125; public void setSnatchItem(String snatchItem) &#123; this.snatchItem = snatchItem; &#125; public boolean isStartFlag() &#123; return startFlag; &#125; public void setStartFlag(boolean startFlag) &#123; this.startFlag = startFlag; &#125; public int getIndex() &#123; return index; &#125; public void setIndex(int index) &#123; this.index = index; &#125; public String getThirdSystem() &#123; return thirdSystem; &#125; public void setThirdSystem(String thirdSystem) &#123; this.thirdSystem = thirdSystem; &#125;&#125; 用于显示表格数据的SnatchInfoTableModel：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859** * Created by j.tommy on 2017/9/21. */public class SnatchInfoTableModel implements TableModel &#123; private String[] headers = &#123;"编号","第三方系统","抓取项","是否开启抓取"&#125;; private java.util.List&lt;SnatchConfig&gt; configs = new ArrayList&lt;SnatchConfig&gt;(); public SnatchInfoTableModel(List&lt;SnatchConfig&gt; configs ) &#123; this.configs = configs; &#125; @Override public int getRowCount() &#123; return configs.size(); &#125; @Override public int getColumnCount() &#123; return headers.length; &#125; @Override public String getColumnName(int columnIndex) &#123; return headers[columnIndex]; &#125; @Override public Class&lt;?&gt; getColumnClass(int columnIndex) &#123; if (columnIndex == 0) return Integer.class; if (columnIndex == 1) return String.class; if (columnIndex == 2) return String.class; if (columnIndex == 3) return Boolean.class; // 返回bool类型，swing就会显示CheckBox了。 return null; &#125; @Override public boolean isCellEditable(int rowIndex, int columnIndex) &#123; return columnIndex == 0 ? false : true; &#125; @Override public Object getValueAt(int rowIndex, int columnIndex) &#123; SnatchConfig sc = configs.get(rowIndex); if (columnIndex == 0) return sc.getIndex(); if (columnIndex == 1) return sc.getThirdSystem(); if (columnIndex == 2) return sc.getSnatchItem(); if (columnIndex == 3) return sc.isStartFlag(); return null; &#125; @Override public void setValueAt(Object aValue, int rowIndex, int columnIndex) &#123; SnatchConfig sc = configs.get(rowIndex); if (null == sc) sc = new SnatchConfig(); if (columnIndex == 0) System.out.println("暂不提供修改功能。"); else if (columnIndex == 1) sc.setThirdSystem((String) aValue); else if (columnIndex == 2) sc.setSnatchItem((String) aValue); else if (columnIndex == 3) sc.setStartFlag((Boolean) aValue); &#125; @Override public void addTableModelListener(TableModelListener l) &#123; &#125; @Override public void removeTableModelListener(TableModelListener l) &#123; &#125;&#125; 用于开启抓取项的StartSnatchItemManager：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * Created by j.tommy on 2017/9/21. */public final class StartSnatchItemManager &#123; private static boolean login(TomcatMonitor tm) throws IOException &#123; String username = PropertiesUtils.getString(PropertiesUtils.KEY_LOGIN_USERNAME); String pwd = PropertiesUtils.getString(PropertiesUtils.KEY_LOGIN_PWD); String loginUrl = PropertiesUtils.getString(PropertiesUtils.KEY_LOGIN_URL); Map&lt;String,Object&gt; params = new HashMap&lt;String, Object&gt;(2); params.put("username",username); params.put("pwd",pwd); String content = HttpClientUtils.post(loginUrl, params, null); System.out.println(content); boolean loginCheck = false; if (null != content &amp;&amp; !"".equals(content)) &#123; String returnCode = (String) JsonUtil.getValue(content,"returncode"); if (null != returnCode &amp;&amp; "0".equals(returnCode)) &#123; loginCheck = true; &#125; else &#123; String errmsg = (String) JsonUtil.getValue(content,"errmsg"); String msg = "登录管理中心失败！无法开启抓取项。错误信息：" + errmsg; tm.insertLog(msg); &#125; &#125; return loginCheck; &#125; /** * 开启抓取项 * @param tm * @param snatchUrl 开启抓取项的URL * @param snatchNode 抓取节点 * @param snatchItems 抓取项（见属性文件配置） */ public static void startSnatchItems(TomcatMonitor tm,String snatchUrl,String snatchNode,String snatchItems) &#123; boolean loginResult = false; try &#123; loginResult = login(tm); &#125; catch (IOException e) &#123; tm.insertLog("登录失败！err=" + e.getMessage()); e.printStackTrace(); &#125; if (!loginResult) &#123; return; &#125; Map&lt;String,Object&gt; params = new HashMap&lt;String, Object&gt;(4); if (null != snatchItems &amp;&amp; !"".equals(snatchItems)) &#123; String[] items = snatchItems.split(","); params.clear(); for (String item : items) &#123; String startFlag = item.split("#")[2]; if (!"1".equals(startFlag)) &#123; continue; &#125; params.put("onlyCode",snatchNode); params.put("operateStatus","1"); params.put("thirdSystem",item.split("#")[0]); params.put("snatchItem",item.split("#")[1]); // 开启抓取项 String result = null; try &#123; result = HttpClientUtils.get(snatchUrl, params, "utf-8"); &#125; catch (IOException e) &#123; tm.insertLog("开启抓取项失败！err=" + e.getMessage()); e.printStackTrace(); &#125; if (null != result) &#123; Double returncode = (Double) JsonUtil.getValue(result,"returncode"); if (null != result &amp;&amp; returncode == 0) &#123; String msg = "抓取项：[" + item.split("#")[0] + "." + item.split("#")[1] + "]开启成功！"; System.out.println(msg); tm.insertLog(msg); &#125; else &#123; String errmsg = (String) JsonUtil.getValue(result,"errmsg"); String errMsg = "抓取项：[" + item.split("#")[0] + "." + item.split("#")[1] + "]开启失败！msg=" + errmsg; tm.insertLog(errMsg); &#125; &#125; &#125; &#125; &#125;&#125; 用来展示GUI和事件处理的TomcatMonitor：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365/** * Tomcat监控助手。 * 用来实现在Tomcat服务异常时，自动重启Tomcat服务。 * Created by j.tommy on 2017/9/17. */public class TomcatMonitor &#123; /** * Tomcat启动脚本位置 */ private JTextField textField1; /** * 监控地址URL */ private JTextField textField2; /** * 用来显示监控日志的Panel */ private JTextPane logPanel; /** * 使用帮助按钮 */ private JButton helpButton; JPanel mainPanel; /** * 开始监控按钮 */ private JButton jkButton; /** * 监控间隔（秒） */ private JTextField textField3; private JTabbedPane tp; private JTextField snatchNodeFd = new JTextField(60); private JTextField snatchUrlField = new JTextField(60); /** * 是否监控的标志位 */ private boolean listenFlag = true; private final DateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); private String tomcatHome; private String listenUrl; private String interval; private String snatchNode; private String snatchItems; private String snatchUrl; /** * 监控线程 */ private ListenThread lt = null; public TomcatMonitor() &#123; initSecondPane(); loadConf(); helpButton.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; JOptionPane.showMessageDialog(null, "这是一个tomcat监控小工具，通过定时扫描指定的页面来确认服务是否正常。\n在服务异常时，自动重新启动tomcat服务器。\n启动是通过命令行启动的tomcat的startup.bat脚本。\n", "使用说明", JOptionPane.INFORMATION_MESSAGE); &#125; &#125;); logPanel.setContentType("text/html"); logPanel.setEditable(false); jkButton.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; String text = "监控中..."; if (jkButton.getText().equals(text)) &#123; int r = JOptionPane.showConfirmDialog(null,"停止监控？","系统提示",JOptionPane.YES_NO_OPTION); if (r == JOptionPane.YES_OPTION) &#123; TomcatMonitor.this.lt = null; TomcatMonitor.this.listenFlag = false; jkButton.setText("开始监控"); &#125; return; &#125; boolean validateFlag = validateForm(); if (validateFlag) &#123; TomcatMonitor.this.listenFlag = true; if (lt == null ) &#123; lt = new ListenThread(); lt.start(); &#125; jkButton.setText(text); &#125; &#125; &#125;); insertLog("tomcat监控助手启动成功！"); &#125; /** * 初始化抓取项配置TAB组件 */ private void initSecondPane() &#123; JPanel secondPane = new JPanel(); GridBagLayout gbl = new GridBagLayout(); secondPane.setLayout(gbl); List&lt;SnatchConfig&gt; snatchConfigs = getSnatchConfigs(); SnatchInfoTableModel sitm = new SnatchInfoTableModel(snatchConfigs); final JTable jt = new JTable(sitm); Font font = new Font("宋体",Font.BOLD,13); jt.getTableHeader().setFont(font); jt.setFont(font); JScrollPane jp = new JScrollPane(jt); // 设置表格的宽度和高度 for (int i=0;i&lt;jt.getColumnCount();i++) &#123; if (i == 0) jt.getColumnModel().getColumn(i).setPreferredWidth(30); if (i == 1) jt.getColumnModel().getColumn(i).setPreferredWidth(100); if (i == 2) jt.getColumnModel().getColumn(i).setPreferredWidth(200); &#125; jt.setRowHeight(40); jt.setPreferredScrollableViewportSize(new Dimension(820,500)); JLabel snatchNodeLbl = new JLabel("抓取项所属节点："); snatchNodeFd.setPreferredSize(new Dimension(200,30)); JLabel snatchUrlLabel = new JLabel("开启抓取项URL："); JButton saveSnatchConfigBtn = new JButton("保存配置"); snatchUrlField.setToolTipText("请输入抓取项URL"); snatchUrlField.setPreferredSize(new Dimension(200,30)); secondPane.add(jp,new GBC(0,0,2,1).setAnchor(GridBagConstraints.WEST).setInsets(-40,10,0,10)); secondPane.add(snatchNodeLbl,new GBC(0,1,1,1).setAnchor(GridBagConstraints.WEST).setInsets(10,10,10,10)); secondPane.add(snatchNodeFd,new GBC(1,1,2,1).setAnchor(GridBagConstraints.WEST).setInsets(10,10,10,10)); secondPane.add(snatchUrlLabel,new GBC(0,3,1,1).setAnchor(GridBagConstraints.WEST).setInsets(10,10,10,10)); secondPane.add(snatchUrlField,new GBC(1,3,2,1).setAnchor(GridBagConstraints.WEST).setInsets(10,10,10,10)); secondPane.add(saveSnatchConfigBtn,new GBC(1,4,1,1).setAnchor(GridBagConstraints.CENTER)); tp.add("抓取项配置",secondPane); /** * 保存抓取配置 */ saveSnatchConfigBtn.addActionListener(new AbstractAction() &#123; @Override public void actionPerformed(ActionEvent e) &#123; boolean dataChangeFlag = false; // 抓取节点 String snatchNode = snatchNodeFd.getText(); if (!snatchNode.equals(TomcatMonitor.this.snatchNode) &amp;&amp; !"".equals(snatchNode)) &#123; dataChangeFlag = true; PropertiesUtils.setString(PropertiesUtils.KEY_SNATCH_NODE,snatchNode); TomcatMonitor.this.snatchNode = snatchNode; &#125; // 抓取URL String snatchURL = snatchUrlField.getText(); if (!snatchURL.equals(snatchUrl) &amp;&amp; !"".equals(snatchURL)) &#123; dataChangeFlag = true; PropertiesUtils.setString(PropertiesUtils.KEY_SNATCH_URL,snatchURL); TomcatMonitor.this.snatchUrl = snatchURL; &#125; int rows = jt.getRowCount(); if (rows &gt; 0) &#123; StringBuffer snatchConfigBuff = new StringBuffer(); for (int i=0;i&lt;rows;i++) &#123; String thirdSystem = (String) jt.getModel().getValueAt(i,1); String snatchItem = (String) jt.getModel().getValueAt(i,2); boolean startFlag = (Boolean)jt.getModel().getValueAt(i,3); snatchConfigBuff.append(thirdSystem).append("#").append(snatchItem).append("#").append(startFlag?1:0).append(","); &#125; String snatchItems = snatchConfigBuff.substring(0,snatchConfigBuff.length()-1); if (!snatchItems.equals(TomcatMonitor.this.snatchItems)) &#123; // 保存到配置文件 PropertiesUtils.setString(PropertiesUtils.KEY_SNATCH_ITEMS,snatchItems); dataChangeFlag = true; TomcatMonitor.this.snatchItems = snatchItems; &#125; &#125; String tipMsg = "配置已保存"; if (!dataChangeFlag) &#123; tipMsg = "配置无修改，无需保存！"; &#125; JOptionPane.showMessageDialog(null,tipMsg,"提示",JOptionPane.INFORMATION_MESSAGE); &#125; &#125;); &#125; /** * 输入框验证 * @return */ private boolean validateForm() &#123; String tomcatHome = textField1.getText(); String listenUrl = textField2.getText(); String interval = textField3.getText(); if (null == tomcatHome || "".equals(tomcatHome)) &#123; JOptionPane.showMessageDialog(null,"请输入tomcat启动脚本位置！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (null == listenUrl || "".equals(listenUrl)) &#123; JOptionPane.showMessageDialog(null,"请输入监控地址！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (!listenUrl.startsWith("http://")) &#123; JOptionPane.showMessageDialog(null,"请输入正确的监控地址！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (!interval.matches("\\d+")) &#123; JOptionPane.showMessageDialog(null,"请输入正确的监控间隔（秒）！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; int intervalTime = Integer.parseInt(interval); if (intervalTime &lt; 10) &#123; JOptionPane.showMessageDialog(null,"监控间隔不能小于10秒！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (!tomcatHome.equals(this.tomcatHome)) &#123; this.tomcatHome = tomcatHome; PropertiesUtils.setString(PropertiesUtils.KEY_TOMCAT_HOME,tomcatHome); &#125; if (!listenUrl.equals(this.listenUrl)) &#123; this.listenUrl = listenUrl; PropertiesUtils.setString(PropertiesUtils.KEY_LISTEN_URL,listenUrl); &#125; if (!interval.equals(this.interval)) &#123; this.interval = interval; PropertiesUtils.setString(PropertiesUtils.KEY_LISTEN_INTERVAL,interval); &#125; return true; &#125; /** * 从配置文件加载tomcat启动脚本位置、监控url、监控间隔、抓取节点、抓取url */ private void loadConf() &#123; String tomcatHome = PropertiesUtils.getString(PropertiesUtils.KEY_TOMCAT_HOME); String listenUrl = PropertiesUtils.getString(PropertiesUtils.KEY_LISTEN_URL); String listenInterval = PropertiesUtils.getString(PropertiesUtils.KEY_LISTEN_INTERVAL); String snatchNode = PropertiesUtils.getString(PropertiesUtils.KEY_SNATCH_NODE); String snatchUrl = PropertiesUtils.getString(PropertiesUtils.KEY_SNATCH_URL); if (null != tomcatHome &amp;&amp; !"".equals(tomcatHome)) &#123; textField1.setText(tomcatHome); this.tomcatHome = tomcatHome; &#125; if (null != listenUrl &amp;&amp; !"".equals(listenUrl)) &#123; textField2.setText(listenUrl); this.listenUrl = listenUrl; &#125; if (null != listenInterval &amp;&amp; !"".equals(listenInterval)) &#123; textField3.setText(listenInterval); this.interval = listenInterval; &#125; if (null != snatchNode &amp;&amp; !"".equals(snatchNode)) &#123; this.snatchNode = snatchNode; snatchNodeFd.setText(snatchNode); &#125; if (null != snatchUrl &amp;&amp; !"".equals(snatchUrl)) &#123; snatchUrlField.setText(snatchUrl); this.snatchUrl = snatchUrl; &#125; &#125; /** * 从配置文件加载抓取项 * @return */ private List&lt;SnatchConfig&gt; getSnatchConfigs() &#123; List&lt;SnatchConfig&gt; snatchConfigs = new ArrayList&lt;SnatchConfig&gt;(); String snatchItems = PropertiesUtils.getString(PropertiesUtils.KEY_SNATCH_ITEMS); this.snatchItems = snatchItems; if (null != snatchItems &amp;&amp; !"".equals(snatchItems)) &#123; String[] items = snatchItems.split(","); int index = 1; for (String item : items) &#123; String[] itemConfig = item.split("#"); boolean startFlag = "0".equals(itemConfig[2]) ? false : true; snatchConfigs.add(new SnatchConfig(index,itemConfig[0],itemConfig[1],startFlag)); index++; &#125; &#125; return snatchConfigs; &#125; /** * 开启tomcat，然后等待120S，待tomcat启动完毕后，开启指定的抓取项。 */ private void startTomcat() &#123; Runtime runtime = Runtime.getRuntime(); try &#123; runtime.exec(tomcatHome); insertLog("120秒后检测是否启动成功..."); // 休眠120秒后启动抓取项 Thread.sleep(120000); insertLog("检测是否启动成功..."); // 检查是否启动成功 String content = HttpClientUtils.get(listenUrl,null,"utf-8"); if (null != content &amp;&amp; !"".equals(content)) &#123; // 开启抓取项 insertLog("Tomcat启动成功！正在开启抓取项..."); StartSnatchItemManager.startSnatchItems(this,snatchUrl,snatchNode,snatchItems); &#125; else &#123; insertLog("启动tomcat失败！"); &#125; &#125; catch (IOException e) &#123; insertLog("启动tomcat失败！error=" + e.getMessage()); &#125; catch (InterruptedException e) &#123; insertLog("启动tomcat失败！error=" + e.getMessage()); &#125; &#125; /** * 向logPanel插入日志 * @param msg */ public void insertLog(String msg) &#123; StyledDocument sd = logPanel.getStyledDocument(); try &#123; String current = df.format(new Date()); msg = current + "," + msg +"\n"; int docLength = sd.getLength(); if (docLength &gt; 100000) &#123; sd.remove(0,docLength); sd.insertString(sd.getLength(),"日志过多，之前的日志已被清除！", logPanel.getCharacterAttributes()); &#125; sd.insertString(sd.getLength(),msg,logPanel.getCharacterAttributes()); &#125; catch (BadLocationException e) &#123; e.printStackTrace(); &#125; &#125; /** * tomcat监控线程，定时请求给定的URL，检测服务是否正常。在tomcat服务异常时自动重启tomcat。 */ class ListenThread extends Thread &#123; private int count = 0; public void run() &#123; while (listenFlag) &#123; try &#123; String content = HttpClientUtils.get(listenUrl,null,"utf-8"); String f = "成功"; if (null == content) &#123; f = "失败"; count++; &#125; String msg = "请求URL：" + listenUrl + ",结果："+ f; insertLog(msg); if (count &gt;= 3) &#123; insertLog("tomcat服务监控连续3次异常，重新启动..."); startTomcat(); count = 0; &#125; &#125; catch (Exception e) &#123; String msg = "监控异常！error=" + e.getMessage(); insertLog(msg); insertLog("正在重新启动Tomcat..."); startTomcat(); &#125; finally &#123; try &#123; Thread.sleep(1000*Long.parseLong(interval)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; JFrame frame = new JFrame("Tomcat监控小工具"); final TomcatMonitor tm = new TomcatMonitor(); frame.setContentPane(tm.tp); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setResizable(false); frame.pack(); frame.setSize(900,750); frame.setLocationRelativeTo(tm.tp); frame.setVisible(true); frame.addWindowListener(new WindowAdapter() &#123; @Override public void windowClosing(WindowEvent e) &#123; super.windowClosing(e); tm.listenFlag = false; &#125; &#125;); &#125;&#125; 这里特别说明：GUI使用idea来创建的。TAB导航也是可以通过idea来添加的。但是这里我第2个TAB是自己用代码写的，费时费力，完全是不必要的。 打包说明最后是打包成Jar运行的。将要打包的文件（.class和.properties）复制到E:/test 注意：要将idea生成的class也复制过来 打包命令：E:>jar -cvf aa.jar -C test .上面的命令即将test目录下的所有文件和目录打成一个jar包。 将依赖的jar放到一个lib目录中，然后将打包后的文件和lib放到一个目录中。比如： 用解压缩软件打开aa.jar，修改MANIFEST.MF文件，增加Main-Class和Class-Path，如下：Main-Class用来指定程序启动入口，Class-Path指定依赖的jar包。然后双击aa.jar或者在命令行执行java -jar aa.jar就可以执行了。 jar包中读写配置文件后来发现上面的方式，读取jar中的配置文件是OK的，但是写入报错。后采用了下面的方式处理：这里打包的目录结构如图：compile是class文件，lib是依赖的jar包，res是配置文件。将程序的class文件拷贝到compile目录，依赖的jar拷贝到lib，依赖的配置文件拷贝到res目录，然后命令行切换到E:/test目录。执行：E:\test&gt;jar -cvf /test/aa.jar -C compile/ .这样就会在/test目录生成aa.jar。修改aa.jar中的MANIFEST.MF，修改Main-Class和Class-Path，这个是跟上面一样的。然后执行java -jar aa.jar就可以了。 属性文件的读取时使用读写文件，如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Created by j.tommy on 2017/9/17. */public final class PropertiesUtils &#123; private final static Properties properties = new Properties(); private final static String CONF_FILE = "/res/TomcatMonitor.properties"; public final static String KEY_TOMCAT_HOME = "tomcat.home"; public final static String KEY_LISTEN_URL = "listen.url"; public final static String KEY_LISTEN_INTERVAL = "listen.interval"; public final static String KEY_SNATCH_NODE = "snatch.node"; public final static String KEY_SNATCH_ITEMS = "snatch.items"; public final static String KEY_SNATCH_URL = "snatch.url"; public final static String KEY_LOGIN_URL = "snatch.login.url"; public final static String KEY_LOGIN_USERNAME = "snatch.login.username"; public final static String KEY_LOGIN_PWD = "snatch.login.pwd"; private static String fullConfigPath = null; static &#123; String rootPath = getRootPath(); fullConfigPath = rootPath + CONF_FILE; System.out.println(fullConfigPath); try &#123; BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(new File(fullConfigPath)))); properties.load(br); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private static String getRootPath() &#123; String rootPath = System.getProperty("user.dir").replace("\\", "/"); return rootPath; &#125; public static String getString(String key) &#123; return properties.getProperty(key); &#125; public static void setString(String key,String value) &#123; properties.setProperty(key,value); try &#123; properties.store(new FileOutputStream(fullConfigPath),"update " + key); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; &#125;&#125; 这样执行程序是会报错的，但打jar包执行没问题。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA-SWING监控Tomcat小工具]]></title>
    <url>%2F2017%2F09%2F17%2Fjava-swing-tomcat-monitor%2F</url>
    <content type="text"><![CDATA[由于线上的一个抓取节点Tomcat经常莫名其妙的被关掉，所以准备写个小工具来监控。在Tomcat服务异常时，重新启动。 界面使用的intellij idea设计。 设计完毕后，点右键-&gt;Jump to source 注意：idea不会为你生成main方法，需要自己写。 完整代码：TomcatMonitor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208/** * Tomcat监控助手。 * 用来实现在Tomcat服务异常时，自动重启Tomcat服务。 * Created by j.tommy on 2017/9/17. */public class TomcatMonitor &#123; /** * Tomcat启动脚本位置 */ private JTextField textField1; /** * 监控地址URL */ private JTextField textField2; /** * 用来显示监控日志的Panel */ private JTextPane logPanel; /** * 使用帮助按钮 */ private JButton helpButton; JPanel mainPanel; /** * 开始监控按钮 */ private JButton jkButton; /** * 监控间隔（秒） */ private JTextField textField3; /** * 是否监控的标志位 */ private boolean listenFlag = true; private final DateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); private String tomcatHome; private String listenUrl; private String interval; /** * 监控线程 */ private ListenThread lt = null; public TomcatMonitor() &#123; loadConf(); helpButton.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; JOptionPane.showMessageDialog(null, "这是一个tomcat监控小工具，通过定时扫描指定的页面来确认服务是否正常。\n在服务异常时，自动重新启动tomcat服务器。\n启动是通过命令行启动的tomcat的startup.bat脚本。\n", "使用说明", JOptionPane.INFORMATION_MESSAGE); &#125; &#125;); logPanel.setContentType("text/html"); logPanel.setEditable(false); jkButton.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; String text = "监控中..."; if (jkButton.getText().equals(text)) &#123; int r = JOptionPane.showConfirmDialog(null,"停止监控？","系统提示",JOptionPane.YES_NO_OPTION); if (r == JOptionPane.YES_OPTION) &#123; TomcatMonitor.this.lt = null; TomcatMonitor.this.listenFlag = false; jkButton.setText("开始监控"); &#125; return; &#125; boolean validateFlag = validateForm(); if (validateFlag) &#123; TomcatMonitor.this.listenFlag = true; if (lt == null ) &#123; lt = new ListenThread(); lt.start(); &#125; jkButton.setText(text); &#125; &#125; &#125;); insertLog("tomcat监控助手启动成功！"); &#125; private boolean validateForm() &#123; String tomcatHome = textField1.getText(); String listenUrl = textField2.getText(); String interval = textField3.getText(); if (null == tomcatHome || "".equals(tomcatHome)) &#123; JOptionPane.showMessageDialog(null,"请输入tomcat启动脚本位置！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (null == listenUrl || "".equals(listenUrl)) &#123; JOptionPane.showMessageDialog(null,"请输入监控地址！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (!listenUrl.startsWith("http://")) &#123; JOptionPane.showMessageDialog(null,"请输入正确的监控地址！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (!interval.matches("\\d+")) &#123; JOptionPane.showMessageDialog(null,"请输入正确的监控间隔（秒）！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; int intervalTime = Integer.parseInt(interval); if (intervalTime &lt; 10) &#123; JOptionPane.showMessageDialog(null,"监控间隔不能小于10秒！","系统提示",JOptionPane.WARNING_MESSAGE); return false; &#125; if (!tomcatHome.equals(this.tomcatHome)) &#123; this.tomcatHome = tomcatHome; PropertiesUtils.setString(PropertiesUtils.KEY_TOMCAT_HOME,tomcatHome); &#125; if (!listenUrl.equals(this.listenUrl)) &#123; this.listenUrl = listenUrl; PropertiesUtils.setString(PropertiesUtils.KEY_LISTEN_URL,listenUrl); &#125; if (!interval.equals(this.interval)) &#123; this.interval = interval; PropertiesUtils.setString(PropertiesUtils.KEY_LISTEN_INTERVAL,interval); &#125; return true; &#125; private void loadConf() &#123; String tomcatHome = PropertiesUtils.getString(PropertiesUtils.KEY_TOMCAT_HOME); String listenUrl = PropertiesUtils.getString(PropertiesUtils.KEY_LISTEN_URL); String listenInterval = PropertiesUtils.getString(PropertiesUtils.KEY_LISTEN_INTERVAL); if (null != tomcatHome &amp;&amp; !"".equals(tomcatHome)) &#123; textField1.setText(tomcatHome); this.tomcatHome = tomcatHome; &#125; if (null != listenUrl &amp;&amp; !"".equals(listenUrl)) &#123; textField2.setText(listenUrl); this.listenUrl = listenUrl; &#125; if (null != listenInterval &amp;&amp; !"".equals(listenInterval)) &#123; textField3.setText(listenInterval); this.interval = listenInterval; &#125; &#125; private void startTomcat() &#123; Runtime runtime = Runtime.getRuntime(); try &#123; runtime.exec(tomcatHome); &#125; catch (IOException e) &#123; insertLog("启动tomcat失败！error=" + e.getMessage()); &#125; &#125; private void insertLog(String msg) &#123; StyledDocument sd = logPanel.getStyledDocument(); try &#123; String current = df.format(new Date()); msg = current + "," + msg +"\n"; int docLength = sd.getLength(); if (docLength &gt; 100000) &#123; sd.remove(0,docLength); sd.insertString(sd.getLength(),"日志过多，之前的日志已被清除！", logPanel.getCharacterAttributes()); &#125; sd.insertString(sd.getLength(),msg,logPanel.getCharacterAttributes()); &#125; catch (BadLocationException e) &#123; e.printStackTrace(); &#125; &#125; class ListenThread extends Thread &#123; public void run() &#123; while (listenFlag) &#123; HttpURLConnection connection = null; try &#123; URL url = new URL(listenUrl); connection = (HttpURLConnection) url.openConnection(); connection.connect(); int responseCode = connection.getResponseCode(); String msg = "请求URL：" + listenUrl + ",结果："+ (responseCode &gt; 200 ? "失败":"成功") + ",responseCode=" + responseCode; insertLog(msg); &#125; catch (Exception e) &#123; String msg = "监控异常！error=" + e.getMessage(); insertLog(msg); insertLog("正在重新启动Tomcat..."); startTomcat(); &#125; finally &#123; try &#123; if (null != connection) &#123; connection.disconnect(); &#125; Thread.sleep(1000*Long.parseLong(interval)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; JFrame frame = new JFrame("Tomcat监控小工具"); final TomcatMonitor tm = new TomcatMonitor(); JScrollPane jsp = new JScrollPane(tm.mainPanel); frame.setContentPane(jsp); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setResizable(false); frame.pack(); frame.setSize(800,600); frame.setLocationRelativeTo(jsp); frame.setVisible(true); frame.addWindowListener(new WindowAdapter() &#123; @Override public void windowClosing(WindowEvent e) &#123; super.windowClosing(e); tm.listenFlag = false; &#125; &#125;); &#125;&#125; 一个属性文件读写工具类12345678910111213141516171819202122232425262728293031323334/** * Created by j.tommy on 2017/9/17. */public final class PropertiesUtils &#123; private final static Properties properties = new Properties(); private final static String CONF_FILE = "/TomcatMonitor.properties"; public final static String KEY_TOMCAT_HOME = "tomcat.home"; public final static String KEY_LISTEN_URL = "listen.url"; public final static String KEY_LISTEN_INTERVAL = "listen.interval"; static &#123; InputStream in = PropertiesUtils.class.getResourceAsStream(CONF_FILE); try &#123; properties.load(in); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static String getString(String key) &#123; return properties.getProperty(key); &#125; public static void setString(String key,String value) &#123; properties.setProperty(key,value); try &#123; properties.store(new FileOutputStream(PropertiesUtils.class.getResource(CONF_FILE).getPath()),"update " + key); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; &#125;&#125; 属性文件TomcatMonitor.properties：123tomcat.home=D:/soft/tomcat7.0.1/bin/startup.batlisten.url=http://localhost:8080/abc/test.jsplisten.interval=10 最后打成一个JAR包，方便执行。注意：idea设计的GUI窗体代码在com/intellij下面，这个也要打进去。 将相关的classes复制到一个单独的目录。如图：注意包括配置文件。 然后用java命令打包12cd E:jar -cvf aa.jar -C test . 这样打包后jar中的MANIFEST.MF文件中没有Main-Class配置，增加： 然后双击或者在命令行执行java -jar TomcatMonitor.jar就可以了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2017%2F09%2F15%2Fobserver-design%2F</url>
    <content type="text"><![CDATA[在软件系统中，当一个对象的行为依赖另外一个对象的状态时，观察者模式就很有用。若不使用观察者模式，实现类似的功能，需要在一个线程中不断监听对象状态的变化。在一个复杂的系统中，可能会因此开启很多线程，这将使系统性能产生额外的负担。 观察者模式的意义也在于此，它可以在单线程中，在自身状态发生变化时，及时通知所依赖的对象。 以下使用一个例子来说明。AbstractSubject抽象主题对象12345678910111213141516/** * 抽象主题类。模拟在修改主题的text属性时，通知所有观察者。 * Created by j.tommy on 2017/9/15. */public abstract class AbstractSubject &#123; // 主题属性 String text; // 添加观察者 public abstract void addObserver(IObserver observer); // 删除观察者 public abstract void removeObserver(IObserver observer); // 通知所有观察者 abstract void inform(); // 设置主题属性 public abstract void setText(String text);&#125; 具体主题对象ConcreteSubject123456789101112131415161718192021222324252627282930/** * Created by j.tommy on 2017/9/15. */public class ConcreteSubject extends AbstractSubject &#123; private final Vector&lt;IObserver&gt; observers = new Vector&lt;IObserver&gt;(); public void addObserver(IObserver observer) &#123; if (null != observer) &#123; observers.addElement(observer); &#125; &#125; public void removeObserver(IObserver observer) &#123; if (null != observer) &#123; observers.removeElement(observer); &#125; &#125; void inform() &#123; Event event = new Event(); event.setMsg(text); // 通知所有观察者 for (IObserver observer : observers) &#123; observer.changeEvent(event); &#125; &#125; // 设置主题属性，并通知所有观察者 public void setText(String text) &#123; this.text = text; System.out.println(this.getClass().getName() + " setText. Text is [" + text + "]."); inform(); &#125;&#125; 在具体的观察者实现类中，维护了一个观察者队列，并提供了添加和删除观察者的方法。在自身状态（text属性）发生变化时，通知所有观察者。 观察者接口对象IObserver12345678/** * 观察者接口。 * Created by j.tommy on 2017/9/15. */public interface IObserver &#123; // 给主题回调的方法 public void changeEvent(Event event);&#125; 具体的观察者ConcreateObserver12345678910111213/** * Created by j.tommy on 2017/9/15. */public class ConcreateObserver implements IObserver &#123; private String name; public ConcreateObserver(String name) &#123; this.name = name; &#125; @Override public void changeEvent(Event event) &#123; System.out.println(this.name + " received subject event. msg=" + event.getMsg()); &#125;&#125; 主题对象属性text发生变化时，通知观察者的方法参数Event123456789101112/** * Created by j.tommy on 2017/9/15. */public class Event &#123; private String msg; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125;&#125; 测试类12345678910111213141516/** * Created by j.tommy on 2017/9/15. */public class Main &#123; public static void main(String[] args) &#123; // 构造一个主题 AbstractSubject subject = new ConcreteSubject(); // 添加2个观察者 subject.addObserver(new ConcreateObserver("observer-1")); subject.addObserver(new ConcreateObserver("observer-2")); // 对主题对象的一个属性设值 subject.setText("hello"); System.out.println("=================="); subject.setText("你好"); &#125;&#125; 测试结果： 观察者模式如此常用，以至于JDK内部就为我们开发人员提供了一套观察者模式的实现。在java.util包中，包括Observable类和Observer接口。在Observable中，已经实现了主要的功能，包括添加观察者、删除观察者、通知观察者。在Observer接口中，定义了update方法，它会在Observable中的nofityObservers方法中被调用，以获得最新的状态变化。我们只需要继承Observable、并实现Observer接口即可。 下面仍然是实现上面例子的功能，但这里使用JDK提供的Observable和Observer。具体主题类：1234567891011121314/** * Created by j.tommy on 2017/9/15. */public class MyJdkObservable extends Observable &#123; private String name; public void setName(String name) &#123; this.name = name; this.setChanged(); this.notifyObservers(); &#125; public String getName() &#123; return this.name; &#125;&#125; 具体观察者：1234567891011121314151617/** * Created by j.tommy on 2017/9/15. */public class MyJdkObserver implements Observer &#123; private String name; public MyJdkObserver(String name) &#123; this.name = name; &#125; @Override public void update(Observable o, Object arg) &#123; if (o instanceof MyJdkObservable) &#123; MyJdkObservable myJdkObservable = (MyJdkObservable) o; System.out.println(this.name + " received event.MyJdkObservable.name=" + myJdkObservable.getName()); &#125; &#125;&#125; 测试代码：123456MyJdkObservable myJdkObservable = new MyJdkObservable();myJdkObservable.addObserver(new MyJdkObserver("observer-1"));myJdkObservable.addObserver(new MyJdkObserver("observer-2"));myJdkObservable.setName("hello");System.out.println("===================");myJdkObservable.setName("你好"); 测试结果： 在JDK中，观察者模式也得到的普遍的应用。一个典型的例子就是JButton。JButton继承自AbstractButton，AbstractButton中维护着一组监听器，它们就扮演着观察者的角色。 参考《Java程序性能优化-让你的Java程序更快、更稳定》(葛一宁等编著)。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的native关键字]]></title>
    <url>%2F2017%2F09%2F15%2Fjava-native-keywords%2F</url>
    <content type="text"><![CDATA[在看《《Java程序性能优化-让你的Java程序更快、更稳定》(葛一宁等编著)》一书时，文中提到JDK中OutputStream和InputStream使用观察者模式，提高I/O性能。如下代码：1DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(new FileOutputStream("d:test.txt"))); 通过结合BufferedOutputStream对数据做了缓存处理，调用write方法时并不是每次都会直接写入磁盘。只有当缓冲区满的时候，才会写入磁盘。代码片段：123456789101112131415public synchronized void write(byte b[], int off, int len) throws IOException &#123; if (len &gt;= buf.length) &#123; /* If the request length exceeds the size of the output buffer, flush the output buffer and then write the data directly. In this way buffered streams will cascade harmlessly. */ flushBuffer(); out.write(b, off, len); return; &#125; if (len &gt; buf.length - count) &#123; flushBuffer(); &#125; System.arraycopy(b, off, buf, count, len); count += len;&#125; 如上代码，最后实际是调用的FileOutputStream的write方法写入磁盘的。最终调用的是FileOutputStream的writeBytes方法，这是一个native方法。12private native void writeBytes(byte b[], int off, int len, boolean append) throws IOException; 可以看到，它的实现并不在FileOutputStream。 那么，到底最终是如何写入磁盘的呢？ native关键字说明其修饰的方法是一个原生态方法，方法对应的实现不是在当前文件，而是在用其他语言（如C和C++）实现的文件中。Java语言本身不能对操作系统底层进行访问和操作，但是可以通过JNI接口调用其他语言来实现对底层的访问。 具体可以参考这2篇文章：Java中native关键字、在 Windows 中实现 Java 本地方法.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[装饰者模式]]></title>
    <url>%2F2017%2F09%2F14%2Fdecorator-design%2F</url>
    <content type="text"><![CDATA[装饰者模式有一个设计非常巧妙的结构，可以为对象动态添加功能。在基本的设计原则中，有一个重要的原则叫做合成/聚合复用原则。根据该原则的思想，代码复用应该尽可能使用委托，而不是继承。因为继承是一种紧密耦合，任何父类的改动都会影响其子类，不利于系统维护。而委托则是松散耦合，只要接口不变，委托类的变动并不会影响其上层维护对象。 装饰者模式充分运用了这种思想，通过委托机制，复用系统的各个组件，在运行时，将这些组件功能进行叠加，从而构造出一个“超级对象”，使其拥有所有这些组件的功能。而各个子功能模块，被很好的维护在各个组件的相关类中，拥有简洁的系统结构。 下面以一个例子来说明。IPacketCretor即装饰者接口，用于处理具体的内容。PacketBodyCreator是具体的组件，用于构造要发布的信息的核心内容，但是它不负责将其构造成一个格式工整、可直接发布的数据格式。PacketHTTPHeaderCreator负责给具体的内容加上HTTP头部，PacketHTMLHeaderCreator负责将给定的内容格式化成HTML文本。3个功能组件相互独立且分离，便于系统维护。IPacketCreator123456/** * Created by j.tommy on 2017/9/14. */public interface IPacketCreator &#123; public String handleContent(); // 用于处理具体内容&#125; PacketBodyCreator123456789/** * Created by j.tommy on 2017/9/14. */public class PacketBodyCreator implements IPacketCreator &#123; @Override public String handleContent() &#123; return "Content of packet."; &#125;&#125; PacketDecorator123456789/** * Created by j.tommy on 2017/9/14. */public abstract class PacketDecorator implements IPacketCreator &#123; IPacketCreator ipc; public PacketDecorator(IPacketCreator ipc) &#123; this.ipc = ipc; &#125;&#125; PacketHTMLHeaderCreator123456789101112131415161718/** * Created by j.tommy on 2017/9/14. */public class PacketHTMLHeaderCreator extends PacketDecorator &#123; public PacketHTMLHeaderCreator(IPacketCreator ipc) &#123; super(ipc); &#125; @Override public String handleContent() &#123; StringBuffer buffer = new StringBuffer(); buffer.append("&lt;html&gt;"); buffer.append("&lt;body&gt;"); buffer.append(ipc.handleContent()); buffer.append("&lt;/body&gt;"); buffer.append("&lt;/html&gt;"); return buffer.toString(); &#125;&#125; PacketHTTPHeaderCreator123456789101112131415/** * Created by j.tommy on 2017/9/14. */public class PacketHTTPHeaderCreator extends PacketDecorator &#123; public PacketHTTPHeaderCreator(IPacketCreator ipc) &#123; super(ipc); &#125; @Override public String handleContent() &#123; StringBuffer buffer = new StringBuffer(); buffer.append("Cache-Control:no-cache\n"); buffer.append(ipc.handleContent()); return buffer.toString(); &#125;&#125; 测试类Main123456789/** * Created by j.tommy on 2017/9/14. */public class Main &#123; public static void main(String[] args) &#123; IPacketCreator ipc = new PacketHTTPHeaderCreator(new PacketHTMLHeaderCreator(new PacketBodyCreator())); System.out.println(ipc.handleContent()); &#125;&#125; 输出： 对于装饰者模式，另一个值得关注的地方是它的使用方法。在本例中，通过层层构造和组装装饰者与被装饰者到一个对象中，使其有机的结合在一起工作。 在本例中，共生成3个对象实例，PacketBodyCreator作为核心组件被首先 构造，其次是PacketHTMLHeaderCreator（将内容包装成HTML格式），最后是PacketHTTPHeaderCreator（添加HTTP头）。 在JDK的实现中，也有装饰者模式的实现。一个典型的例子就是OutputStream和InputStream的实现。以OutputStream为例，OutputStream提供的功能较弱，通过各种装饰器的增强，OutputStream可以被赋予强大的功能。 生成一个有缓冲功能的流对象1DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(new FileOutputStream("d:/test.txt"))); 生成一个没有缓冲功能的流对象1DataOutputStream dos = new DataOutputStream(new FileOutputStream("d:/test.txt")); 第1种加入了性能组件BufferedOutputStream，第二种则没有。因此第1种拥有更好的性能。 在BufferedOutputStream中，并不是每次调用write方法都会向磁盘写入数据，而是将数据写入缓冲，只有缓冲满的时候才会调用FileOutputStream的write方法向磁盘写入，以此实现功能组件与性能组件的完美分离。 参考：《《Java程序性能优化-让你的Java程序更快、更稳定》(葛一宁等编著)》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[享元模式]]></title>
    <url>%2F2017%2F09%2F14%2Fflwweight-design%2F</url>
    <content type="text"><![CDATA[定义：享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。 它与单例模式相似，最大区别在于单例模式一个类只有一个实例；享元模式一个类有多个实例。 来自微博Barret李靖对享元模式的说明：如何理解享元模式，“享”是共享的意思，“元”指的是元件，也就是小颗粒的东西，享元顾名思义便是共享小部件，很多系统或者程序包含大量对象，但是这些对象绝大多数都是差不多的，除了一些极个别的属性外。在享元模式中有两个比较重要的关键词，内部变量和外部变量；内部变量是可以共享的属性集，而外部变量是对象之间的差异部分，通过相同+不同的方式组合诸多对象，可以有效地节省系统空间，降低内存大小。 这里有一个使用五子棋来说明的例子。http://blog.csdn.net/xu__cg/article/details/53054439 其他参考：http://www.runoob.com/design-pattern/flyweight-pattern.htmlhttp://blog.csdn.net/jason0539/article/details/22908915]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime-Text3使用]]></title>
    <url>%2F2017%2F09%2F14%2FSublime-Text3%2F</url>
    <content type="text"><![CDATA[Sublime Text是一款神奇的编辑器，号称程序员必备神器！。以下简称ST。ST是一款收费软件，但可以免费无限制无限期的使用，只是偶尔会提示你。ST的一些说明：http://www.iplaysoft.com/sublimetext.html. 下载与安装首先，从Sublime Text官网下载ST3。下载后直接双击安装即可。 字体设置点击“Preferences-&gt;Settings”菜单，在用户设置中增加font_face，然后保存即可。如上，我使用的字体是Monaco，字体大小是10号。效果看起来还不错。 安装包管理器打开https://packagecontrol.io/installation复制红框中的代码，打开ST，选择菜单“View-&gt;Show Console”，然后在控制台粘贴刚刚复制的代码，然后回车，等待安装完成。安装完成后，重启ST，在ST的“Preferences”菜单中可以看到“Package Control”。 后续安装插件，CTRL+SHIFT+P，输入install，回车，然后输入要安装的插件名称，回车就可以安装了。 常用插件安装1、主题插件Boxy-Theme说明：这个插件我用绿色版的ST3在线安装时没找到。 2、Markdown EditingMarkdown编辑高亮插件。 3、OmniMarkupPreviewerMarkdown实时预览插件参考：近乎完美的 Markdown 写作体验 - Sublime Text 3 + OmniMarkupPreviewer 4、BracketHighlighter用于匹配括号，引号和html标签。对于很长的代码很有用。安装好之后，不需要设置插件会自动生效 5、Emmet快速生成HTML代码段的插件，强大到无与伦比:可以超快速编写HTML/CSS/JS，当然这个插件还支持多种编译环境，如常见的：Eclipse/Aptana、Coda、Notepad++、Adobe Dreamweaver、TextMate等，web开发必备！！！。 更多使用技巧参考：如何优雅地使用Sublime Text、Sublime Text 3 全程详细图文原创教程（持续更新中。。。） 问题记录1、404 error on preview … “buffer_id(29) is not valid (closed or unsupported file format)”解决办法：http://blog.csdn.net/zhangyunfei_happy/article/details/54573435]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代理模式]]></title>
    <url>%2F2017%2F09%2F10%2Fproxy-mode%2F</url>
    <content type="text"><![CDATA[前言代理模式是一种常见的设计模式，它使用代理对象完成用户请求，屏蔽了用户对真实对象的访问。 在软件设计中，使用代理模式的意图也很多。比如因为安全原因，屏蔽客户端直接访问真实对象。或者在远程调用中，使用代理类来屏蔽远程方法调用的技术细节。或为了提升系统性能，将真实对象封装，达到延迟加载的目的。比如hibernate就使用了cglib来实现延迟加载。这里使用代理模式实现延迟加载，提升系统性能和速度。 不使用代理模式的直接调用这里定义一个IUserService接口类，提供一个request方法；UserService实现IUserService接口。Main为测试类。123456/** * Created by j.tommy on 2017/9/10. */public interface IUserService &#123; String request();&#125; 123456789/** * Created by j.tommy on 2017/9/10. */public class UserService implements IUserService &#123; @Override public String request() &#123; return "hello"; &#125;&#125; 12345678910/** * Created by j.tommy on 2017/9/10. */public class Main &#123; public static void main(String[] args) &#123; IUserService ius = new UserService(); String result = ius.request(); System.out.println("result:" + result); &#125;&#125; 静态代理下面定义一个UserServiceProxy来代理UserService，对外提供服务。123456789101112131415/** * Created by j.tommy on 2017/9/10. */public class UserServiceProxy implements IUserService &#123; private UserService us = null; @Override public String request() &#123; // 延迟加载us的实例，在实际使用时初始化 if (null == us) &#123; us = new UserService(); System.out.println("Created UserService."); &#125; return us.request(); &#125;&#125; 测试类：123456789101112/** * Created by j.tommy on 2017/9/10. */public class Main &#123; public static void main(String[] args) &#123; // 通过代理类调用 IUserService ius = new UserServiceProxy(); System.out.println("Created proxy."); String result = ius.request(); System.out.println("result:" + result); &#125;&#125; 输出：可以看到，在实际调用request()方法时才初始化UserService.静态代理很大的一个问题：所有的代理类必须实现接口，现在是一个UserService，如果还有其他的XXService，每个XXServiceProxy都需要实现XXService接口，这是很麻烦的。 JDK动态代理上面看到了使用静态代理的一个大问题，我们可以通过JDK动态代理来实现。123456789101112131415161718192021222324/** * jdk动态代理。 * Created by j.tommy on 2017/9/10. */public class JdkDynamicProxy implements InvocationHandler &#123; // 真实对象 private Object target; public JdkDynamicProxy(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 调用真实对象的方法 Object result = method.invoke(target,args); return result; &#125; /** * 获取目标对象的代理对象 * @return */ public Object getProxy() &#123; return Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(),target.getClass().getInterfaces(),this); &#125;&#125; 测试类：1234567891011121314/** * Created by j.tommy on 2017/9/10. */public class Main &#123; public static void main(String[] args) &#123; // JDK动态代理 // 真实对象 IUserService ius = new UserService(); // 代理对象 IUserService us = (IUserService) new JdkDynamicProxy(ius).getProxy(); String result = us.request(); System.out.println("result:" + result); &#125;&#125; 如上代码，可以代理任何接口。但它也有个问题，要代理的类必须实现接口。。如果不想实现接口，还要能够代理，可以使用cglib. cglib动态代理cglib是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类进行代理。12345678910111213141516171819/** * Created by j.tommy on 2017/9/10. */public class CglibProxy implements MethodInterceptor &#123; private Enhancer enhancer = new Enhancer(); @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; // 通过代理类调用父类中的方法 return methodProxy.invokeSuper(o,args); &#125; public Object getProxy(Class clazz) &#123; // 设置需要创建之类的类 enhancer.setSuperclass(clazz); enhancer.setCallback(this); // 通过字节码结束创建之类实例 return enhancer.create(); &#125;&#125; 测试类：1234567891011/** * Created by j.tommy on 2017/9/10. */public class Main &#123; public static void main(String[] args) &#123; CglibProxy cp = new CglibProxy(); UserService ius = (UserService) cp.getProxy(UserService.class); String result = ius.request(); System.out.println("result:" + result); &#125;&#125; 更多代理模式参考：http://blog.csdn.net/yakoo5/article/details/9099133/http://www.importnew.com/22015.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper客户端api操作]]></title>
    <url>%2F2017%2F09%2F09%2Fzookeeper-client-api%2F</url>
    <content type="text"><![CDATA[这里记录zookeeper java客户端api的使用。 客户端创建Zookeeper实例，然后调用这个类提供的方法与zookeeper服务器进行交互。Zookeeper的构造函数有如下4种：1234ZooKeeper(connectString, sessionTimeout, watcher);ZooKeeper(connectString, sessionTimeout, watcher,canBeReadOnly);ZooKeeper(connectString, sessionTimeout, watcher, sessionId, sessionPasswd);ZooKeeper(connectString, sessionTimeout, watcher, sessionId, sessionPasswd, canBeReadOnly); 参数说明：connectString: 连接字符串 例如 “127.0.0.1:2181”sessionTimeout: 会话超时时间 以毫秒为单位的整型值 在sessionTimeout时间内服务端与客户端没有有效的心跳检测 则会话失效watcher: 默认的事件通知处理器sessionId: 会话IDsessionPasswd: 会话秘钥canBeReadOnly: 是否是只读 String create(String path, byte[] data, List acl,CreateMode createMode)创建一个给定的目录节点 path, 并给它设置数据，CreateMode 标识有四种形式的目录节点，分别是 PERSISTENT：持久化目录节点，这个目录节点存储的数据不会丢失；PERSISTENT_SEQUENTIAL：顺序自动编号的目录节点，这种目录节点会根据当前已近存在的节点数自动加 1，然后返回给客户端已经成功创建的目录节点名；EPHEMERAL：临时目录节点，一旦创建这个节点的客户端与服务器端口也就是 session 超时，这种节点会被自动删除；EPHEMERAL_SEQUENTIAL：临时自动编号节点 Stat exists(String path, boolean watch)判断某个 path 是否存在，并设置是否监控这个目录节点，这里的 watcher 是在创建 ZooKeeper 实例时指定的 watcher，exists方法还有一个重载方法，可以指定特定的watcher Stat exists(String path,Watcher watcher)重载方法，这里给某个目录节点设置特定的 watcher，Watcher 在 ZooKeeper 是一个核心功能，Watcher 可以监控目录节点的数据变化以及子目录的变化，一旦这些状态发生变化，服务器就会通知所有设置在这个目录节点上的 Watcher，从而每个客户端都很快知道它所关注的目录节点的状态发生变化，而做出相应的反应 void delete(String path, int version)删除 path 对应的目录节点，version 为 -1 可以匹配任何版本，也就删除了这个目录节点所有数据 ListgetChildren(String path, boolean watch)获取指定 path 下的所有子目录节点，同样 getChildren方法也有一个重载方法可以设置特定的 watcher 监控子节点的状态 Stat setData(String path, byte[] data, int version)给 path 设置数据，可以指定这个数据的版本号，如果 version 为 -1 怎可以匹配任何版本 byte[] getData(String path, boolean watch, Stat stat)获取这个 path 对应的目录节点存储的数据，数据的版本等信息可以通过 stat 来指定，同时还可以设置是否监控这个目录节点数据的状态 void addAuthInfo(String scheme, byte[] auth)客户端将自己的授权信息提交给服务器，服务器将根据这个授权信息验证客户端的访问权限。 Stat setACL(String path,List acl, int version)给某个目录节点重新设置访问权限，需要注意的是 Zookeeper 中的目录节点权限不具有传递性，父目录节点的权限不能传递给子目录节点。目录节点 ACL由两部分组成：perms 和 id。Perms 有 ALL、READ、WRITE、CREATE、DELETE、ADMIN 几种,而 id 标识了访问目录节点的身份列表，默认情况下有以下两种：ANYONE_ID_UNSAFE = new Id(“world”, “anyone”) 和 AUTH_IDS = new Id(“auth”, “”) 分别表示任何人都可以访问和创建者拥有访问权限。 List getACL(String path,Stat stat)获取某个目录节点的访问权限列表 下面通过一个配置JDBC的url、username、password，并从zookeeper读取的示例来说明配置类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * Created by j.tommy on 2017/9/8. */public class ZkTest1 &#123; private final static String ZK_CONNECTION_STR = "192.168.74.125:2181"; private final static int SESSION_TIMEOUT = 30000; private final static String AUTH_TYPE = "digest"; private final static String AUTH_ID_PWD = "admin:123456"; private final static String ZK_ROOT = "/dbConf"; private final static String ZK_URL = ZK_ROOT + "/url"; private final static String ZK_USERNAME = ZK_ROOT + "/username"; private final static String ZK_PWD = ZK_ROOT + "/password"; private ZooKeeper zk = null; public ZkTest1() &#123; getZK(); &#125; public ZooKeeper getZK() &#123; try &#123; zk = new ZooKeeper(ZK_CONNECTION_STR, SESSION_TIMEOUT, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(watchedEvent); &#125; &#125;); while (zk.getState() != ZooKeeper.States.CONNECTED) &#123; Thread.sleep(1000L); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return zk; &#125; private void createNode(String path,byte[] value,String idPassword) &#123; // 指定认证模式为digest Id id = new Id(AUTH_TYPE,idPassword); // 创建的节点有所有权限 ACL acl = new ACL(ZooDefs.Perms.ALL,id); try &#123; zk.create(path, value, Collections.singletonList(acl), CreateMode.PERSISTENT); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private String getNodeValue(String path,String idPassword) &#123; try &#123; // 由于创建节点时指定了权限，所以这里必须设置权限才能查询 // 注意：这里auth是不用加密的。 zk.addAuthInfo(AUTH_TYPE,AUTH_ID_PWD.getBytes()); return new String(zk.getData(path,false,null)); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return null; &#125; private void closeZK() &#123; if (null != zk) &#123; try &#123; zk.close(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; ZkTest1 zkTest1 = new ZkTest1(); try &#123; String idPassword = DigestAuthenticationProvider.generateDigest(AUTH_ID_PWD); // 创建根节点 zkTest1.createNode(ZK_ROOT,"abc".getBytes(),idPassword); String rootValue = zkTest1.getNodeValue(ZK_ROOT,idPassword); if (StringUtils.isNotEmpty(rootValue)) &#123; System.out.println(ZK_ROOT + "节点创建成功！value=" + rootValue); &#125; // 创建url节点 zkTest1.createNode(ZK_URL,"10.10.1.19".getBytes(),idPassword); String urlValue = zkTest1.getNodeValue(ZK_URL,idPassword); if (StringUtils.isNotEmpty(urlValue)) &#123; System.out.println(ZK_URL + "节点创建成功！value=" + urlValue); &#125; // 创建username节点 zkTest1.createNode(ZK_USERNAME,"root".getBytes(),idPassword); String usernameValue = zkTest1.getNodeValue(ZK_USERNAME,idPassword); if (StringUtils.isNotEmpty(urlValue)) &#123; System.out.println(ZK_USERNAME + "节点创建成功！value=" + usernameValue); &#125; // 创建password节点 zkTest1.createNode(ZK_PWD,"123456".getBytes(),idPassword); String pwdValue = zkTest1.getNodeValue(ZK_PWD,idPassword); if (StringUtils.isNotEmpty(pwdValue)) &#123; System.out.println(ZK_PWD + "节点创建成功！value=" + pwdValue); &#125; zkTest1.closeZK(); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 读取zookeeper配置的类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * Created by j.tommy on 2017/9/8. */public class ZKTest2 &#123; private final static String ZK_CONNECTION_STR = "192.168.74.125:2181"; private final static int SESSION_TIMEOUT = 30000; private final static String ZK_ROOT = "/dbConf"; private final static String ZK_URL_PATH = ZK_ROOT+"/url"; private final static String ZK_USERNAME_PATH = ZK_ROOT+"/username"; private final static String ZK_PASSWD_PATH = ZK_ROOT+"/password"; private final static String AUTH_TYPE = "digest"; private final static String AUTH_PASSWD = "admin:abc1"; private String url; private String username; private String password; private ZooKeeper zk = null; private ZooKeeper getZK() throws IOException, InterruptedException &#123; zk = new ZooKeeper(ZK_CONNECTION_STR,SESSION_TIMEOUT,new MyWatcher()); while (zk.getState() != ZooKeeper.States.CONNECTED) &#123; Thread.sleep(1000L); &#125; zk.addAuthInfo(AUTH_TYPE,AUTH_PASSWD.getBytes()); return zk; &#125; private void getZKValue() &#123; try &#123; this.url = new String(zk.getData(ZK_URL_PATH,true,null)); this.username = new String(zk.getData(ZK_USERNAME_PATH,true,null)); this.password = new String(zk.getData(ZK_PASSWD_PATH,true,null)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; class MyWatcher implements Watcher &#123; @Override public void process(WatchedEvent watchedEvent) &#123; Event.EventType eventType = watchedEvent.getType(); if (eventType == Event.EventType.None) &#123; System.out.println("服务器连接成功"); &#125; else if (eventType == Event.EventType.NodeCreated) &#123; System.out.println("节点创建成功"); &#125; else if (eventType == Event.EventType.NodeDataChanged) &#123; System.out.println("数据修改成功"); getZKValue(); &#125; else if (eventType == Event.EventType.NodeDeleted) &#123; System.out.println("节点删除成功"); &#125; else if (eventType == Event.EventType.NodeChildrenChanged) &#123; System.out.println("子节点数据修改成功"); getZKValue(); &#125; &#125; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public static void main(String[] args) throws InterruptedException, IOException, NoSuchAlgorithmException &#123; ZKTest2 zkTest2 = new ZKTest2(); ZooKeeper zk = zkTest2.getZK(); String auth = DigestAuthenticationProvider.generateDigest(AUTH_PASSWD); System.out.println("auth:" +auth); int loopCount = 10; int i=0; while (i &lt; loopCount) &#123; zkTest2.getZKValue(); System.out.println("url:" + zkTest2.getUrl()); System.out.println("username:" + zkTest2.getUsername()); System.out.println("password:" + zkTest2.getPassword()); System.out.println("--------------------------------------"); i++; Thread.sleep(5000L); &#125; zk.close(); &#125;&#125; 代码中，创建节点时使用的是digest认证，id和password为admin:123456，但读取时为admin:abc1.这个时候运行程序是会出错的，如下：提示没有权限，将读取配置类中id和password修改为与创建节点的一样（admin:123456），再次运行。 创建节点时id与password是要经过加密的，即DigestAuthenticationProvider.generateDigest(AUTH_PASSWD);但是验证时不需要。同时在zookeeper的客户端中执行命令创建节点时，使用明文密码时可以创建成功的，但没法验证成功。 zookeeper客户端中，使用$ZOOKEEPER_HOME/bin/zkCli.sh -server zookeeper服务器IP:端口连接zookeeper服务器。输入help查看所有命令： zookeeper权限验证：http://blog.csdn.net/cainiaoxiaozhou/article/details/52954851zookeeper客户端api操作：https://www.2cto.com/kf/201610/558610.htmlhttp://www.cnblogs.com/ggjucheng/p/3370359.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper安装与配置]]></title>
    <url>%2F2017%2F09%2F09%2Fzookeeper-install-and-config%2F</url>
    <content type="text"><![CDATA[介绍ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现。参考：http://blog.csdn.net/u013068377/article/details/52620647http://blog.csdn.net/xuxiuning/article/details/51218941zookeeper官方文档：https://zookeeper.apache.org/doc/trunk/最好还是读官方文档，很详细。 安装这里以Linux为例。zookeeper官网：https://zookeeper.apache.org/从官网下载最新稳定版本，这里测试版本为3.4.9. 下载后，解压缩1tar -xvf zookeeper-3.4.9.tar.gz 注意：zookeeper运行需要依赖java环境，所以需要配置好java环境。 单机配置在$ZOOKEEPER_HOME$/conf目录下，新建zoo.cfg文件。内容如下：123tickTime=2000dataDir=/var/zookeeperclientPort=2181 具体的配置参数的含义后面介绍。 配置完毕后，在$ZOOKEEPER_HOME$执行下面的命令启动zookeeper1./bin/zkServer.sh start &amp; 伪集群配置参考“集群配置”，伪集群实际上是在一台机器部署多个zookeeper实例来构建集群，因为是同一台机器，所以各个zookeeper实例的端口与dataDir不同。配置参考：12345678tickTime=2000 dataDir=/var/zookeeper/ clientPort=2181 initLimit=5 syncLimit=2 server.1=localhost:2887:3887 server.2=localhost:2888:3888 server.3=localhost:2889:3889 集群配置为了获得可靠的zookeeper服务，实际使用应该部署zookeeper集群。只要多于半数的zookeeper服务OK，那么整个zookeeper服务也是OK的。而且，部署时最好部署奇数台zookeeper服务。 在每个zookeeper实例的dataDir参数指定的目录中，创建一个名为myid的文件，文件的内容指定自身的id值。假设部署3台zookeeper构成的集群，分别命名为server1,server2,server3，那么server1的myid的内容就是1，server2的myid的内容就是2，等等…每个zookeeper的conf目录中，新建zoo.cfg，内容如下：12345678tickTime=2000 dataDir=/var/zookeeper/ clientPort=2181 initLimit=5 syncLimit=2 server.1=server1:2888:3888 server.2=server2:2888:3888 server.3=server3:2888:3888 server.id=host:port:port，指示了集群中所有zookeeper。第一个port是follower与leader通信的端口，第2个port是进行leader选举的端口。 zookeeper配置参数tickTime：心跳时间，为了确保连接存在的，以毫秒为单位，最小超时时间为2个心跳时间initLimit：多少个心跳时间内，允许其他server连接并初始化数据，如果ZooKeeper管理的数据较大，则应相应增大这个值clientPort：服务的监听端口dataDir：用于存放内存数据库快照的文件夹，同时用于集群的myid文件也存在这个文件夹里（注意：一个配置文件只能包含一个dataDir字样，即使它被注释掉了。）dataLogDir：用于单独设置transaction log的目录，transaction log分离可以避免和普通log还有快照的竞争syncLimit：多少个tickTime内，允许follower同步，如果follower落后太多，则会被丢弃。 server.A=B：C：D：A是一个数字,表示这个是第几号服务器,B是这个服务器的ip地址C第一个端口用来集群成员的信息交换,表示的是这个服务器与集群中的Leader服务器交换信息的端口D是在leader挂掉时专门用来进行选举leader所用]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式的实现方式]]></title>
    <url>%2F2017%2F09%2F03%2Fsingleton%2F</url>
    <content type="text"><![CDATA[饿汉式1234567public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton() &#123;&#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 注意：必须是私有构造方法，防止不会被其他代码实例化。这种实现唯一的不足是不能实现延迟加载。 懒汉式-不同步12345678910public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 注意：这种实现没有考虑多线程的情况，需要做同步处理，否则多线程会导致产生多个实例。 懒汉式-同步1234567891011121314public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 注意：这种实现考虑了多线程的情况，但是由于做了同步，会导致性能较差（相对于饿汉式）。 懒汉式改造123456789public class StaticSingleton &#123; private StaticSingleton() &#123;&#125; private static class SingletonHolder &#123; private static StaticSingleton instance = new StaticSingleton(); &#125; public static StaticSingleton getInstance() &#123; return SingletonHolder.instance; &#125;&#125; 在这种实现中，使用内部类来维护单例的实例。当StaticSingleton被实例化时，其内部类并不会实例化。当getInstance()方法被调用时，才会加载SingletonHolder，从而初始化instance。同时，由于实例的建立，是在类加载时完成的，所以天生对多线程友好。getInstance()方法也不需要同步关键字。因此，这种实现既做到了延迟加载，又不用使用同步关键字。 使用枚举1234567891011121314151617181920212223242526272829303132333435363738/** * @author j.tommy * @version 1.0 * @date 2018/8/7 */public class SingleObject &#123; private SingleObject() &#123; &#125; private enum SingletonInstance &#123; INSTANCE; private SingleObject instance; //JVM会保证此方法绝对只调用一次 SingletonInstance() &#123; instance = new SingleObject(); &#125; public SingleObject getInstance() &#123; return instance; &#125; &#125; public static SingleObject getInstance() &#123; return SingletonInstance.INSTANCE.getInstance(); &#125; public static void main(String[] args) &#123; // 测试100个线程获取单例实例对象是否是同一个。 IntStream.rangeClosed(1,100).forEach(i -&gt; new Thread("t-"+i)&#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + "==&gt;" + SingleObject.getInstance()); &#125; &#125;.start()); &#125;&#125; 确保反序列化仍然得到单例对象通常，使用上面的方式创建的单例已经能确保是唯一的实例。但仍然有例外情况生成多个实例。比如，通过反射机制，强行调用类的私有构造方法。或者对象序列化/反序列化。实现序列化接口的单例类：1234567public class SerSingleton implements Serializable &#123; private static SerSingleton instance = new SerSingleton(); private SerSingleton() &#123;&#125; public static SerSingleton getInstance() &#123; return instance; &#125;&#125; 测试1234567891011121314SerSingleton s1 = SerSingleton.getInstance();// 将单例对象串行化到文件String filepath = "d:/SerSingleton.txt";ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(filepath));oos.writeObject(s1);oos.flush();oos.close();System.out.println(s1);// 从文件读出原有的单例对象ObjectInputStream ois = new ObjectInputStream(new FileInputStream(filepath));SerSingleton s2 = (SerSingleton) ois.readObject();ois.close();System.out.println(s2);System.out.println(s1 == s2); 测试结果：可以看到，经过反序列化后产生了不同的实例。 我们现在对SerSinglton增加一个readResolve()方法：12345678910public class SerSingleton implements Serializable &#123; private static SerSingleton instance = new SerSingleton(); private SerSingleton() &#123;&#125; public static SerSingleton getInstance() &#123; return instance; &#125; private Object readResolve() &#123; // 阻止生成新的实例，总是返回当前对象。 return instance; &#125;&#125; 再次测试：可以看到，经过反序列化后得到的仍然是同一个实例对象。事实上，在实现了私有的readResolve()方法后，readObject已经形同虚设，它直接使用了readResolve()替换了原本的返回值，从而在形式上构造了单例。 实际使用建议使用静态内部类或枚举的方式，既能保证延迟初始化，又是线程安全的。 参考：《Java程序性能优化-让你的Java程序更快、更稳定》(葛一宁等编著)》]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汽车后视镜调节]]></title>
    <url>%2F2017%2F09%2F03%2Fcar-juge%2F</url>
    <content type="text"><![CDATA[汽车后视镜调整 内后视镜保证内后视镜看到后挡风玻璃的四角； 外后视镜倾角 让车身占后视镜内1/4.左右都一样 仰角 左后视镜天地（路面和天空）各占1/2，右后视镜天占1/3，地占2/3。]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>汽车</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决国产浏览器github提示不支持的问题]]></title>
    <url>%2F2017%2F09%2F01%2Fresolve-github-not-support-browser%2F</url>
    <content type="text"><![CDATA[像QQ、搜狗等国产浏览器访问Github时，会提示“现在不支持你的浏览器，请使用Chrome或Firefox”。 那么如何解决这个问题呢？ 答案就是改浏览器的UserAgent为Chrome或Firefox的。 这里以搜狗浏览器为例。这里用到一款插件“User-Agent Switcher”，是一个Chrome扩展。下载完毕后，直接双击User-Agent Switcher.crx文件，搜狗浏览器会提示你进行安装。可以看到自带有很多个UA（针对不同的系统和浏览器）选择“选项”，可以添加自定义的UserAgent。如果发现选择了一个UA后还是不行，可以自定义。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3大对象复制框架性能对比]]></title>
    <url>%2F2017%2F08%2F31%2Fthree-object-copy-lib-compare%2F</url>
    <content type="text"><![CDATA[Apache common-utils的BeanUtils，Spring的BeanUtils，以及cglib的BeanCopier复制对象属性的性能对比。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import org.apache.commons.beanutils.BeanUtils;import org.springframework.cglib.beans.BeanCopier;import java.lang.reflect.InvocationTargetException;*** 测试apache BeanUtils和cglib的BeanCopier的性能对比。* @author j.tommy* @date 2016-09-13 15:20.*/public class BeanCopyTest &#123; public static void main(String[] args) &#123; Teacher t = new Teacher(1,"admin"); Teacher t2 = new Teacher(); testSpringBeanUtils(t); testCommonUtils(t); testCgLib(t); &#125; public static void testSpringBeanUtils(Teacher teacher) &#123; Teacher t = new Teacher(); Long start = System.currentTimeMillis(); for (int i=0;i&lt;100*10000;i++) &#123; org.springframework.beans.BeanUtils.copyProperties(t, teacher); &#125; Long end = System.currentTimeMillis(); System.out.println("Spring time spend:" + (end - start)); &#125; public static void testCommonUtils(Teacher teacher) &#123; Teacher t = new Teacher(); Long start = System.currentTimeMillis(); for (int i=0;i&lt;100*10000;i++) &#123; try &#123; BeanUtils.copyProperties(t,teacher); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; e.printStackTrace(); &#125; &#125; Long end = System.currentTimeMillis(); System.out.println("Common-utils time spend:" + (end - start)); &#125; public static void testCgLib(Teacher teacher) &#123; Teacher copy = new Teacher(); BeanCopier bc = BeanCopier.create(Teacher.class,Teacher.class,false); Long start = System.currentTimeMillis(); for (int i=0;i&lt;100*10000;i++) &#123; bc.copy(teacher,copy,null); &#125; Long end = System.currentTimeMillis(); System.out.println("CGlib time spend:" + (end-start)); &#125; static class Teacher &#123; private int id; private String name; public Teacher() &#123; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Teacher(int id, String name) &#123; this.id = id; this.name = name; &#125; &#125;&#125; 可以看出，common-utils的BeanUtils复制对象属性是最差的，最好的是CGLIB，统计结果都是复制100万次属性。所以，在大量复制对象属性的场合，最好使用cglib的BeanCopier来做。 使用BeanCopier需要注意的事项：1）目标类的getter方法不能比setter方法多；这个是cglib的一个bug,它是读取所有的getter方法，然后调用相关的setter方法去注入属性，所以会触发空指针异常。这个是在使用BeanCopier的create方法时发生的。bug可以参考：https://sourceforge.net/p/cglib/bugs/32/ 2）使用时最好缓存BeanCopier，而不是每次使用的时候创建一个。具体类说就是使用一个静态的变量，而不是一个类成员变量。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jprofiler_监控远程linux服务器的tomcat进程]]></title>
    <url>%2F2017%2F08%2F31%2Fjprofiler-linux-tomcat-monitor%2F</url>
    <content type="text"><![CDATA[jprofiler_监控远程linux服务器的tomcat进程(实践)参考jprofiler_监控远程linux服务器的tomcat进程(实践) 需要注意的是：1.Session–&gt;Integration Wizards–&gt;New Server Intergration，不是New Remote Integration.如下图 2.执行./bin/startup_jprofile.sh后，不能ctrl+C，否则就将进程干掉了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用AjaxAnywhere实现页面局部刷新]]></title>
    <url>%2F2017%2F08%2F31%2Fajaxanywhere-usage%2F</url>
    <content type="text"><![CDATA[前言 页面局部刷新是日常工作中使用的很多的功能，通常会借助jQuery的load/get/post/ajax方法，或者使用jquery.form.js的ajaxSubmit来提交表单。使用传统的jQuery的load/get/post/Ajax方式组装表单，以及返回的响应内容太过麻烦，除了使用jquery.form.js，我们还可以使用AjaxAnywhere来实现页面局部的刷新。 使用步骤1.添加maven依赖：12345&lt;dependency&gt; &lt;groupId&gt;org.ajaxanywhere&lt;/groupId&gt; &lt;artifactId&gt;ajaxanywhere&lt;/artifactId&gt; &lt;version&gt;1.2-rc2&lt;/version&gt;&lt;/dependency&gt; 2.在web.xml中配置aa过滤器：123456789&lt;!--界面局部刷新--&gt;&lt;filter&gt; &lt;filter-name&gt;AjaxAnywhere&lt;/filter-name&gt; &lt;filter-class&gt;org.ajaxanywhere.AAFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;AjaxAnywhere&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 3.测试页面：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;%-- Created by IntelliJ IDEA. User: Administrator Date: 2017/6/1 Time: 19:10 To change this template use File | Settings | File Templates.--%&gt;&lt;%@include file="/WEB-INF/views/head.jsp" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;AjaxAnywhere使用&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form name="myForm" action="$&#123;ctx&#125;/aa/test" method="post"&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt; &lt;label for="username"&gt;&lt;/label&gt; &lt;input type="text" name="username" id="username"/&gt; &lt;/td&gt; &lt;td&gt; &lt;button type="button" onclick="searchForm();"&gt;查询&lt;/button&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/form&gt;&lt;hr&gt;&lt;aa:zone name="refreshDataZone"&gt; &lt;table border="1" style="border-collapse:collapse;"&gt; &lt;thead&gt; &lt;tr&gt; &lt;td&gt;编号&lt;/td&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;年龄&lt;/td&gt; &lt;td&gt;性别&lt;/td&gt; &lt;td&gt;电话&lt;/td&gt; &lt;td&gt;住址&lt;/td&gt; &lt;/tr&gt; &lt;tbody&gt; &lt;c:forEach var="item" varStatus="j" items="$&#123;dataList&#125;"&gt; &lt;tr&gt; &lt;td&gt;$&#123;j.index+1&#125;&lt;/td&gt; &lt;td&gt;$&#123;item.name&#125;&lt;/td&gt; &lt;td&gt;$&#123;item.age&#125;&lt;/td&gt; &lt;td&gt;$&#123;item.sex==1?"男":"女"&#125;&lt;/td&gt; &lt;td&gt;$&#123;item.phone&#125;&lt;/td&gt; &lt;td&gt;$&#123;item.address&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/tbody&gt; &lt;/thead&gt; &lt;/table&gt;&lt;/aa:zone&gt;&lt;script src="$&#123;ctx&#125;/js/jquery.js"&gt;&lt;/script&gt;&lt;script src="$&#123;ctx&#125;/js/aa.js"&gt;&lt;/script&gt;&lt;script&gt; function searchForm() &#123; var aa = new AjaxAnywhere(); aa.formName = "myForm"; aa.getZonesToReload = function() &#123; return "refreshDataZone"; &#125;; aa.submitAJAX(); &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; head.jsp：12345678910&lt;%@ page language="java" pageEncoding="UTF-8"%&gt;&lt;%@taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c"%&gt;&lt;%@taglib uri="http://java.sun.com/jsp/jstl/fmt" prefix="fmt"%&gt;&lt;%@taglib uri="http://java.sun.com/jsp/jstl/functions" prefix="fn" %&gt;&lt;%@taglib uri="http://ajaxanywhere.sourceforge.net/" prefix="aa" %&gt;&lt;% String path = request.getContextPath(); String basePath = request.getScheme() + "://" + request.getServerName() + ":" + request.getServerPort() + path + "/";%&gt;&lt;c:set var="ctx" value="&lt;%=path%&gt;" /&gt; 页面步骤：1、 添加aa的标签引用；2、 添加aa.js(ajaxAnywhere的js)3、 在页面中使用aa:zone指定需要刷新的区域。如上例4、 点击查询的方法处理添加aa的处理。formName:指定表单的名称；重写aa.getZonesToReload方法，返回刷新区域的名称，aa:zone中指定的名称。最后一步调用aa.submitAJAX()；aa会自动组装form表单的内容提交。 后台代码：1234567891011121314151617181920212223@Controller@RequestMapping("/aa")public class AjaxAnywhereController &#123; @RequestMapping("/test") public ModelAndView aaTest() &#123; // 准备测试数据 List&lt;User&gt; users = new ArrayList&lt;&gt;(15); for (int i=0;i&lt;15;i++) &#123; User user = new User(); user.setUserId(new Long(i+1)); user.setName("测试用户" + (i + 1)); user.setAge((short) (Math.random() * 100)); user.setSex((short) (Math.random() &lt; 0.5 ? 0 : 1)); user.setPhone("138-8888-8888"); user.setAddress("广东省深圳市福田区商业大厦A栋16楼"); users.add(user); &#125; ModelAndView mv = new ModelAndView(); mv.setViewName("/aa/aaTest"); mv.addObject("dataList",users); return mv; &#125;&#125; 使用AjaxAnyWhere应该是实现页面局部刷新最简答的一种方式了。传统的是直接方法一个页面，如果是Ajax请求后台需要做特殊处理，比如spring需要使用@ResponseBody来指定，前台也相应的需要修改。使用了AjaxAnyWhere后后台没有任何改动，页面仅仅需要添加几行代码就搞定了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows上使用Nginx+tomcat做负载均衡]]></title>
    <url>%2F2017%2F08%2F31%2Fwindows-use-Nginx-tomcat-load-balance%2F</url>
    <content type="text"><![CDATA[Nginx作为反向代理服务器，可以对Web服务器提供加速，并且具有负载均衡的功能。参考：http://blog.csdn.net/cclovett/article/details/26377269 本例使用Nginx在2个Tomcat做负载均衡，并做了资源分离。即静态资源（js,css,图片）给nginx，JSP等请求分发给tomcat处理。1）Nginx的安装和启动这里使用的Nginx版本是1.8.0，从http://nginx.org/en/download.html下载Windows版本。下载的文件很小，只有1.22M，下载完毕将文件解压到nginx-1.8.0。我这里的目录是d:/soft/nginx-1.8.0。 可以直接双击nginx.exe来启动，或进入nginx目录，执行start nginx启动。使用nginx -s stop来关闭nginx。启动nginx后，访问http://localhost，出现下面的页面即表示成功。2）Nginx负载均衡配置主要是修改nginx.conf文件。找到#gzip on;一行，在下面增加：12345upstream local_tomcat &#123; server 127.0.0.1:8081 weight=1; server 127.0.0.1:8082 weight=1; #ip_hash;&#125; 我们这里本地测试，tomcat端口分别为8081和8082.weight表示权重，默认为1.表示请求分发的比例。这里为1:1表示2个tomcat均衡的处理请求。server部分配置如下：1234567891011121314151617181920212223242526272829303132server &#123; listen 80; server_name 127.0.0.1; #charset koi8-r; #access_log logs/host.access.log main; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; #禁止访问WEB-INF目录下的文件 location ~ ^/(WEB-INF)/ &#123; deny all; &#125; #静态资源文件到下面的文件夹去取 location ~ \.(html|js|css|png|gif)$ &#123; root D:/soft/test/static; &#125; #其他的请求，如果jsp，或后台action请求交由tomcat处理 location / &#123; proxy_pass http://local_tomcat; &#125;&#125; listen:表示nginx监听的端口，默认是80.比例我上面配置了2个tomcat，端口分别为8081和8082.单独访问某个tomcat的系统（比例8081）：http://127.0.0.1:8081/系统名。上面配置了nginx监听80端口，接收到请求后，静态资源从d:/soft/test/static目录查，动态资源请求分发给2个tomcat处理。这样访问http://127.0.0.1/系统名时就可以了。 server_name：表示监听到之后需要转到哪里去，这时我们直接转到本地，这时是直接到nginx文件夹内。location：表示匹配的路径，这时配置了/表示所有请求都被匹配到这里root：里面配置了root这时表示当匹配这个请求的路径时，将会在这个文件夹内寻找相应的文件，这里对我们之后的静态文件伺服很有用。index：当没有指定主页时，默认会选择这个指定的文件，它可以有多个，并按顺序来加载，如果第一个不存在，则找第二个，依此类推。下面的error_page是代表错误的页面，这里我们暂时不用，先不管它。 配置完成后，在命令行执行nginx -t来查看配置时候正确。 如果已经启动了nginx，没必要关闭后再打开。可以执行nginx -s reload来重新加载配置。 3）tomcat配置修改上面已经说明了2个tomcat的端口是8081和8082.因此需要分别修改2个tomcat的server.xml，更改端口。改这2个地方： 然后 将相同的打包文件分别复制到2个tomcat的webapp下。我的打包文件如下： index.jsp中加了标识，方便区分是哪个tomcat的请求。resources目录下是使用的资源文件。 4）静态资源文件处理因为上面2）中配置了静态资源到d:/soft/test/static目录查，因此将打包文件中的resources文件夹复制到d:/soft/test/static目录下。 完毕之后启动2个tomcat，然后启动nginx。刷新一下页面： 由此，可以看到负载均衡已经实现了。 下面测试一下静态资源文件的分离：也是Ok的。这里特别说一下，比如http://127.0.0.1/helloweb/resources/js/jquery-loadmask-0.4/jquery.loadmask.css这个静态资源文件。在JSP中是helloweb/resources/js/jquery-loadmask-0.4/jquery.loadmask.css，那么nginx配置的静态资源文件查找的目录必须也要匹配上面的路径。]]></content>
      <tags>
        <tag>tomcat</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多个tomcat session共享]]></title>
    <url>%2F2017%2F08%2F31%2Fmulti-tomcat-session-share%2F</url>
    <content type="text"><![CDATA[这里使用的是tomcat的广播机制实现的。这里使用Nginx+2台tomcat做测试，2台tomcat端口分别为8080和8081。 nginx配置 tomcat修改tomcat1：修改server.xml，找到&lt;Engine标签，增加属性jvmRoute=”tomcat1”，将&lt;Cluster放开。如图： tomcat2：同样，只是将jvmRoute=”tomcat1”改成tomcat2。这个是方便标识session是哪台tomcat的。 另外，还需要修改应用的web.xml，增加。 然后启动2个tomcat就可以了。访问tomcat1： 访问tomcat2：可以看到访问2个tomcat，session都是一样的。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在外部tomcat中运行spring boot应用]]></title>
    <url>%2F2017%2F08%2F31%2Foutter-tomcat-springboot%2F</url>
    <content type="text"><![CDATA[默认，Springboot使用内嵌的tomcat来运行springboot应用。如果你想使用外部tomcat来运行，需要做一些修改。 在pom.xml中将应用修改为war这个应该没什么疑问，默认springboot是当做一个jar来运行的。 应用启动类修改需要继承SpringBootServletInitializer，并重写configure方法。123456789101112131415161718192021@SpringBootApplication@MapperScan("com.ybf.activity.web.mapper")public class Application extends SpringBootServletInitializer &#123; private final static Logger logger = LoggerFactory.getLogger(Application.class); @Bean public ServletRegistrationBean statViewServlet () &#123; ServletRegistrationBean reg = new ServletRegistrationBean(); reg.setServlet (new StatViewServlet()); reg.addUrlMappings ("/druid/*"); return reg; &#125; @Override protected SpringApplicationBuilder configure( SpringApplicationBuilder application) &#123; return application.sources(Application.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); logger.info("Application [activity-web] started!"); &#125;&#125; 添加spring-boot-starter-tomcat依赖。12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 在项目的根目录执行mvn clean package -DskipTests=true这样会自动处理模块间的依赖关系，并且会将该项目的每个模板都进行打包。 打包完毕后，将WAR丢到tomcat就可以跑了。 问题记录1.系统环境变量的JDK版本要和你的项目保持一致。 我就是因为不一致找了很久的原因。我的项目是JDK1.8，系统环境变量是JDK1.7，丢到tomcat日志只有logback初始化的打印，再没有其他信息，后面就提示已经启动。但访问controller之类的都是404. 2.我的工程使用了mybatis，要打印SQL。在mybatis-config.xml中配置的logImpl位log4j。1&lt;setting name="logImpl" value="LOG4J"/&gt; 但我的依赖中没有引入log4j，导致报错。Caused by: java.lang.NoClassDefFoundError: org/apache/log4j/Priority.我的日志输出组件是logback，mybatis是不支持的，所以配置的STDOUT_LOGGING就OK了。但用idea集成的tomcat跑没问题。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在外部tomcat中运行spring boot应用]]></title>
    <url>%2F2017%2F08%2F31%2F%E5%9C%A8%E5%A4%96%E9%83%A8tomcat%E4%B8%AD%E8%BF%90%E8%A1%8Cspring%20boot%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[默认，Springboot使用内嵌的tomcat来运行springboot应用。如果你想使用外部tomcat来运行，需要做一些修改。 在pom.xml中将应用修改为war这个应该没什么疑问，默认springboot是当做一个jar来运行的。 应用启动类修改需要继承SpringBootServletInitializer，并重写configure方法。123456789101112131415161718192021@SpringBootApplication@MapperScan("com.ybf.activity.web.mapper")public class Application extends SpringBootServletInitializer &#123; private final static Logger logger = LoggerFactory.getLogger(Application.class); @Bean public ServletRegistrationBean statViewServlet () &#123; ServletRegistrationBean reg = new ServletRegistrationBean(); reg.setServlet (new StatViewServlet()); reg.addUrlMappings ("/druid/*"); return reg; &#125; @Override protected SpringApplicationBuilder configure( SpringApplicationBuilder application) &#123; return application.sources(Application.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); logger.info("Application [activity-web] started!"); &#125;&#125; 添加spring-boot-starter-tomcat依赖。12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 在项目的根目录执行mvn clean package -DskipTests=true这样会自动处理模块间的依赖关系，并且会将该项目的每个模板都进行打包。 打包完毕后，将WAR丢到tomcat就可以跑了。 问题记录1.系统环境变量的JDK版本要和你的项目保持一致。 我就是因为不一致找了很久的原因。我的项目是JDK1.8，系统环境变量是JDK1.7，丢到tomcat日志只有logback初始化的打印，再没有其他信息，后面就提示已经启动。但访问controller之类的都是404. 2.我的工程使用了mybatis，要打印SQL。在mybatis-config.xml中配置的logImpl位log4j。1&lt;setting name="logImpl" value="LOG4J"/&gt; 但我的依赖中没有引入log4j，导致报错。Caused by: java.lang.NoClassDefFoundError: org/apache/log4j/Priority.我的日志输出组件是logback，mybatis是不支持的，所以配置的STDOUT_LOGGING就OK了。但用idea集成的tomcat跑没问题。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot日志配置+mybatis输出SQL]]></title>
    <url>%2F2017%2F08%2F31%2Fspring%20boot%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE%2Bmybatis%E8%BE%93%E5%87%BASQL%2F</url>
    <content type="text"><![CDATA[这里以logback为例。 其实只需要在logback.xml中增加下面一行配置就而已了。1&lt;logger name="mapper所在的包名" level="DEBUG"&gt;&lt;/logger&gt; 下面贴一个完整的logback的配置：123456789101112131415161718192021222324252627282930313233343536&lt;configuration&gt; &lt;!-- %m输出的信息,%p日志级别,%t线程名,%d日期,%c类的全名,,,, --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d %p (%file:%line\)- %m%n&lt;/pattern&gt; &lt;charset&gt;GBK&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="baselog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;File&gt;log/base.log&lt;/File&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;log/base.log.%d.%i&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;!-- or whenever the file size reaches 64 MB --&gt; &lt;maxFileSize&gt;64 MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt; %d %p (%file:%line\)- %m%n &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="STDOUT"/&gt; &lt;/root&gt; &lt;logger name="com.ybf" level="DEBUG"&gt; &lt;appender-ref ref="baselog"/&gt; &lt;/logger&gt; &lt;logger name="com.ybf.activity.web.mapper" level="DEBUG"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/logger&gt;&lt;/configuration&gt; 注：测试的spring boot版本为1.5.4.RELEASE.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot日志配置+mybatis输出SQL]]></title>
    <url>%2F2017%2F08%2F31%2Fspringboot-log-config-mybatis-print-SQL%2F</url>
    <content type="text"><![CDATA[这里以logback为例。 其实只需要在logback.xml中增加下面一行配置就而已了。1&lt;logger name="mapper所在的包名" level="DEBUG"&gt;&lt;/logger&gt; 下面贴一个完整的logback的配置：123456789101112131415161718192021222324252627282930313233343536&lt;configuration&gt; &lt;!-- %m输出的信息,%p日志级别,%t线程名,%d日期,%c类的全名,,,, --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;%d %p (%file:%line\)- %m%n&lt;/pattern&gt; &lt;charset&gt;GBK&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="baselog" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;File&gt;log/base.log&lt;/File&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;log/base.log.%d.%i&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;!-- or whenever the file size reaches 64 MB --&gt; &lt;maxFileSize&gt;64 MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt; %d %p (%file:%line\)- %m%n &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="STDOUT"/&gt; &lt;/root&gt; &lt;logger name="com.ybf" level="DEBUG"&gt; &lt;appender-ref ref="baselog"/&gt; &lt;/logger&gt; &lt;logger name="com.ybf.activity.web.mapper" level="DEBUG"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;/logger&gt;&lt;/configuration&gt; 注：测试的spring boot版本为1.5.4.RELEASE.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统session共享方案]]></title>
    <url>%2F2017%2F08%2F31%2Fdistribute-session-share%2F</url>
    <content type="text"><![CDATA[分布式系统中，sessiong共享有很多的解决方案，其中托管到缓存中应该是最常用的方案之一， Spring Session官方说明 Spring Session provides an API and implementations for managing a user’s session information. 如何使用1、引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、Session配置：1234@Configuration@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 86400*30)public class SessionConfig &#123;&#125; maxInactiveIntervalInSeconds: 设置Session失效时间，使用Redis Session之后，原SringBoot的server.session.timeout属性不再生效 好了，这样就配置好了，我们来测试一下3、测试添加测试方法获取sessionid123456789@RequestMapping("/uid")String uid(HttpSession session) &#123; UUID uid = (UUID) session.getAttribute("uid"); if (uid == null) &#123; uid = UUID.randomUUID(); &#125; session.setAttribute("uid", uid); return session.getId();&#125; 登录redis 输入 keys ‘sessions‘12t&lt;spring:session:sessions:db031986-8ecc-48d6-b471-b137a3ed6bc4t(spring:session:expirations:1472976480000 其中 1472976480000为失效时间，意思是这个时间后session失效，db031986-8ecc-48d6-b471-b137a3ed6bc4 为sessionId,登录http://localhost:8080/uid 发现会一致，就说明session 已经在redis里面进行有效的管理了。 如何在两台或者多台中共享session其实就是按照上面的步骤在另一个项目中再次配置一次，启动后自动就进行了session共享。 参考：http://www.ityouknow.com/springboot/2016/03/06/springboot(%E4%B8%89)-Spring-Boot%E4%B8%ADRedis%E7%9A%84%E4%BD%BF%E7%94%A8.html]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot集成Redis]]></title>
    <url>%2F2017%2F08%2F31%2Fspringboot-Redis%2F</url>
    <content type="text"><![CDATA[前言Redis是目前使用的非常广泛的内存数据库，相比memcached，它支持更加丰富的数据类型。本来简要介绍在springboot中使用redis的方法。 如何使用？1、引入spring-boot-starter-redis12345&lt;!-- redis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、在application.properties增加Redis的配置12345678# 使用的数据库（0-15），默认为0spring.redis.database=0 # Redis服务器地址spring.redis.host=127.0.0.1# Redis服务器连接端口spring.redis.port=6379 # Redis服务器连接密码（默认为空）spring.redis.password= 3、使用12345678910111213141516@Autowiredprivate StringRedisTemplate stringRedisTemplate;@RequestMapping(value = "/redis/&#123;key&#125;/&#123;value&#125;",method = RequestMethod.GET)@ResponseBodypublic String redisTest(@PathVariable String key,@PathVariable String value) &#123; String redisValue = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isEmpty(redisValue)) &#123; stringRedisTemplate.opsForValue().set(key,value); return "操作成功！"; &#125; if (!redisValue.equals(value)) &#123; stringRedisTemplate.opsForValue().set(key,value); return "操作成功！"; &#125; return String.format("redis中已存在[key=%s,value=%s]的数据！",key,value);&#125; 随便写的一个例子。 4、Sentinel模式配置上面的是单机的一个配置，如果是主从，参考：123456789#redis配置spring.redis.database=0spring.redis.password=systemspring.redis.pool.max-idle=10spring.redis.pool.min-idle=0spring.redis.pool.max-active=10spring.redis.pool.max-wait=-1spring.redis.sentinel.master=mymasterspring.redis.sentinel.nodes=192.168.74.135:26379,192.168.74.136:26379 5、redis的全部配置：12345678910111213141516# REDIS (RedisProperties)spring.redis.cluster.max-redirects= # Maximum number of redirects to follow when executing commands across the cluster.spring.redis.cluster.nodes= # Comma-separated list of &quot;host:port&quot; pairs to bootstrap from.spring.redis.database=0 # Database index used by the connection factory.spring.redis.url= # Connection URL, will override host, port and password (user will be ignored), e.g. redis://user:password@example.com:6379spring.redis.host=localhost # Redis server host.spring.redis.password= # Login password of the redis server.spring.redis.ssl=false # Enable SSL support.spring.redis.pool.max-active=8 # Max number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.spring.redis.pool.max-idle=8 # Max number of &quot;idle&quot; connections in the pool. Use a negative value to indicate an unlimited number of idle connections.spring.redis.pool.max-wait=-1 # Maximum amount of time (in milliseconds) a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.spring.redis.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.spring.redis.port=6379 # Redis server port.spring.redis.sentinel.master= # Name of Redis server.spring.redis.sentinel.nodes= # Comma-separated list of host:port pairs.spring.redis.timeout=0 # Connection timeout in milliseconds. 6、使用redis自动缓存数据可以把一些经常查询的数据放到redis缓存起来，不用每次都查询数据库。a.增加一个redis的配置类：12345678910111213141516171819202122232425262728293031323334353637@Configuration@EnableCachingpublic class RedisConfig&#123; @Bean public KeyGenerator redisKeyGenerator()&#123; return new KeyGenerator() &#123; @Override public Object generate(Object target, Method method, Object... params) &#123; StringBuilder sb = new StringBuilder(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125; &#125;; &#125; @Bean public CacheManager cacheManager( @SuppressWarnings("rawtypes") RedisTemplate redisTemplate) &#123; return new RedisCacheManager(redisTemplate); &#125; @Bean public RedisTemplate&lt;String, String&gt; redisTemplate( RedisConnectionFactory factory) &#123; StringRedisTemplate template = new StringRedisTemplate(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; &#125;&#125; b.在需要缓存的service方法上加上注解：1234@Cacheable(value = "userCache")public TUser findById(String id) &#123; return this.userRepository.findOne(id);&#125; 这样，就只有redis没有相应的Key的时候才会查询数据库。 我们看下redis： 图中，redis的key就是你的参数。所以实际使用最好指定Cacheable的key，保证唯一。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot集成Redis]]></title>
    <url>%2F2017%2F08%2F31%2Fspringboot%E9%9B%86%E6%88%90Redis%2F</url>
    <content type="text"><![CDATA[前言Redis是目前使用的非常广泛的内存数据库，相比memcached，它支持更加丰富的数据类型。本来简要介绍在springboot中使用redis的方法。 如何使用？1、引入spring-boot-starter-redis12345&lt;!-- redis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2、在application.properties增加Redis的配置12345678# 使用的数据库（0-15），默认为0spring.redis.database=0 # Redis服务器地址spring.redis.host=127.0.0.1# Redis服务器连接端口spring.redis.port=6379 # Redis服务器连接密码（默认为空）spring.redis.password= 3、使用12345678910111213141516@Autowiredprivate StringRedisTemplate stringRedisTemplate;@RequestMapping(value = "/redis/&#123;key&#125;/&#123;value&#125;",method = RequestMethod.GET)@ResponseBodypublic String redisTest(@PathVariable String key,@PathVariable String value) &#123; String redisValue = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isEmpty(redisValue)) &#123; stringRedisTemplate.opsForValue().set(key,value); return "操作成功！"; &#125; if (!redisValue.equals(value)) &#123; stringRedisTemplate.opsForValue().set(key,value); return "操作成功！"; &#125; return String.format("redis中已存在[key=%s,value=%s]的数据！",key,value);&#125; 随便写的一个例子。 4、Sentinel模式配置上面的是单机的一个配置，如果是主从，参考：123456789#redis配置spring.redis.database=0spring.redis.password=systemspring.redis.pool.max-idle=10spring.redis.pool.min-idle=0spring.redis.pool.max-active=10spring.redis.pool.max-wait=-1spring.redis.sentinel.master=mymasterspring.redis.sentinel.nodes=192.168.74.135:26379,192.168.74.136:26379 5、redis的全部配置：12345678910111213141516# REDIS (RedisProperties)spring.redis.cluster.max-redirects= # Maximum number of redirects to follow when executing commands across the cluster.spring.redis.cluster.nodes= # Comma-separated list of &quot;host:port&quot; pairs to bootstrap from.spring.redis.database=0 # Database index used by the connection factory.spring.redis.url= # Connection URL, will override host, port and password (user will be ignored), e.g. redis://user:password@example.com:6379spring.redis.host=localhost # Redis server host.spring.redis.password= # Login password of the redis server.spring.redis.ssl=false # Enable SSL support.spring.redis.pool.max-active=8 # Max number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.spring.redis.pool.max-idle=8 # Max number of &quot;idle&quot; connections in the pool. Use a negative value to indicate an unlimited number of idle connections.spring.redis.pool.max-wait=-1 # Maximum amount of time (in milliseconds) a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.spring.redis.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.spring.redis.port=6379 # Redis server port.spring.redis.sentinel.master= # Name of Redis server.spring.redis.sentinel.nodes= # Comma-separated list of host:port pairs.spring.redis.timeout=0 # Connection timeout in milliseconds. 6、使用redis自动缓存数据可以把一些经常查询的数据放到redis缓存起来，不用每次都查询数据库。a.增加一个redis的配置类：12345678910111213141516171819202122232425262728293031323334353637@Configuration@EnableCachingpublic class RedisConfig&#123; @Bean public KeyGenerator redisKeyGenerator()&#123; return new KeyGenerator() &#123; @Override public Object generate(Object target, Method method, Object... params) &#123; StringBuilder sb = new StringBuilder(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125; &#125;; &#125; @Bean public CacheManager cacheManager( @SuppressWarnings("rawtypes") RedisTemplate redisTemplate) &#123; return new RedisCacheManager(redisTemplate); &#125; @Bean public RedisTemplate&lt;String, String&gt; redisTemplate( RedisConnectionFactory factory) &#123; StringRedisTemplate template = new StringRedisTemplate(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; &#125;&#125; b.在需要缓存的service方法上加上注解：1234@Cacheable(value = "userCache")public TUser findById(String id) &#123; return this.userRepository.findOne(id);&#125; 这样，就只有redis没有相应的Key的时候才会查询数据库。 我们看下redis： 图中，redis的key就是你的参数。所以实际使用最好指定Cacheable的key，保证唯一。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决使用maven生成项目很慢]]></title>
    <url>%2F2017%2F08%2F31%2Fresolve-maven-create-projects-too-low%2F</url>
    <content type="text"><![CDATA[如上图标红部分，加上archetypeCatalog=internal，不加这个参数，在maven生成骨架的时候将会非常慢，有时候会直接卡住。 来自网上的解释： archetypeCatalog表示插件使用的archetype元数据，不加这个参数时默认为remote，local，即中央仓库archetype元数据，由于中央仓库的archetype太多了，所以导致很慢，指定internal来表示仅使用内部元数据。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Maven多环境配置打包和部署]]></title>
    <url>%2F2017%2F08%2F31%2Fmaven-multi-env-package-deploy%2F</url>
    <content type="text"><![CDATA[基本每个项目都会有开发环境（本地环境）、开发集成环境、测试环境、预发布环境、正式环境。最少也有开发环境（本地环境）、测试环境、生产环境3个环境，每个环境的配置是不一样的，如果每次打包都手动修改配置文件，工作量大且容易出错。所以这个时候就可以考虑使用maven的profiles来实现多环境配置的打包。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;profiles&gt; &lt;profile&gt; &lt;!-- 本地开发环境 --&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;development&lt;/profiles.active&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 测试环境 --&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;test&lt;/profiles.active&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;!-- 生产环境 --&gt; &lt;id&gt;prd&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;production&lt;/profiles.active&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; &lt;build&gt; &lt;finalName&gt;hhly-common-$&#123;project.version&#125;-$&#123;profiles.active&#125;&lt;/finalName&gt; &lt;!--最终生成的文件名--&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;!-- 资源根目录排除各环境的配置，使用单独的资源目录来指定 --&gt; &lt;excludes&gt; &lt;exclude&gt;test/*&lt;/exclude&gt; &lt;exclude&gt;production/*&lt;/exclude&gt; &lt;exclude&gt;development/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/$&#123;profiles.active&#125;&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- 编译插件 --&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!--&lt;outputDirectory&gt;/target/classes&lt;/outputDirectory&gt; &lt;testOutputDirectory&gt;/target/test-classes&lt;/testOutputDirectory&gt;--&gt;&lt;/build&gt; 如上，默认开发环境的profile是active的，也就是你执行mvn:compile,mvn:install,mvn:package等都是使用的开发环境的配置文件。如果要打其他环境，比如测试环境的包，可以这样mvn package -P test.注意：每次打包前建议先执行clean，否则会使用之前打包的配置文件。mvn clean package -P test. 那如果要自动部署到tomcat，可以增加一个plugin.1234567891011121314&lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;url&gt;$&#123;deploy.url&#125;&lt;/url&gt; &lt;server&gt;tomcat&lt;/server&gt; &lt;path&gt;$&#123;webname&#125;&lt;/path&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;tomcat&lt;/password&gt; &lt;update&gt;true&lt;/update&gt; &lt;/configuration&gt;&lt;/plugin&gt; profile这样配置：123456789101112&lt;profile&gt; &lt;!-- 本地开发环境 --&gt; &lt;id&gt;development&lt;/id&gt; &lt;properties&gt; &lt;profiles.active&gt;development&lt;/profiles.active&gt; &lt;deploy.url&gt;http://localhost:8080/manager/text&lt;/deploy.url&gt; &lt;webname&gt;/basketball_manage&lt;/webname&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt;&lt;/profile&gt; &lt;deploy.url&gt;中后面的/manager/text不能变，端口就看你打开了哪个tomcat。执行mvn tomcat7:deploy 或者mvn tomcat7:redeploy部署到tomcat。注意：执行部署命令前要将tomcat打开，这样就会将工程自动部署到tomcat。如上其他环境也一样，比如测试环境的tomcat，你在开发环境也是可以自动部署过去的。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用maven构建多模块工程]]></title>
    <url>%2F2017%2F08%2F31%2Fmaven-multi-modules-project%2F</url>
    <content type="text"><![CDATA[一、使用maven构建多模块工程1、随便创建一个maven工程（quickstart/webapp）都可以，创建完毕后将pom.xml中type改为pom。如图： pom 2、新建子模块，父模块为刚刚创建的maven工程。如图我这里创建了4个模块，如图：父工程的pom.xml如图： 二、多模块合并打包比如上面architecture1-customermgr和architecture1-goodsmgr位war类型，现在将这2个模块合并打包到architecture1-web中。在architecture1-web的pom文件中增加2处：1、增加2个模块的依赖 注意：type=war 2、在build plugin中增加overlays 3、执行父工程的maven install就可以生成了。 注意：如果多个war包存在路径相同且同名的文件，总的会覆盖分支的；如果总的没有，那么看合并的顺序，留下第一个的文件。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea远程连接Tomcat调试]]></title>
    <url>%2F2017%2F08%2F31%2Fidea-remote-tomcat-debug%2F</url>
    <content type="text"><![CDATA[这里以Windows为例1、Tomcat配置a.打开catalina.bat，找到set JPDA_ADDRESS=8000，修改为其他端口，比如19876。b.调试模式启动tomcat，cmd窗口执行catalina jpda start，启动后可以看到：2、idea配置新建一个new tomcat server,修改端口为tomcat中配置的端口， 选择Type为Same file system，必须保证远程tomcat的代码与本地idea一致。 参考：http://blog.csdn.net/xlgen157387/article/details/50268457http://wenku.baidu.com/link?url=kR05WgbdIA-U7sNhxekUGx6fcOVYehpM46mQHXbMRxTUKozOoEm5RqM7BuzaPBYXux4TXjiUiWW28WCIzMo-924v9OCZLWgxqY8rUeoWs8q 远程tomcat出现Debugger failed to attach: handshake failed - connection prematurally closed错误的解决办法：http://blog.csdn.net/mingjie1212/article/details/52440608]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea提交SVN时忽略某些文件或文件夹]]></title>
    <url>%2F2017%2F08%2F31%2Fidea-svn-ignore%2F</url>
    <content type="text"><![CDATA[在Changes试图中，可以看到默认只有一个Default change list。默认SVN提交时使用的就是Default组。 如果想忽略某个文件或文件夹，首先在Changes视图新建一个Changelist，比如截图中的ignore list。 然后再提交SVN时（如第一个图），将不提交SVN的文件Move到另外一个Changelist，如图： 这样Default视图就没有要忽略的文件了，就可以愉快的提交了。一些常见的需要忽略提交的文件：.iml,/target目录。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ngrok将本地Web服务映射到外网]]></title>
    <url>%2F2017%2F08%2F31%2Fngrok-intranet-to-network%2F</url>
    <content type="text"><![CDATA[一条命令解决的外网访问内网问题，本地WEB外网访问、本地开发微信、TCP端口转发。官网地址：https://www.ngrok.cc/ 第一步：开通隧道平台登陆地址：http://www.ngrok.cc/login登录进去后，点开通隧道，选择Y0.00/月。点立即购买如图：如上图，隧道名称随便填，前置域名为tommy，那么生成的域名就是tommy.ngrok.cc。最后2项http验证用户名和密码，在你访问你本地的应用时，会提示你输入用户名和密码，就是这个。 这个是我之前开通的一个隧道，前置域名tommy.ngrok.cc。 第二步：开启隧道1）从官网下载相应平台的客户端，解压缩。2）执行《Sunny-Ngrok启动工具.bat》输入客户端id即可如上图，127.0.0.1:8080已经映射到了http://tommy.ngrok.cc.ngrok.cc。所以如果你本地访问应用的URL是http://127.0.0.1:8080/MySpringMVC，那么现在使用http://tommy.ngrok.cc.ngrok.cc/MySpringMVC/也可以访问了，而且是外网也可以访问的。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fiddler抓取https请求，chrome提示证书无效的解决办法]]></title>
    <url>%2F2017%2F08%2F31%2FFiddler-chrome-ssl%2F</url>
    <content type="text"><![CDATA[https相关的配置已经增加 但用谷歌访问HTTPS网站，提示证书无效！ 解决办法：右键，用管理员身份打开Fiddler就可以了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10使用360WIFI抓手机APP网络请求]]></title>
    <url>%2F2017%2F08%2F31%2FWin10-use-360WIFI-APP%2F</url>
    <content type="text"><![CDATA[下载Fiddlerhttps://www.telerik.com/download/fiddler/fiddler4操作步骤：1.打开Fiddler，Tools-Fiddler Options-Connections，勾选Allow remote computers to connect，端口为8888，保存选项后重启Fiddler；2.在电脑上查看360wifi无线网卡IP地址，运行命令ipconfig /all，查看无线局域网适配器的IP信息，我的是172.27.35.1；3.手机wifi中设置代理为步骤2中的IP地址，端口为步骤1中的端口8888；4.打开应用开始愉快的抓包吧 其实上面的原理就是让手机和PC使用同一网络，并经过Fiddler的代理端口，拦截请求。 Win10需要注意：1）启动Fiddler可能没有创建127.0.0.1:8888的代理，比如你使用了Chrome或Firefox浏览器，需要自行设置。2）不论PC端还是手机端访问应用，Fiddler都没有显示请求。你可能需要关闭防火墙，且设置应用可使用本地代理网络运行。如图： 在win8/win10，从应用商店下载的应用都是在沙箱运行的，没法使用本地代理网络。在Fiddler中，有WinConfig，勾选需要使用本地代理网络的应用，点Save Changes保存设置，这样就可以了。 如果你之前已经安装过Fiddler，上面的试验都不成功，果断卸载重新安装吧。 如果要抓https请求：在https选项中，勾选 然后确定，重启Fiddler。 这里我以Firefox浏览器为例：打开Firefox浏览器，输入127.0.0.1:8888，会显示根证书的下载地址，如图： 点击该连接，设置为受信任的根证书，并且将Firefox代理中的https也勾选上，如图： 对于IPhone，经过上面的设置后，可以捕捉http请求，如果要捕捉https请求，需要安装证书。打开系统自带的浏览器（UC不行），访问127.0.0.1:8888，会出现根证书的下载地址，点击会提示你安装证书，安装后显示“已验证”就OK了。如果显示未验证：安装一个证书生成器，下载地址：http://www.enhanceie.com/dl/FiddlerCertMaker.exe然后重启Fiddler重新导出证书即可。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux使用vi如何跳转到指定行]]></title>
    <url>%2F2017%2F08%2F31%2Flinux-use-vi-to-lines%2F</url>
    <content type="text"><![CDATA[linux使用vi如何跳转到指定行linux vi如何跳转到指定行，就一句话。比如我想跳转到2012行，那么输入冒号，后面接2012，回车。如下面例子1:2012 就这简单。 linux vi如何显示行号：12:set number :set nonumber 参考：linux使用vi如何跳转到指定行]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis发布订阅示例]]></title>
    <url>%2F2017%2F08%2F31%2Fredis-pubsub%2F</url>
    <content type="text"><![CDATA[在redis中可以同时订阅多个频道，有消息发布时redis会发出通知。jedis中提供了JedisPubSub抽象类来提供发布/订阅的机制，在实际应用中需要实现JedisPubSub类。 示例代码： import org.apache.log4j.Logger; import org.springframework.context.ApplicationContext; import org.springframework.context.support.ClassPathXmlApplicationContext; import redis.clients.jedis.Jedis; import redis.clients.jedis.JedisPubSub; import redis.clients.jedis.JedisSentinelPool; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; /** * Redis发布订阅模式Test * @author j.tommy * @date 2016-09-07 10:46. */ public class RedisPubSubTest { public static final Logger logger = Logger.getLogger(RedisPubSubTest.class); public static final String CHANNEL_NAME = "testChannel"; static class Publisher { private Logger logger = Logger.getLogger(Publisher.class); private Jedis jedis; public Publisher(Jedis jedis) { this.jedis = jedis; } public void start() { logger.info("Type your message (quit for terminate)"); try { BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); while (true) { String line = reader.readLine(); if (!"quit".equals(line)) { jedis.publish(RedisPubSubTest.CHANNEL_NAME, line); } else { break; } } } catch (IOException e) { logger.error("IO failure while reading input, e"); } } } static class Subcriber extends JedisPubSub { private Logger logger = Logger.getLogger(Publisher.class); @Override public void onMessage(String channel, String message) { logger.info("Message received.Channel=" + channel + ",message=" + message); } @Override public void onPMessage(String s, String s1, String s2) { } @Override public void onSubscribe(String s, int i) { } @Override public void onUnsubscribe(String s, int i) { } @Override public void onPUnsubscribe(String s, int i) { } @Override public void onPSubscribe(String s, int i) { } } public static void main(String[] args) { ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext_redis.xml"); JedisSentinelPool jedisSentinelPool = ac.getBean(JedisSentinelPool.class); final Jedis subcriberJedis = jedisSentinelPool.getResource(); // 订阅频道 new Thread(new Runnable() { @Override public void run() { try { logger.info("Subscribing to " + CHANNEL_NAME + ",this thread will be blocked."); subcriberJedis.subscribe(new Subcriber(),CHANNEL_NAME); // 会一直阻塞在这一行 logger.info("Subscribing ended. "); // 不会执行这一句。 } catch (Exception e) { logger.error("Subcribe channel failed." ,e); } } }).start(); // 发布信息 Jedis publisherJedis = jedisSentinelPool.getResource(); new Publisher(publisherJedis).start(); } } 参考：http://outofmemory.cn/code-snippet/3866/redis-dingyue-publish-example]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot定时任务]]></title>
    <url>%2F2017%2F08%2F31%2Fspringboot-timetask%2F</url>
    <content type="text"><![CDATA[springboot定时任务参考：http://spring.io/guides/gs/scheduling-tasks/ 创建一个springboot定时任务非常容易，2步完成：1）在启动类（Application）中增加@EnableScheduling；2）定时任务方法增加@Scheduled。 示例：12345678910111213141516171819202122232425262728package com.coding.springboot.demo.task;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.Date;/** * Created by j.tommy on 2015/11/2. * springboot定时任务，参考：http://spring.io/guides/gs/scheduling-tasks/ */@Componentpublic class TaskDemo1 &#123; public static final Logger LOGGER = LoggerFactory.getLogger(TaskDemo1.class); public static final DateFormat DATE_FORMAT = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss"); @Scheduled(fixedRate = 5000) public void task() throws Exception &#123; LOGGER.info("现在时间是：" + DATE_FORMAT.format(new Date())); // 这里抛出一个异常，测试发现任务并不会终止。并不会影响下一次任务的执行 throw new Exception(); // int i = 1/0; &#125; @Scheduled(cron = "0/5 * * * * ?") public void task2() &#123; LOGGER.info("task2 executed." + DATE_FORMAT.format(new Date())); &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring+redis sentinel主从切换]]></title>
    <url>%2F2017%2F08%2F31%2FSpring%2Bredis%20sentinel%20%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[Spring+redis sentinel 主从切换(failover)redis sentinel配置参考：http://www.cnblogs.com/yjmyzz/p/redis-sentinel-sample.htmlredis sentinel与spring的集成参考：http://www.cnblogs.com/yjmyzz/p/integrate-redis-with-spring.htmlredis对象的缓存也参考上面的文章。 sentinel模式的spring文件配置 12345678910111213141516171819202122232425262728293031323334353637383940&lt;context:property-placeholder location="classpath:redis.properties"/&gt;&lt;beans&gt; &lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;"/&gt; &lt;property name="maxTotal" value="$&#123;redis.maxActive&#125;"/&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWait&#125;"/&gt; &lt;property name="testOnBorrow" value="$&#123;redis.testOnBorrow&#125;"/&gt; &lt;/bean&gt; &lt;bean id="jedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="usePool" value="true"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;redis.sentinel.password&#125;"/&gt; &lt;property name="timeout" value="10000"/&gt; &lt;property name="database" value="0"&gt;&lt;/property&gt; &lt;constructor-arg index="0" ref="sentinelConfiguration"/&gt; &lt;constructor-arg index="1" ref="poolConfig"/&gt; &lt;/bean&gt; &lt;bean id="sentinelConfiguration" class="org.springframework.data.redis.connection.RedisSentinelConfiguration"&gt; &lt;property name="master"&gt; &lt;bean class="org.springframework.data.redis.connection.RedisNode"&gt; &lt;property name="name" value="$&#123;redis.sentinel.master&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="sentinels"&gt; &lt;set&gt; &lt;bean class="org.springframework.data.redis.connection.RedisNode"&gt; &lt;constructor-arg name="host" value="$&#123;redis.sentinel1.host&#125;"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="$&#123;redis.sentinel1.port&#125;"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.StringRedisTemplate"&gt; &lt;property name="connectionFactory" ref="jedisConnectionFactory"/&gt; &lt;/bean&gt;&lt;/beans&gt; redis配置文件123456789redis.properties:redis.maxIdle=5redis.maxActive=10redis.maxWait=1000redis.testOnBorrow=trueredis.sentinel.master=mymasterredis.sentinel.password=systemredis.sentinel1.host=192.168.10.237redis.sentinel1.port=26379 注意：上面的端口是sentinel的端口，不是redis实例的端口。 测试代码123456789101112131415@Testpublic void testSentinelBySpring() &#123; ApplicationContext ctx = new ClassPathXmlApplicationContext("applicationContext_redis_sentinel.xml"); StringRedisTemplate redisTemplate = ctx.getBean(StringRedisTemplate.class); Collection&lt;RedisServer&gt; redisServers = redisTemplate.getConnectionFactory().getSentinelConnection().masters(); System.out.println(redisServers); String key = "test"; String value = redisTemplate.opsForValue().get(key); System.out.println(value); redisServers = redisTemplate.getConnectionFactory().getSentinelConnection().masters(); System.out.println(redisServers); redisTemplate.opsForValue().set(key,"New Master..."); value = redisTemplate.opsForValue().get(key); System.out.println(value);&#125; jedisConnFactory中配置的是master的ip和端口，端口不是sentinel的端口，是redis实例的端口（在redis.conf中配置的）。redisSentinelConfiguration的sentinels属性配置的是哨兵，用于监控master，在确认master宕掉后根据一定的算法从哨兵中拿一个提升为master。 说下使用的Jar的版本：spring:3.2.10.RELEASEjedis:2.5.2spring-data-redis:1.4.1.RELEASE可能还依赖其他的一些jar，比如jackson。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring+redis sentinel主从切换]]></title>
    <url>%2F2017%2F08%2F31%2FSpring-redis-sentinel-master-slave%2F</url>
    <content type="text"><![CDATA[Spring+redis sentinel 主从切换(failover)redis sentinel配置参考：http://www.cnblogs.com/yjmyzz/p/redis-sentinel-sample.htmlredis sentinel与spring的集成参考：http://www.cnblogs.com/yjmyzz/p/integrate-redis-with-spring.htmlredis对象的缓存也参考上面的文章。 sentinel模式的spring文件配置 12345678910111213141516171819202122232425262728293031323334353637383940&lt;context:property-placeholder location="classpath:redis.properties"/&gt;&lt;beans&gt; &lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;"/&gt; &lt;property name="maxTotal" value="$&#123;redis.maxActive&#125;"/&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWait&#125;"/&gt; &lt;property name="testOnBorrow" value="$&#123;redis.testOnBorrow&#125;"/&gt; &lt;/bean&gt; &lt;bean id="jedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="usePool" value="true"&gt;&lt;/property&gt; &lt;property name="password" value="$&#123;redis.sentinel.password&#125;"/&gt; &lt;property name="timeout" value="10000"/&gt; &lt;property name="database" value="0"&gt;&lt;/property&gt; &lt;constructor-arg index="0" ref="sentinelConfiguration"/&gt; &lt;constructor-arg index="1" ref="poolConfig"/&gt; &lt;/bean&gt; &lt;bean id="sentinelConfiguration" class="org.springframework.data.redis.connection.RedisSentinelConfiguration"&gt; &lt;property name="master"&gt; &lt;bean class="org.springframework.data.redis.connection.RedisNode"&gt; &lt;property name="name" value="$&#123;redis.sentinel.master&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="sentinels"&gt; &lt;set&gt; &lt;bean class="org.springframework.data.redis.connection.RedisNode"&gt; &lt;constructor-arg name="host" value="$&#123;redis.sentinel1.host&#125;"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="$&#123;redis.sentinel1.port&#125;"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.StringRedisTemplate"&gt; &lt;property name="connectionFactory" ref="jedisConnectionFactory"/&gt; &lt;/bean&gt;&lt;/beans&gt; redis配置文件123456789redis.properties:redis.maxIdle=5redis.maxActive=10redis.maxWait=1000redis.testOnBorrow=trueredis.sentinel.master=mymasterredis.sentinel.password=systemredis.sentinel1.host=192.168.10.237redis.sentinel1.port=26379 注意：上面的端口是sentinel的端口，不是redis实例的端口。 测试代码123456789101112131415@Testpublic void testSentinelBySpring() &#123; ApplicationContext ctx = new ClassPathXmlApplicationContext("applicationContext_redis_sentinel.xml"); StringRedisTemplate redisTemplate = ctx.getBean(StringRedisTemplate.class); Collection&lt;RedisServer&gt; redisServers = redisTemplate.getConnectionFactory().getSentinelConnection().masters(); System.out.println(redisServers); String key = "test"; String value = redisTemplate.opsForValue().get(key); System.out.println(value); redisServers = redisTemplate.getConnectionFactory().getSentinelConnection().masters(); System.out.println(redisServers); redisTemplate.opsForValue().set(key,"New Master..."); value = redisTemplate.opsForValue().get(key); System.out.println(value);&#125; jedisConnFactory中配置的是master的ip和端口，端口不是sentinel的端口，是redis实例的端口（在redis.conf中配置的）。redisSentinelConfiguration的sentinels属性配置的是哨兵，用于监控master，在确认master宕掉后根据一定的算法从哨兵中拿一个提升为master。 说下使用的Jar的版本：spring:3.2.10.RELEASEjedis:2.5.2spring-data-redis:1.4.1.RELEASE可能还依赖其他的一些jar，比如jackson。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activemq集群之master-slave+zookeeper]]></title>
    <url>%2F2017%2F08%2F31%2Factivemq-master-slave-zookeeper%2F</url>
    <content type="text"><![CDATA[参考ActiveMQ的集群方案对比及部署 本文使用的是activemq的master slave集群，俗称高可用，并没有考虑负载均衡。使用Zookeeper来管理各个broker. 由于zookeeper选举原则是2N+1，所以至少要有3个broker。否则会提示“Not enough cluster members when using LevelDB replication”。这样就没法选择Master。 本文的例子是在Windows64位环境。 zookeeper安装下载就不说了，我下载的是zookeeper-3.3.6版本。下载下来后解压缩，然后在conf目录新建zoo.cfg文件，内容如下：123456789101112# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.dataDir=D:/luckystar88/soft/zookeeper-3.3.6/zookeeper-3.3.6/data/1# the port at which the clients will connectclientPort=2181 启动zookeeper执行$zookeeper_home$/bin下的zkServer.cmd即可。 activemq安装下载不多说，我这里使用的是apache-activemq-5.14.2版本。解压缩，新建目录activemqtest，复制到该目录，并重命名为brokerA。 同样的，复制brokerA的副本，并重命名，得到brokerB,brokerC。这样就有3个broker。 activemq各个broker配置brokerA的配置打开brokerA/conf下的activemq.xml文件。 1.找到&lt;broker…，将brokerName设置为一个值，比如broker1. 2.找到下面的代码，并注释掉。123&lt;persistenceAdapter&gt; &lt;kahaDB directory="$&#123;activemq.data&#125;/kahadb"/&gt;&lt;/persistenceAdapter&gt; 3.增加下面的代码123456789101112&lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory="$&#123;activemq.data&#125;/leveldb" replicas="3" bind="tcp://0.0.0.0:0" zkAddress="192.168.33.87:2181" zkPassword="" hostname="192.168.33.87" sync="local_disk" zkPath="/activemq/leveldb-stores/group1" /&gt; &lt;/persistenceAdapter&gt; zkAddress的IP即为安装和打开zookeeper的电脑的IP，port即为zoo.cfg中配置的clientPort。 4.修改transportConnector的端口为61616.1234&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name="openwire" uri="tcp://192.168.33.87:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600"/&gt;&lt;/transportConnectors&gt; 5.修改jetty.xml中的端口为8161.12345&lt;bean id="jettyPort" class="org.apache.activemq.web.WebConsolePort" init-method="start"&gt; &lt;!-- the default port number for the web console --&gt; &lt;property name="host" value="0.0.0.0"/&gt; &lt;property name="port" value="8161"/&gt;&lt;/bean&gt; brokerB的配置修改同brokerA，但transportConnector的端口改为61617，jetty的端口改为8162. brokerC的配置修改同brokerA，但transportConnector的端口改为61618，jetty的端口改为8163. 启动activemq集群为了启动方便，我写了一个bat脚本，即activemqtest目录下的startCluster.bat。内容如下：12345678910d:cd luckystar88/soft/activemqtestcd brokerA/bin/win64start activemq.batcd ../../../brokerB/bin/win64/start activemq.batcd ../../../brokerC/bin/win64/start activemq.bat 双击startCluster.bat，即可启动。（前提是zookeeper要先启动）如上图所示，其中一个broker成为了master，其他2个成为了slave。 java client连接activemq集群配置如下：123456789101112131415161718&lt;bean id="jmsFactory1_node1" class="org.apache.activemq.pool.PooledConnectionFactory" init-method="start" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;!--&lt;property name="brokerURL" value="failover://(tcp://127.0.0.1:61616,tcp://127.0.0.1:61617,tcp://127.0.0.1:61618,tcp://192.168.10.237:61619,tcp://192.168.10.237:61620,tcp://192.168.10.237:61621)"&gt;&lt;/property&gt;--&gt; &lt;property name="brokerURL" value="failover:(tcp://192.168.33.87:61616,tcp://192.168.33.87:61617,tcp://192.168.33.87:61618)" &gt;&lt;/property&gt; &lt;property name="userName" value="admin"&gt;&lt;/property&gt; &lt;property name="password" value="admin"&gt;&lt;/property&gt; &lt;property name="useAsyncSend" value="true"&gt;&lt;/property&gt; &lt;property name="alwaysSessionAsync" value="false"&gt;&lt;/property&gt; &lt;property name="optimizeAcknowledge" value="true"&gt;&lt;/property&gt; &lt;property name="producerWindowSize" value="1024000"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="5"&gt;&lt;/property&gt; &lt;property name="idleTimeout" value="0"&gt;&lt;/property&gt; &lt;property name="expiryTimeout" value="600000"&gt;&lt;/property&gt;&lt;/bean&gt; 消息生产者可以每隔几秒钟发送一条数据到mq，消费者一直监听消息。在发送几条数据后，关闭master的broker，可以发现还是可以继续发送信息，并不会出错。而且http://localhost:8161,http://localhost:8162,http://localhost:8163同一时间只有一个能打开。 注意事项 3个broker的brokerName,zkPath等必须一致。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring结合activemq使用]]></title>
    <url>%2F2017%2F08%2F31%2Fspring-activemq%2F</url>
    <content type="text"><![CDATA[spring结合activemq使用依赖如下：1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt; &lt;version&gt;5.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;xml-apis&lt;/groupId&gt; &lt;artifactId&gt;xml-apis&lt;/artifactId&gt; &lt;version&gt;1.4.01&lt;/version&gt;&lt;/dependency&gt; 发送和接收队列消息的配置：123456789101112131415161718192021 &lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL"&gt; &lt;value&gt;tcp://192.168.10.65:61616&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"&gt;&lt;/property&gt; &lt;!--如果使用jmsTemplate发送时不指定destination，则发送到默认的destination，即这里配置的--&gt; &lt;property name="defaultDestination" ref="destination"&gt;&lt;/property&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"&gt;&lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="destination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg index="0" value="spring-queue"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 发送和接收消息都是通过JmsTemplate类操作的。在JmsTemplate中有defaultDestination属性，表示默认的目的地，可以是队列也可以是Topic。当你配置了默认的destination后，在使用jmsTemplate发送消息不指定destination时就使用默认的destination。 发送消息的代码：123456789101112131415161718192021222324252627282930import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.jms.core.JmsTemplate;import org.springframework.jms.core.MessageCreator;import org.springframework.stereotype.Component;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.Session;import javax.jms.TextMessage;/** * @author j.tommy * @date 2017-04-06 17:59. */@Componentpublic class QueueSendTest &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args) &#123; ApplicationContext ac = new ClassPathXmlApplicationContext("application*.xml"); QueueSendTest qst = ac.getBean(QueueSendTest.class); qst.jmsTemplate.send(new MessageCreator() &#123; @Override public Message createMessage(Session session) throws JMSException &#123; TextMessage msg = session.createTextMessage("Spring msg ==="); return msg; &#125; &#125;); &#125;&#125; 接收消息的代码为：123456789101112131415161718192021import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.jms.core.JmsTemplate;import org.springframework.stereotype.Component;/** * @author j.tommy * @date 2017-04-06 18:02. */@Componentpublic class QueueRecvTest &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args) &#123; ApplicationContext ac = new ClassPathXmlApplicationContext("application*.xml"); QueueRecvTest qrt = ac.getBean(QueueRecvTest.class); String msg = (String) qrt.jmsTemplate.receiveAndConvert(); System.out.println("recv msg : " + msg); &#125;&#125; 先启动发送端，再启动接收端就可以接收到消息了。 发送和接收topic消息123456789101112131415161718192021222324252627&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactory" destroy-method="stop"&gt; &lt;property name="connectionFactory"&gt; &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL"&gt; &lt;value&gt;tcp://192.168.10.65:61616&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name="maxConnections" value="100"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;property name="connectionFactory" ref="jmsFactory"&gt;&lt;/property&gt; &lt;!--如果使用jmsTemplate发送时不指定destination，则发送到默认的destination，即这里配置的--&gt; &lt;property name="defaultDestination" ref="destinationTopic"&gt;&lt;/property&gt; &lt;property name="messageConverter"&gt; &lt;bean class="org.springframework.jms.support.converter.SimpleMessageConverter"&gt;&lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="destinationTopic" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg index="0" value="spring-topic"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean id="jmsContainer" class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="jmsFactory"&gt;&lt;/property&gt; &lt;property name="destination" ref="destinationTopic"&gt;&lt;/property&gt; &lt;property name="messageListener" ref="messageListener"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="messageListener" class="com.hhly.jms.MyMessageListener"&gt;&lt;/bean&gt; 发送端的代码与队列一样。接收端：123456789101112131415161718192021import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageListener;import javax.jms.TextMessage;/** * @author j.tommy * @date 2017-04-07 09:25. */public class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; if (message instanceof TextMessage) &#123; TextMessage tm = (TextMessage) message; try &#123; System.out.println("接收到消息：" + tm.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 启动发送端就可以了。 说明： 在JmsTemplate中配置了defaultDestination属性后，在发送时如果不指定destination将使用默认的。建议在发送时指定Destionation。如图： 最佳实践 最好不要使用failover，使用failover在broker异常时会阻塞住。使用spring的DefaultMessageListenerContainer会自动重连，如图：。failover能够在你配置了多个activemq时自动选择可用的broker，但broker异常会导致线程阻塞。如果一定要使用failover，比如就配置了一个activemq，建议数据放到队列，同时队列设置一定的容量，有专门的线程从队列取数据放入mq。 log4j日志级别不能配置error，否则spring和activemq的日志显示不了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ICEBOX使用示例]]></title>
    <url>%2F2017%2F08%2F31%2Ficebox-usage%2F</url>
    <content type="text"><![CDATA[系统安装ice3.4.1，并配置环境变量； 定义slice文件12345678910[[ "java:package:com.hhly.tel.ice"]]module book &#123; interface OnlineBook &#123; void bookTick(string name,double price,string content); &#125;; interface SMSService &#123; void sendSMS(string name,double price,string content); &#125;;&#125;; 这表示有2个接口，一个OnlineBook，一个SMSService，都位于com.hhly.tel.ice.book下面。 生成JAVA类使用slice2java xx.ice生成 然后将生成的类复制到工程中 上图中圈红的都是ice生成的类。 实现我们自己的逻辑如上图的service下面，是OnlineBook和SMSService的实现，代码如下：12345678910111213141516171819202122232425262728293031323334package com.hhly.tel.ice.book.service;import Ice.Communicator;import Ice.Current;import Ice.ObjectAdapter;import IceBox.Service;import com.hhly.tel.ice.book._OnlineBookDisp;import org.apache.log4j.Logger;/*** @Author j.tommy* @Date 2016/6/19 0019 上午 4:08*/public class ICEBookService extends _OnlineBookDisp implements Service&#123; public static final Logger log = Logger.getLogger(ICEBookService.class); private ObjectAdapter _adapter; @Override public void bookTick(String name, double price, String content, Current __current) &#123; log.info("Call bookTick()...params-&gt;[name=" + name + ",price=" + price + ",content=" + content + "]."); &#125; @Override public void start(String name, Communicator communicator, String[] strings) &#123; // 创建objectAdapter,这里和service同名 _adapter = communicator.createObjectAdapter(name); // 传Serant并激活 Ice.Object object = this; _adapter.add(object,communicator.stringToIdentity(name)); _adapter.activate(); log.info(name + " started."); &#125; @Override public void stop() &#123; log.info(this._adapter.getName() + " stoped."); _adapter.destroy(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334package com.hhly.tel.ice.book.service;import Ice.Communicator;import Ice.Current;import Ice.ObjectAdapter;import IceBox.Service;import com.hhly.tel.ice.book._SMSServiceDisp;import org.apache.log4j.Logger;/*** @Author j.tommy* @Date 2016/6/19 0019 上午 4:08*/public class ICESMSService extends _SMSServiceDisp implements Service&#123; public static final Logger log = Logger.getLogger(ICESMSService.class); private ObjectAdapter _adapter; @Override public void start(String name, Communicator communicator, String[] strings) &#123; // 创建objectAdapter,这里和service同名 _adapter = communicator.createObjectAdapter(name); // 传Serant并激活 Ice.Object object = this; _adapter.add(object,communicator.stringToIdentity(name)); _adapter.activate(); log.info(name + " started."); &#125; @Override public void stop() &#123; log.info(this._adapter.getName() + " stoped."); _adapter.destroy(); &#125; @Override public void sendSMS(String name, double price, String content, Current __current) &#123; log.info("Call sendSMS()...params-&gt;[name=" + name + ",price=" + price + ",content=" + content + "]."); &#125;&#125; icebox的配置文件：1234567891011121314151617181920212223242526272829303132333435363738394041#server properties# icebox实例的名字IceBox.InstanceName=MyAppIceBox 1# =1表示所有的服务使用Icebox中的配置IceBox.InheritProperties=1# =1会在icebox启动完毕后打印MyAppIceBox 1 readyIceBox.PrintServicesReady=MyAppIceBox 1#IceBox的管理组件，使之能够被远程访问，默认关闭，下面将其绑定到本地9999端口IceBox.ServiceManager.Endpoints=tcp -p 8989 -h localhost#performance propertiesIce.ThreadPool.Server.Size=4Ice.ThreadPool.Server.SizeMax=100Ice.ThreadPool.Server.SizeWarn=10Ice.ThreadPool.Client.Size=4Ice.ThreadPool.Client.SizeMax=100Ice.ThreadPool.Client.SizeWarn=40#for system strongerIce.ACM.Client=300Ice.ACM.Server=300#log and trace#表明日志存放在日志文件中，否则会打印到控制台。#Ice.LogFile=iceserv.logIce.PrintStackTraces=1Ice.Trace.Retry=2Ice.Trace.Network=2Ice.Trace.ThreadPool=1Ice.Trace.Locator=2Ice.Warn.Connections=1Ice.Warn.Dispatch=1Ice.Warn.Endpoints=1#service defined beginIceBox.Service.OnlineBook=com.hhly.tel.ice.book.service.ICEBookService prop1=1 prop2=2 prop3=3IceBox.Service.SMSService=com.hhly.tel.ice.book.service.ICESMSServiceOnlineBook.Endpoints=tcp -p 9000 -h localhostSMSService.Endpoints=tcp -p 9001 -h localhost#service defined end#server load orderIceBox.LoadOrder=OnlineBook,SMSService#service share communicatorIceBox.UseSharedCommunicator.OnlineBook=1IceBox.UseSharedCommunicator.SMSService=1 IceBox.Service.name=entry_point [–key=value] [args]各个参数的定义：name定义了service的名字，如上面定了2个Service，一个OnlineBook,一个SMSService.entry_point是service的完整类名[–key=value]将会被作为property属性，用于构造该服务的communicator，用来更加精确的控制每个Ice服务的性能调优，这里也可以使用–Ice.Config=xxx.cfg的方式从具体的配置文件加载参数。IceBox.InheritProperties=1，让所有的ice服务都使用IceBox的配置属性。[args]作为参数传入start()方法的args参数，作为服务端启动初始化参数。 Ice.MessageSizeMax:做大消息包的字节数Ice.Trace.Network=1，开启网络事件相关的日志追踪Ice.Trace.ThreadPool=1，开启线程池事件的日志追踪Ice.Trace.Locator=1，开启Locator对象的日志追踪 IceBox.UseShardedCommunicator.serviceName=1，实现服务本地调用的优化。如上面的OnlineBook和SMSService，都部署在同一个IceBox中，定义他们使用同一个Communicator对象，实现本地调用的优化。 IceBox.LoadOrder=serv1,serv2,serv3，指定服务的加载顺序，如上面的OnlineBook和SMSService。 启动服务，并启动1234567891011package com.hhly.tel.ice.book.client;/** * @Author j.tommy * @Date 2016/6/19 0019 上午 4:33 */public class Server &#123; public static void main(String[] args) &#123; IceBox.Server server = new IceBox.Server(); server.main(new String[]&#123;"--Ice.Config=icebox.properties"&#125;); &#125;&#125; 编写客户端并启动1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.hhly.tel.ice.book.client;import com.hhly.tel.ice.book.*;/*** @Author j.tommy* @Date 2016/6/19 0019 上午 4:27*/public class Client &#123; public static void main(String[] args) &#123; // 调用OnlineBook接口 bookTick(args); // 调用SMSService接口 sendSMS(args); &#125; private static void bookTick(String[] args) &#123; int status = 0; Ice.Communicator ic = null; try &#123; ic = Ice.Util.initialize(args); Ice.ObjectPrx base = ic.stringToProxy("OnlineBook:default -p 9000"); OnlineBookPrx onlineBookPrx = OnlineBookPrxHelper.checkedCast(base); if (onlineBookPrx == null) &#123; throw new Error("Invalid proxy"); &#125; onlineBookPrx.bookTick("ICE权威指南",59,"这是一本介绍ICE的书籍。"); &#125; catch (Error error) &#123; error.printStackTrace(); status = 1; &#125; finally &#123; if (ic != null) &#123; ic.destroy(); &#125;// System.exit(status); &#125; &#125; private static void sendSMS(String[] args) &#123; int status = 0; Ice.Communicator ic = null; try &#123; ic = Ice.Util.initialize(args); Ice.ObjectPrx base = ic.stringToProxy("SMSService:default -p 9001"); SMSServicePrx smsServicePrx = SMSServicePrxHelper.checkedCast(base); if (smsServicePrx == null) &#123; throw new Error("Invalid proxy"); &#125; smsServicePrx.sendSMS("ICE权威指南",59,"这是一本介绍ICE的书籍。"); &#125; catch (Error error) &#123; error.printStackTrace(); status = 1; &#125; finally &#123; if (ic != null) &#123; ic.destroy(); &#125; System.exit(status); &#125; &#125;&#125; ICE Service之间的调用ICESMSService的实现方法修改如下： @Override public void sendSMS(String name, double price, String content, Current __current) { if (name.startsWith("book")) { Ice.ObjectPrx base = _adapter.getCommunicator().stringToProxy("OnlineBook"); OnlineBookPrx onlineBookPrx = OnlineBookPrxHelper.checkedCast(base); if (null != onlineBookPrx) { onlineBookPrx.bookTick(name,price,content); log.info("通过短信购买图书！...params-&gt;[name=" + name + ",price=" + price + ",content=" + content + "]."); } else { throw new Error("Can't find OnlinkBook Service."); } } else { log.info("发送短信成功...params-&gt;[name=" + name + ",price=" + price + ",content=" + content + "]."); } } 上面的代码表明：如果name以book开头，则内部调用OnlineBookService购买图书。否则就是发送短信。 试验：客户端代码： private static void sendSMS(String name,double price,String content,String[] args) { int status = 0; Ice.Communicator ic = null; try { ic = Ice.Util.initialize(args); Ice.ObjectPrx base = ic.stringToProxy("SMSService:default -p 9001"); SMSServicePrx smsServicePrx = SMSServicePrxHelper.checkedCast(base); if (smsServicePrx == null) { throw new Error("Invalid proxy"); } smsServicePrx.sendSMS(name,price,content); } catch (Error error) { error.printStackTrace(); status = 1; } finally { if (ic != null) { ic.destroy(); } // System.exit(status); } } public static void main(String[] args) { // 调用OnlineBook接口 bookTick(args); System.out.println("bookTick(args) Finished"); // 调用SMSService接口 sendSMS("book ICE权威指南",59,"这是一本介绍ICE的书籍。",args); System.out.println("sendSMS() Finished"); // 在SMSService中调用OnlineBookService，演示ICE服务之间的调用 sendSMS("发送短信",59,"这是一本介绍ICE的书籍。",args); System.out.println("Send Message Finished."); }]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>ice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[封装ICE客户端]]></title>
    <url>%2F2017%2F08%2F31%2Fpackage-ice-client%2F</url>
    <content type="text"><![CDATA[来自《ICE权威指南》一书中的Ice的一个工具类。 IceClientUtil.java:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127package com.lucky.interf.util;import Ice.Communicator;import Ice.ObjectPrx;import java.lang.reflect.Method;import java.util.HashMap;import java.util.Locale;import java.util.Map;import java.util.ResourceBundle;import java.util.concurrent.TimeUnit; /** * @Author j.tommy * @Date 2016/7/3 0003 下午 9:50 */ public class IceClientUtil &#123; private static final Map&lt;Class, ObjectPrx&gt; cls2PrxMap = new HashMap&lt;Class, ObjectPrx&gt;(); private static volatile Ice.Communicator ic = null; private static volatile long lastAccessTime = 0L; private static volatile MonitorThread monitorThread; private static int idleTimeoutSeconds = 300; private static final String locatorKey = "--Ice.Default.Locator"; private static String iceLocator = null; // private static final String clientConfigFile = "iceconfig/iceclient.conf"; /** * 获取代理对象 * @param clazz * @return */ public static ObjectPrx getServicePrx(Class clazz) &#123; ObjectPrx prx = cls2PrxMap.get(clazz); if (prx != null) &#123; lastAccessTime = System.currentTimeMillis(); return prx; &#125; prx = createServicePrx(getIceCommunicator(),clazz); cls2PrxMap.put(clazz,prx); lastAccessTime = System.currentTimeMillis(); return prx; &#125; // 创建守护线程，关闭长时间不使用的连接 private static void createMonitorThread() &#123; monitorThread = new MonitorThread(); monitorThread.setDaemon(true); monitorThread.start(); &#125; private static Ice.Communicator getIceCommunicator() &#123; if (ic == null) &#123; synchronized (IceClientUtil.class) &#123; if (ic == null) &#123; if (iceLocator == null) &#123; ResourceBundle rb = ResourceBundle.getBundle("iceclient", Locale.ENGLISH); iceLocator = rb.getString(locatorKey); idleTimeoutSeconds = Integer.parseInt(rb.getString("idleTimeoutSeconds")); String[] initParams = new String[]&#123;locatorKey + "=" + iceLocator&#125;; ic = Ice.Util.initialize(initParams); createMonitorThread(); &#125; // 另外一种创建Ice.Communicator的方式 /*Ice.InitializationData initData = new InitializationData(); initData.properties = Ice.Util.createProperties(); initData.properties.load(clientConfigFile); ic = Ice.Util.initialize(initData);*/ &#125; &#125; &#125; return ic; &#125; /** * 使用反射方式创建ice代理对象 * @param ic * @param clazz * @return */ private static ObjectPrx createServicePrx(Communicator ic, Class clazz) &#123; ObjectPrx prx = null; String className = clazz.getName(); String serviceName = clazz.getSimpleName(); int pos = serviceName.lastIndexOf("Prx"); if (pos &lt;= 0) &#123; throw new IllegalArgumentException("Invalid ObjectPrx class,class name must end with Prx."); &#125; String realServiceName = serviceName.substring(0, pos); try &#123; Ice.ObjectPrx base = ic.stringToProxy(realServiceName); prx = (ObjectPrx) Class.forName(className + "Helper").newInstance(); Method method = prx.getClass().getDeclaredMethod("uncheckedCast",Ice.ObjectPrx.class); prx = (ObjectPrx) method.invoke(prx,base); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; return prx; &#125; static class MonitorThread extends Thread &#123; public void run() &#123; while (!monitorThread.isInterrupted()) &#123; try &#123; TimeUnit.SECONDS.sleep(5); if (lastAccessTime + idleTimeoutSeconds &lt; System.currentTimeMillis()) &#123; closeCommunicator(true); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void closeCommunicator(boolean removeServicesCache) &#123; synchronized (IceClientUtil.class) &#123; if (ic != null) &#123; safeShutdown(); monitorThread.interrupt(); if (removeServicesCache &amp;&amp; !cls2PrxMap.isEmpty()) &#123; cls2PrxMap.clear(); &#125; &#125; &#125; &#125; private void safeShutdown() &#123; try &#123; ic.shutdown(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; ic.destroy(); ic = null; &#125; &#125;&#125; iceclient.properties文件：12--Ice.Default.Locator=DemoGrid/Locator:tcp -h 127.0.0.1 -p 4061:tcp -h 127.0.0.1 -p 4062idleTimeoutSeconds = 300 调用： import com.lucky.interf.generated.CalcServiceIcePrx; import com.lucky.interf.generated.MessageServiceIcePrx; import com.lucky.interf.util.IceClientUtil; /** * @Author j.tommy * @Date 2016/7/2 0002 下午 12:34 */ public class Test { public static void main(String[] args) { MessageServiceIcePrx msip = (MessageServiceIcePrx) IceClientUtil.getServicePrx(MessageServiceIcePrx.class); String result = msip.sendMessage("IceBox msg"); System.out.println("result-&gt;" + result); CalcServiceIcePrx csip = (CalcServiceIcePrx) IceClientUtil.getServicePrx(CalcServiceIcePrx.class); double sum = csip.calc(0.999, 0.001); System.out.println("sum-&gt;" + sum); } }]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>ice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea git操作]]></title>
    <url>%2F2017%2F08%2F31%2Fidea-git%2F</url>
    <content type="text"><![CDATA[这里以git@oschina举例说明。git的pull就相当于svn的update，push就相当于commit。 前提虽然idea集成了git插件，但你仍然需要安装git（windows版本git for windows）。然后在idea的Version Control中选择git.exe的位置。 下面的例子已osc@git为例说明 一、从git仓库checkout项目到idea复制git仓库地址，然后idea中选择VCS-&gt;Check out from Version Control-&gt;Git后面会提示你输入osc@git的用户名和密码，然后就可以checkout下来了。 二、将idea中已有的项目分享到git@osc1 .在osc@git上创建一个仓库，比如：https://git.oschina.net/qincd/readimage.git2 .idea操作没有办法像SVN一样，直接将项目share到远程仓库。需要使用命令行执行git命令。如下：1）选择要share的项目，然后vcs-&gt;Import into Version Control-&gt;Create git repository然后选择你要share的项目。 2)打开命令行，切换到你要share的项目路径，执行下面的命令执行完毕后，就将本地仓库和远程仓库建立了联系。 3）回到idea，执行git-&gt;add命令，然后commit and push就可以了，后面就可以愉快的执行pull/push操作了。注意：执行git的commit只是提交到本地仓库，需要再执行push命令才能提交到远程git仓库 提交代码到远程操作1.执行add操作（右键Git–&gt;Add），将文件添加到版本控制；2.执行commit操作（右键Git-&gt;Commit Directory/File），将文件提交到本地仓库；3.执行push操作（这一步是将本地仓库的变更提交到远程仓库）。如果在第2步，最后点的“Commit”按钮，那么可以通过右键-&gt;Git-&gt;Repository-&gt;Push来执行Push操作。 从远程仓库更新代码右键Git-Repository-Pull即可。 注意：如果有多个分支，注意选择对应的分支更新。 查看提交历史记录右键Git-&gt;Show History。注意：所有pull/push操作都是可以针对某个目录或文件的。 git冲突解决如果本地修改了某个文件，此时从远程仓库更新会提示冲突。解决方法有2种：1.执行commit，然后push操作，这时会提示你有冲突（会弹出一个提示窗口，可以选择Merge），Merge即可； 2.如果代码未开发完，此时还不想提交。可以执行Git-&gt;Repository-Stash Changes（此操作会将你的本地变更保存起来）起一个名字，然后执行pull操作。此时更新操作会成功，然后执行Git-&gt;Repository-Unstash Changes，选择刚刚Stash Changes起的名字，此时会提示代码有冲突。会弹出Merge窗口，执行Merge操作即可。 注意：执行此操作后Merge后的文件只是在本地，需要执行Git Commit&amp;Push来提交到远程仓库。 参考：https://blog.csdn.net/qq_33039699/article/details/82866785 Checkout某个分支/Tag/某次提交1.checkout某个分支一般开发中都会有Master/Develop/feature/fix等等分支，checkout某个分支很简单。首先使用git-&gt;-&gt;Repository-&gt;fetch，将分支更新到本地。在idea右下角显示的是当前的分支，点击当前显示的分支，然后选择当前项目的要切换的分支，选择Checkout即可。 2.checkout某个Tag在idea右下角显示的是当前的分支，点击当前显示的分支，然后点“Checkout Tag or Revision”，然后输入Tag即可。 3.checkout某次提交a. Git-&gt;Show History，找到你想checkout的某次提交；b. 右键，选择“Copy Revision Number”；c. 点击在idea右下角的当前显示的分支，然后选择“Checkout Tag or Revision”，然后粘贴刚刚复制的Revision Number即可。 注意：如果已经checkout了某个分支，比如feature，你切换到其他分支，比如develop，此时想切到feature，那么选择的是“local branch”，然后点“checkout”。 合并分支比如我们在Develop分支开发，在上线后需要将Develop分支合并到Master分支。 1.checkout master分支；2.点击要Merge的项目的Remote Branches，选择要合并的分支（这里是Develop），然后选择“Merge into current”。 创建/搜索/删除Tag创建Tag1.Git-&gt;Show History。2.选择要打tag的某次提交，然后右键New Tag，然后输入Tag的名字。名字最好有意义，可以是版本号。这里只是测试，输入的名字为testtag23.push到远程仓库。项目右键Git-&gt;Repository-Push。注意要勾选“Push Tags”，另外注意一下All和Current Branch的区别。All和Current Branch的区别：也就是说，如果你选择All，不属于当前选择分支的tag也会提交到远程仓库；如果你选择Current Branch，那么就只会提交当前分支的Tag。 搜索Tag在Git-&gt;Show History中，点击查找按钮，然后输入Tag名字即可，回车后即跳转到创建Tag的某次提交记录。 删除Tag1.查找到Tag对应的提交记录；2.右键-&gt;Tag xx-&gt;delete3.在删除本地的Tag后，会有提示框，点击“Delete On Remote”来删除远程参考的Tag。 创建/删除分支创建分支1.Git-&gt;Show History。2.选择要创建分支的某次提交记录。3.右键New branch，然后输入名字。 此时，分支只是在本地创建好了。修改代码，然后提交到远程仓库在远程参考创建分支。 删除分支1.Git-&gt;Show History。2.搜索要删除的分支；3.右键选择Branch XXX -&gt; Delete。此时idea询问是否删除远程的branch，选择是，这样远程参考的分支就删除了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web推送技术之comet4j使用]]></title>
    <url>%2F2017%2F08%2F31%2FWeb-push-comet4j%2F</url>
    <content type="text"><![CDATA[Web推送技术之comet4j使用参考：[comet4j开发指南]、[comet4j使用Demo]、[“服务器推”技术之使用HTTP长轮询的Comet] JAR包为comet4j-tomcat7.jar，可以百度搜索，从CSDN下载。还有一个js文件comet4j.js，同样可以从CSDN下载。使用参考上面2篇文章就OK了，使用还比较简单。comet4j-tomcat7.jar适用tomcat7和tomcat8.0.28，试验tomcat8.5.6报错了。 ClassNotFoundException: org.apache.catalina.comet.CometProcessor 在tomcat_home/lib目录中的catalinar.jar确实没有找到这个类，tomcat8.0.28版本是有的。可以看到消息数量是在变化的，但Network标签并没有产生新的请求，总共就2个请求，一个是刚进入页面时对服务器建立连接，第二个连接则是通信的。也就是说，在建立连接后，一直用的同一个连接进行的通信。 demo参见：云笔记IT Tchnology/性能优化/《Web推送技术之comet4j使用（实践）demo》另外，源代码可以在git@osc查看。 websocket与comet4j性能对比：websocket与comet4j性能对比]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>推送技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot+mybatis分页配置]]></title>
    <url>%2F2017%2F08%2F31%2Fspring-boot-mybatis-pagination%2F</url>
    <content type="text"><![CDATA[mybatis和分页插件的依赖配置：123456789101112&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--mybatis分页插件--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt;&lt;/dependency&gt; application.yml配置：12345mybatis:#mapper-locations: classpath:/mybatis/mysql/*Mapper.xml#type-aliases-package: com.ybf.activity.web.entityconfig-location: classpath:/mybatis/mybatis-config.xmlcheck-config-location: true mybatis-config.xml配置：12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="logImpl" value="LOG4J"/&gt; &lt;/settings&gt; &lt;typeAliases&gt; &lt;typeAlias type="com.ybf.activity.web.entity.Student" alias="Student" /&gt; &lt;/typeAliases&gt; &lt;plugins&gt; &lt;!--mybatis分页插件--&gt; &lt;plugin interceptor="com.github.pagehelper.PageHelper"&gt; &lt;property name="dialect" value="mysql"/&gt; &lt;property name="offsetAsPageNum" value="false"/&gt; &lt;property name="rowBoundsWithCount" value="false"/&gt; &lt;property name="pageSizeZero" value="true"/&gt; &lt;property name="reasonable" value="false"/&gt; &lt;property name="supportMethodsArguments" value="false"/&gt; &lt;property name="returnPageInfo" value="none"/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;mappers&gt; &lt;mapper resource="mybatis/mapper/mysql/StudentMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; spring启动类增加Mapper扫描：12345678910111213141516171819202122/** * Created by Administrator on 2017/7/6. */@SpringBootApplication// Mapper扫描@MapperScan("com.ybf.activity.web.mapper")public class WebApplication extends SpringBootServletInitializer &#123; private final static Logger logger = LoggerFactory.getLogger(WebApplication.class); // 编码过滤器 @Bean Filter characterEncodingFilter() &#123; logger.info("==========初始化编码过滤器================="); CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding("UTF-8"); filter.setForceEncoding(true); return filter; &#125; public static void main(String[] args) &#123; SpringApplication.run(WebApplication.class,args); logger.info("Application [activity-web] started!"); &#125;&#125; Mapper接口：1234public interface StudentMapper extends BaseMapper&#123; Student getById(int id); List&lt;Student&gt; sel();&#125; StudentMapper.xml:1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.ybf.activity.web.mapper.StudentMapper"&gt; &lt;resultMap id="stuMap" type="Student"&gt; &lt;id property="id" column="id" /&gt; &lt;result property="name" column="name" /&gt; &lt;result property="sumScore" column="score_sum" /&gt; &lt;result property="avgScore" column="score_avg" /&gt; &lt;result property="age" column="age" /&gt; &lt;/resultMap&gt; &lt;select id="getById" resultMap="stuMap" resultType="Student"&gt; SELECT * FROM STUDENT a WHERE ID = #&#123;id&#125; &lt;/select&gt; &lt;select id="sel" resultType="Student" resultMap="stuMap"&gt; select * from student a &lt;/select&gt;&lt;/mapper&gt; 用法：在查询之前使用PageHelper.startPage()设置分页。1234567891011121314@Controllerpublic class IndexController &#123; @Autowired private StudentMapper sm; @RequestMapping("/student/page/&#123;pageNo&#125;") @ResponseBody public List&lt;Student&gt; getStduentByPage(@PathVariable int pageNo) &#123; if (pageNo &gt; 0) &#123; PageHelper.startPage(pageNo,3); return sm.selectByCondition(); &#125; return null; &#125;&#125; 注：测试的spring boot版本为1.5.4.RELEASE.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot+mybatis分页配置]]></title>
    <url>%2F2017%2F08%2F31%2Fspring%20boot%20mybatis%2B%E5%88%86%E9%A1%B5%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mybatis和分页插件的依赖配置：123456789101112&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--mybatis分页插件--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt;&lt;/dependency&gt; application.yml配置：12345mybatis:#mapper-locations: classpath:/mybatis/mysql/*Mapper.xml#type-aliases-package: com.ybf.activity.web.entityconfig-location: classpath:/mybatis/mybatis-config.xmlcheck-config-location: true mybatis-config.xml配置：12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="logImpl" value="LOG4J"/&gt; &lt;/settings&gt; &lt;typeAliases&gt; &lt;typeAlias type="com.ybf.activity.web.entity.Student" alias="Student" /&gt; &lt;/typeAliases&gt; &lt;plugins&gt; &lt;!--mybatis分页插件--&gt; &lt;plugin interceptor="com.github.pagehelper.PageHelper"&gt; &lt;property name="dialect" value="mysql"/&gt; &lt;property name="offsetAsPageNum" value="false"/&gt; &lt;property name="rowBoundsWithCount" value="false"/&gt; &lt;property name="pageSizeZero" value="true"/&gt; &lt;property name="reasonable" value="false"/&gt; &lt;property name="supportMethodsArguments" value="false"/&gt; &lt;property name="returnPageInfo" value="none"/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;mappers&gt; &lt;mapper resource="mybatis/mapper/mysql/StudentMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; spring启动类增加Mapper扫描：12345678910111213141516171819202122/** * Created by Administrator on 2017/7/6. */@SpringBootApplication// Mapper扫描@MapperScan("com.ybf.activity.web.mapper")public class WebApplication extends SpringBootServletInitializer &#123; private final static Logger logger = LoggerFactory.getLogger(WebApplication.class); // 编码过滤器 @Bean Filter characterEncodingFilter() &#123; logger.info("==========初始化编码过滤器================="); CharacterEncodingFilter filter = new CharacterEncodingFilter(); filter.setEncoding("UTF-8"); filter.setForceEncoding(true); return filter; &#125; public static void main(String[] args) &#123; SpringApplication.run(WebApplication.class,args); logger.info("Application [activity-web] started!"); &#125;&#125; Mapper接口：1234public interface StudentMapper extends BaseMapper&#123; Student getById(int id); List&lt;Student&gt; sel();&#125; StudentMapper.xml:1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.ybf.activity.web.mapper.StudentMapper"&gt; &lt;resultMap id="stuMap" type="Student"&gt; &lt;id property="id" column="id" /&gt; &lt;result property="name" column="name" /&gt; &lt;result property="sumScore" column="score_sum" /&gt; &lt;result property="avgScore" column="score_avg" /&gt; &lt;result property="age" column="age" /&gt; &lt;/resultMap&gt; &lt;select id="getById" resultMap="stuMap" resultType="Student"&gt; SELECT * FROM STUDENT a WHERE ID = #&#123;id&#125; &lt;/select&gt; &lt;select id="sel" resultType="Student" resultMap="stuMap"&gt; select * from student a &lt;/select&gt;&lt;/mapper&gt; 用法：在查询之前使用PageHelper.startPage()设置分页。1234567891011121314@Controllerpublic class IndexController &#123; @Autowired private StudentMapper sm; @RequestMapping("/student/page/&#123;pageNo&#125;") @ResponseBody public List&lt;Student&gt; getStduentByPage(@PathVariable int pageNo) &#123; if (pageNo &gt; 0) &#123; PageHelper.startPage(pageNo,3); return sm.selectByCondition(); &#125; return null; &#125;&#125; 注：测试的spring boot版本为1.5.4.RELEASE.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot利用swagger构建api文档]]></title>
    <url>%2F2017%2F08%2F31%2Fspringboot-use-swagger-to-build-api-docs%2F</url>
    <content type="text"><![CDATA[前言 Swagger 是一款RESTFUL接口的文档在线自动生成+功能测试功能软件。本文简单介绍了在项目中集成swagger的方法和一些常见问题。如果想深入分析项目源码，了解更多内容，见参考资料。 Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 添加swagger依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt; 添加swagger配置123456789101112131415161718192021@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("com.ybf.activity.web.controller")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("springboot利用swagger构建api文档") .description("简单优雅的restful风格，http://luckystar88.github.io/") .termsOfServiceUrl("http://luckystar88.github.io/") .version("1.0") .build(); &#125;&#125; 注意spring boot的包结构，否则会导致配置无效。示例程序的包结构：com.ybf.activity.web|———————-|config—————————–Swagger2.java———————-Application.java 在接口方法上使用注解添加描述信息123456789101112131415161718@ApiOperation(value = "用户某个用户的信息",notes = "根据用户id获取用户详细信息")@ApiImplicitParam(name = "id",value = "用户id",required = true,dataType = "int",paramType = "path")@RequestMapping(value = "/student/&#123;id&#125;",method = RequestMethod.GET)@ResponseBodypublic Student student(@PathVariable int id) &#123; return studentMapper.getById(id);&#125;@ApiOperation(value = "获取用户信息（分页）",notes = "根据传入的页数获取用户信息")@ApiImplicitParam(name="pageNo",value = "页数",required = true,dataType = "int",paramType = "path")@RequestMapping(value = "/student/page/&#123;pageNo&#125;",method = RequestMethod.GET)@ResponseBodypublic List&lt;Student&gt; selectStudentByPage(@PathVariable int pageNo) &#123; if (pageNo &gt; 0) &#123; PageHelper.startPage(pageNo,3); // 设置分页，参数1=页数，参数2=每页显示条数 &#125; return studentMapper.sel();&#125; 默认会对所有的方法生成API文档，如果某个方法不需要，可以添加@ApiIgnore。 启动SpringBoot程序，浏览器输入:项目上下文路径/swagger-ui.html就可以看到效果。 点击某个请求，可以查看详情：输入参数，点击Try it out按钮可以查看响应。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot利用swagger构建api文档]]></title>
    <url>%2F2017%2F08%2F31%2Fspringboot%E5%88%A9%E7%94%A8swagger%E6%9E%84%E5%BB%BAapi%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[前言 Swagger 是一款RESTFUL接口的文档在线自动生成+功能测试功能软件。本文简单介绍了在项目中集成swagger的方法和一些常见问题。如果想深入分析项目源码，了解更多内容，见参考资料。 Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 添加swagger依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt;&lt;/dependency&gt; 添加swagger配置123456789101112131415161718192021@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("com.ybf.activity.web.controller")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("springboot利用swagger构建api文档") .description("简单优雅的restful风格，http://luckystar88.github.io/") .termsOfServiceUrl("http://luckystar88.github.io/") .version("1.0") .build(); &#125;&#125; 注意spring boot的包结构，否则会导致配置无效。示例程序的包结构：com.ybf.activity.web|———————-|config—————————–Swagger2.java———————-Application.java 在接口方法上使用注解添加描述信息123456789101112131415161718@ApiOperation(value = "用户某个用户的信息",notes = "根据用户id获取用户详细信息")@ApiImplicitParam(name = "id",value = "用户id",required = true,dataType = "int",paramType = "path")@RequestMapping(value = "/student/&#123;id&#125;",method = RequestMethod.GET)@ResponseBodypublic Student student(@PathVariable int id) &#123; return studentMapper.getById(id);&#125;@ApiOperation(value = "获取用户信息（分页）",notes = "根据传入的页数获取用户信息")@ApiImplicitParam(name="pageNo",value = "页数",required = true,dataType = "int",paramType = "path")@RequestMapping(value = "/student/page/&#123;pageNo&#125;",method = RequestMethod.GET)@ResponseBodypublic List&lt;Student&gt; selectStudentByPage(@PathVariable int pageNo) &#123; if (pageNo &gt; 0) &#123; PageHelper.startPage(pageNo,3); // 设置分页，参数1=页数，参数2=每页显示条数 &#125; return studentMapper.sel();&#125; 默认会对所有的方法生成API文档，如果某个方法不需要，可以添加@ApiIgnore。 启动SpringBoot程序，浏览器输入:项目上下文路径/swagger-ui.html就可以看到效果。 点击某个请求，可以查看详情：输入参数，点击Try it out按钮可以查看响应。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS模板引擎art-template]]></title>
    <url>%2F2017%2F08%2F31%2FJS-art-template%2F</url>
    <content type="text"><![CDATA[art-template 是一个简约、超快的模板引擎。它采用作用域预声明的技术来优化模板渲染速度，从而获得接近 JavaScript 极限的运行性能，并且同时支持 NodeJS 和浏览器。 文档地址：https://aui.github.io/art-template/docs/index.html gitHub地址：https://github.com/aui/art-template 使用例子在github的example中有。 通常，在不借助模板引擎Ajax查询数据列表，需要自己手动拼写N多个tr和td。比如：123456789101112131415$.get("$&#123;ctx&#125;/student/list",function(r) &#123; if (r.returncode == 0) &#123; if (r.data) &#123; var t = $('#list tbody').empty(); for (var i=0;i&lt; r.data.length;i++) &#123; var item = r.data[i]; var tr = "&lt;tr&gt;&lt;td&gt;"+ (i+1)+"&lt;/td&gt;&lt;td&gt;" + item.name + "&lt;/td&gt;&lt;td&gt;" + item.age + "&lt;/td&gt;&lt;td&gt;" + item.scoreSum+ "&lt;/td&gt;&lt;td&gt;"+ item.scoreAvg + "&lt;td&gt;&lt;/tr&gt;"; t.append($(tr)); &#125; &#125; &#125; else &#123; layer.alert(r.errmsg); &#125;&#125;); 使用JS模板引起后：123456789101112131415161718192021222324252627282930&lt;script type="text/javascript" src="$&#123;ctx&#125;/asset/js/art-template/template-web.js"&gt;&lt;/script&gt;&lt;script id="template" type="text/html"&gt; &#123;&#123;each data item index&#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123;index+1&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;item['name']&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;item['age']&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;item['score_sum']&#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123;item['score_avg']&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123;/each&#125;&#125;&lt;/script&gt;// 获取模板内容字符串var templateHtml = $('#template').html();// 编译模板var render = template.compile(templateHtml);$('#queryAll').click(function () &#123; $.get("$&#123;ctx&#125;/student/list", function (r) &#123; if (r.returncode == 0) &#123; if (r.data) &#123; // 渲染模板 var html = render(r); $('#list tbody').html(html); &#125; &#125; else &#123; layer.alert(r.errmsg); &#125; &#125;);&#125;);]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle存储过程导出结果到文本文件]]></title>
    <url>%2F2017%2F08%2F30%2FOracle-procedure-to-files%2F</url>
    <content type="text"><![CDATA[前言在存储过程中，我们经常会使用dbms_output来输出一些调试信息到控制台，方便查看。在使用PLSQL DEV的过程中，经常会遇到缓冲区太小的情况，如果你要显示的内容比较多的话。这个时候我们可以使用oracle提供的UTL_FILE包来实现将这些信息输出到一个文本文件中。 操作说明创建一个目录（需要管理员权限）1create or replace directory MY_DIR as 'D:/MY_DIR/'; 注意：这里创建的目录是创建在oracle服务器上，在执行上述SQL后，需要手动建立相关目录，否则使用时会报错。 授权给使用存储过程的用户1grant read,write on directory MY_DIR to hhlydev; 存储过程中使用1234567891011create or replace procedure p_file_test is v_file UTL_FILE.file_type;begin --打开文件 v_file := UTL_FILE.FOPEN('MY_DIR', 'test.txt', 'w'); --写入内容 UTL_FILE.put_line(v_file, '开始写入SQL脚本...'); UTL_FILE.put_line(export_handle, '脚本写入结束...'); --最后关闭文件 UTL_FILE.FCLOSE(export_handle);end;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis安装+Sentinel模式配置]]></title>
    <url>%2F2017%2F08%2F30%2FRedis-Sentinel%2F</url>
    <content type="text"><![CDATA[系统：ubuntu 一、安装redistip:redis这里下载在usr/local/src/安装到usr/local/redis目录 1)进入文件夹usr/local/srccd /usr/local/src 2)下载redis2.8.9.tar.gzwget http://download.redis.io/releases/redis-2.8.9.tar.gz 3)解压缩tar -zxvf redis-2.8.9.tar.gz4)建立一个链接ln -s redis-2.8.9 redis这样使用cd redis就可以进入redis2.8.9这个文件夹了。5)创建文件夹usr/local/redismkdir usr/local/redis 6)安装到usr/local/redis目录make PREFIX=/usr/local/redis/ install 二、sentinel模式配置说明配置：有2台虚拟机，IP分别为192.168.25.129,192.168.25.130192.168.25.129配置:6379:主服务器6380:从服务器 192.168.25.130配置：6379:从服务器6380:从服务器也就是192.168.25.129的6379端口作为主服务器，其他几个作为从服务器。 2个redis实例分别有2个哨兵监控master。 在usr/local/src/redis中创建目录conf将redis.conf和sentinel.conf复制进去。mkdir confcp redis.conf ./confcp sentinel.conf ./conf redis.conf重命名为redis6379.conf（或者上面复制的时候使用cp redis.conf ./conf/redis6379.conf）mv redis.conf redis6379.conf redis6379.conf改动如下：只要修改如下几行pidfile /var/run/redis_6379.pidport 6379logfile /var/log/redis_6379.logdbfilename dump_6379.rdb重新复制一份重命名为redis6380.conf，改动同redis6379.conf，将相应的6379改成6380即可。 sentinel.conf删除全部内容，粘贴如下内容：port 26379dir “/home/smith/log/redis/sentinels/26379”sentinel monitor mymaster 192.168.25.12963791sentinel down-after-milliseconds mymaster 30000sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000 192.168.25.130的配置同192.168.25.129。 部署：1）启动192.168.25.129的6379端口；redis-server ../conf/redis6379.conf 2）启动192.168.25.129的6380端口；redis-server ../conf/redis6380.conf 3）将192.168.25.129的638端口作为从服务器；redis-cli -p 6380 slaveof 192.168.25.1296379 4）启动哨兵监控master（在129执行）redis-server ../conf/sentinel.conf –sentinel 5）启动192.168.25.130的6379端口；redis-server ../conf/redis6379.conf 6）启动192.168.25.130的6380端口；redis-server ../conf/redis6380.conf 6）将192.168.25.130的6379端口设置为从服务器；redis-cli -p 6379 slaveof 192.168.25.1296379 7）将192.168.25.130的6380端口设置为从服务器；redis-cli -p 6380 slaveof 192.168.25.1296379 8）启动哨兵监控master（在130执行）redis-server ../conf/sentinel.conf –sentinel 查看master有几个从服务器在master机器执行如下命令：redis-cli -p 6379 info replication显示如下：可以看到有3个从服务器。哨兵监控信息显示如下：模拟master故障在192.168.25.129执行：redis-cli -p 6379 shutdown哨兵会从从服务器中选择一台来作为主服务器。原来的主服务器重新启动后，会被当做新服务器的从服务器，如下：参考：http://my.oschina.net/guol/blog/182272]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK搭建手册]]></title>
    <url>%2F2017%2F08%2F30%2FELK-use%2F</url>
    <content type="text"><![CDATA[参考:https://my.oschina.net/itblog/blog/547250?p=2&amp;temp=1503478503046#blog-comments-list head插件安装参考：https://wenku.baidu.com/view/1c61ece6162ded630b1c59eef8c75fbfc77d94e5.html 说明：测试机器为192.168.74.125. 下载软件123elasticsearch-5.5.0.tar.gzlogstash-5.5.2.tar.gzkibana-5.5.0-linux-x86_64.tar.gz 下载地址：https://www.elastic.co/downloads下载速度较慢，可以使用香港网络下载。软件下载的位置：/data/soft 安装1、安装并配置JAVA环境变量1、安装JDKES要求JDK版本至少1.8.从oracle网站下载jdk-8u144-linux-x64.tar.gz。下载完毕后，使用tar –zxvf jdk-8u144-linux-x64.tar.gz –C /usr/java，将JDK解压到/usr/java。解压后得到：/usr/java/jdk1.8.0_144 2、配置环境变量vi /etc/profile，在文件末尾添加：123export JAVA_HOME=/usr/java/jdk1.8.0_144export CLASSPATH=$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jarexport PATH=$&#123;PATH&#125;:$&#123;JAVA_HOME&#125;/bin 然后:wq保存文件。 然后执行source /etc/profile使环境变量生效。最后用java –version来验证一下。 安装ElasticSearch在/data/soft目录，执行tar –zxvf elasticsearch-5.5.0.tar.gz解压缩es。 由于es不能使用root用户运行，所以这里创建用户组bd和用户bd，密码为test123456 步骤如下：123groupadd bduseradd bdpasswd bd 然后输入密码test123456然后将/data/soft/elasticsearch-5.5.0的拥有者改为bd。进入/data/soft，执行sudo chown -R bd:bd ./elasticsearch-5.5.0。 修改es的配置文件123456789101112131415cd $ES_HOME$/config，vi elasticsearch.yml打开配置文件。cluster.name: es-clusterpath.data: /tmp/es/datapath.logs: /tmp/es/logs# ----------------------------------- Memory -----------------------------------## Lock the memory on startup:#bootstrap.memory_lock: falsebootstrap.system_call_filter: falsenetwork.host: 0.0.0.0http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 启动es./bin/elasticsearch &amp; 在浏览器打开：http://192.168.74.125:9200/如果可以看到上图则es安装成功。 安装head插件Es5.0的head插件安装还是很麻烦的，具体可以参考：https://wenku.baidu.com/view/1c61ece6162ded630b1c59eef8c75fbfc77d94e5.html a. 安装git1yum –y install git 安装完毕后，就可以下载Head的源代码了。1git clone git://github.com/mobz/elasticsearch-head.git 注：这里我们仍然下载的/data/soft目录。 b. 安装node由于head插件本质上还是一个nodejs工程，因此需要安装node，使用npm来安装依赖的包。去官网下载nodejs，https://nodejs.org/en/download/ 下载下来的jar包是xz格式的，一般的linux可能不识别，还需要安装xz.1yum -y install xz 然后解压nodejs的安装包:12xz -d node*.tar.xz tar -xvf node*.tar -C /user/node 解压完node的安装文件后，需要配置下环境变量,编辑/etc/profile，添加12export NODE_HOME=/usr/node/node-v6.11.2-linux-x64export PATH=$&#123;PATH&#125;:$&#123;NODE_HOME&#125;/bin 别忘记立即执行以下1source /etc/profile 这个时候可以测试一下node是否生效： 注意：npm安装插件，经常受网络影响，无法下载受网络影响建议安装cnpm（淘宝团队建立的中国镜像）1npm install cnpm -g --registry=https://registry.npm.taobao.org c. 安装gruntgrunt是一个很方便的构建工具，可以进行打包压缩、测试、执行等等的工作，5.0里的head插件就是通过grunt启动的。因此需要安装一下grunt。安装grunt-cli1npm install –g grunt-cli 安装完毕后，检查一下： 注意：如果安装报错，到/usr/node/ node-v6.11.2-linux-x64目录执行上述命令。 d. 修改head源码修改服务器监听地址：目录：elasticsearch-head/Gruntfile.js1234567891011connect: &#123; server: &#123; options: &#123; port:9100, hostname: &apos;*&apos;, base: &apos;.&apos;, keepalive:true &#125; &#125;&#125; 增加hostname属性，设置为* 修改连接地址：目录：elasticsearch-head/_site/app.js修改head的连接地址:1this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://localhost:9200&quot;; 把localhost修改成你es的服务器地址，如:1this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://10.10.10.10:9200&quot;; e. 运行head插件首先运行es。然后在head目录中，执行1npm install 下载以来的包 最后，启动nodejs1grunt server 这个时候访问192.168.74.125:9100就可以访问Head插件了。 安装logstash执行tar –zxvf logstash-5.5.2.tar.gz解压缩logstash。进入config目录，新增log4j_to_es.conf文件。1cd /data/soft/logstash-5.5.2/config 文件内容：1234567891011121314151617181920212223# For detail structure of this file# Set: https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.htmlinput &#123; # For detail config for log4j as input, # See: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-log4j.html log4j &#123; mode =&gt; &quot;server&quot; host =&gt; &quot;0.0.0.0&quot; port =&gt; 4567 &#125;&#125;filter &#123; #Only matched data are send to output.&#125;output &#123; # For detail config for elasticsearch as output, # See: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html elasticsearch &#123; action =&gt; &quot;index&quot; #The operation on ES hosts =&gt; &quot;192.168.74.125:9200&quot; #ElasticSearch host, can be array. index =&gt; &quot;applog&quot; #The index to write data to. &#125;&#125; 这里的配置说明可以参考：https://my.oschina.net/itblog/blog/547250?p=2&amp;temp=1503478503046#blog-comments-list 最后使用./bin/logstash –f ./config/log4j_to_es.conf来启动logstash。 接下来创建一个示例工程，演示使用将log4j日志输出到logstash。新建一个elk-demo的maven工程， Maven依赖：12345&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; Log4j配置如下：123456789101112131415161718log4j.rootLogger=INFO,console# for package com.tommy.elk, log would be sent to socket appender.log4j.logger.com.tommy.elk=DEBUG, socket# appender socketlog4j.appender.socket=org.apache.log4j.net.SocketAppenderlog4j.appender.socket.Port=4567log4j.appender.socket.RemoteHost=192.168.74.125log4j.appender.socket.layout=org.apache.log4j.PatternLayoutlog4j.appender.socket.layout.ConversionPattern=%d [%-5p] [%l] %m%nlog4j.appender.socket.ReconnectionDelay=10000# appender consolelog4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.target=System.outlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=%d [%-5p] [%l] %m%n 可以看到log4j中指定了一个appder为socket，配置了远程的host和端口，这个就是上面在logstash中配置的。 测试代码：123456789101112131415/** * Hello world! * */public class App &#123; private static final Logger LOGGER = Logger.getLogger(App.class); public static void main( String[] args ) throws InterruptedException &#123; LOGGER.info( "Hello World!" ); for (int i = 0; i &lt; 10; i++) &#123; LOGGER.error("测试消息 [" + i + "]."); Thread.sleep(500); &#125; &#125;&#125; 运行一下App.java，控制台输出了log4j日志。 我们刷新一下head插件，在索引TAB中可以看到在数据浏览TAB中可以看到日志信息，点击某一个可以看到详情 安装Kibana执行tar –zxvf kibana-5.5.0-linux-x86_64.tar.gz解压缩kibana。然后进入config目录，编辑kibana配置文件12cd kibana-5.5.0-linux-x86_64vi ./config/kibana.yml 修改下面几项：1234server.port: 5601server.host: “192.168.74.125”elasticsearch.url: http://192.168.74.125:9200kibana.index: “.kibana” 然后启动kinaba.1./bin/kibana 启动后用浏览器打开http://192.168.74.125:5601/ 为了后续使用Kibana，需要配置至少一个Index名字或者Pattern，它用于在分析时确定ES中的Index。这里我输入之前配置的Index名字applog，Kibana会自动加载该Index下doc的field，并自动选择合适的field用于图标中的时间字段： 点击Create后，可以看到左侧增加了配置的Index名字：可以在上面的输入框中输入内容搜索 常见问题 java.lang.RuntimeException: can not run elasticsearch as root使用非root用户执行。创建用户组bdgroupadd bd创建用户bd,属组bduseradd bd -g bd给用户bd设置密码passwd bd(密码为test123456) 已经在/etc/profile中修改了环境变量，将java环境变量设置为了1.8，使用source /etc/profile后root用户下已生效。但切换到非root用户下，仍然显示的之前的java版本。解决：http://blog.csdn.net/newtelcom/article/details/49967919 启动es时，提示无权限java.nio.file.AccessDeniedException: /data/soft/elasticsearch-5.5.0/config/elasticsearch.yml解决：改变elasticsearch文件夹所有者到当前用户sudo chown -R 非root用户组:非root用户 elasticsearch比如问题1中添加的用户组bd和用户bd.sudo chown -R bd:bd elasticsearch 提示数据目录或日志目录无权限java.nio.file.AccessDeniedException: /tmp/es/data/nodes解决：参考3.将/tmp/es目录所有者设置为bd.sudo chown -R bd:bd es seccomp unavailable: requires kernel 3.5+ with CONFIG_SECCOMP and CONFIG_SECCOMP_FILTER compiled in报了一大串错误，其实只是一个警告。解决：使用心得linux版本，就不会出现此类问题了。 max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]max number of threads [1024] for user [lishang] likely too low, increase to at least [2048]解决：切换到root用户，编辑limits.conf 添加类似如下内容vi /etc/security/limits.conf添加如下内容: 1234* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 max number of threads [1024] for user [lish] likely too low, increase to at least [2048]解决：切换到root用户，进入limits.d目录下修改配置文件。vi /etc/security/limits.d/90-nproc.conf修改如下内容：* soft nproc 1024修改为* soft nproc 2048 max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]解决：切换到root用户修改配置sysctl.confvi /etc/sysctl.conf添加下面配置：vm.max_map_count=655360并执行命令：sysctl -p然后，重新启动elasticsearch，即可启动成功。 system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk问题原因：因为Centos6不支持SecComp，而ES默认bootstrap.system_call_filter为true进行检测，所以导致检测失败，失败后直接导致ES不能启动。详见 ：https://github.com/elastic/elasticsearch/issues/22899解决方法：在elasticsearch.yml中配置bootstrap.system_call_filter为false，注意要在Memory下面:bootstrap.memory_lock: falsebootstrap.system_call_filter: false 安装head插件后，head插件访问es提示跨域问题。解决：在$ES_HOME$/config/elasticsearch.yml中增加下面的配置：//增加新的参数，这样head插件可以访问eshttp.cors.enabled: truehttp.cors.allow-origin: “*” logstash5启动方式./bin/logstash -f ./config/log4j_to_es.conf logstash错误：Cannot assign requested address将配置文件中的host改成：0.0.0.0.参考：https://stackoverflow.com/questions/30624467/connect-logstash-1-5-0-with-log4j-of-several-servers]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java通过Cookie实现sso]]></title>
    <url>%2F2017%2F08%2F30%2Fjava-cookie-sso%2F</url>
    <content type="text"><![CDATA[学习的慕课网视频，主要使用Cookie来处理的。 sso的流程： 同域的情况：http://www.aaa.com/demo1/main.actionhttp://www.aaa.com/demo2/main.actionCookie的设置：123Cookie cookie = new Cookie("sso","sso_login");cookie.setPath("/")response.addCookie(cookie); 同父域：http://www.aaa.xx.com/demo1/main.actionhttp://www.bbb.xx.com/demo2/main.actionCookie的设置：123Cookie cookie = new Cookie("sso","sso_login");cookie.setDomain(".xx.com"); // 设置父域可见cookie.setPath("/"); 跨域：http://www.aaa.com/demo1/main.actionhttp://www.bbb.com/demo2/main.action在demo1和demo2工程都有addCookie方法，该方法的代码如下：12345public void addCookie() &#123; Cookie cookie = new Cookie("sso","sso_login"); cookie.setsPath("/"); response.addCookie(cookie);&#125; 这个方法的作用就是向本域中写入cookie. 比如现在要访问demo1，会先跳转到sso server的登录页面，在sso server端登录成功后，会重定向到demo1，在demo1中有一个hiddenUrlList，url为上面demo1和demo2的addCookie：12hidenUrlList.ad(&quot;http://www.aaa.com/demo1/addCookie.action&quot;);hidenUrlList.ad(&quot;http://www.bbb.com/demo2/addCookie.action&quot;); 在demo1向浏览器展示demo1/main.action时，通过一个隐藏的IFrame将hiddenUrlList中的url执行一次，将cookie写入到dmeo1和demo2.123&lt;c:forEach var="item" items="$&#123;hiddenUrlList&#125;"&gt;&lt;iframe src="$&#123;item&#125; width="0px" height="0px" style="display:none" /&gt;&lt;/c:forEach&gt; SSO登录校验逻辑1、 校验是否Cookie有sso;2、 校验cookie名为sso的cookie是否合法。即cookie的value是否是设置的值。实际使用需要考虑cookie的安全性，以及有效期。 本地测试，可以设置hosts文件：123127.0.0.1 www.aaa.com127.0.0.1 www.bbb.com127.0.0.1 www.xx.com]]></content>
      <tags>
        <tag>单点登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS自定义登录页面]]></title>
    <url>%2F2017%2F08%2F30%2FCAS-custom-login-page%2F</url>
    <content type="text"><![CDATA[参考：http://www.imooc.com/article/3720不过参考链接中介绍的并不详细，这里具体说明一下。 /css/下复制cas.css，并重命名为nebula.css.文件内容不变，将#container改成如下：12345678910#container &#123; position: fixed; top: 50%; left: 50%; width:50%; height: 50%; -webkit-transform: translateX(-50%) translateY(-50%); -moz-transform: translateX(-50%) translateY(-50%); -ms-transform: translateX(-50%) translateY(-50%); transform: translateX(-50%) translateY(-50%); &#125; 因为后面会把页眉和页脚的一些东西，包括右侧的banner删除，所以这里的CSS是让内容居中显示。 /WEB-INF/classes下复制cas_views.properties，并重命名为nebula_views.properties.并增加下面的内容（默认是空的）：1234nebulaLoginView.(class)=org.springframework.web.servlet.view.JstlViewnebulaLoginView.url=/WEB-INF/view/jsp/nebula/ui/casLoginView.jspnebulaIndexView.(class)=org.springframework.web.servlet.view.JstlViewnebulaIndexView.url=/WEB-INF/view/jsp/nebula/ui/casIndexView.jsp /WEB-INF/classes下复制cas-theme-default.properties，并重命名为nebula-theme.properties.并修改js和css的路径：12standard.custom.css.file=/css/nebula.csscas.javascript.file=/js/cas.js /WEB-INF/view/jsp下新增文件夹nebula/ui，将/WEB-INF/view/jsp/default/ui下的casLoginView.jsp，casGenericSuccessView.jsp，includes复制到/nebula/ui，并重命名为nebulaLoginView.jsp和nebulaIndexView.jsp. 将/WEB-INF/view/jsp/nebula/ui/nebulaLoginView.jsp中无关的东西都删除，只保留登录的form相关，这个可以慢慢删除调试。nebulaIndexView是登录成功后显示的页面,内容如下：12&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; isELIgnored=&quot;false&quot; %&gt;&lt;div&gt;你好，你在CAS Server已登录成功！&lt;a href=&quot;logout&quot;&gt;退出&lt;/a&gt;&lt;/div&gt; /WEB-INF/webflow/login下复制login-webflow.xml，并重命名为nebula-login-webflow.xml。将viewLoginForm中的casLoginView修改为nebulaLoginView.将viewGenericLoginSuccess中的view改为nebulaIndexView./WEB-INF/webflow/login下复制logout-webflow.xml，并重命名为nebula-logout-webflow.xml。 修改/WEB-INF/cas.properties，将cas.themeResolver.defaultThemeName改成nebula-theme. /WEB-INF/cas-servlet.xml文件修改： viewResolver中cas_views改成nebula_views. internalViewResolver中defaultViewsPathPrefix改成/WEB-INF/view/jsp/nebula/ui/. loginFlowRegistry中，将value改成：/login/nebula-login-webflow.xml. logoutFlowRegistry中，将value改成：/logout/nebula-logout-webflow.xml. 最后的效果：登录的界面： 登录成功的界面： 问题：1、 CAS做了国际化，不过默认是英文的，如果想使用中文显示，可以/WEB-INF/classes下messages.properties重命名为messages_en.properties。同时，将messages_zh_CN.properties重命名为messages.properties. 2、 页面显示乱码的问题。在JSP页面中增加：1&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; isELIgnored=&quot;false&quot; %&gt;]]></content>
      <tags>
        <tag>单点登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS使用]]></title>
    <url>%2F2017%2F08%2F30%2FCAS-use%2F</url>
    <content type="text"><![CDATA[CAS的官方网址是： https://www.apereo.org/projects/cas工程代码网址：https://github.com/Jasig/cas 使用参考：http://www.imooc.com/article/3576 问题1.未认证授权的服务不允许使用CAS来认证您访问的目标应用。解决办法：在/cas-server/WEB-INF/classes/services/HTTPSandIMAPS-10000001.json文件中添加对Http的支持。默认只支持https/imaps.12 &quot;@class&quot; : &quot;org.jasig.cas.services.RegexRegisteredService&quot;,&quot;serviceId&quot; : &quot;^(http|https|imaps)://.*&quot;,]]></content>
      <tags>
        <tag>单点登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cas多系统集成统一认证]]></title>
    <url>%2F2017%2F08%2F30%2Fcas-multi-system%2F</url>
    <content type="text"><![CDATA[参考：http://blog.csdn.net/lifetragedy/article/details/43817903 这里有2个ssoclient工程，代码一样，只是端口不一样。一个端口为8080，一个为8888，cas server的端口为8899.ssoclient使用的springmvc+spring.拿其中一个ssoclient的代码说明。 maven依赖：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293 &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring.version&gt;4.3.1.RELEASE&lt;/spring.version&gt; &lt;jackson.version&gt;2.5.0&lt;/jackson.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jasig.cas.client&lt;/groupId&gt; &lt;artifactId&gt;cas-client-core&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0-alpha-1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring-core.xml:1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.1.xsd"&gt; &lt;!--自动扫描含有@Service将其注入为bean --&gt; &lt;context:component-scan base-package="com.tommy" &gt; &lt;/context:component-scan&gt;&lt;/beans&gt; spring-mvc.xml:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.1.xsd"&gt; &lt;!-- 自动扫描controller包下的所有类，如果@Controller注入为bean --&gt; &lt;context:component-scan base-package="com.tommy.sso.controller" /&gt; &lt;!-- 避免IE执行AJAX时,返回JSON出现下载文件 --&gt; &lt;bean id="mappingJacksonHttpMessageConverter" class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"&gt; &lt;property name="supportedMediaTypes"&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 启动Spring MVC的注解功能，完成请求和注解POJO的映射 --&gt; &lt;bean class="org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter"&gt; &lt;property name="messageConverters"&gt; &lt;list&gt; &lt;!-- json转换器 --&gt; &lt;ref bean="mappingJacksonHttpMessageConverter" /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 对模型视图名称的解析，即在模型视图名称添加前后缀 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView" /&gt; &lt;property name="prefix" value="/views" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt; &lt;!-- 配置多文件上传 --&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="defaultEncoding"&gt; &lt;value&gt;UTF-8&lt;/value&gt; &lt;/property&gt; &lt;property name="maxUploadSize"&gt; &lt;!-- 上传文件大小限制为31M，31*1024*1024 --&gt; &lt;value&gt;32505856&lt;/value&gt; &lt;/property&gt; &lt;property name="maxInMemorySize"&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; web.xml:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:web="http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" id="WebApp_ID" version="2.5"&gt; &lt;display-name&gt;cas-sample-site2&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-core.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 防止spring内存溢出监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.IntrospectorCleanupListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;listener-class&gt;org.jasig.cas.client.session.SingleSignOutHttpSessionListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;filter&gt; &lt;filter-name&gt;CAS Single Sign Out Filter&lt;/filter-name&gt; &lt;filter-class&gt;org.jasig.cas.client.session.SingleSignOutFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS Single Sign Out Filter&lt;/filter-name&gt; &lt;url-pattern&gt;*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;CAS Validation Filter&lt;/filter-name&gt; &lt;filter-class&gt;org.jasig.cas.client.validation.Cas20ProxyReceivingTicketValidationFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;casServerUrlPrefix&lt;/param-name&gt; &lt;param-value&gt;http://www.cas.com:8899/cas/&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;serverName&lt;/param-name&gt; &lt;param-value&gt;http://www.ssoclient.com:8080/&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;useSession&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;redirectAfterValidation&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS Validation Filter&lt;/filter-name&gt; &lt;url-pattern&gt;*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;CAS Filter&lt;/filter-name&gt; &lt;filter-class&gt;org.jasig.cas.client.authentication.AuthenticationFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;casServerLoginUrl&lt;/param-name&gt; &lt;param-value&gt;http://www.cas.com:8899/cas/login&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;serverName&lt;/param-name&gt; &lt;param-value&gt;http://www.ssoclient.com:8080/&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS Filter&lt;/filter-name&gt; &lt;url-pattern&gt;*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;CAS HttpServletRequest Wrapper Filter&lt;/filter-name&gt; &lt;filter-class&gt;org.jasig.cas.client.util.HttpServletRequestWrapperFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS HttpServletRequest Wrapper Filter&lt;/filter-name&gt; &lt;url-pattern&gt;*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;servlet&gt; &lt;description&gt;spring mvc servlet&lt;/description&gt; &lt;servlet-name&gt;rest&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; /WEB-INF/spring-mvc.xml &lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;rest&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 注意：web.xml中cas相关的listener和filter的顺序，不一致可能导致登录或退出有问题。 IndexController.java:123456789101112/** * Created by Administrator on 2017/5/17. */@Controllerpublic class IndexController &#123; @RequestMapping("/index.do") public String showIndex(HttpServletRequest request, HttpServletResponse response) &#123; Principal principal = request.getUserPrincipal(); request.getSession().setAttribute("user", principal.getName()); return "/index"; &#125;&#125; /view/index.jsp:12345678&lt;%@ page contentType="text/html;charset=UTF-8" isELIgnored="false" %&gt;&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;html&gt;&lt;body&gt;$&#123;user&#125;, 你好啊！ &lt;a href="http://www.ssoclient.com:8888/ssoclient/index.do"&gt;访问ssoclient1&lt;/a&gt;&amp;nbsp;&lt;a href="http://www.cas.com:8899/cas/logout"&gt;登出&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 这里2个ssoclient工程在不同的tomcat中，分别部署后。 访问http://www.ssoclient.com:8888/ssoclient/index.do会跳转到cas server的登录页面。 访问http://www.ssoclient.com:8080/ssoclient/index.do会跳转到cas server的登录页面。 在任意一个ssoclient执行登录操作（比如8888的ssoclient），登录成功后。访问8080的ssoclient会发现直接就可以访问，达到登录一个系统，其他系统不用再登录的目的。 在任意一个ssoclient执行退出操作（比如8888的ssoclient），执行后。8888的ssoclient刷新8080的ssoclient会发现会跳转到cas server的登录页面。达到任意一个系统退出，其他系统自动退出的目的。 注意：如果有client的工程与cas server部署在一个tomcat，这个client是不会因为另外一个client执行logout而退出的。注意浏览器缓存，退出操作。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>单点登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Aop+注解实现日志记录]]></title>
    <url>%2F2017%2F08%2F30%2FSpringAop-autowire-log%2F</url>
    <content type="text"><![CDATA[系统业务操作日志记录是每个系统必不可少的一部分，但通常的做法是在每个需要记录日志的地方，调用添加日志的Service方法，这样做主要是显的麻烦。我们可以使用Spring AOP结合注解来实现这一功能。 1、首先定义一个注解类，如下：1234567@Target(value = ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface SysLog &#123; String module() default ""; String desc() default "";&#125; 注解类有2个属性，module是操作的模块，desc为具体记录的日志信息。2、定义切面类：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.reflect.MethodSignature;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.web.context.request.RequestAttributes;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpSession;import java.lang.reflect.Method;/** * Created by Administrator on 2017/6/2. */@Aspectpublic class LogAspect &#123; private final Logger logger = LoggerFactory.getLogger(LogAspect.class); private long timeStart; @Before(value = "execution(* aop.service..*.*(..))") public void doBefore(JoinPoint joinPoint) &#123; timeStart = System.currentTimeMillis(); &#125; @After(value = "execution(* aop.service..*.*(..))") public void doAfter(JoinPoint joinPoint) &#123; long timeEnd = System.currentTimeMillis(); logger.info("方法：" + joinPoint.getTarget().getClass().getSimpleName()+"."+joinPoint.getSignature().getName() + "执行结束。耗时：" + (timeEnd-timeStart)+"ms."); Method proxyMethod = ((MethodSignature)(joinPoint.getSignature())).getMethod(); try &#123; Method sourceMethod = joinPoint.getTarget().getClass().getMethod(proxyMethod.getName(), proxyMethod.getParameterTypes()); SysLog sysLog = sourceMethod.getAnnotation(SysLog.class); if (sysLog != null) &#123; String module = sysLog.module(); String desc = sysLog.desc(); // 这里获取登陆用户信息 /** * 1.获取request信息 * 2.根据request获取session * 3.从session中取出登录用户信息 */ RequestAttributes ra = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes sra = (ServletRequestAttributes)ra; HttpServletRequest request = sra.getRequest(); HttpSession session = request.getSession(); // 从session中获取用户信息 String loginInfo = (String) session.getAttribute("username"); String username = "admin"; logger.info(username + "在[" + module + "]" + desc); &#125; &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3、spring配置文件加入：12&lt;aop:aspectj-autoproxy proxy-target-class="true" /&gt;&lt;bean id="aspectEventLog" class="aop.LogAspect" /&gt; 4、maven依赖：12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.12&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;$&#123;spring.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; 5、测试service：123456789101112@Servicepublic class TestService &#123; @SysLog(module = SysConstant.MODULE_USER_MGR,desc = "添加用户") public void test() &#123; System.out.println("执行了test()方法,username=" + username); try &#123; Thread.sleep((long) (Math.random()*3000L)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果：123执行了test()方法12:39:30,355 INFO main aop.LogAspect:33 - 方法：TestService.test执行结束。耗时：1601ms.12:39:30,356 INFO main aop.LogAspect:44 - admin在[系统管理]添加用户 最后说明一下，这种事没法很具体的，比如某个人添加了某个用户，这种级别做不到。上面拿到httpservletrequest后当然可以拿到所有的请求参数，如果要更具体，就需要在每个请求上携带特定的参数。 比如用户AA添加了用户BB，BB就得放到固定名字的参数中。如果不用注解，就是把模块名和具体的日志信息都放到request中，在切面中从request获取，不过这样就比较麻烦了。 如果只是需要具体到模块，并记录IP之类的，上面的就可以满足了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在线接口文档管理工具（小幺鸡）使用说明]]></title>
    <url>%2F2017%2F08%2F30%2Fapi-docs-xiaoyaoji%2F</url>
    <content type="text"><![CDATA[小幺鸡的地址：http://www.xiaoyaoji.cn/ 几大看点： 在线接口测试； 可视化编辑与分享； 代码开源。可以离线部署。 下面简单介绍下怎么离线安装与使用。 1.下载与安装代码在：http://git.oschina.net/zhoujingjie/apiManager 从http://git.oschina.net/zhoujingjie/apiManager/releases下载最新版本。 解压到tomcat_home/webapps/ROOT目录下 新建MYSQL数据库-编码格式utf8mb4格式，INNODB引擎。 导入sql - SQL文件在doc目录下 修改tomcat_home/webapps/ROOT/WEB-INF/classes/config.properties 的数据库与其他信息 启动tomcat，使用chrome浏览器访问http://localhost:8080 2.基本使用在tomcat中运行起来后，点击首页中的“立即使用”按钮。这个时候会跳转到登陆页面，没有账号就点一下“免费注册”注册一个账号，然后登陆。 登陆进去后，首先创建一个项目。 默认有一个文档，我们点击重命名改成文档说明。 这个就是接口文档的一个简要介绍。示例： 假如现在要添加一个用户登录的接口，那第一步先创建一个文件夹（用户信息接口） 然后在这个文件夹下面创建一个http接口： 示例： 然后点一下右上角的保存，然后点预览文档看下效果：在下面填入相关参数，点“立即运行”就可以调试接口了。 3.多环境支持不同的环境，接口的地址不同。我们可以在全局设置中添加环境变量。进入某个项目后，点击上面的“编辑文档”，然后点“全局设置”，然后点“环境变量”。比如这里配置了2个不同的host和port 在接口地址中，使用$变量名$就可以了。比如： 在演示的地方，可以切换不同的环境： 问题： 提示跨域错误 解决参考：http://www.xiaoyaoji.cn/help.html 注：这里的版本为xiaoyaoji-2.0.1.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在线接口文档管理工具（小幺鸡）使用说明]]></title>
    <url>%2F2017%2F08%2F30%2F%E5%9C%A8%E7%BA%BF%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%EF%BC%88%E5%B0%8F%E5%B9%BA%E9%B8%A1%EF%BC%89%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[小幺鸡的地址：http://www.xiaoyaoji.cn/ 几大看点： 在线接口测试； 可视化编辑与分享； 代码开源。可以离线部署。 下面简单介绍下怎么离线安装与使用。 1.下载与安装代码在：http://git.oschina.net/zhoujingjie/apiManager 从http://git.oschina.net/zhoujingjie/apiManager/releases下载最新版本。 解压到tomcat_home/webapps/ROOT目录下 新建MYSQL数据库-编码格式utf8mb4格式，INNODB引擎。 导入sql - SQL文件在doc目录下 修改tomcat_home/webapps/ROOT/WEB-INF/classes/config.properties 的数据库与其他信息 启动tomcat，使用chrome浏览器访问http://localhost:8080 2.基本使用在tomcat中运行起来后，点击首页中的“立即使用”按钮。这个时候会跳转到登陆页面，没有账号就点一下“免费注册”注册一个账号，然后登陆。 登陆进去后，首先创建一个项目。 默认有一个文档，我们点击重命名改成文档说明。 这个就是接口文档的一个简要介绍。示例： 假如现在要添加一个用户登录的接口，那第一步先创建一个文件夹（用户信息接口） 然后在这个文件夹下面创建一个http接口： 示例： 然后点一下右上角的保存，然后点预览文档看下效果：在下面填入相关参数，点“立即运行”就可以调试接口了。 3.多环境支持不同的环境，接口的地址不同。我们可以在全局设置中添加环境变量。进入某个项目后，点击上面的“编辑文档”，然后点“全局设置”，然后点“环境变量”。比如这里配置了2个不同的host和port 在接口地址中，使用$变量名$就可以了。比如： 在演示的地方，可以切换不同的环境： 问题： 提示跨域错误 解决参考：http://www.xiaoyaoji.cn/help.html 注：这里的版本为xiaoyaoji-2.0.1.]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录密码思路]]></title>
    <url>%2F2017%2F08%2F30%2Fremember-password%2F</url>
    <content type="text"><![CDATA[通常记住密码之后的作用就是用户此次会话失效后，下次登录网站用户直接处于会话活动状态，不必输入用户名密码重新登录，一个很好的用户体验但是处理不好也会存在用户信息泄露的问题。 1、建一张表用来存储md5(username+md5(user_agent))，这个值也就是存储在客户端cookie中的。 表结构12345678910CREATE TABLE `j_user_tokens` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `user_id` int(10) unsigned NOT NULL, `user_agent` varchar(40) NOT NULL, --user_agent MD5值 `token` varchar(40) DEFAULT NULL, --md5(username+md5(user_agent)) `type` varchar(100) DEFAULT NULL, `created` int(10) unsigned DEFAULT NULL, `expires` int(10) unsigned NOT NULL, --过期时间，也就是记住密码多久 PRIMARY KEY (`id`), UNIQUE KEY `uniq_token` (`token`), KEY `fk_user_id` (`user_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 2、用户在某次选择”记住密码“登录时，在登录成功后将目前的信息作为一条新纪录都写入到j_user_tokens中，同时也要将token值写入到cookie名为autologin中。3、用户关闭浏览器或此次session会话失效后；用户再次访问网站时，网站检测获取当前用户对象时首先在session中找寻，其次会进入记住密码机制查找；那么服务器获取到autologin值以及user_agent的值在j_user_tokens中检索匹配，如找到记录则检测是否已过期，过期则提示登录，未过期则获取user_id从而得到user对象，如未匹配到记录则直接提示登录。 这样的处理好处就是，避免将用户个人信息写入到不安全的cookie中去，不必采用username+password进行验证的方式。 注意：这种存储方式避免了存储用户名和密码等关键信息到cookie，但如果获取了用户的cookie，并且使用和用户浏览器一样的userAgent来提交，会导致验证通过。 用户在登录界面选择了“记住密码”，那么登录成功后，关闭浏览器，后续在有效期内再次进入系统无需登录；如果用户在登录系统后，选择了退出系统，则后面再次进入系统需要登录；修改密码，也需要再次登录。 目前的这种设计仍然需要考虑cookie被劫持的情况]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度云盘下载提速]]></title>
    <url>%2F2017%2F08%2F30%2Fbaiduyun-speedup%2F</url>
    <content type="text"><![CDATA[正常情况下，在百度云盘下载文件速度只有几百KB，这是因为百度对下载速度做了限制。如何突破百度的速度限制呢？ 这里使用一款名为Internet Download Manager的软件来实现。百度搜索下载，安装（如果你安装了chrome浏览器，会自动给你安装插件）。安装后打开IDM，会提示你在chrome浏览器的扩展程序里面把IDM的文件访问权限和隐藏模式运行打开。然后重启浏览器，进入pan.baidu.com，下载一个比较大的文件，这是IDM会自动检测到要下载的文件链接，然后点开始下载就可以了。如下图，可以看到速度是3.5M/s。]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[导入铃声到IPhone]]></title>
    <url>%2F2017%2F08%2F30%2Fimport-sings-to-iPhone%2F</url>
    <content type="text"><![CDATA[导入到iPhone的铃声格式是m4r，且40s内。所以如果是其他格式的音乐文件，需要先转成m4r格式。 1，使用酷狗音乐的制作铃声功能建音乐件裁剪成40s内。2，通过itools将铃声转换并导入iPhone。]]></content>
      <categories>
        <category>人文</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ajax请求遇到session失效问题]]></title>
    <url>%2F2017%2F08%2F30%2FAjax-session%2F</url>
    <content type="text"><![CDATA[现在很多菜单的内容都是通过Ajax加载来呈现的，那么如果遇到session失效，该证明处理呢？ 其实方法不难，Ajax请求的请求头X-Requested-With的值为XMLHttpRequest。后台通过request获取到这个请求头，就知道是普通的http请求还是Ajax请求。如果是Ajax请求，那么可以添加一个响应头，然后页面上Ajax完成时，获取请求头，判断做相应处理就可以了。 后端：1234567891011// ajax请求，session超时处理。添加header，页面Ajax设置全局complete处理方法，如果发现请求头包含session timeout，则跳转到登陆页面String requestType = httpRequest.getHeader("X-Requested-With");if(StringUtils.isNotBlank(requestType) &amp;&amp; requestType.equalsIgnoreCase("XMLHttpRequest"))&#123; httpResponse.setHeader("sessionstatus", "timeout"); httpResponse.sendError(518, "session timeout."); return;&#125;// 普通http请求，直接跳转到登陆页面((HttpServletResponse) servletResponse).sendRedirect(((HttpServletRequest) servletRequest).getContextPath() + "/user/toLogin");如上面的代码，在Ajax请求时，添加一个响应头sessionstatus，值为timeout。 前端：123456789101112131415/*** 设置未来(全局)的AJAX请求默认选项* 主要设置了AJAX请求遇到Session过期的情况*/$.ajaxSetup(&#123; type: 'POST', complete: function(xhr,status) &#123; var sessionStatus = xhr.getResponseHeader('sessionstatus'); if(sessionStatus == 'timeout') &#123; layer.confirm('由于您长时间没有操作, session已过期, 请重新登录.',function() &#123; window.location.href = "$&#123;ctx&#125;/"; &#125;); &#125; &#125; &#125;);]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hexo+github搭建个人博客]]></title>
    <url>%2F2017%2F08%2F26%2Fhexo-github-personal-blog%2F</url>
    <content type="text"><![CDATA[hexo+github搭建个人博客 参考：http://www.cnblogs.com/dantefung/p/d8c48ba8030bcab7cfc364d423186fee.html 问题记录问题1：执行npm install时或安装hexo时很久没反应。解决：受网络影响建议安装cnpm（淘宝团队建立的中国镜像）npm install cnpm -g –registry=https://registry.npm.taobao.org后面可以使用cnpm来替代npm.错误2：fatal: could not read Username for ‘https://github.com&#39;: No error解决：修改_config.yml中的部署配置：12345# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:luckystar88/luckystar88.github.io.git 错误3：Please make sure you have the correct access rights解决：参考：http://blog.csdn.net/u014343528/article/details/48787221在git Bash中，输入：1ssh-keygen -t rsa -C &quot;username&quot; (注：username为你git上的用户名) 后面一直回车，直到结束。 参考：http://blog.csdn.net/binyao02123202/article/details/20130891打开生成的id_rsa.pub文件，复制公钥到github的ssh key。 配置完毕后，使用下面的命令测试一下SSH Key1ssh -T git@github.com 后面你使用hexo d直接就提交到github仓库中了。 更多配置hexo站点域名配置：http://www.cnblogs.com/penglei-it/p/hexo_domain_name.html hexo提交搜索引起：http://www.cnblogs.com/tengj/p/5357879.html hexo主题next优化： http://blog.csdn.net/mynamelijun/article/details/52196184 Hexo添加不蒜子和LeanCloud统计无标题文章:http://www.jianshu.com/p/702a7aec4d00注意：LeanCloud中Web安全域名要配置正确，否则可能会导致403禁止访问。next主题使用帮助：http://theme-next.iissnan.com/getting-started.html 加入站点内容搜索功能:本站点使用的是Local Search。加入站点内容搜索功能步骤如下： 安装hexo-generator-searchdb$ npm install hexo-generator-searchdb –save注意：安装时应在站点根目录下 然后将next主题配置文件中的搜索enable设置为true即可。 使用友言评论友言官网：http://www.uyan.cc/进入官网，注册，登陆，获取代码。你需要记下来的是代码中uid=”***”的值，等下要用到。这一步很简单。 修改主题中的youyan_uid为上面的uid即可。 加入百度统计到https://tongji.baidu.com注册，并添加域名后，复制代码中的问号后面的一串id。 修改主题中的baidu_analytics为上面复制的id。 菜单与logo设置在next主题的_config.yml中，找到menu:配置菜单项的配置：技术: /categories/tech || th-list冒号前是菜单项的名字，||前是路径，后面是logo。logo的名字可以在http://fontawesome.dashgame.com/查看。 将博客文章、配置与主题设置备份到osc我的博客文章发布在github，备份在osc。这里说一下怎么将博客文章、配置与主题备份到osc。在博客目录执行git init命令初始化博客与git关联。在博客跟目录执行git remote add origin https://xxx.git(osc上的git路径)1234git pull origin master // 拉取更新git add . // 添加本地文件git commit // 提交到本地git push origin master // 提交到远程分支 但是，这个时候发现主题没有提交上去。到hexo-theme-next中查看已经存在.git文件夹，删除它。（如果你直接在hexo-theme-next执行git add /git commit会提示modified: hexo-theme-next (modified content, untracked content)）。1234git rm -rf --cached themes/hexo-theme-next/git add themes/hexo-theme-next/*git commitgit push origin master 搞定。 后面添加新的文章，只需要在博客根目录执行下面的命令即可：123git add .git commit -m &apos;注释信息&apos;git push origin master 参考：http://www.cnblogs.com/wanqieddy/p/4210767.htmlhttp://www.cnblogs.com/super-d2/p/3341864.html 写文章用到的图片处理使用markdown写文章有一个问题就是图片只支持链接，不能粘贴。我这里使用的是“极简图床”提供的服务，支持上传图片、拖拽、粘贴图片，可以生成外链地址，并可以直接以markdown复制。我这里绑定了七牛云，可以使用10G的免费空间。 Hexo博客收录百度、谷歌、360-基于Next主题分别注册，并添加站点。选择“HTML标签验证”，然后复制标签的content内容。在next主题的配置文件中，添加然后使用hexo g,hexo d重新生成文章，并发布。然后在百度/谷歌/360的站长平台点击“验证”。 去掉底部的“由Hexo强力驱动”修改\themes\hexo-theme-next\layout_partials\footer.swig，去掉文件最后下面截图中的部分。 博客首页文章只显示摘要部分默认首页显示5篇文章，且显示的是全部的内容，导致首页内容太多。解决方法有2种：1.在next主题的_config.yml文件中，找到123auto_excerpt: enable: false length: 150 将enable改成true，length即为摘要显示的长度。不过这样有个缺陷，会导致本来该一起显示的内容可能会被分开。 2.文章中使用&lt;!-- more --&gt;可以在文章显示摘要结束的部分增加&lt;!-- more --&gt;来标识。&lt;!-- more --&gt;之前的内容即为要显示的摘要部分。 Next中推荐的是第2种，这样可以自主控制摘要部分。 github pages开启https支持参考：https://likfe.com/2018/05/03/github-pages-custom-domains-support-https/ 使用hexo-theme-bubuzou主题目前在用的主题是hexo-theme-bubuzou，使用比较简单，使用参考https://github.com/Bulandent/hexo-theme-bubuzou。更新于2017.11 使用hexo s命令不成功提示如下：但是hexo g命令是成功的。 PS：需要执行npm install hexo-server --save，然后再执行hexo s即可。 可能还缺少其他的组件，使用npm audit fix来查看缺少的组件，然后依次安装。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
